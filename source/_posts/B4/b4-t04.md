title: B4-T04
date: 2019-01-16 16:11:23
---

Gestión de la configuración. Gestión de librerías de programas y de medios magnéticos. Controles de cambios y de versiones. Los lenguajes de control de trabajos. Las técnicas y herramientas de operación automática.
======================================================================================================================================================================================================================

Gestión de Librerías de Programas
---------------------------------

Cuando hablamos de librerías nos referimos a conjuntos de programas, rutinas o funciones ya preparadas y a disposición de los programadores durante el desarrollo de aplicaciones. Su practicidad reside en que evitan la reescritura de algoritmos usados con frecuencia, ya que éstos pueden ser incluidos en librerías que posteriormente podrán ser llamadas desde los distintos programas a implementar.

### Gestión de Librerías en C

Propiedades de las librerías en C:

-   Una librería es un archivo que agrupa a otros archivos denominados miembros de la librería.
-   La estructura de las librerías hace posible que puedan extraerse sus miembros.
-   Al agregar archivos a una librería, se introducirá en la misma tanto el contenido de aquellos como su información de gestión (fechas, propietarios, grupos, permisos, etc).

**Librerías Estáticas y Dinámicas**

**Librerías Estáticas**

También denominadas librerías-objeto, son agrupaciones de archivos objeto (.obj) compilados en un solo archivo de extensión **.OBJ** o **.LIB** .

Los modelos de las funciones empleadas en estas librerías, junto con algunas constantes predefinidas y macros que facilitan su uso, constituyen los denominados archivos de cabecera, debido a que suelen ser llamados desde las primeras líneas (cabeceras) de los distintos archivos fuente.

Las librerías estáticas están constituidas por uno o varios archivos **.lib** , **.obj** o **.bpi** junto con uno o varios archivos de cabecera ( **.h** ). Al compilar un programa, el linkador agrega al ejecutable los módulos que incluyen a las funciones utilizadas en el programa, pasando aquellos a formar parte del ejecutable. Esta forma de enlazar las librerías con los programas es la que les da el nombre de estáticas.

**Librerías Dinámicas**

Las librerías de enlazado dinámico (DLL) son muy utilizadas en la programación para SO Windows; sistemas que incluyen multitud de librerías de este tipo en disposición de ser utilizadas por cualquier aplicación.

Aunque las librerías dinámicas se asocian generalmente a la extensión **.DLL** , también pueden estar definidas con extensiones del tipo **.EXE** , **.BPI** , **.DRV** , **.FON** , etc.

La programación de aplicaciones Windows consiste en la concatenación de llamadas a librerías dinámicas.

**Manejo de Librerías**

Para la programación en lenguaje C, el manejo de librerías presenta dos aspectos:

-   La utilización de librerías.
-   La construcción de librerías.

La utilización es segura para cualquier programa, ya que, como mínimo, habrá que hacer uso de alguna librería perteneciente a la Librería Estándar. En cuanto a la construcción, también podría darse en cualquier programa, pero dada la gran cantidad de librerías existentes, lo normal es que sólo se necesite crear una librería cuando el programa a desarrollar sea considerablemente extenso.

Evidentemente, tanto la utilización como la construcción de librerías serán diferentes dependiendo de si se trata de librerías estáticas o dinámicas.

### Librerías de Enlace Dinámico en Windows

Como mencionábamos en un epígrafe anterior, las librerías dinámicas son archivos que contienen funciones y/o recursos que pueden ser requeridos por cualquier aplicación Windows. También indicábamos que podían tener tanto la extensión **.DLL** como extensiones del tipo **.EXE** (ejecutable), **.DRV** (controlador de dispositivo), **.FON** (fuente de Windows), etc. La diferencia entre las librerías cuyo archivo tiene extensión **.DLL** y las creadas sobre archivos **.EXE** , **.DRV** , **.FON** , etc, es que, mientras que las primeras se cargan porque son solicitadas por los programas al SO, el resto se cargan porque aparecen referenciadas (por el propio Windows o por un determinado programa) en archivos de inicialización de Windows.

**Ventajas e Inconvenientes del Empleo de DLL’s**

Ventajas:

-   El contenido de una DLL puede ser usado por cualquier aplicación Windows.
-   La reutilización de las DLL’s implica una reducción en el tamaño de las aplicaciones.
-   Reducción del tiempo de compilación y/o carga de las aplicaciones, debido a la disminución del tamaño de las mismas.
-   Ahorro de espacio en disco.
-   Independencia de las DLL’s respecto de las aplicaciones.

Inconvenientes:

-   Tienen que almacenarse en la carpeta del sistema para poder ser utilizadas.
-   El tiempo que tarda la aplicación en acceder al código que necesita de la DLL es mayor del que emplearía si dicho código formara parte de la propia aplicación.

**Estructura de una DLL de 32 Bits**

Podríamos dividir la DLL en los siguientes elementos:

-   Archivo de cabecera. Conjunto de declaraciones y/o definiciones (de variables, funciones, procedimientos, etc) a usar por la librería.
-   Punto de entrada y salida de la DLL (DllEntryPoint). Función que se ocupa de la carga y descarga de la DLL en la memoria principal.
-   Funciones de la DLL. Aquellas especificadas e implementadas por el programador de la librería.

**Creación de una DLL de 32 Bits**

Para la creación de una DLL podemos usar lenguajes del tipo Visual Basic, Delphi, Visual C++, etc.

Con cualquiera de los lenguajes deberemos crear varios archivos, cada uno de los cuales contendrá un tipo de elemento útil para la construcción de la librería. Por ejemplo, si empleásemos Visual C++, deberíamos crear:

-   Un archivo con extensión .c que contendrá el código fuente de las funciones de la librería.
-   Un archivo con extensión .def que contendrá la información necesaria para el linkador.
-   Dos archivos con extensión .h que será los archivos de cabecera del archivo fuente (estos sólo serán necesarios para crear un programa que utilice la DLL, pero no para la creación de la DLL en sí).

**Compilación y Linkado de la Librería**

Tras la compilación de los archivos anteriores, el compilador generará un archivo **.lib** . Después del linkado, se creará un archivo **.dll** (esta sería la librería en sí).

El acceso a esta DLL podrá hacerse mediante dos tipos de llamadas:

**Llamada Estática**

Este tipo de llamada va a utilizar el archivo creado por el compilador ( **.lib** ).

Con este método, el enlace entre el programa y los recursos de la DLL tiene lugar durante el linkado del programa. Es decir, será el linkador quien, utilizando los archivos objeto ( **.obj** ), los archivos librerías ( **.lib** ) y los archivos de recursos compilados (.res), cree la aplicación Windows ( **.exe** ).

Con este proceso, el código de la librería queda incluido en el ejecutable.

Ventajas:

-   La librería se carga junto con el ejecutable (la contiene).
-   El enlace tiene lugar en tiempo de compilación.
-   Las funciones de la librería pueden ser utilizadas como funciones internas de la aplicación.

Inconvenientes:

-   La aplicación almacena en su interior el código de la librería, lo que hace que su tamaño sea mayor.
-   La librería tiene que incluirse en cada aplicación que la necesite.
-   El objetivo de la reutilización sólo se cumple en parte.
-   La memoria principal contiene a la librería durante todo el tiempo de ejecución de la aplicación.
-   La librería y la aplicación tienen una dependencia total.

**Llamada Dinámica**

La llamada dinámica emplea el archivo creado por el linkador ( **.dll** ).

El enlace dinámico, como su nombre indica, se producirá en tiempo de ejecución; es decir, la librería se cargará en memoria cuando la aplicación la requiera al sistema. Este proceso utilizará las funciones LoadLibrary y FreeLibrary para la carga y descarga, respectivamente, de la dll en la memoria principal.

Ventajas:

-   La aplicación no almacena junto con su código a la librería, lo que reduce el tamaño de la aplicación (la librería se almacena en un archivo aparte).
-   Ninguna aplicación que utilice a la librería deberá incluirla en su código.
-   Se utilizan los beneficios de la reutilización en su totalidad.
-   La librería sólo se carga en la memoria principal cuando va a utilizarse. Cuando deja de utilizarse podrá descargarse de la memoria.
-   La librería y la aplicación son independientes.

Inconvenientes:

-   Necesidad de solicitar al SO la carga de la librería.
-   El enlace se produce en tiempo de ejecución, hecho que dificulta la manipulación de la librería.
-   Las funciones de la librería deben ser llamadas mediante punteros.

Gestión de Medios Magnéticos
----------------------------

### Discos Magnéticos

**Propiedades de los Discos Magnéticos**

Un disco magnético (rígido o flexible) consiste en un soporte de almacenamiento externo que complementa a la memoria principal (RAM) de una computadora.

Sus propiedades más significativas son:

-   Capacidad de almacenamiento masivo de información en un espacio muy reducido, con el consiguiente bajo coste relativo por byte almacenado. El cliente realiza una llamada a un servicio como si fuera local.
-   El memoria no volátil, ya que mantiene la información almacenada aún a falta de suministro eléctrico.
-   Proporciona acceso casi directo al lugar donde se encuentra el bloque de datos a leer o escribir.
-   La información almacenada en un disco se agrupa en archivos o ficheros (files) identificables por su nombre.

Actualmente, la mayoría de procesos de E/S de datos utilizan en su origen o destino los discos magnéticos:

-   La inmensa mayoría de las aplicaciones se encuentran almacenadas en disco (en forma de archivos ‘ejecutables’). Cuando van a utilizarse estas aplicaciones, se copian (en parte) en la memoria principal y son ejecutadas desde ésta.
-   Después de procesar los datos que se encuentran en la memoria principal, los resultados de este proceso se almacenarán en disco.

Por último, otra característica a indicar sobre los discos magnéticos (los ‘discos duros’ en este caso), es que se pueden utilizar como memoria virtual; es decir, como una extensión de la memoria principal del ordenador.

**Estructura Física de los Discos Magnéticos**

Físicamente, los discos magnéticos están fabricados con: mylard en el caso de los discos flexibles y aluminio o cristal cerámico en el caso de los discos rígidos.

La estructura física de un disco la forman unas superficies magnéticas denominadas **caras** , cada una de las cuales se divide en anillos concéntricos que constituyen las **pistas** , que a su vez agrupan a los **sectores** (unidades mínimas de almacenamiento cuya capacidad habitual suele ser de 512 bytes de información).

El proceso de grabación de los discos se logra, al igual que en un grabador de audio, por la acción de un campo magnético de polaridad reversible (N-S ó S-N), que imanta la pista al actuar sobre ella. Para este proceso, existe una cabeza para cada cara del disco. Los brazos que soportan a las cabezas se mueven juntos; es decir, que si la cabeza de la cara superior está sobre una determinada pista, la de la cara inferior se encontrará situada en la misma pista.

La lectura la realizan las mismas cabezas, mediante un proceso inverso al de grabación, a través del cual detectarán los campos magnéticos existentes a lo largo de la pista accedida.

En el proceso, tanto de grabación como de lectura, sólo podrá encontrarse activa una única cabeza de las existentes en el medio magnético (dos en los discos flexibles y múltiples en los rígidos).

En las propiedades indicadas en el epígrafe anterior se hacía referencia al acceso casi directo de los discos magnéticos. Conociendo ya la estructura física de estos discos podemos indicar que lo de directo se refiere a la forma de acceso a las pistas y lo de casi hace referencia a la forma de acceso a los sectores una vez situados en la pista correspondiente (este último es un acceso secuencial cuyo tiempo es tan reducido que se considera despreciable). Para esta operación de localización de un sector concreto dentro del disco se emplea lo que se conoce como su dirección o CHS (número de cilindro, número de cabeza, y número de sector).

**Importancia del concepto de cilindro**

El hecho de que un disco rígido sea en realidad una agrupación de discos (o platos) cada uno de los cuales dispone de dos caras, además de duplicar la capacidad de almacenamiento, permite la lectura o escritura del doble de datos antes de desplazar el cabezal a otra pista, accediendo a una cara y luego a la contraria. De esto surge el concepto de cilindro que no es más que el conjunto de pistas que se sitúan bajo las cabezas de lectura/escritura en un momento determinado (o conjunto de pistas de un disco que tienen el mismo radio). Este concepto también es aplicable a los discos flexibles, aunque, al disponer estos de dos caras únicamente, se suele asociar a los discos rígidos porque en estos el concepto de cilindro es gráficamente más evidente.

De lo anterior se deduce que la mejor forma de graba la información sobre los discos magnéticos es cilindro a cilindro acelerando con ello el proceso de escritura/lectura al minimiza los movimientos de los cabezales en búsqueda de las pistas.

El número de cilindros de un disco, por tanto, se corresponderá con el número de posiciones en las que pueden situarse los cabezales; enumerándose aquellos desde 0 (el más exterior) en forma creciente hacia el interior, correspondiendo el número mayor al más interno.

![](https://gsitic.files.wordpress.com/2018/02/cilindros_hd.png?w=825)

**Posicionamiento, Latencia y Acceso en un Disco Rígido o Flexible**

El acceso a un sector situado en una determinada cara del disco, pasa por posicionar el cabezal sobre el cilindro donde se encuentra la pista que contiene el sector, y, posteriormente, esperar a que, mediante el giro del disco, el sector deseado se sitúe debajo de la cabeza. En esta operación intervienen dos tiempos:

-   **Posicionamiento** . Tiempo necesario para que el brazo con la cabeza correspondiente se coloque directamente sobre el cilindro seleccionado (pocos milisegundos).
-   **Latencia (demora rotacional)** . Tiempo necesario para que el sector a localizar se sitúe bajo la cabeza lectora/escritora (en promedio es el tiempo de media vuelta).

El tiempo de acceso resulta pues, la suma de los anteriores, o lo que sería igual, el tiempo que transcurre desde que la controladora envía la orden al cabezal de posicionarse sobre un cilindro, hasta que la cabeza correspondiente accede al sector buscado.

![](https://gsitic.files.wordpress.com/2018/02/tiempo_acceso.png?w=825)

**Estructura Lógica de los Discos Magnéticos**

Desde el punto de vista de la estructura lógica de un disco duro, podríamos dividirlo en:

-   **Sector de arranque (Master Boot Record)** . Es el primer sector del disco (0, 0, 0), y en él se encuentra la tabla de particiones y un pequeño programa de inicialización. Este programa se ejecuta al encender la computadora, y su función es leer la tabla de particiones y ceder el control a la partición primaria activa.
-   **Espacio particionado** . Zona del disco que contiene las particiones. Una partición es cada una de las divisiones de tamaño fijo de un disco que se asocia a una unidad lógica (C:, D:, etc, en el caso de los SO Windows). Cada partición ocupa un bloque de cilindros contiguos del disco duro, pudiendo establecerse distintos sistemas de archivos (FAT, NTFS, …) para las distintas particiones posibles.
-   **Espacio NO particionado.** Se trata de la zona de disco que no ha sido particionada y que, por lo tanto, no puede ser utilizada.

La tabla de particiones del disco duro puede contener hasta 4 entradas, lo que determina el número máximo de particiones primarias que se pueden crear en el disco. No obstante, este límite de particiones puede superarse empleando una de las entradas para almacenar una partición extendida (tendríamos 3 primarias y 1 extendida). La partición extendida podrá contener tantas unidades lógicas como necesitemos.

La principal diferencia entre las particiones primarias y las extendidas es que, mientras que las primeras son arrancables y pueden ser utilizadas para contener a los SO, las extendidas no son arrancables y se utilizan normalmente para almacenar datos. Además, de entre las distintas particiones primarias, habrá que indicar cuál es la activa, es decir, la verdaderamente arrancable.

Visto lo anterior, lo primero que hay que hacer con un disco duro antes de su utilización es:

-   **Crear las particiones** (utilizando herramientas del tipo FDISK).
-   **Formatear las particiones creadas** . Este proceso consiste en la creación de la estructura que permita el almacenamiento de información utilizando un determinado sistema de archivos.

En el sistema de archivos FAT (MS-DOS y sistemas Windows), la estructura lógica de una partición la forman: el sector de arranque, varias copias de la tabla de asignación de archivos, el directorio raíz y el área de datos. La FAT (tabla de asignación de archivos) es el índice del disco. En ella se indican los clusters (unidades de asignación) que utiliza cada archivo, así como los libres y los defectuosos.

La estructura lógica de una partición utilizada por un sistema UNIX tradicional está constituida: un bloque de arranque, un superbloque (contiene el número de inodos, el número de bloques, etc), un vector de inodos (similar a la FAT anterior) y los bloques de datos.

**Herramientas para la Gestión de Discos Magnéticos**

Considerando como herramientas de gestión las expuestas en el punto anterior (herramientas de particionado y formateo), en este punto vamos a centrarnos en otras herramientas no tan esenciales como aquellas, pero sí bastante comunes en la gestión de discos magnéticos:

-   **Comprobador de errores** . Su misión es analizar el contenido del disco en búsqueda de incoherencias en el sistema de archivos. Si, por ejemplo, en un sistema FAT existen dos archivos que apuntan al mismo contenido aparecerá un error de vínculos cruzados o si aparecen datos no asociados a ningún archivo se indicará el error de cadenas perdidas. Comprobadores de errores usuales son: chkdsk /f en MS-DOS, ScanDisk en Windows y fsck en UNIX.
-   **Desfragmentador de disco** . Esta herramienta busca la agrupación física (sobre el disco) de toda la información concerniente a un mismo archivo, con el fin de acelerar la lectura de datos. La fragmentación se produce por la creación, modificación y eliminación de archivos. El sistema de archivos de UNIX no precisa de desfragmentador debido a que su velocidad de trabajo no se degrada con la creación, modificación y eliminación de archivos.
-   **Compresor de datos** . Se trata de un método que busca maximizar la capacidad de las particiones mediante la compresión de la información que contienen. No obstante, esta metodología ralentiza el funcionamiento general del SO, debido a que deben ejecutarse continuamente algoritmos de compresión/descompresión. Además, tiene como inconveniente la dependencia de la información del programa de compresión, circunstancia que podría provocar problemas de incompatibilidad d futuros en caso de producirse errores.

Normalmente, resulta más eficaz la compresión de ficheros de forma independiente (en lugar de particiones completas).

Los SO actuales incorporan sus propios métodos de compresión/descompresión (en UNIX: gzip -> para archivos independientes, tar -> para árboles de archivos). Además, existen herramientas ajenas a los SO para realizar estas operaciones (WinZip, WinRAR, IsoBuster, …)

-   **Copias de seguridad** . La realización de copias de seguridad del contenido del disco en otro medio de almacenamiento, es un método para garantizar la recuperación de datos destruidos por errores humanos, de situaciones imprevistas o de hardware.

**Sistemas RAID (Redundant Array Of Independent Or Inexpensive Disks)**

Los sistemas de matriz de discos independientes (baratos) redundantes son utilizados para el control de errores en los discos. Emplean varios discos para evitar (o minimizar) la pérdida de información en caso de que se produzca algún error. La redundancia hace referencia a la información extra que no sería necesaria si no se produjesen errores.

La gestión de los sistemas RAID no es accesible por el usuario, pudiendo ser gestionada por hardware (tarjetas RAID) o por software (SO). como suele ocurrir, el método más eficiente (pero más costoso económicamente) es el que utiliza tarjetas hardware, debido a que desocupa a la CPU de las tareas RAID.

A continuación se enumeran los niveles RAID más habituales:

-   **RAID 0** (disk striping, discos en bandas). En este nivel, la información se distribuye entre todos los discos que forman el conjunto RAID, proporcionando una mayor velocidad en las transferencias debido al trabajo conjunto de todos los discos para acceder a un mismo archivo. No obstante, si falla alguno de los discos perderemos toda la información. La implementación de RAID 0 precisa de 2 discos como mínimo.
-   **RAID 1** (disk mirroring, discos en espejo). Basado en el empleo de discos para duplicar la información. Con este método, cada vez que se escriba en un disco, deberá grabarse la información de su disco copia para mantener la coherencia. A diferencia del método anterior, si en éste falla un disco, el sistema podrá continuar funcionando sin detenerse. Es habitual implementar RAID 1 con 2 discos. Este sistema permite una capacidad de almacenamiento igual a la mitad de la capacidad total de los discos de que disponemos. Pueden combinarse RAID 0 y RAID 1 para formar el sistema RAID 10. Con RAID 10, la información se distribuye en bandas por varios discos y cada disco se duplica, lo que requiere un número par de discos (4, 6, 8, …).
-   **RAID 2** . Ofrece detección y corrección de errores en los discos mediante la utilización de códigos de Hamming. Este nivel está incluido en la actualidad en los propios discos, por lo que ha dejado de ser un sistema a elegir por el usuario.
-   **RAID 3** . Emplea un disco para almacenar la paridad. La información se distribuye a nivel de bits entre los distintos discos. Si un disco falla, la información se reconstruiría mediante la operación O-exclusiva (XOR) de los discos restantes. Son necesarios un mínimo de 3 discos para implementar un RAID 3. Todos los discos funcionan a la vez, lo que hace bajar el rendimiento con sistemas transaccionales (múltiples accesos sobre pequeñas cantidades de datos).
-   **RAID 4** . Utiliza un disco para el almacenamiento de la paridad, al igual que el anterior; si embargo, los datos se distribuyen a nivel de bloque (en lugar de a nivel de bits) y se puede acceder a cada disco de forma individual. Este hecho mejora el rendimiento en sistemas transaccionales.
-   **RAID 5** . La paridad se almacena entre todos los discos, eliminando el excesivo uso del disco de paridad que hacían los dos niveles anteriores. Este método es el más eficiente, ofreciendo la mayor tasa rendimiento/coste y el menos coste por megabyte de información. Se necesitan al menos 3 discos para su desarrollo; no obstante, el funcionamiento óptimo se alcanza a partir de los 7 discos.

Los últimos tres niveles se denominan de discos en bandas con paridad (disk striping with parity), y en ellos, podremos calcular la capacidad máxima de información que pueden almacenar sumando la capacidad de todos los discos y restándoles la capacidad de uno (redundancia).

### Otros Medios Magnéticos

**ZIP**

Tienen un tamaño similar a los floppys de 3,5″, lo que los hace fácilmente portables. Sus capacidades habituales son 100 y 250 Mb, aunque actualmente existen de 750 Mb.

**JAZZ**

Son discos similares a los anteriores (son compatibles) pero con capacidades de 1 y 2 Gb.

**Tecnología Magneto-Óptica**

**LS-120 Superdisk**

La tecnología Láser Servo fue desarrollada en 1996. Se trata de una tecnología mixta (magnética y óptica) compatible con la de los floppys tradicionales; es decir, un lector/grabador de este tipo puede leer y escribir sus propios discos de 120 Mb y los floppys convencionales de 1,44 Mb.

Este sistema es producto de una mezcla de tecnologías de los floppys, discos duros y CD-ROM’s.

Combina una medio magnético con un método óptico utilizado para el posicionamiento de las cabezas de lectura/escritura, lo que conduce a un aumento considerable de la capacidad del medio respecto de los floppys, y a lograr velocidades de transferencia de hasta 400 kb/s (la mitad de veloces que los ZIP).

**Discos Magneto Ópticos (MO)**

Emplean, para la grabación del medio, un láser que calienta la superficie del disco (302º F). Existen dos variantes de funcionamiento de esta tecnología:

-   El calor provoca la oxidación del metal del medio, lo que permite la orientación de su magnetismo mediante un imán (es la técnica más empleada).
-   El calor cambia la estructura del medio, provocando que sea cristalino o amorfo.

Existen discos de 5,25″ (650 Mb, 1.3 Gb, 2.6 Gb y 4.6 Gb) y de 3,5″ (128, 230 y 640 Mb).

**Cintas Magnéticas**

Ofrecen una gran capacidad de información junto con velocidades de transferencia muy bajas; motivo por el cual son empleadas casi exclusivamente para realizar copias de seguridad. Suponen un coste ínfimo por Mb.

![](https://gsitic.files.wordpress.com/2018/02/cintas_magneticas.png?w=825)

### Copias de Seguridad (BACKUP)

Las copias de seguridad o backups pueden definirse como copias de la información realizadas usando un medio de almacenamiento secundario, cuyo objetivo es salvaguardar la información ante posibles errores humanos, de hardware, etc.

**Pérdida de información**

Las pérdidas de datos pueden provenir de las circunstancias más variadas:

-   Fallo del disco duro.
-   Error humano (eliminación no deseada).
-   Interrupción de una aplicación por fallo durante la grabación de la información en el disco.
-   Acción de un virus o troyano.
-   Accidente inevitable en el entorno del sistema informático (incendio, inundación, etc).

**Frecuencia de Backups**

La frecuencia de ejecución de backups dependerá tanto de la frecuencia de actualización de la información del sistema como de la información que el administrador del mismo esté dispuesto a perder.

En sistemas relativamente importantes los backups son diarios.

**Medios empleados para las Backups**

Las copias de seguridad pueden hacerse, entre otros medios, sobre:

-   Una partición dentro del mismo disco duro que contiene la información a proteger (mínima protección).
-   Un disco duro auxiliar, dentro del mismo equipo donde se encuentra el disco duro con la información a proteger.
-   Un disco duro en un equipo distinto al que contiene la información a proteger (backup por red).
-   Un CD-R, CD-RW, DVD-RW, DVD+RW, etc.
-   Una cinta magnética (tape backup).
-   Floppys, ZIP’s, JAZZ’s, etc. (para copias de pequeñas cantidades de información).

**Tipos de Backups**

-   Completa. Copia de toda la información a salvaguardar.
-   Progresiva o Incremental. Copia de la información nueva o modificada desde el último backup completo o progresivo (se necesitaría la última copia completa y todas las copias incrementales para restaurar la información).
-   Diferencial. Copia de la información nueva o modificada desde la última copia completa (la recuperación de los datos precisa de la última copia completa y la última diferencial).

Controles de Cambio
-------------------

### Controlar el Proyecto y Eliminar los Retrasos

Los cambios son un pilar básico dentro de la vida del desarrollo de software. En la práctica, el trabajo requiere de una administración formal de los cambios. Si contamos con una administración de cambios del software realmente efectiva podremos conseguir que:

-   Los equipos de desarrollo puedan entregar el software dentro del tiempo y presupuesto establecidos y con una calidad predecible.
-   Los líderes de proyecto conozcan en todo momento el estado y avance del desarrollo del software y tengan certeza del mismo dentro del tiempo prefijado.
-   Los desarrolladores utilicen y controlen con orden y seguridad sus colecciones de archivos y componentes diferentes para cada aplicación.
-   Los ‘probadores’ sepan cuándo una nueva construcción de software requiere ser sometida a un paquete de pruebas y las mejoras o correcciones que debe presentar.

Las organizaciones de desarrollo exitosas consideran que el control de cambios durante todo el ciclo es la clave para asignar prioridades a las actividades del equipo, así como para controlar las dificultades que surjan durante el desarrollo. Si no implementamos dicho control, el caos de los cambios se apoderará del control del proyecto.

La Administración de la Configuración y Control de Cambios (SCM) es la disciplina de la ingeniería de software que agrupa las herramientas y técnicas de uso de las mismas que una compañía emplea para administrar los cambios de los componentes de software. Cuando la SCM se encuentra integrada en otras actividades del desarrollo (requerimientos, análisis y diseño, construcción, pruebas), se denomina Gestión de Cambio Unificada (UCM).

Existen guías que describen cómo controlar, dar seguimiento y monitorear los cambios para permitir un desarrollo iterativo exitoso; así como la forma de establecer espacios de trabajo seguros para cada desarrollador, aislándolo de los cambios realizados en otros espacios de trabajo y controlando los cambios de todos los artefactos de software (modelos, código, documentos, etc) Para llevar a cabo estas metodologías, se utilizan herramientas de ‘control de versiones y configuraciones’ y de ‘control de cambios’ que, por un lado, automatizan las metodologías, y por otro unen al equipo de desarrollo para conseguir un trabajo paralelo y coordinado. Estas herramientas permiten a cada desarrollador contar con un espacio de trabajo seguro donde puede realizar los cambios de manera independiente para que una vez probados puedan integrarse con el resto del desarrollo, garantizando de esta forma la calidad, el tiempo de entrega y la satisfacción del cliente con el producto desarrollado.

### Gestión de Cambios

Podemos distinguir dos enfoques diferentes dentro de la gestión de cambios, dependiendo del mayor o menor grado de modificación del producto.

Si el cambio a realizar afecta a gran parte de los componentes del producto, podrá plantearse como un nuevo desarrollo, y aplicar un nuevo ciclo de vida desde el principio, aunque aprovechando lo ya desarrollado de la misma forma que se reutilizan los prototipos.

Si el cambio afecta a una parte bastante localizada del producto, entonces se puede organizar como simple modificación de elementos. Hay que tener en cuenta que cualquier cambio en el código del producto software siempre implicará una revisión de los elementos de documentación afectados; es decir, cambiar el código de algunos módulos puede requerir, además, modificar los documentos de diseño o incluso, en el caso de mantenimiento perfectivo, modificar el documento de especificación de requisitos.

Tomando como referencia la gestión, la realización de cambios se puede controlar mediante dos clases de documentos, que en ocasiones pueden unirse para forma un único informe:

-   Informe de problema: describe una dificultar en la utilización del software que precisa de alguna modificación para subsanarla.
-   Informe de cambio: describe la solución dada a un problema y el cambio realizado en el producto software.

El primer documento puede ser originado por los propios usuarios. Este informe se pasa a un grupo de ingeniería para la comprobación y codificación del problema planteado, y posteriormente a un grupo de gestión para decidir la solución a adoptar. Este grupo de gestión da comienzo al informe de cambio, que se pasa de nuevo al grupo de ingeniería para su total desarrollo y ejecución.

### Comprobación de los Objetivos del Control de Cambios

Los objetivos del control de cambios son comprobados al realizar entrevistas con:

-   El Director de Tecnologías de Información.
-   La Administración de la Función de Servicios de Información.
-   La Administración de Desarrollo de Sistemas, Aseguramiento de la Calidad de Control de Cambios, Operaciones y Seguridad.
-   La Administración de Usuarios implicada en el diseño y manejo de aplicaciones de sistemas de información.

De las que se obtienen:

-   Procedimientos organizacionales relacionados con la planificación de sistemas de información, el control de cambios, la seguridad y el ciclo de vida de desarrollo de sistemas.
-   Procedimientos de la función de servicios de sistemas de información relacionados con la metodología del ciclo de vida de desarrollo de sistemas, el aseguramiento independiente de la calidad, los estándares de seguridad, la implementación, la distribución, el mantenimiento, la liberación del software, los cambios de emergencia y el control de versiones del sistema.
-   Un plan de desarrollo de aplicaciones.
-   Formato y bitácora de requisitos de control de cambios.
-   Contratos con proveedores relacionados con servicios de desarrollo de aplicaciones.

### Evaluación de los Controles

La evaluación de los controles de cambios deberá tener en cuenta si:

-   La bitácora de control de cambios garantiza que cualquiera de los cambios mostrados han sido resueltos.
-   El control de cambios es un procedimiento formal tanto para los grupos de desarrollo como para los usuarios.
-   El usuario está conforme con el resultado de los cambios solicitados, el tiempo de realización de los mismos y los costes.
-   Para una muestra de cambios en la bitácora de control de cambios:
    -   la documentación actual refleja con exactitud el ambiente modificado,
    -   los cambios hayan sido efectuados tal y como fueron documentados,
    -   el cambio implicó modificaciones en los programas y operaciones.
-   El proceso de cambios es controlado respecto de las mejoras en el conocimiento, la efectividad en el tiempo de respuesta y la satisfacción del usuario con el resultado del proceso.
-   El mantenimiento del sistema de Intercambio de Rama Privada (PBX) se incluye en los procedimientos de control de cambios.

### Evaluación de la Suficiencia

La comprobación de la suficiencia del control se realizará probando que:

-   Para una selección de cambios, la administración ha aprobado los siguientes puntos:
    -   petición del cambio,
    -   descripción del cambio,
    -   acceso al programa fuente,
    -   terminación del cambio por parte del programador,
    -   solicitud para trasladar el programa fuente al entorno de prueba,
    -   finalización de las pruebas de aceptación,
    -   solicitud de compilación y traslado al grupo de producción,
    -   identificación y aceptación del impacto general y específico,
    -   elaboración de un proceso de distribución,

y revisando el control de cambios en cuanto a la inclusión de:

-   fecha del cambio solicitado,
-   persona o grupo que lo solicita,
-   petición aprobada de cambios,
-   aprobación del cambio efectuado (servicios de información),
-   aprobación del cambio efectuado (usuarios),
-   fecha de actualización de la documentación,
-   fecha del traslado al grupo de producción,
-   aprobación del cambio por parte del grupo de aseguramiento de la calidad,
-   aceptación por parte del grupo de operaciones.

También se tendrán en cuenta, a la hora de evaluar esta suficiencia:

-   Los tipos de análisis de cambios realizados sobre el sistema para la determinación de tendencias.
-   La valoración de la adecuación de las librerías de la función de servicios de información y la identificación de la existencia de niveles de código base para advertir y prevenir la ocurrencia de errores.
-   Si existen procedimientos de E/S (“check in/check out”) para cambios.
-   Si la totalidad de los cambios en la bitácora fueron resueltos con la conformidad de los usuarios y si no se llevaron a cabo cambios que no hayan sido anteriormente especificados en la bitácora.
-   Si los usuarios tienen conocimiento de la necesidad de procedimientos formales de control de cambios.
-   El proceso de reforzamiento del personal garantiza el cumplimiento de cada uno de los procedimientos de control de cambios.

### Evaluación del Riesgo de los Objetivos de Control NO Alcanzados

Esta evaluación se realizará llevando a cabo mediciones (“benchmarking”) de la administración del control de cambios contra organizaciones similares o estándares internacionales de buenas prácticas reconocidas en la industria correspondiente.

Para sistemas seleccionados de la función de servicios de información, se ejecutará:

-   Una verificación para comprobar si la documentación determina el requerimiento o si el cambio del sistema ha sido aprobado y priorizado por parte de la administración de las áreas usuarias afectadas y el proveedor de servicios.
-   La confirmación de la existencia y adecuación de evaluación del impacto en formas de control de cambios.
-   La obtención del conocimiento del cambio mediante una comunicación de la función de servicios de información.
-   La asignación del cambio a los correspondientes recursos de desarrollo.
-   La adecuación de los sistemas y los planes de prueba de los usuarios.
-   La migración formal de prueba a producción a través del grupo de aseguramiento de la calidad.
-   La puesta al día de los manuales de usuario y de operación para mostrar el cambio efectuado.
-   El reparto de la nueva versión a los usuarios correspondientes.

Además, la evaluación de este riesgo concluirá determinando, para una selección de cambios de información, que:

-   Sólo se efectuaron cambios que hayan sido aprobados por la función de servicios de información.
-   Todos los cambios han sido tenidos en cuenta.
-   Las librerías actuales (fuente y objeto) muestran los últimos cambios llevados a cabo.
-   Las modificaciones en el procedimiento de control de cambios de:
    -   aplicaciones internas y adquiridas,
    -   software de sistemas y de aplicación,
    -   gestión del control de cambios por parte del proveedor.

Bibliografía
------------

-   [Scribd (Ibiza Ales)](https://es.scribd.com/document/357447350/TICB3-Gestion-de-Librerias-y-Medios-Magneticos)
