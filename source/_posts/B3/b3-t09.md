title: B3-T09
date: 2019-01-16 16:11:23
---

Diseño de programas. Diseño estructurado. Análisis de transformación y de transacción. Cohesión y acoplamiento.
===============================================================================================================

Introducción al Diseño Estructurado
-----------------------------------

### Conceptos Generales Sobre el Diseño

Definición: “Diseño es el proceso de aplicar distintas técnicas y principios con el propósito de definir un dispositivo, proceso, o sistema, con los suficientes detalles como para permitir su realización física”.

El objetivo del diseñador es producir un modelo de una entidad que se construirá más adelante. El proceso por el cual se desarrolla el modelo combina:

-   La intuición y los criterios en base a la experiencia de construir entidades similares.
-   Un conjunto de principios y/o heurísticas que guían la forma en la que se desarrolla el modelo.
-   Un conjunto de criterios que permiten discernir sobre la calidad.
-   Un proceso de iteración que conduce finalmente a una representación del diseño final.

La actividad de Diseño se dedica a asignar porciones de la especificación estructurada (también conocida como modelo esencial) a procesadores adecuados (sean máquinas o humanos) y a labores apropiadas (o tareas, particiones, etc) dentro de cada procesador. Dentro de cada labor, la actividad de diseño se dedica a la creación de una jerarquía apropiada de módulos de programas y de interfaces entre ellos para implantar la especificación creada en la actividad de análisis. Además, la actividad de diseño se ocupa de la transformación de modelos de datos de entidad/relación en un diseño de base de datos.

### ¿Qué es Diseño Estructurado?

Definición: “Diseño estructurado es el proceso de decidir qué componentes, y la interconexión entre los mismos, para solucionar un problema bien especificado”.

El diseño es una actividad que comienza cuando el analista de sistemas ha producido un conjunto de requerimientos funcionales lógicos para un sistema, y finaliza cuando el diseñador ha especificado los componentes del sistema y las relaciones entre los mismos.

Frecuentemente analista y diseñador son la misma persona, sin embargo es necesario que se realice un cambio de enfoque mental al pasar de una etapa a la otra. _Al abordar la etapa de diseño, la persona debe quitarse el sombrero de analista y colocarse el sombrero de diseñador_ .

Una vez que se han establecido los requisitos del software (en el análisis), el diseño del software es la primera de tres actividades técnicas: _diseño_ , _codificación_ y _prueba_ . Cada actividad transforma la información de forma que finalmente se obtiene un software para computadora válido.

En la figura se muestra el flujo de información durante la fase de desarrollo. Los requisitos del sistema, establecidos mediante los _modelos de información_ , _funcional_ y _de comportamiento_ , alimentan el proceso del diseño. Mediante alguna metodología (en nuestro caso, estructurada basada en el flujo de información) se realiza el diseño estructural, procedimiental y de datos.

![](https://gsitic.files.wordpress.com/2018/04/flujo_informacion_fase_desarrollo.png?w=825)

El _diseño de datos_ transforma el modelo del campo de información, creado durante el análisis, en las estructuras de datos que se van a requerir para implementar el software.

El _diseño estructural_ define las relaciones entre los principales elementos estructurales del programa. El objetivo principal del diseño estructural es desarrollar una estructura de programa modular y representar las relaciones de control entre los módulos.

El _diseño procedimental_ transforma los elementos estructurales en una descripción procedimental del software. El diseño procedimental se realiza después de que se ha establecido la estructura del programa y de los datos. Define los algoritmos de procesamiento necesarios.

Concluido el diseño se genera el código fuente y para integrar y validar el software, se llevan a cabo pruebas de testeo.

Las fases del diseño, codificación y prueba absorben el 75% o más del coste de la ingeniería del software (excluyendo el mantenimiento). Es aquí donde se toman _decisiones_ que afectarán finalmente al éxito de la implementación del programa y, con igual importancia, a la facilidad de mantenimiento que tendrá el software. Estas decisiones se llevan a cabo durante el diseño del software, haciendo que sea un paso _fundamental_ de la fase de desarrollo.

La importancia del diseño del software se pueden sentar con una única palabra: _calidad_ . El diseño es el proceso en el que se asienta la calidad del desarrollo del software. El diseño produce las representaciones del software de las que puede evaluarse su calidad. El diseño sirve como base para todas las posteriores etapas del desarrollo y de la fase de mantenimiento. Sin diseño nos arriesgamos a construir un sistema inestable, un sistema que falle cuando se realicen pequeños cambios, un sistema que pueda ser difícil de probar, un sistema cuya calidad no pueda ser evaluada hasta más adelante en el proceso de ingeniería de software, cuando quede poco tiempo y se haya gastado ya mucho dinero.

![](https://gsitic.files.wordpress.com/2018/04/con_disec3b1o_sin_disec3b1o.png?w=825)

### Objetivos del Diseño Estructurado

_El diseño estructurado, tiende a transformar el desarrollo de software de una práctica artesanal a una disciplina de ingeniería._

-   Eficiencia
-   Mantenibilidad
-   Modificabilidad
-   Flexibilidad
-   Generalidad
-   Utilidad

_“Diseño” significa planear la forma y método de una solución_ . Es el proceso que determina las características principales del sistema final, establece los límites en performance y calidad que la mejor implementación puede alcanzar, y puede determinar a qué costos se alcanzará.

El diseño se caracteriza usualmente por un gran número de decisiones técnicas individuales. En orden de transformar el desarrollo de software en una disciplina de ingeniería, se debe sistematizar tales decisiones, hacerlas más explícitas y técnicas, y menos implícitas y artesanales.

Un ingeniero no busca simplemente _una_ solución, busca la _mejor_ solución, dentro de las _limitaciones_ reconocidas, y realizando _compromisos_ requeridos en el trabajo del mundo real.

En orden de convertir el diseño de sistemas de computadoras en una disciplina de ingeniería, previo a todo, debemos definir _objetivos técnicos claros_ para los programas de computadora. Es esencial además comprender las _restricciones_ primarias que condicionan las soluciones posibles.

Para realizar decisiones concisas y deliberadas, debemos identificar los _puntos de decisión_ .

Finalmente necesitamos una _metodología_ que nos asista en la _toma de decisiones_ .

Dadas estas cosas: objetivos, restricciones, decisiones reconocidas, y una metodología efectiva, podemos obtener soluciones de ingeniería, y no artesanales.

**_Diseño estructurado y calidad del software_**

Un concepto importante a clarificar es el de _calidad_ . Desafortunadamente, muchos diseñadores se conforman con un sistema que “funcione” sin reparar en un _buen_ sistema.

Una corriente de pensamiento estima que un programa es bueno si sus algoritmos son astutos y no obvios a otro programador; esto refleja la “inteligencia” del programador.

Otra escuela de pensamiento asocia calidad con incremento de la velocidad de ejecución y disminución de los requerimientos de memoria central. Estos son aspectos de un concepto más amplio: _eficiencia_ . En general, se busca diseños que hagan un uso inteligente de los _recursos_ . Estos recursos no incluyen solamente procesador y memoria, también incluyen almacenamiento secundario, tiempo de periféricos de entrada/salida, tiempo de líneas de teleproceso, tiempo de personal y más.

Otra medida de calidad es la _confiabilidad_ . Es importante notar que si bien la confiabilidad del software puede ser vista como un problema de depuración de errores en los programas, es también un problema de diseño. La confiabilidad se expresa en como MTBF (mean time between fairules: tiempo medio entre fallas).

Un concepto muy relacionado a la confiabilidad y de suma importancia es el de _mantenibilidad_ . Podemos definir la mantenibilidad como:

![](https://gsitic.files.wordpress.com/2018/04/mantenibilidad.png?w=825)

donde:

-   MBTF: tiempo medio entre fallas.
-   MTTR: tiempo medio de reparación (mean time to repair).

Diremos que un sistema es mantenible si permite la detección, análisis, rediseño y corrección de errores fácilmente.

En tanto la mantenibilidad afecta la viabilidad del sistema en un entorno relativamente constante, la _modificabilidad_ influye en los costos de mantener un sistema viable en condiciones de cambio de requerimientos. La modificabilidad es la posibilidad de realizar modificaciones y extensiones a partes del sistema, o agregar nuevas partes con facilidad (no corrección de errores).

En estudios realizados se determinó que las organizaciones abocadas al procesamiento de datos invierten aproximadamente un 50% del presupuesto en mantenimiento de los sistemas, involucrando esto corrección de errores y modificaciones, razón por la cual la mantenibilidad y la modificabilidad son dos objetivos primarios en el diseño de software.

La _flexibilidad_ representa la facilidad de que el mismo sistema pueda realizar variaciones sobre una misma temática, sin necesidad de modificaciones.

La _generalidad_ expresa el alcance sobre un determinado tema.

Flexibilidad y generalidad son dos objetivos importantes en el diseño de sistemas del tipo de propósitos generales.

La _utilidad_ o facilidad de uso es un factor importante que influye en el éxito del sistema y su aceptación por parte del usuario. Un sistema bien diseñado pero con interfaces muy “duras” tiende a ser resistido por los usuarios.

Finalmente diremos que eficiencia, mantenibilidad, modificabilidad, flexibilidad, generalidad y utilidad, con componentes de la _calidad_ objetiva de un sistema.

En términos simples también diremos que nuestro objetivo primario es obtener sistemas de _costo mínimo_ . Es decir, es nuestro interés obtener sistemas económicos para desarrollar, operar, mantener y modificar.

### Restricciones, compromisos y decisiones del Diseño

Podemos ver los objetivos técnicos del diseño como constituyendo una “función objetivo” de un problema de optimización, la cual se desea maximizar, sujeta a ciertas restricciones.

Como regla, las restricciones sobre un proceso de diseño de un sistema, caen en dos categorías: _restricciones de desarrollo_ y _restricciones operacionales_ .

Las **restricciones de desarrollo** son limitaciones al consumo de recursos durante el período de desarrollo, y pueden ser expresadas en términos generales o descomponerla en sus partes como ser tiempo de máquina y horas/hombre. Dentro de las restricciones de desarrollo, entran también las _restricciones de planificación_ . Estas se refieren a metas y plazos a ser cumplidos (“el módulo X debe terminarse para Febrero”).

Las **restricciones operacionales** pueden ser expresadas en términos técnicos, como ser máximo tamaño de memoria disponible, máximo tiempo de respuesta aceptable, etc.

El carácter de muchas decisiones de diseño no fija límites rígidos, si no un intervalo de tolerancia, dentro del cual el diseñador puede moverse a costa de variaciones en otros aspectos del sistema. Por ejemplo se puede priorizar eficiencia, en detrimento de facilidad de mantenimiento, o velocidad de ejecución contra tamaño de memoria utilizada.

La esencia del diseño en el mundo real y las decisiones inherentes al mismo es obtener una solución de _compromiso_ .

El diseño total es el resultado acumulativo de un gran número de _decisiones técnicas_ incrementales.

### Principios utilizados por el Diseño Estructurado

**Abstracción**

La noción psicológica de abstracción permite concentrarse en un problema al mismo nivel de generalización, independientemente de los detalles irrelevantes de bajo nivel. El uso de la abstracción también permite trabajar con conceptos y términos que son familiares al entorno del problema, sin tener que transformarlos a una estructura no familiar.

Cada paso de un proceso de ingeniería de software es un refinamiento del nivel de abstracción de la solución de software.

Conforme nos movemos por diferentes niveles de abstracción, trabajamos para crear _abstracciones_ de datos y de procedimientos. Una _abstracción procedural_ es una determinada secuencia de instrucciones que tienen una función limitada y específica.

Una _abstracción de datos_ es una determina colección de datos que describen un objeto.

-   **Rumbaugh: O.O. Modeling and Design**  
    _La abstracción es el exámen selectivo de ciertos aspectos de un problema_ . El objetivo de la abstracción es aislar aquellos aspectos que son importantes para algún propósito y suprimir aquellos aspectos que no son importantes. La abstracción debe realizarse siempre con un propósito, ya que el propósito determina que es y que no es relevante. Muchas abstracciones son posibles sobre una misma cosa, dependiendo de cual sea su propósito.
-   **Alan Cameron Will (Object Expert Jan/Feb 1996)**  
    _La abstracción, para mí, es cercana a palabras como “teórico”, “esotérico”, “académico”, e “impráctico”. Pero en un sentido en particular, significa la separación de los aspectos más importantes de un determinado problema, del detalle. Este el el único camino que tengo para abordar con mi mente finita cualquier tema complejo_ .

**Refinamiento sucesivo**

El _refinamiento sucesivo_ es una primera estrategia de diseño descendente propuesta por Niclaus Wirth. La arquitectura de un programa se desarrolla en niveles sucesivos de refinamiento de los detalles procedimentales. Se desarrolla una jerarquía descomponiendo una declaración macroscópica de una función de una forma sucesiva, hasta que se llega a las sentencias del lenguaje de programación.

**Modularidad**

La arquitectura implica modularidad, el software se divide en componentes con nombres y ubicaciones determinados, que se denominan _módulos_ , y que se integran para satisfacer los requisitos del problema.

**Arquitectura del software**

La _arquitectura del software_ se refiere a dos características importantes del software de computadoras:

-   la estructura jerárquica de los componentes procedimientales (módulos)
-   la estructura de datos

**Jerarquía de control**

La _jerarquía de control_ , también denominada _estructura de programa_ , representa la organización (frecuentemente jerárquica) de los componentes del programa (módulos) e implica una jerarquía de control. No representa aspectos procedimentales del software, tales como secuencias de procesos, o la repetición de operaciones.

**Estructura de datos**

La _estructura de datos_ es una representación de la relación lógica existente entre los elementos individuales de datos. Debido a que la estructura de la información afectará invariablemente al diseño procedimental final, la estructura de datos es tan importante como la estructura del programa en la representación de la arquitectura del software.

**Procedimientos del software**

La estructura del programa define la jerarquía de control, independientemente de las decisiones y secuencias de procesamiento. El procedimiento del software se centra sobre los detalles de procesamiento de cada módulo individual.

El procedimiento debe proporcionar una especificación precisa del procesamiento, incluyendo la secuencia de sucesos, los puntos concretos de decisiones, la repetición de operaciones, e incluso la organización/estructura de los datos.

**Ocultamiento de la información**

El principio de _ocultamiento de la información_ sugiere que los módulos se han de caracterizar por decisiones de diseño que los oculten unos a otros. Los módulos deben especificarse y diseñarse de forma que la información (procedimientos y datos) contenida dentro de un módulo sea accesible a otros módulos únicamente a través de las _interfaces_ formales establecidas para cada módulo.

Conceptos Básicos de Diseño Estructurado
----------------------------------------

### Estrategia del Diseño Estructurado

Cuando se trata con un problema de diseño de reducida envergadura, por ejemplo un sistema que pueda ser desarrollado en un par de semanas,no se tienen mayores problemas, y el desarrollador puede tener todos los elementos del problema “en mente” a la vez. Sin embargo cuando se trabaja en proyectos de gran escala, es difícil que una sola persona sea capaz de llevar todas las tareas y tener en mente todos los elementos a la vez.

El diseño exitoso se basa en un viejo principio conocido desde los días de Julio César: _Divide y conquistarás_ .

Específicamente, diremos que el costo de implementación de un sistema de computadora podrá minimizarse cuando pueda separarse en partes:

-   _manejablemente pequeñas_
-   _solucionables separadamente_

Por supuesto la interpretación de manejablemente pequeña varía de persona en persona. Por otro lado muchos intentos de particionar sistemas en pequeñas partes arribaron incrementos en los tiempos de implementación. Esto se debe fundamentalmente al segundo punto: solucionables separadamente. En muchos sistemas para implementar la parte A, debemos conocer algo sobre la B, y para implementar algo de B, debemos conocer algo de C.

De manera similar, podemos decir que el costo de _mantenimiento_ puede ser minimizado cuando las partes de un sistema son:

-   _fácilmente relacionables con la aplicación_
-   _manejablemente pequeñas_
-   _corregibles separadamente_

Muchas veces la persona que realiza la modificación no es quien diseñó el sistema. Es importante que las partes de un sistema sean manejablemente pequeñas en orden de simplificar el mantenimiento. Un trabajo de encontrar y corregir un error en una “pieza” de código de 1000 líneas es muy superior a hacerlo con piezas de 20 líneas. No solo disminuye el tiempo de localizar la falla sino que si la modificación es muy engorrosa, puede reescribirse la pieza completamente. Este concepto de “módulos descartables” ha sido utilizado con éxito muchas veces.

Por otra parte, para minimizar los costos de mantenimiento debemos lograr que cada pieza sea independiente de otra. En otras palabras debemos ser capaces de realizar modificaciones al módulo A sin introducir efectos indeseados en el módulo B.

Finalmente, diremos que el costo de _modificación_ de un sistema puede minimizarse si sus partes son:

-   _fácilmente relacionables con la aplicación_
-   _modificables separadamente_

En resumen, podemos afirmar lo siguiente: los costos de implementación, mantenimiento y modificación, generalmente serán minimizados cuando _cada pieza del sistema corresponda a exactamente una pequeña, bien definida pieza del dominio del problema, y cada relación entre las piezas del sistema corresponde a relaciones entre piezas del dominio del problema_ .

En la siguiente figura apreciamos este concepto.

![](https://gsitic.files.wordpress.com/2018/04/dominio_problema.png?w=825)

### Particionamiento y Organización

Un buen diseño estructurado es un ejercicio de particionamiento y organización de los componentes de un sistema.

Entenderemos por particionamiento, la subdivisión de un problema en subproblemas más pequeños, de tal forma que cada subproblema corresponda a una pieza del sistema. La cuestión es: ¿Dónde y cómo debe dividirse el problema? ¿Qué aspectos del problema deben pertenecer a la misma pieza del sistema, y cuales a distintas piezas? El diseño estructurado responde estas preguntas con dos principios básicos:

-   _Partes del problema altamente interrelacionadas deberán pertenecer a la misma pieza del sistema_ .
-   _Partes sin relación entre ellas, deben pertenecer a diferentes piezas del sistema sin relación directa_ .

Otro aspecto importante del diseño estructurado es la organización del sistema. Debemos decidir como se interrelacionan las partes, y que parte está en relación con cual.

El objetivo es organizar el sistema de tal forma que no existan piezas más grandes de lo estrictamente necesario para resolver los aspectos del problema que ella abarca. Igualmente importante, es el evitar la introducción de relaciones en el sistema, que no existe en el dominio del problema.

### El concepto de Cajas Negras

Una caja negra es un sistema (o un componente) con entradas conocidas, salidas conocidas, y generalmente transformaciones conocidas, pero del cual no se conoce el contenido en su interior.

En la vida diaria existe innumerable cantidad de ejemplos de uso cotidiano: una radio, un televisor, un automóvil, son cajas negras que usamos a diario sin conocer (en general) como funciona en su interior. Solo conocemos como controlarlos (entradas) y las respuestas que podemos obtener de los artefactos (salidas).

El concepto de caja negra utiliza el principio de _abstracción_ .

Este concepto es de suma utilidad e importancia en la ingeniería en general, y por ende en el desarrollo de software. Lamentablemente muchas veces para poder hacer un uso efectivo de determinado módulo, el diseñador debe revisar su contenido ante posibles contingencias como ser comportamientos no deseados ante determinados valores. Por ejemplo es posible que una rutina haya sido desarrollada para aceptar un determinado rango de valores y falla si se la utiliza con valores fuera de dicho rango, o produce resultados inesperados. Una buena documentación en tales casos, es de utilidad pero no transforma al módulo en una verdadera caja negra. Podríamos hablar en todo caso de “cajas blancas”.

Los módulos de programas de computadoras pueden variar en un amplio rango de aproximación al ideal de caja negra. En la mayoría de los casos podemos hablar de “cajas grises”.

La Estructura de los Programas de Computadora
---------------------------------------------

### Diagramas de Flujo y Diagramas de Estructura

Normalmente los procedimientos se representan con _diagramas de flujo_ (no confundir con diagramas de flujo de datos) los cuales modelan la secuencia de operaciones que realiza el programa a través del tiempo.

Un _diagrama de estructura_ en cambio no modela la secuencia de ejecución sino la _jerarquía de control_ existente entre los módulos que conforman el programa, independientemente del factor tiempo. Existe un módulo raíz de máximo nivel, del cual dependen los demás, en una estructura arborescente.

### Notación de los Diagramas de Flujo de Control

![](https://gsitic.files.wordpress.com/2018/04/notacion_diagramas_flujo_control.png?w=825)

![](https://gsitic.files.wordpress.com/2018/04/construcciones_estructuradas.png?w=825)

### Notación de los Diagramas de Estructura

![](https://gsitic.files.wordpress.com/2018/04/notacion_diagramas_estructura.png?w=825)

### Ejemplo comparativo entre Diagramas de Procesamiento y de Estructura

![](https://gsitic.files.wordpress.com/2018/04/diagrama_flujo.png?w=825) ![](https://gsitic.files.wordpress.com/2018/04/diagrama_estructura.png?w=825)

Acoplamiento
------------

### Introducción

Muchos aspectos de la modularización pueden ser comprendidos solo si se examinan módulos en relación con otros. En principio veremos el concepto de _independencia_ : diremos que dos módulos son totalmente independientes si ambos pueden funcionar completamente sin la presencia del otro. Esto implica que no existen interconexiones entre los módulos, y que se tiene un valor cero en la escala de “dependencia”.

En general veremos que a mayor número de interconexiones entre dos módulos, se tiene una menor independencia.

El concepto de independencia funcional es una derivación directa del de modularidad y de los conceptos de abstracción y ocultamiento de la información.

La cuestión aquí es: ¿cuánto debe conocerse acerca de un módulo para poder comprender otro módulos? Cuanto más debamos conocer acerca del módulo B para poder comprender el módulo A, menos independientes serán A y B.

La simple cantidad de conexiones entre módulos, no es una medida completa de la independencia funcional. La dependencia funcional se mide con dos criterios cualitativos: _acoplamiento_ y _cohesión_ . Estudiaremos en principio el primero de ellos.

Módulos altamente “acoplados” estarán unidos por fuertes interconexiones, módulos débilmente acoplados tendrán pocas y débiles interconexiones, en tanto que los módulos “desacoplados” no tendrán interconexiones entre ellos y serán independientes.

> El _acoplamiento_ es un concepto abstracto que nos indica el grado de interdependencia entre módulos.

En la práctica podemos materializarlo como la probabilidad de que en la codificación, depuración, o modificación de un determinado módulo, el programador necesite tomar conocimiento acerca de partes de otro módulo. Si dos módulos están fuertemente acoplados, existe una alta probabilidad de que el programador necesite conocer uno de ellos en orden de intentar realizar modificaciones al otro.

Claramente, el costo total del sistema se verá fuertemente influenciado por el grado de acoplamiento entre módulos.

### Factores que influencian el Acoplamiento

Los cuatro factores principales que influyen en el acoplamiento entre módulos son:

-   _Tipo de conexión entre módulos_ : los sistemas normalmente conectados, tienen menor acoplamiento que aquellos que tienen conexiones patológicas.
-   _Complejidad de la interface_ : está determinada por la cantidad, accesibilidad y estructura de la información que define la interface.
-   _Tipo de flujo de información en la conexión_ : los sistemas con acoplamiento de datos tienen menor acoplamiento que los sistema con acoplamiento de control y estos a su vez menos que los que tienen acoplamiento híbrido.
-   _Momento en que se produce el ligado de la Conexión_ : conexiones ligadas a referentes fijos en tiempo de ejecución, resultan con menor acoplamiento que cuando el ligado tiene lugar en tiempo de carga, el cual tiene a su vez menor acoplamiento que cuando el ligado se realiza en tiempo de ligado (link-edición), el cual tiene menos acoplamiento que el que se realiza en tiempo de compilación, todos los que a su vez tiene menos acoplamiento que cuando el ligado se realiza en tiempo de codificación.

### Acoplamiento en Entorno Común (common-environment coupling)

Siempre que dos o más módulos interactúan con un entorno de datos común, se dice que dichos módulos están en _acoplamiento por entorno común_ .

Ejemplos de entorno común pueden ser áreas de datos globales como la DATA DIVISION de COBOL, un archivo en disco.

El acoplamiento de entorno común es una forma de acoplamiento de segundo orden, distinto de los tratados anteriormente. La severidad del acoplamiento dependerá de la cantidad de módulos que acceden simultáneamente al entorno común. En el caso extremo de solo dos módulos donde uno utiliza como entrada los datos generados por el otro hablaremos de un acoplamiento de _entrada/salida_ .

El punto es que el acoplamiento por entorno común no es necesariamente malo y deba ser evitado a toda costa. Por el contrario existen ciertas circunstancias en que es una opción válida.

### Desacoplamiento

El concepto de acoplamiento invita a un concepto recíproco: _desacoplamiento_ .

Desacoplamiento es cualquier método sistemático o técnica para hacer más independientes a los módulos de un programa.

Cada tipo de acoplamiento generalmente sugiere un método de desacoplamiento. Por ejemplo, el acoplamiento causado por ligado, puede desacoplarse cambiando los parámetros apropiados.

El desacoplamiento desde el punto de vista funcional, rara vez puede realizarse, excepto en los comienzos de la fase del diseño.

Como regla general, una disciplina de diseño que favorezca el acoplamiento de entrada/salida y el acoplamiento de control por sobre el acoplamiento por contenido y el acoplamiento híbrido, y que busque limitar el alcance del acoplamiento por entorno común es el enfoque más efectivo.

Otras técnicas para reducir el acoplamiento son:

-   Convertir las referencias implícitas en explícitas. Lo que puede verse con mayor facilidad es más fácil de comprender.
-   Estandarización de las conexiones.
-   Uso de “buffers” para los elementos comunicados en una conexión. Si un módulo puede ser diseñado desde el comienzo asumiendo que un buffer mediará cada corriente de comunicación, las cuestiones temporización, velocidad, frecuencia, etc, dentro de un módulo no afectarán al diseño de otros.
-   Localización. Utilizado para reducir el acoplamiento por entorno común. Consiste en dividir el área común en regiones para que los módulos solo tengan acceso a aquellos datos que les son de su estricta incumbencia.

Cohesión
--------

### Introducción: Relación Funcional

Hemos visto que la determinación de módulos en un sistema no es arbitraria. La manera en la cual dividimos físicamente un sistema en piezas (particularmente en relación con la estructura del problema) puede afectar significativamente la complejidad estructural del sistema resultante, así como el número total de referencias intermodulares.

Adaptar el diseño del sistema a la estructura del problema (o estructura de la aplicación, o dominio del problema) es una filosofía de diseño sumamente importante. A menudo encontramos que elementos de procesamiento del dominio del problema altamente relacionados, son trasladados en código altamente interconectado. Las estructuras que agrupan elementos del problema altamente interrelacionados, tienden a ser modularmente efectivas.

Imaginemos que tengamos una magnitud para medir el grado de relación funcional existente entre pares de módulos. En términos de tal medida, diremos que el sistema más modularmente efectivo será aquel cuya suma de relación funcional entre pares de elementos que pertenezcan a diferentes módulos sea mínima. Entre otras cosas, esto tiende a minimizar el número de conexiones intermodulares requeridas y el acoplamiento intermodular.

> Esta relación funcional intramodular se conoce como _cohesión_ . La cohesión es la medida cualitativa de cuan estrechamente relacionados están los elementos internos de un módulo.

Otros términos utilizados frecuentemente son “fuerza modular”, “ligazón” y “funcionalidad”.

En la práctica un elemento de procesamiento simple aislado, puede estar funcionalmente relacionado en diferentes grados a otros elementos. Como consecuencia, diferentes diseñadores, con diferentes “visiones” o interpretaciones de un mismo problema, pueden obtener diferentes estructuras modulares con diferentes niveles de cohesión y acoplamiento. A esto se suma el inconveniente de que muchas veces es difícil evaluar el grado de relación funcional de un elemento respecto de otro.

La cohesión modular puede verse como el cemento que amalgama junto a los elementos de procesamiento dentro de un mismo módulo. Es el factor más crucial en el diseño estructurado, y el de mayor importancia en un diseño modular efectivo.

Este concepto representa la técnica principal que posee un diseñador para mantener su diseño lo más semánticamente próximo al problema real, o dominio del problema.

Claramente los conceptos de cohesión y acoplamiento están íntimamente relacionados. Un mayor grado de cohesión implica uno menor de acoplamiento. Maximizar el nivel de cohesión intramodular en todo el sistema resulta en una minimización del acoplamiento intermodular.

### Niveles de Cohesión

Diferentes principios asociativos fueron desenvolviéndose a través de los años por medio de la experimentación, argumentos teóricos, y la experiencia práctica de muchos diseñadores.

Existen siete niveles de cohesión distinguibles por siete principios asociativos. Estos se listan a continuación en orden creciente del grado de cohesión, de menor a mayor relación funcional:

-   Cohesión Casual (la peor)
-   Cohesión Lógica (sigue a la peor)
-   Cohesión Temporal (de moderada a pobre)
-   Cohesión de Procedimiento (moderada)
-   Cohesión de Comunicación (moderada a buena)
-   Cohesión Secuencial
-   Cohesión Funcional (la mejor)

Podemos visualizar el grado de cohesión como un espectro que va desde un máximo a un mínimo.

**Cohesión Casual (la peor)**

La _cohesión casual_ ocurre cuando existe poca o ninguna relación entre los elementos de un módulo.

La cohesión casual establece un punto cero en la escala de cohesión.

Es muy difícil encontrar módulos puramente casuales. Puede aparecer como resultado de la modularización de un programa ya escrito, en el cual el programador encuentra una determinada secuencia de instruccciones que se repiten de forma aleatoria, y decide por lo tanto agruparlas en una rutina.

Otro factor que influenció muchas veces la confección de módulos casualmente cohesivos, fue la mala práctica de la programación estructurada, cuando los programadores mal entendían que modularizar consistía en cambiar las sentencias GOTO por llamadas a subrutinas.

Finalmente diremos que si bien en la práctica es difícil encontrar módulos casualmente cohesivos en su totalidad, es común que tengan elementos casualmente cohesivos. Tal es el caso de operaciones de inicialización y terminación que son puestas juntas en un módulo superior.

Debemos notar que si bien la cohesión casual no es necesariamente perjudicial (de hecho es preferible un casualmente cohesivo a uno lineal), dificulta las modificaciones y mantenimiento del código.

**Cohesión Lógica (sigue a la peor)**

Los elementos de un módulo están _lógicamente_ asociados si puede pensarse en ellos como pertenecientes a la misma clase lógica de funciones, es decir, aquellas que pueden pensarse como juntas lógicamente.

Por ejemplo, se puede combinar en un módulo simple todos los elementos de procesamiento que caen en la clase de “entradas”, que abarca todas las operaciones de entrada.

Podemos tener un módulo que lea desde consola una tarjeta con parámetros de control, registros con transacciones erróneas de un archivo en cinta, registros con transacciones válidas de otro archivo en cinta, y los registros maestros anterior de un archivo en disco. Este módulo que podría llamarse “Lecturas”, y que agrupa todas las operaciones de entrada, es lógicamente cohesivo.

La cohesión lógica es más fuerte que la casual, debido a que representa un mínimo de asociación entre el problema y los elementos del módulo. Sin embargo podemos ver que un módulo lógicamente cohesivo no realiza una función específica, sino que abarca una serie de funciones.

**Cohesión Temporal (de moderada a pobre)**

_Temporal cohesión_ significa que todos los elementos de procesamiento de una colección ocurren en el mismo periodo de tiempo durante la ejecución del sistema. Debido a que dicho procesamiento debe o puede realizarse en el mismo periodo de tiempo, los elementos asociados temporalmente pueden combinarse en un único módulo que los ejecute a la misma vez.

Existe una relación entre cohesión lógica y la temporal, sin embargo, la primera no implica una relación de tiempo entre los elementos de procesamiento. La cohesión temporal es más fuerte que la cohesión lógica, ya que implica un nivel de relación más: el factor tiempo. Sin embargo la cohesión temporal aún es pobre en nivel de cohesión y acarrea inconvenientes en el mantenimiento y modificación del sistema.

Un ejemplo común de cohesión temporal son las rutinas de inicialización (start-up) comúnmente encontradas en la mayoría de los programas, donde se leen parámetros de control, se abren archivos, se inicializan variables contadores y acumuladores, etc.

**Cohesión de Procedimiento (moderada)**

Elementos de procesamiento relacionados _proceduralmente_ son elementos de una unidad procedural común. Estos se combinan en un módulo de cohesión procedural. Una unidad procedural común puede ser un proceso de iteración (loop) y de decisión, o una secuencia lineal de pasos. En este último caso la cohesión es baja y es similar a la cohesión temporal, con la diferencia que la cohesión temporal no implica una determinada secuencia de ejecución de los pasos.

Al igual que en los casos anteriores, para decir que un módulo tiene _solo_ cohesión procedural, los elementos de procesamiento deben ser elementos de alguna iteración, decisión, o secuencia, pero no deben estar vinculados con ningún principio asociativo de orden superior.

La cohesión procedural asocia elementos de procesamiento sobre la base de sus relaciones algorítmicas o procedurales.

Este nivel de cohesión comúnmente se tiene como resultado de derivar una estructura modular a partir de modelos de procedimiento como ser diagramas de flujo, o diagramas Nassi-Shneiderman.

**Cohesión de Comunicación (moderada a buena)**

Ninguno de los niveles de cohesión discutidos previamente están fuertemente vinculados a una estructura de problema en particular. _Cohesión de Comunicación_ es el menor nivel en el cual encontramos una relación entre los elementos de procesamiento que es intrínsecamente _dependiente del problema._

Decir que un conjunto de elementos de procesamiento están vinculados por comunicación significa que _todo los elementos operan sobre el mismo conjunto de datos de entrada o de salida_ .

![](https://gsitic.files.wordpress.com/2018/04/cohesion_comunicacion.png?w=825)

En el diagrama de la figura podemos observar que los elementos de procesamiento 1, 2 y 3 están asociados por comunicación sobre la corriente de datos de entrada, en tanto que 2, 3 y 4 se vinculan por los datos de salida.

Los diagramas de flujo de datos (DFD) son un medio objetivo para determinar si los elementos en un módulo están asociados por comunicación.

Las relaciones por comunicación presentan un grado de cohesión aceptable.

La cohesión por comunicación es común en aplicaciones comerciales. Ejemplos típicos pueden ser:

-   un módulo que imprima o grabe un archivo de transacciones
-   un módulo que reciba datos de diferentes fuentes y los transforme y ensamble en una línea de impresión

**Cohesión Secuencial**

El siguiente nivel de cohesión en la escala es la asociación _secuencial_ . En ella, los datos de salida (resultados) de un elemento de procesamiento sirven como datos de entrada al siguiente elemento de procesamiento.

En términos de un diagrama de flujo de datos de un problema, la cohesión secuencial combina una cadena lineal de sucesivas transformaciones de datos.

Este es claramente un principio asociativo relacionado con el dominio del problema.

**Cohesión Funcional (la mejor)**

En el límite superior del espectro de relación funcional encontramos la cohesión funcional. En un módulo completamente funcional, cada elemento de procesamiento, es parte integral de, y esencial para, la realización de una función simple.

En términos prácticos podemos decir que cohesión funcional es aquella que no es secuencial, por comunicación, por procedimiento, temporal, lógica o casual.

Los ejemplos más claros y comprensibles provienen del campo de las matemáticas. Un módulo para realizar el cálculo de raíz cuadrada ciertamente será altamente cohesivo, y probablemente, completamente funcional. Es improbable que haya elementos superfluos más allá de los absolutamente esenciales para realizar la función matemática, y es improbable que elementos de procesamiento puedan ser agregados sin alterar el cálculo de alguna forma.

En contraste, un módulo que calcule la raíz cuadrada y coseno, es improbable que sea enteramente funcional (deben realizarse dos funciones ambiguas).

En adición a estos ejemplos matemáticos obvios, usualmente podemos reconocer módulos funcionales que son elementales en naturaleza. Un módulo llamado LEER-REGISTRO-MAESTRO o TRATAR-TRANS-TIPO3, presumiblemente serán funcionalmente cohesivos, en cambio TRATAR-TODAS-TRANS presumiblemente realizará más de una función y será lógicamente cohesivo.

### Criterios para establecer el grado de cohesión

Una técnica útil para determinar si un módulo está acotado funcionalmente, es escribir una frase que describa la función (propósito) del módulo y luego examinar dicha frase. Puede hacerse la siguiente prueba:

1.  Si la frase resulta ser una sentencia compuesta, contiene una coma, o contiene más de un verbo, probablemente el módulo realiza más de una función: por tanto, probablemente tienen vinculación secuencial o de comunicación.
2.  Si la frase contiene palabras relativas al tiempo, tales como “primero”, “a continuación”, “entonces”, “después”, “cuando”, “al comienzo”, etc, entonces probablemente el módulo tiene una vinculación secuencial o temporal.
3.  Si el predicado de la frase no contiene un objeto específico sencillo a continuación del verbo, probablemente el módulo esté acotado lógicamente. Por ejemplo _editar todos los datos_ tiene una vinculación lógica; _editar sentencia fuerte_ puede tener vinculación funcional.
4.  Palabras tales como “inicializar”, “limpiar”, etc, implican vinculación temporal.

Los módulos acotados funcionalmente siempre se pueden describir en función de sus elementos usando una sentencia compuesta. Pero si no se puede evitar el lenguaje anterior, siendo aún una descripción completa de la función del módulo, entonces probablemente el módulo no esté acotado funcionalmente.

Es importante notar que no es necesario determinar el nivel preciso de cohesión. En su lugar, lo importante es intentar conseguir una cohesión alta y saber reconocer la cohesión baja, de forma que se pueda modificar el diseño del software para que disponga de una mayor independencia funcional.

**Árbol de valuación**

![](https://gsitic.files.wordpress.com/2018/04/arbol_de_evaluacion.png?w=825)

Análisis de Transformación
--------------------------

### Introducción

> El _Análisis de Transformación, o diseño centrado en la transformación_ , es una estrategia para derivar diseños estructurados que son bastante buenos (con respecto a su modularidad) y que necesitan solo una modesta reestructuración para llegar al diseño final.

Es una forma particular de la estrategia descendente (top-down), que toma ventaja de la perspectiva global. Aplicado rigurosamente, el análisis de transacción conduce a estructuras que son altamente factorizadas. Produce un número variable de módulos en los niveles intermedios de la jerarquía, los cuales representan composición de funciones básicas. Siempre se trata de evitar que los módulos intermedios realicen cualquier “trabajo” excepto el de control y coordinación de sus subordinados.

El propósito de la estrategia es el de identificar las funciones de procesamiento primarias del sistema, las entradas de alto nivel de dichas funciones, y las salidas de alto nivel. Se crean módulos de alto nivel dentro de la jerarquía que realizan cada una de estas tareas: creación de entradas de alto nivel, transformación de entradas en salidas de alto nivel, y procesamiento de dichas salidas.

> El análisis de transformación es un modelo de _flujo de información_ más que un modelo procedural.

La estrategia de análisis de transformación consiste de **cuatro pasos** principales:

1.  Plantear el problema como un diagrama de flujo de datos.
2.  Identificar los elementos de datos aferentes y eferentes.
    -   _Datos Aferentes_ .  
        Son aquellos elementos de datos de alto nivel que habiendo sido removidos de sus entradas físicas, todavía pueden considerarse entradas al sistema.
    -   _Datos Eferentes_ .  
        Son elementos de datos que desde sus salidas física a través de los flujos, hasta que no puedan seguir siendo considerados como datos de salida del sistema.
3.  Factorización del primer nivel.
4.  Factorización de las ramas aferente, eferente y de transformación.

Análisis de Transacción
-----------------------

### Introducción

En el anterior capítulo exploramos la estrategia del análisis de transformación como la estrategia principal para el diseño de programas y sistemas bien estructurados. En verdad, el análisis de transformación, servirá de guía en el diseño de la mayoría de los sistemas. Sin embargo hay numerosas situaciones en las cuales estrategias adicionales pueden utilizarse para suplementar, y aún reemplazar, el enfoque básico del análisis de transformación.

Una de estas estrategias suplementarias principales se conoce como _Análisis de Transacción_ .

El análisis de transacción es sugerido por un DFD del siguiente tipo:

![](https://gsitic.files.wordpress.com/2018/04/analisis_transaccic3b3n.png?w=825)

En este DFD existe una transformación que bifurca la corriente de datos de entrada en varias corrientes de salida discretas. En muchos sistemas tal transformación puede ocurrir dentro de la transformación _central_ . En otros, podremos encontrarla tanto en las ramas aferentes como eferentes del diagrama de estructura.

La frase análisis de transacción sugiere que construiremos un sistema alrededor del concepto de “transacción”, y para muchos la palabra transacción está asociada con sistemas administrativos. Esto si bien es cierto, es común encontrar centros de transacción en los sistemas administrativos, también pueden encontrarse en otro tipo de sistemas como los de tiempo real, aplicaciones de ingeniería, etc.

Un factor importante es como definimos el término transacción. En el sentido más general podemos decir:

> _Una transacción es cualquier elemento de datos, control, señal, evento, o cambio de estado, que causa, dispara o inicia alguna acción o secuencia de acciones._

Acorde a esta definición, un gran número de situaciones encontradas en aplicaciones de procesamiento de datos comunes pueden ser consideradas transacciones. Por ejemplo cualquiera de los siguientes casos pueden considerarse transacciones:

-   El operador presiona el botón de inicio de un dispositivo de entrada.
-   Algún tipo de datos de entrada que designe un ingreso en el inventario.
-   Un carácter de escape desde una terminal, indicando la necesidad e un procesamiento especial.
-   Una interrupción de hardware ante un índice fuera de los rangos definidos dentro de un programa de aplicación.
-   Un cuelgue o descuelgue de teléfono para un sistema de control de llamadas telefónicas.

Bibliografía
------------

-   [Universidad Tecnológica Nacional – F.R.R.](http://exa.unne.edu.ar/informatica/anasistem2/public_html/apuntes/de1.pdf)

