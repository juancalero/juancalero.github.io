<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Hexo</title>
  
  <subtitle>Lorem ipsum dolor sit amet</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://localhost:4000/"/>
  <updated>2019-01-18T10:45:16.569Z</updated>
  <id>http://localhost:4000/</id>
  
  <author>
    <name>Juan Calero</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>B2</title>
    <link href="http://localhost:4000/wiki/B2/b2-index/"/>
    <id>http://localhost:4000/wiki/B2/b2-index/</id>
    <published>2019-01-17T15:11:00.000Z</published>
    <updated>2019-01-18T10:45:16.569Z</updated>
    
    <content type="html"><![CDATA[<p>B2 Tecnología básica   </p><p>01 Tecnologías actuales de ordenadores: de los dispositivos móviles a los superordenadores y arquitecturas escalables y de altas prestaciones. Computación en la nube. Base tecnológica. Componentes, funcionalidades y capacidades.</p><p>02 Conceptos de sistemas operativos: Características, evolución y tendencias. Estructuras, componentes y funciones. Sistemas operativos multiprocesador.</p><p>03 Características técnicas y funcionales de los sistemas operativos: Windows, Linux, Unix y otros. Sistemas operativos para dispositivos móviles.</p><p>04 Características técnicas de los lenguajes y paradigmas actuales de programación.</p><p>05 Inteligencia de negocios: cuadros de mando integral, sistemas de soporte a las decisiones, sistemas de información ejecutiva y almacenes de datos. OLTP y OLAP.</p><p>06 Sistemas de gestión de bases de datos relacionales: características y elementos constitutivos. Antecedentes históricos. El lenguaje SQL. Estándares de conectividad: ODBC y JDBC.</p><p>07 Arquitectura de sistemas cliente-servidor y multicapas: tipología. Componentes. Interoperabilidad de componentes. Ventajas e inconvenientes. Arquitectura de servicios web (WS).</p><p>08 El modelo TCP/IP y el modelo de referencia de interconexión de sistemas abiertos (OSI) de ISO: arquitectura, capas, interfaces, protocolos, direccionamiento y encaminamiento.</p><p>09 Lenguajes de marca o etiqueta. Características y funcionalidades. SGML, HTML, XML y sus derivaciones. Lenguajes de script.</p><p>10 Análisis y gestión de riesgos de los sistemas de información. La metodología MAGERIT: método, elementos, técnicas.</p><p>11 Auditoría Informática: objetivos, alcance y metodología. Técnicas y herramientas. Normas y estándares. Auditoría del ENS y de protección de datos. Auditoría de seguridad física.</p><p>12 Gestión de la atención a clientes y usuarios: centros de contacto, CRM. Arquitectura multicanal. Sistemas de respuesta de voz interactiva (IVR). Voice XML.</p><p>13 Seguridad física y lógica de un sistema de información. Herramientas en ciberseguridad. Gestión de incidentes. Informática forense.</p><p>15 Técnicas de evaluación de alternativas y análisis de viabilidad. Personal, procedimientos, datos, software, hardware. Presupuestación y control de costes de un proyecto informático.</p><p>16 Documática. Gestión y archivo electrónico de documentos. Sistemas de gestión documental y de contenidos. Sindicación de contenido. Sistemas de gestión de flujos de trabajos. Búsqueda de información: robots, spiders, otros. Posicionamiento y buscadores (SEO)</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;B2 Tecnología básica   &lt;/p&gt;
&lt;p&gt;01 Tecnologías actuales de ordenadores: de los dispositivos móviles a los superordenadores y arquitecturas
      
    
    </summary>
    
      <category term="B2" scheme="http://localhost:4000/categories/B2/"/>
    
    
  </entry>
  
  <entry>
    <title>B2-T01</title>
    <link href="http://localhost:4000/wiki/B2/b2-t01/"/>
    <id>http://localhost:4000/wiki/B2/b2-t01/</id>
    <published>2019-01-17T15:11:00.000Z</published>
    <updated>2019-01-18T10:45:16.571Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Tecnologias-actuales-de-ordenadores-de-los-dispositivos-moviles-a-los-superordenadores-y-arquitecturas-escalables-y-de-altas-prestaciones-Computacion-en-la-nube-Base-tecnologica-Componentes-funcionalidades-y-capacidades"><a href="#Tecnologias-actuales-de-ordenadores-de-los-dispositivos-moviles-a-los-superordenadores-y-arquitecturas-escalables-y-de-altas-prestaciones-Computacion-en-la-nube-Base-tecnologica-Componentes-funcionalidades-y-capacidades" class="headerlink" title="Tecnologías actuales de ordenadores: de los dispositivos móviles a los superordenadores y arquitecturas escalables y de altas prestaciones. Computación en la nube. Base tecnológica. Componentes, funcionalidades y capacidades."></a>Tecnologías actuales de ordenadores: de los dispositivos móviles a los superordenadores y arquitecturas escalables y de altas prestaciones. Computación en la nube. Base tecnológica. Componentes, funcionalidades y capacidades.</h1><h2 id="Tecnologias-actuales-de-ordenadores-de-los-dispositivos-moviles-a-los-superordenadores-y-arquitecturas-escalables-grid-cluster-MPP-SMP-arquitecturas-multinucleo-y-otros"><a href="#Tecnologias-actuales-de-ordenadores-de-los-dispositivos-moviles-a-los-superordenadores-y-arquitecturas-escalables-grid-cluster-MPP-SMP-arquitecturas-multinucleo-y-otros" class="headerlink" title="Tecnologías actuales de ordenadores: de los dispositivos móviles a los superordenadores y arquitecturas escalables (grid, cluster, MPP, SMP, arquitecturas multinúcleo y otros)."></a>Tecnologías actuales de ordenadores: de los dispositivos móviles a los superordenadores y arquitecturas escalables (grid, cluster, MPP, SMP, arquitecturas multinúcleo y otros).</h2><h3 id="Tecnologias-actuales-de-ordenadores"><a href="#Tecnologias-actuales-de-ordenadores" class="headerlink" title="Tecnologías actuales de ordenadores"></a>Tecnologías actuales de ordenadores</h3><p>El acrónimo <strong>TIC “Tecnologías de la Información y de la Comunicación”</strong> agrupa elementos y técnicas utilizadas en el tratamiento y transmisión de la información, principalmente de informática, internet y telecomunicaciones.</p><p>Podemos decir que las TIC son herramientas informáticas que almacenan, procesan y presentan información de formas muy diferentes. Estas Tecnologías incluyen ordenadores, internet, tecnologías de radiodifusión (radio y televisión) y telefonía.</p><h3 id="Dispositivos-moviles"><a href="#Dispositivos-moviles" class="headerlink" title="Dispositivos móviles"></a>Dispositivos móviles</h3><p>Generalmente, los dispositivos móviles los definimos como aquellos micro-ordenadores que son lo suficientemente ligeros como para ser transportados por una persona, y que disponen de la capacidad de batería suficiente como para poder funcionar de forma autónoma.</p><p>Es importante destacar que los ordenadores portátiles no se consideran dispositivos móviles debido a que consumen más batería y suelen ser más pesados.</p><p>A grandes rasgos se pueden dividir los dispositivos móviles en tres amplios grupos que son: teléfonos, PDAs y consolas.</p><p><em><strong>Teléfonos</strong></em></p><p>Son los más pequeños del grupo, y por tanto los más ligeros y más transportables. Su función primordial era clara históricamente, lo que hace un teléfono cualquiera: recibir y realizar llamadas; aunque desde hace ya tiempo es impensable concebir un teléfono móvil que solamente haga eso. Funcionalidades propias de ordenadores, o de dispositivos de otro tipo, como la grabación y edición de vídeo, realización de fotografías, lectura de documentos, localización en mapas, navegación por internet, y muchas cosas más.</p><p><em><strong>PDAs (Personal Digital Assistant) (Asistente Personal Digital)</strong></em></p><p>También son conocidos como ordenadores de mano u organizadores electrónicos.</p><p>Su funcionalidad principal es servir como organizadores, con agenda, calendario, gestión de contactos, y posteriormente han ido creciendo, de forma que actualmente sirven tanto como aparatos en los que leer un libro como en los que encontrarse en un mapa. La línea que los separa de los teléfonos es cada vez más difusa.</p><p><em><strong>Consolas</strong></em></p><p>En realidad esta categoría debería llamarse “dispositivos orientados a jugar”, porque son más que simples consolas. Dos de los ejemplos en el mercado son la Sony PlayStation Portable (PSP) y la Nintendo DS, que no sólo sirven para jugar, sino que integran algunas de las funcionalidades típicas de una PDA, como reproducción de archivos multimedia, integración con agenda y calendario, o navegador de internet.</p><h3 id="Dispositivos-fijos-Computadoras"><a href="#Dispositivos-fijos-Computadoras" class="headerlink" title="Dispositivos fijos. Computadoras."></a>Dispositivos fijos. Computadoras.</h3><p>Estos dispositivos requieren de una ubicación física permanente o prácticamente permanente ya que necesitan de una toma de corriente, a no ser que lleven una batería, como los ordenadores portátiles. Aun así, la autonomía de los portátiles es limitada lo que les convierte en dispositivos fijos. Además de su dependencia de la corriente eléctrica, una computadora tiene una envergadura y peso que les convierte en incómodos de trasladar.</p><h4 id="Microordenadores"><a href="#Microordenadores" class="headerlink" title="Microordenadores"></a>Microordenadores</h4><p><em><strong>Ordenador portátil</strong></em></p><p>Llamamos ordenador portátil al ordenador que puede funcionar autónomamente sin necesidad de tenerlo enchufado a la red eléctrica, y el cual puede ser trasladado de un lugar a otro con facilidad.</p><p>Se distinguen tres tipos de portátiles: Deskbook, Desktop y Mobile.</p><ul><li><strong>Deskbook</strong> : Son portátiles de bajo precio. En realidad son utilizados como ordenadores de sobremesa pero que se pueden transportar. Son grandes, pesados y no traen batería.</li><li><strong>Desktop</strong> : Estos son los portátiles por excelencia. Son iguales que los deskbook pero estos sí que tienen batería incorporada, lo que hace que se puedan transportar con mayor facilidad. Son más ligeros y tienen prácticamente las mismas prestaciones que los de sobremesa.</li><li><strong>Mobile</strong> : Pertenecen a la última generación de ordenadores portátiles. Son los más ligeros, se calientan mucho menos y su batería tienen una autonomía mayor. Todo esto hace que sean más manejables. Además, hacen menos ruido. Tienen el mismo rendimiento y prestaciones que un desktop.</li></ul><p><em><strong>Ordenador de sobremesa</strong></em></p><p>El conocido como PC (Personal Computer), Ordenador personal, etc. Es el computador por excelencia.</p><p>Están fabricados para el uso de una persona, son de un tamaño medio… y cumple multitud de funcionalidades.</p><p>Fueron concebidos para usuarios domésticos, pero su potencial y sus programas los han implantado en el ámbito laboral y profesional.</p><p><em><strong>Estaciones de Trabajo o Workstation</strong></em></p><p>Son equipos de gran potencia. Son sofisticados y especialmente diseñados para niveles de alto rendimiento. Suelen ser utilizados para ingeniería, cálculos técnicos, diseño, gráfico, diseño de software, …</p><p>Estas computadoras de gama alta están equipadas con funciones adicionales como por ejemplo, procesadores más rápidos, monitores de alta resolución, tarjetas gráficas potentes, y aplicaciones integradas que vienen instaladas por defecto.</p><p><em><strong>Servidor</strong></em></p><p>Es un ordenador que ha sido optimizado para proveer de servicios a otros ordenadores sobre una red local o de internet. Usualmente disponen de procesadores de alta potencia, mucha memoria y varios discos duros de gran tamaño.</p><h4 id="Miniordenadores"><a href="#Miniordenadores" class="headerlink" title="Miniordenadores"></a>Miniordenadores</h4><p>Son ordenadores de tamaño medio, con unas capacidades intermedias entre ordenadores personales y los grandes ordenadores.</p><p>Pueden ser utilizados por varios usuarios al mismo tiempo y disponen de mayores recursos que los microordenadores.</p><p>Cuentan con una mayor capacidad de proceso, mayor memoria, periféricos más sofisticados y posibilidad de conectar más de un puesto de trabajo. Son también conocidos como ordenadores departamentales.</p><h4 id="Ordenadores-grandes-o-Mainframes"><a href="#Ordenadores-grandes-o-Mainframes" class="headerlink" title="Ordenadores grandes o Mainframes"></a>Ordenadores grandes o Mainframes</h4><p>Son ordenadores de gran capacidad, tanto de procesamiento como de almacenamiento, comunicaciones, etc. Son capaces de gestionar múltiples bases de datos, procesar miles de transacciones al minuto procedentes de miles de terminales a la vez.</p><p>Es frecuente encontrar varios procesadores trabajando en paralelo, lo cual requiere sistemas más complejos y equipos especialistas.</p><h4 id="SuperOrdenadores"><a href="#SuperOrdenadores" class="headerlink" title="SuperOrdenadores"></a>SuperOrdenadores</h4><p>Son ordenadores de gran potencia y elevadísimas prestaciones. Se utilizan principalmente para cálculos científicos que necesitan una gran capacidad de proceso. Es capaz de realizar miles de millones de operaciones por segundo.</p><h3 id="Arquitecturas-Escalables"><a href="#Arquitecturas-Escalables" class="headerlink" title="Arquitecturas Escalables"></a>Arquitecturas Escalables</h3><p>Una arquitectura escalable es aquella que tiene la capacidad de incrementar el rendimiento sin que tenga que rediseñarse y simplemente aprovecha el hardware adicional que se le disponga.</p><p>Generalmente podemos definir la escalabilidad como la capacidad que tiene un sistema informático de modificar su configuración o su tamaño, para ajustarse a los cambios.</p><ul><li><strong>Dimensiones</strong> . La escalabilidad de un sistema se puede medir en distintas dimensiones.</li><li><strong>Escalabilidad de carga</strong> . Esto se hace más fácil mediante un sistema distribuido, podemos ampliar y reducir los recursos con mayor facilidad para adecuar las cargas ya sean pesadas o ligeras según sea necesario.</li><li><strong>Escalabilidad geográfica</strong> . Un sistema es escalable geográficamente cuando su uso y sus ventajas se conservan sin que afecte la distancia de los usuarios.</li><li><strong>Escalabilidad administrativa</strong> . Este debe de manejarse con facilidad sin importar las organizaciones que necesiten compartir un solo sistema distribuido.</li><li><strong>Escalabilidad vertical</strong> . También se dice escala hacia arriba, quiere decir que en un solo nodo del sistema es donde se han agregado más recursos. Ejemplo, añadir memoria a un disco duro de una computadora.</li><li><strong>Escalabilidad horizonal</strong> . Quiere decir que se agregan más nodos a un sistema. Ejemplo, agregar una nueva computadora a un programa de aplicación para espejo.</li></ul><h4 id="MPP-Massive-Parallel-Processing"><a href="#MPP-Massive-Parallel-Processing" class="headerlink" title="MPP (Massive Parallel Processing)"></a>MPP (Massive Parallel Processing)</h4><p>Un computador masivamente paralelo es un sistema de Memoria Distribuida que consiste en muchos nodos individuales, cada uno de los cuales es esencialmente un ordenador independiente en sí mismo, y consiste en al menos un procesador, su propia memoria y un enlace a la red que lo une con el resto de nodos. El término masivo supone cientos o miles de nodos. Los nodos se comunican por paso de mensajes, usando estándares como MPI.</p><p><strong>MPI (Message Passing Interface)</strong></p><p>Una API que permite a procesos comunicarse con otros enviando y recibiendo mensajes. Es un estándar de facto para programas paralelos ejecutándose en clusters de ordenadores y supercomputadores.</p><h3 id="SMP-Symmetric-Multiprocessing"><a href="#SMP-Symmetric-Multiprocessing" class="headerlink" title="SMP (Symmetric Multiprocessing)"></a>SMP (Symmetric Multiprocessing)</h3><p>Una arquitectura multiprocesador donde dos o más procesadores idénticos se conectan a una Memoria Principal compartida y controlado por una sola instancia del sistema operativo. Está claro que está hablando de las máquinas PC de hoy día, donde cada chip es de doble o cuádruple núcleo, hay una memoria principal y hay un sistema operativo en ejecución.</p><h3 id="Grid"><a href="#Grid" class="headerlink" title="Grid"></a>Grid</h3><p>Puede ser visto como un sistema distribuido. Lo que lo distingue de un clúster es que el grid tiende a estar más débilmente acoplado, heterogéneo y geográficamente disperso. Aunque se puede dedicar el grid a una aplicación específica, es más común que un solo grid se use para una variedad de propósitos diferentes. Normalmente los recursos no se administran de forma centralizada, se usan estándares abiertos y se obtiene calidad de servicio.</p><h3 id="Cluster"><a href="#Cluster" class="headerlink" title="Clúster"></a>Clúster</h3><p>Un grupo de ordenadores enlazados, trabajando juntos, colaborando estrechamente, formando uno solo en muchos aspectos. Normalmente están conectados por redes de área local rápidas. El servicio que se suele dar es mejorar la disponibilidad y el rendimiento. Distinguimos estas categorías:</p><ul><li>Clústers de Alta Disponibilidad. Linux-HA es un proyecto que sirve para esto.</li><li>Clústers de Balanceo de Carga.</li><li>Clústers de computación. Donde empezamos a colisionar con el concepto de grid. Se usan para simulaciones, modelado, predicción del tiempo, etc.</li></ul><h3 id="Multinucleo"><a href="#Multinucleo" class="headerlink" title="Multinúcleo"></a>Multinúcleo</h3><p>Los núcleos pueden o no compartir caché y pueden implementar métodos de comunicación:</p><ul><li>paso de mensajes</li><li>memoria compartida</li><li>comunicación internúcleo</li></ul><p>Algunas topologías son:</p><ul><li>bus</li><li>anillo</li><li>malla bidimensional</li><li>crossbar</li></ul><p><em><strong>Ley de Amdahl</strong></em></p><p>Encontrar el máximo nivel de mejora para un sistema completo cuando solo una parte es mejorada. Se usa normalmente en computación paralela para predecir la mejora máxima teórica utilizando múltiples procesadores o núcleos.</p><p>Por ejemplo, si un programa necesita 20 horas en un solo núcleo y una porción particular de 1 hora no puede ser paralelizada, pero las 19 horas restantes sí pueden serlo, entonces independientemente de cuantos procesadores utilicemos el mínimo tiempo de ejecución posible no puede ser menor a esa hora.</p><h2 id="Bibliografia"><a href="#Bibliografia" class="headerlink" title="Bibliografía"></a>Bibliografía</h2><ul><li><a href="http://www.eclap.jcyl.es" rel="external nofollow noopener noreferrer" target="_blank">Escuela de Administración Pública de Castilla y León</a> .</li><li><a href="http://danielside.nom.es/temariogsi2011/Bloque_II_Tema_01_Arquitectura_Ordenadores.html" rel="external nofollow noopener noreferrer" target="_blank">Danielside</a> .</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Tecnologias-actuales-de-ordenadores-de-los-dispositivos-moviles-a-los-superordenadores-y-arquitecturas-escalables-y-de-altas-prestac
      
    
    </summary>
    
      <category term="B2" scheme="http://localhost:4000/categories/B2/"/>
    
    
  </entry>
  
  <entry>
    <title>B3-T19</title>
    <link href="http://localhost:4000/wiki/B3/b3-t19/"/>
    <id>http://localhost:4000/wiki/B3/b3-t19/</id>
    <published>2019-01-17T15:11:00.000Z</published>
    <updated>2019-01-18T10:45:16.876Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Mineria-de-datos-Aplicacion-a-la-resolucion-de-problemas-de-gestion-Tecnologia-y-algoritmos-Procesamiento-analitico-en-linea-OLAP-Big-data-Bases-de-datos-NoSQL"><a href="#Mineria-de-datos-Aplicacion-a-la-resolucion-de-problemas-de-gestion-Tecnologia-y-algoritmos-Procesamiento-analitico-en-linea-OLAP-Big-data-Bases-de-datos-NoSQL" class="headerlink" title="Minería de datos. Aplicación a la resolución de problemas de gestión. Tecnología y algoritmos. Procesamiento analítico en línea (OLAP). Big data. Bases de datos NoSQL."></a>Minería de datos. Aplicación a la resolución de problemas de gestión. Tecnología y algoritmos. Procesamiento analítico en línea (OLAP). Big data. Bases de datos NoSQL.</h1><h2 id="La-mineria-de-datos-Data-Mining"><a href="#La-mineria-de-datos-Data-Mining" class="headerlink" title="La minería de datos: Data Mining"></a>La minería de datos: Data Mining</h2><p>El término minería o recopilación de datos (data mining) hace referencia al proceso de análisis semiautomático de BD de gran tamaño para hallar estructuras útiles. Al igual que la búsqueda de conocimiento en la inteligencia artificial o el análisis estadístico, la minería de datos intenta descubrir reglas y estructuras a partir de los datos. Es decir, la minería de datos trata de la búsqueda del conocimiento en las BD.</p><p>Los almacenes de datos guardan todos los datos relevantes para una organización, estando estructurados para que se pueda extraer información a partir de dichos datos. En este tema vamos a ver como la minería de datos permite sacar el máximo provecho del almacén de datos, ofreciendo una serie de técnicas y herramientas que automatizan (o semiautomatizan) el proceso de extracción de información y significado a partir de los datos que éste contiene.</p><p>El nombre de minería de datos (data mining) deriva de las similitudes entre buscar valiosa información de negocios en grandes BD y minar una montaña para encontrar una veta de metales preciosos. Ambos procesos requieren examinar una inmensa cantidad de material, o investigar inteligentemente hasta encontrar exactamente dónde residen los valores.</p><h3 id="El-proceso-de-descubrimiento-de-conocimiento-en-Bases-de-Datos"><a href="#El-proceso-de-descubrimiento-de-conocimiento-en-Bases-de-Datos" class="headerlink" title="El proceso de descubrimiento de conocimiento en Bases de Datos"></a>El proceso de descubrimiento de conocimiento en Bases de Datos</h3><p>El descubrimiento de conocimiento en las BD es el proceso no trivial de identificación de patrones válidos, potencialmente útiles y comprensibles en los datos. El objetivo es la extracción de conocimiento de los datos, en el contexto de las BD de gran tamaño.</p><p>El proceso es iterativo, consta de unos pasos básicos e involucra decisiones por parte del usuario, siendo interactivo. Esto quiere decir que el proceso requiere el entendimiento del dominio de la aplicación por parte del usuario. Se han identificado los siguientes pasos como componentes del proceso:</p><ul><li>Selección de un conjunto de datos objetivo.</li><li>Preprocesamiento y limpieza de los datos.</li><li>Transformación y reducción en la dimensión de los datos.</li><li>Selección del método de minería de datos y de la técnica (algoritmo) de minería de datos e implementación de la técnica para realizar la extracción de patrones.</li><li>Interpretación o evaluación de los patrones extraídos.</li><li>Consolidación del conocimiento descubierto.</li></ul><p>Por otro lado, el consorcio Cross-Industry Standard Process for Data Mining propuso un modelo estándar y de acceso público del proceso. El modelo es jerárquico y consta de cuatro niveles de abstracción:</p><ul><li>El primer nivel está constituido por una serie de fases las cuales se dividen en tareas generales.</li><li>El segundo nivel se conoce como genérico, ya que, trata de cubrir todas las posibles situaciones de minería de datos.</li><li>El tercer nivel es más especializado, describiendo particularmente qué acciones deben llevarse a cabo dependiendo de situaciones específicas.</li><li>El cuarto nivel es la instanciación del proceso, como un registro de acciones, decisiones y resultados del proceso completo de minería de datos.</li></ul><h3 id="Definiciones-de-Mineria-de-Datos"><a href="#Definiciones-de-Mineria-de-Datos" class="headerlink" title="Definiciones de Minería de Datos"></a>Definiciones de Minería de Datos</h3><p>Veamos ahora una serie de definiciones de minería de datos, que ayudan a entender mejor en qué consiste:</p><ul><li>La minería de datos pretende obtener visiones en profundidad de los datos corporativos que no son fácilmente detectables. De hecho, más que analizar los resultados de la actividad, permite modelizarla construyendo patrones o categorías que la identifiquen, respondiendo a las necesidades de información del tipo ¿qué hay en los datos de interés?, o ¿qué podría ocurrir en un futuro?, en base al descubrimiento de tendencias o agrupaciones interesantes de datos. De hecho, las herramientas enmarcadas bajo la denominación de Minería de Datos (MD), permiten no sólo el análisis de información que tradicionalmente ha venido siendo realizado por los Sistemas de Soporte a la Decisión (DSS), sino, y esto es lo realmente importante y diferencial, el planteamiento y descubrimiento automáticos de hechos e hipótesis, ya sean patrones, reglas, grupos, funciones, modelos, secuencias, relaciones, correlaciones, etc. Una cualidad que resalta es la posibilidad de anticiparse a las variaciones del entorno, lo que facilitará darles una mejor y más rápida respuesta.</li><li>La extracción de información oculta y predecible de grandes BD, es una nueva y poderosa tecnología con gran potencial para ayudar a las compañías a concentrarse en la información más importante de sus Bases de Información (Data Warehouse). Las herramientas de Data Mining predicen futuras tendencias y comportamientos, permitiendo en los negocios tomar decisiones proactivas y conducidas por un conocimiento acabado de la información. Los análisis prospectivos automatizados ofrecidos por un producto así van más allá de los eventos pasados provistos por herramientas retrospectivas típicas de sistemas de soporte de decisión. Las herramientas Data Mining pueden responder a preguntas de negocios que tradicionalmente consumen demasiado tiempo para poder ser resueltas y a los cuales los usuarios de esta información casi no están dispuestos a aceptar. Estas herramientas exploran las BD en busca de patrones ocultos, encontrando información predecible que un experto no puede llegar a encontrar porque se encuentra fuera de sus expectativas.</li><li>La minería de datos consiste en la búsqueda de relaciones y patrones globales que se hallan presentes en las grandes BD pero que están “ocultos” entre el gran volumen de datos existente. Estas relaciones representan un conocimiento útil sobre los objetos de la BD y la realidad que representan.</li></ul><p>Los puntos en común que observamos en las definiciones anteriores son:</p><ul><li>Es necesario disponer de unas BD o, mejor aún, de un almacén de datos, sobre los cuales realizar el proceso de minería.</li><li>El proceso de minería debe ser automático en la mayor medida posible, debido a los grandes volúmenes de datos que se analizan.</li><li>Los resultados obtenidos deben representar conocimiento útil y no evidente a primera vista.</li></ul><p>Después de estudiar el concepto y definiciones de la minería de datos, terminamos este punto poniendo de manifiesto que las aplicaciones de MD extraen conocimiento escondido, patrones de comportamiento no explícitos, relaciones ocultas o información predictiva del almacén, sin necesidad de preguntas o peticiones específicas sino utilizando distintas técnicas, tales como algoritmos matemáticos, métodos estadísticos, modelos lógicos borrosos, algoritmos genéticos, inducciones de reglas, sistemas expertos y sistemas basados en el conocimiento y redes neuronales.</p><h3 id="Fundamentos-de-la-Mineria-de-Datos"><a href="#Fundamentos-de-la-Mineria-de-Datos" class="headerlink" title="Fundamentos de la Minería de Datos"></a>Fundamentos de la Minería de Datos</h3><p>Las técnicas de Minería de Datos son el resultado de un largo proceso de investigación y desarrollo de productos. Esta evolución comenzó cuando los datos de negocios fueron almacenados por primera vez en computadoras, y continuó con mejoras en el acceso a los datos, y más recientemente con tecnologías generadas para permitir a los usuarios navegar a través de los datos en tiempo real.</p><p>La Minería de Datos está lista para su aplicación en la comunidad de negocios porque está soportada por tres tecnologías que ya están suficientemente maduras:</p><ul><li>Recolección masiva de datos.</li><li>Potentes computadoras con multiprocesadores.</li><li>Algoritmos de Data Mining.</li></ul><p>Los componentes esenciales de la tecnología de Data Mining han estado bajo desarrollo durante décadas, en áreas de investigación como la estadística, la inteligencia artificial y el aprendizaje de máquinas. Hoy, la madurez de estas técnicas, junto con los motores de BD relacionales de alto rendimiento, han hecho que estas tecnologías sean prácticas para los entorno de data warehouse actuales.</p><h3 id="Fases-del-proceso-de-Mineria-de-Datos"><a href="#Fases-del-proceso-de-Mineria-de-Datos" class="headerlink" title="Fases del proceso de Minería de Datos"></a>Fases del proceso de Minería de Datos</h3><p>Para alcanzar buenos resultados es necesario comprender que la minería de datos no se basa en una metodología estándar y genérica que resuelve todo tipo de problemas, sino que consiste en una metodología dinámica e iterativa que va a depender del problema planteado, de la disponibilidad de la fuente de datos, del conocimiento de las herramientas necesarias, de la metodología desarrollada, y de los requerimientos y recursos de la empresa.</p><p>El procedimiento para resolver un problema a través de la minería de datos se divide en dos grandes etapas: la preparación de los datos y la minería de datos propiamente dicha.</p><p><strong>Pasos en la fase de preparación de los datos</strong></p><ul><li><em>Planteamiento del problema</em> : Definir de manera objetiva cuál es el problema a resolver, determinar con qué recursos humanos y tecnológicos se cuenta, cuáles son las fuentes de información y cuál es la disponibilidad de la información.</li><li><em>Selección de los datos</em> : De todas las fuentes de información disponibles se debe establecer cuáles son las que se van a considerar. Es decir, se decide sobre qué datos se va a trabajar, tanto desde el punto de vista físico, como desde el punto de vista lógico. Se debe realizar un tratamiento y estructuración de la información con el objetivo de presentarla de la mejor manera posible para posteriores análisis.</li><li><em>Limpieza y preprocesamiento de los datos</em> : En esta fase se analizan los datos con la finalidad de reorganizar la información eliminando aquella que es poco útil o completando la que nos falta. Se eliminan los datos irrelevantes, se unifican los criterios de representación que pueden no ser los mismos en todas las fuentes de datos y se eliminan redundancias y duplicados.</li><li><em>Reducción y proyección de datos</em> : Consiste en encontrar las características útiles que representan las dependencias de los datos en el objetivo del proceso.</li></ul><p><strong>Pasos en la Minería de Datos</strong></p><ul><li><em>Selección de técnicas de minería de datos</em> .</li><li><em>Selección de los algoritmos de minería de datos</em> . En él son seleccionados los métodos para que sean usados en la búsqueda de patrones de los datos. Esto incluye decidir qué modelos y parámetros son más apropiados para la adquisición del tipo de conocimiento deseado. A través de la entrega de los datos para los algoritmos de minería de datos seleccionados se llega al conocimiento.</li><li><em>Extracción del conocimiento. Búsqueda de patrones</em> : Es esta fase donde se escogen y se aplican las técnicas de minería de datos para la determinación de patrones de interés en los datos. Para ello se interpretan los resultados obtenidos a lo largo del proceso para la construcción de modelos o se buscan estructuras subyacentes dentro de la información. Las herramientas de minería de datos, analizan los datos ya preparados para extraer significado e información.</li><li><em>Construcción del modelo. Interpretación y evaluación</em> : Con los resultados obtenidos en la fase anterior se lleva a cabo el análisis, interpretación y evaluación para la determinación de un modelo eficiente que sea útil en la toma de decisiones.</li><li><em>Validación del modelo</em> : Implementar el modelo desarrollado en el proceso real y determinar su efectividad en diferentes casos de aplicación. Si las pruebas arrojan resultados satisfactorios, el modelo queda comprobado y garantizado para su uso regular. Sin embargo, si los resultados son poco satisfactorios, se debería regresar a las fases anteriores y fortalecer el análisis para mejorar el modelo final.</li></ul><h3 id="Elementos-o-Tecnicas-de-la-Mineria-de-Datos"><a href="#Elementos-o-Tecnicas-de-la-Mineria-de-Datos" class="headerlink" title="Elementos o Técnicas de la Minería de Datos"></a>Elementos o Técnicas de la Minería de Datos</h3><p>La aplicación ideal de la MD se llevaría a cabo sobre las BD corporativas, que como ya hemos comentado pueden ser un Almacén de Datos, o sobre otras específicas de propósito departamental (o Data Marts), contemplando elementos o técnicas como los siguientes:</p><ul><li><em>Agentes inteligentes</em> : Se encargan de analizar la información para detectar patrones y relaciones, ya sea de forma automática, o bien interactuando con el analista. Las técnicas que utilizan les permiten identificar grupos, comportamientos y reglas cuyo descubrimiento habría supuesto un enorme esfuerzo de trabajo metódico. Son tomados del campo de la inteligencia artificial y entre ellos destacan los sistemas expertos, el aprendizaje automático, la visión por ordenador o la teoría de juegos. Utilizan estructuras de datos y algoritmos basados en árboles de decisión, redes neuronales, técnicas de agrupamiento y lógica difusa. Estas técnicas son especialmente adecuadas para herramientas de minería que utilizan los modelos predictivo y de descubrimiento, ya que son muy buenas en la detección de patrones.</li><li><em>Detección de alarmas</em> : Consiste en la ejecución periódica o permanente de ciertos agentes para detectar acciones o situaciones susceptibles de desencadenar una acción extraordinaria o fuera del ciclo ordinario, pudiéndose activar en tiempo real, o detectarse y almacenarse para su posterior análisis y tratamiento.</li><li><em>Análisis multidimensional</em> : Se basa en la estructuración y presentación de la información bajo aquellas perspectivas, ejes o dimensiones de interés. Las técnicas multidimensionales son muy buenas para cruzar los datos de múltiples formas y con distintos niveles de agregación. Se basan en la utilización de BD multidimensionales. Los estudiaremos con detalle en el apartado dedicado a OLAP.</li><li><em>Consultas e informes</em> : Ésta es la forma tradicional de obtener información a partir de BD. Las plataformas suelen incorporar herramientas de consulta (lenguaje SQL) con interfaces gráficas muy avanzados, intuitivos y fáciles de usar, cierto grado de análisis multidimensional y agentes inteligentes. Adicionalmente pueden utilizar técnicas matemáticas y estadísticas para analizar los datos obtenidos. Estas técnicas son muy apropiadas si se va a utilizar el modelo de Verificación. Su principal ventaja es que son de eficiencia probada, trabajan sobre las BD relacionales ya existentes y además es muy sencillo encontrar herramientas amigables al usuario que las soporten.</li><li><em>Tratamiento de datos</em> : Los datos suelen estar almacenados en los formatos más adecuados para su gestión por parte de los sistemas existentes, pero pueden no ser los más adecuados para su procesamiento por parte de la MD, de ahí que muchos desarrollos de MD incorporen módulos de tratamiento de datos con el objeto de simplificar al máximo las interfaces de datos e información.</li></ul><h2 id="Aplicacion-a-la-Resolucion-de-Problemas-de-Gestion"><a href="#Aplicacion-a-la-Resolucion-de-Problemas-de-Gestion" class="headerlink" title="Aplicación a la Resolución de Problemas de Gestión"></a>Aplicación a la Resolución de Problemas de Gestión</h2><h3 id="Planteamiento-Inicial-del-Problema"><a href="#Planteamiento-Inicial-del-Problema" class="headerlink" title="Planteamiento Inicial del Problema"></a>Planteamiento Inicial del Problema</h3><p>El desarrollo tecnológico ha aumentado considerablemente la mejora de los sistemas de almacenamiento de datos de las empresas. El problema es que, a medida que aumenta nuestra capacidad para almacenar y acceder a la información, más problemas tenemos para tratarla. Un ejemplo claro lo podemos ver en la “revolución” que ha supuesto internet y en cómo la información que se genera dentro de cualquier campo de nuestro interés aumenta considerablemente cada año, mientras que a su vez, cada vez nos vemos más incapaces de asimilarla.</p><p>En la industria, igualmente, la preocupación de las empresas por producir “mejor y más barato”, la búsqueda constante de reducir “incertidumbre” en el proceso de fabricación y el aumento creciente de la información que se tiene que los procesos productivos, hace que crezca, cada vez más, la necesidad por analizarla. Bien es cierto, que esta necesidad solo aparece cuando la empresa tiene un volumen de históricos del proceso realmente importante.</p><h3 id="El-Analisis-de-la-Informacion"><a href="#El-Analisis-de-la-Informacion" class="headerlink" title="El Análisis de la Información"></a>El Análisis de la Información</h3><p>También la evolución de la tecnología ha facilitado y automatizado en gran medida las tareas de análisis de información. Cada paso en esta evolución se apoya en los anteriores, y cada uno de ellos ha supuesto un avance significativo para el usuario, que ha visto como cada progreso le abría nuevas posibilidades de análisis y aumentaba el nivel de abstracción de las consultas.</p><p>Para decidir cuál es la técnica más adecuada para una determinada situación, es necesario distinguir el tipo de información que se desea extraer de los datos. Según su nivel de abstracción, el conocimiento contenido en los datos puede clasificarse en distintas categorías y requerirá una técnica más o menos avanzada para su recuperación. Éstas son las tres categorías de conocimiento con las que nos podemos encontrar.</p><p><strong>Conocimiento Evidente</strong></p><p>Se trata de la información fácilmente recuperable con una simple consulta (por ejemplo con un lenguaje como el SQL). Un ejemplo de este tipo de conocimiento es una pregunta como “¿Cuáles fueron las ventas en España el pasado marzo?”.</p><p><strong>Conocimiento Multidimensional</strong></p><p>El siguiente nivel de abstracción consiste en considerar los datos con una cierta estructura. Por ejemplo, en vez de considerar cada transacción individualmente, las ventas de una compañía pueden organizarse en función del tiempo y de la zona geográfica, y analizarse con diferentes niveles de detalle (país, región, localidad, …).</p><p>Técnicamente, se trata de reinterpretar una tabla con n atributos independientes como un espacio n-dimensional, lo que permite detectar algunas regularidades difíciles de observar con la representación monodimensional clásica.</p><p>Este tipo de información es la que analizan las herramientas OLAP, que estudiaremos más adelante y que resuelven de forma automática cuestiones como “¿Cuáles fueron las ventas en España el pasado marzo? aumentando el nivel de detalle: mostrar las de Madrid”.</p><p><strong>Conocimiento Oculto</strong></p><p>Se trata de la información no evidente, desconocida a priori y potencialmente útil, que puede recuperarse mediante técnicas de minería de datos, como reconocimiento de regularidades. Esta información es de gran valor, puesto que no se conocía y se trata de un descubrimiento real de nuevo conocimiento, del que antes no se tenía constancia, y que abre una nueva visión del problema. Un ejemplo de este tipo sería “¿Qué tipos de clientes tenemos? ¿Cuál es el perfil típico de cada clase de usuario?”.</p><h3 id="La-Mineria-de-Datos-resuelve-el-problema"><a href="#La-Mineria-de-Datos-resuelve-el-problema" class="headerlink" title="La Minería de Datos resuelve el problema"></a>La Minería de Datos resuelve el problema</h3><p>Como se ha visto en el punto anterior, las técnicas disponibles para extraer la información contenida en los datos son muy variadas y cada una de ellas es complementaria del resto, no excluyentes entre sí. Cada técnica resuelve problemas de determinadas características y para extraer todo el conocimiento oculto, en general será necesario utilizar una combinación de varias.</p><p>La mayor parte de la información de interés contenida en una BD, aproximadamente el 80% corresponde a conocimiento superficial, fácilmente recuperable mediante consultas sencillas con SQL. El 20% restante corresponde a conocimiento oculto que requiere técnicas más avanzadas de análisis para su recuperación. Estas cifras pueden dar la false impresión de que la cantidad de información recuperable mediante técnicas de minería de datos es despreciable. Sin embargo, se trata precisamente de información que puede resultar de vital importancia para la empresa y que no se puede desdeñar.</p><p>Básicamente, y como ya hemos comentado, la clave que diferencia la minería de datos respecto de las técnicas clásicas es que el análisis que realiza es exploratorio, no corroborativo. Se trata de descubrir conocimiento nuevo, no de confirmar o desmentir hipótesis. Con cualquiera de las otras técnicas es necesario tener una idea concreta de lo que se está buscando y, por tanto, la información que se obtiene con ellas está condicionada a la idea preconcebida con que se aborde el problema. Con la minería de datos es el sistema y no el usuario el que encuentra la hipótesis, además de comprobar su validez.</p><p>Por lo tanto, queda claro que el descubrimiento de esta información “oculta” es posible gracias a la minería de datos, que entre otras sofisticadas técnicas aplica la inteligencia artificial para encontrar patrones y relaciones dentro de los datos permitiendo la creación de modelos, es decir, representaciones abstractas de la realidad.</p><p>La obtención de un buen modelo permitirá una buena comprensión del funcionamiento de una empresa, y será una base idónea para la toma de decisiones. Es decir, dado que el objetivo último de la gestión de los datos corporativos es ofrecer información de calidad a la dirección, cuanto más eficiente sea el proceso de minería, mayor será en cantidad y en calidad la información disponible para soportar la toma de decisiones.</p><p>Mediante éstas herramientas y técnicas se pueden obtener patrones y estructuras de información muy valiosas para la industria que pueden ayudar, mediante el análisis de los grandes volúmenes de datos de históricos almacenados, a mejorar la calidad y reducir los costes de los procesos productivos así como comprender mejor las causas que generan fallos en los mismos.</p><p>Los beneficios de la utilización de las técnicas de minería de datos en diversas organizaciones son enormes, de forma que las empresas más innovadoras, las están incorporando con gran éxito de forma extensiva.</p><h3 id="Aplicaciones-de-la-Mineria-de-Datos"><a href="#Aplicaciones-de-la-Mineria-de-Datos" class="headerlink" title="Aplicaciones de la Minería de Datos"></a>Aplicaciones de la Minería de Datos</h3><p>La información hallada a través de las técnicas de minería de datos tiene numerosas aplicaciones en el mundo empresarial.</p><p>Las aplicaciones más usadas son las que necesitan algún tipo de predicción. Por ejemplo, cuando una persona solicita una tarjeta de crédito, la compañía emisora quiere predecir si la persona constituye un buen riesgo de crédito. La predicción tiene que basarse en los atributos conocidos de la persona, como edad, sus ingresos, sus deudas, etc. Las reglas para realizar la predicción se deducen de los mismos atributos de titulares de tarjetas de crédito pasados y actuales, junto con su conducta observada.</p><p>Otra clase de aplicaciones busca asociaciones. Por ejemplo, los libros que se suelen comprar juntos. Si un cliente compra un libro, puede que la librería en línea le sugiera otros libros asociados. Puede que otros tipos de asociación lleven al descubrimiento de relaciones causa-efecto. Por ejemplo, el descubrimiento de asociaciones inesperadas entre un medicamento recién introducido y los problemas cardíacos llevó al hallazgo de que el medicamento podía causar problemas cardíacos en algunas personas. El medicamento se retiró del mercado.</p><p>Las asociaciones son un ejemplo de patrones descriptivos. Las agrupaciones son otro ejemplo de este tipo de patrones.</p><p>Algunos ejemplos de campos de aplicación de la minería de datos en el mundo empresarial son:</p><ul><li>Gestión de mercados y de riesgos.</li><li>Diseño de estrategias competitivas.</li><li>Ingeniería financiera y promoción comercial.</li><li>Detección de fraudes.</li></ul><p>Al igual que en el mundo empresarial, en el medio científico es muy habitual la recolección de gran cantidad de datos, de los que resulta muy difícil extraer conocimiento. Por ello, la minería de datos se está aplicando en campos como:</p><ul><li>Diagnóstico médico.</li><li>Clasificación y estudio de señales biomédicas.</li><li>Detección de patrones en imágenes astronómicas.</li><li>Análisis de biosecuencias en biomedicina.</li><li>Técnicas documentales.</li></ul><p>Estudiamos ahora con más profundidad algunas de las aplicaciones más concretas de la minería de datos dentro de las organizaciones en campos como: marketing, predicción, reducción de riesgos, detección de fraudes y control de calidad.</p><p><strong>Marketing</strong></p><p>Éste es uno de los campos donde los éxitos de la minería de datos son más conocidos. Cuanto más precisa sea la información que tengamos sobre los clientes, mayores posibilidades tendremos de aumentar nuestros ingresos y rentabilizar al máximo nuestras acciones. El objetivo fundamental puede resumirse en determinar quién comprará qué, cuándo y dónde. Veamos tres aplicaciones concretas dentro del marketing:</p><ul><li>Targeting: Podemos aumentar espectacularmente el porcentaje de respuesta a una campaña de marketing si se dirige a los objetivos adecuados. La minería de datos permite detectar entre los potenciales clientes los que presentan una mayor probabilidad de responder a la campaña y dirigirla a ellos específicamente, con lo cual se consigue reducir drásticamente los costes.</li><li>Fidelización de clientes: Conseguir un nuevo cliente o recuperar uno perdido resulta mucho más costoso que mantener uno que ya lo es. De ahí la rentabilidad de las campañas de fidelización de clientes, que detectan aquéllos que parece más probable que se vayan a perder, permitiendo llevar a cabo iniciativas que eviten dicha pérdida.</li><li>La minería de datos también permite detectar nuevas oportunidades de mercado, comparando hábitos de consumo de diferentes clientes, por ejemplo, determinando la ubicación más conveniente para un determinado negocio.</li></ul><p><strong>Predicción</strong></p><p>Conocer a priori cómo evolucionará una variable en el futuro constituye una información muy valiosa y supone una indudable ventaja competitiva. Se trata de una herramienta de evidente interés tanto desde el punto de vista comercial, como en gestión o control de procesos.</p><p>A partir de los datos históricos almacenados y utilizando técnicas de minería de datos pueden elaborarse modelos que permitan estimar con precisión la evolución de una variable de futuro. Disponer de esta información con tiempo suficiente permite adecuar la respuesta de forma óptima. Esto puede resulta útil en los campos más diversos:</p><ul><li>Detección de oportunidades.</li><li>Prevención de problemas.</li><li>Gestión óptima del personal.</li><li>Optimización de stocks.</li></ul><p><strong>Reducción de Riesgos</strong></p><p>La minería de datos permite construir sistemas de evaluación automática de riesgos, basados en la experiencia previa. Estos sistemas resultan de gran utilidad cuando la cantidad de casos a evaluar es excesiva para su procesamiento manual. El empleo de técnicas de minería de datos ha aumentado la eficacia y fiabilidad de dichos sistemas, logrando un comportamiento más similar al de los expertos humanos.</p><p><strong>Detección de Fraudes</strong></p><p>Aplicando técnicas de minería de datos, pueden obtenerse modelos que permitan descubrir posibles fraudes, basándose en la detección de comportamientos anómalos, en comparación con los datos registrados anteriormente.</p><p>Podemos encontrar aplicaciones concretas en operadores de telefonía o empresas de gestión de tarjetas de crédito. Estas compañías analizan el uso que los clientes hacen de sus servicios y pueden localizar, de manera muy rápida, un uso fraudulento de los mismos.</p><p><strong>Control de Calidad</strong></p><p>Existen numerosos ejemplos en los que se han aplicado técnicas de minería de datos para desarrollar sistemas automáticos de control de calidad. Estos sistemas suponen un considerable ahorro en el proceso productivo, puesto que facilitan:</p><ul><li>Detección más precisa de productos defectuosos: A menudo el control de calidad se realiza de forma manual y, por tanto, depende de una evaluación subjetiva por parte del personal encargado del mismo. El principal problema de este método es que el criterio de calidad no es estable sino que depende de la persona que realiza el análisis. La minería de datos permite desarrollar sistemas automáticos de control de calidad que discriminan los productos defectuosos con un alto grado de precisión y fiabilidad, según un criterio objetivo.</li><li>Localización precoz de defectos: El control de calidad no sólo debe realizarse al final del proceso. Cuanto antes se detecte un fallo, menor será su impacto. A menudo no resulta fácil medir la variable que determina la calidad del producto en tiempo real o en la cadena de producción. En estos casos, es imprescindible utilizar técnicas de minería de datos para descubrir posibles relaciones que permitan detectar los fallos utilizando las variables disponibles durante el proceso.</li><li>Identificación de causas de fallos: La minería de datos no sólo resulta útil para discriminar los productos defectuosos. También ayuda a determinar los fallos más frecuentes así como identificar las causas de los mismos. Esto permite adoptar medidas para evitarlos en el futuro.</li><li>Análisis no destructivo: A menudo, para obtener la información que se necesita, hay que realizar un análisis destructivo. Un ejemplo típico es la evaluación de la resistencia de un material, medida que se establece forzándolo hasta que se rompe. Utilizando minería de datos es posible estimar con bastante exactitud el valor de este tipo de parámetros en función de otras características que sí pueden medirse sin destruir el producto. Esto permite controlar la calidad de todos los productos fabricados y no sólo de una pequeña muestra, ya que no se destruyen con el examen.</li></ul><h2 id="Tecnologia-y-Algoritmos"><a href="#Tecnologia-y-Algoritmos" class="headerlink" title="Tecnología y Algoritmos"></a>Tecnología y Algoritmos</h2><p>Antes de estudiar las técnicas y algoritmos principales, vamos a ver los modelos que a lo largo del tiempo han ido apareciendo y en los que se apoya la minería de datos.</p><h3 id="Modelos-de-la-Mineria-de-Datos"><a href="#Modelos-de-la-Mineria-de-Datos" class="headerlink" title="Modelos de la Minería de Datos"></a>Modelos de la Minería de Datos</h3><p><strong>Modelo de Verificación</strong></p><p>Este es el modelo más parecido al proceso tradicional de extracción de información basado en lenguajes de consulta a BD (por ejemplo SQL). Su principal característica es que no extrae información nueva, sino que, basándose en los datos del almacén, verifica la validez de las afirmaciones que se le presentan.</p><p>El proceso comienza por el establecimiento de una hipótesis por parte del usuario. Este, a continuación, solicita a la herramienta que verifique su validez. Una vez recibida la respuesta, el usuario puede refinar o detallar la hipótesis, preparar unas preguntas más específicas y solicitar una nueva verificación. De esta manera se consigue un proceso iterativo dirigido por un operador humano.</p><p>La desventaja de este modelo es, que si al usuario no se le ocurre realizar una pregunta clave, o no ve una relación importante entre diferentes elementos de la BD, la herramienta por sí sola carece de iniciativa para investigar por su propia cuenta.</p><p><strong>Los nuevos Modelos Automáticos</strong></p><p>La minería de datos ha dado lugar a una paulatina sustitución del análisis de datos dirigido a la verificación, por un enfoque de análisis de datos dirigido al descubrimiento del conocimiento. La principal diferencia entre ambos se encuentra en que en el último, se descubre información sin necesidad de formular previamente una hipótesis. La aplicación automatizada de algoritmos de minería de datos permite detectar fácilmente patrones en los datos, razón por la cual esta técnica es mucho más eficiente que el análisis dirigido a la verificación cuando se intenta explorar datos procedentes de repositorios de gran tamaño y complejidad elevada. Dichas técnicas emergentes se encuentran en continua evolución como resultado de la colaboración entre campos de investigación tales como BD, reconocimiento de patrones, inteligencia artificial, sistemas expertos, estadística, visualización, recuperación de información, y computación de altas prestaciones.</p><p>Los algoritmos de minería de datos se clasifican en dos grandes categorías de modelos con distintas denominaciones:</p><ul><li>Modelos predictivos, también llamados:<ul><li>Modelos supervisados.</li><li>Modelos basados en la memoria.</li><li>Minería de datos dirigida.</li></ul></li><li>Modelos de descubrimiento del conocimiento, también llamados:<ul><li>Modelos no supervisados.</li><li>Modelos descriptivos.</li><li>Minería de datos no dirigida.</li></ul></li></ul><p>Por lo tanto con los nuevos modelos usamos la minería de datos para:</p><ul><li><em>Predecir</em> : Utilizar algunas variables o campos en un BD para predecir valores desconocidos o futuros.</li><li><em>Describir</em> : Encontrar patrones que describan la información (interpretables por el hombre).</li></ul><p><strong>Modelos Predictivos</strong></p><p>Los algoritmos supervisados o predictivos predicen el valor de un atributo (etiqueta), de un conjunto de datos, conocidos otros atributos (atributos descriptivos). A partir de datos cuya etiqueta se conoce, se induce una relación entre dicha etiqueta y otra serie de atributos. Esas relaciones sirven para realizar la predicción en datos cuya etiqueta es desconocida. Esta forma de trabajar se conoce como aprendizaje supervisado y se desarrolla en dos fases:</p><ul><li>Entrenamiento: Construcción de un modelo usando un subconjunto de datos con etiqueta conocida.</li><li>Prueba: Prueba del modelo sobre el resto de los datos.</li></ul><p>El usuario indica sobre qué variables se quiere obtener la predicción y el sistema proporciona la respuesta. Esta respuesta la puede proporcionar explicando cómo la consiguió, lo cual a su vez puede ser una información tan valiosa como la respuesta en sí misma, o sin explicarlo.</p><p>Cuando una aplicación no es lo suficientemente madura no tiene el potencial necesario para una solución predictiva fiable. En este caso se puede optar por diversos caminos alternativos:</p><ul><li>Modelo predictivo restringido: No se obtiene predicción alguna.</li><li>Modelo predictivo no restringido: Se obliga a la realización de una predicción de menor fiabilidad.</li><li>Modelos de descubrimiento del conocimiento: Que descubren patrones y tendencias en los datos actuales (no utilizan datos históricos).</li></ul><p>Ejemplos: ¿Cuál es el riesgo de este cliente?, ¿Se quedará el cliente?</p><p>Algunas técnicas asociadas a los modelos predictivos:</p><ul><li>Clasificación: Clasificar datos en clases predefinidas.</li><li>Estimación: A diferencia de la clasificación (que trata con resultados discretos), la estimación trata con valores numéricos continuos. A partir de un conjunto de valores de entrada, la estimación obtiene un valor para cierta variable continua, como puede ser una renta, la altura, etc.</li><li>Predicción de valores: Una predicción no es más que un tipo de clasificación o estimación.</li><li>Regresión: función que convierte datos en valores de una función de predicción.</li><li>Árboles de decisión: Son estructuras en forma de árbol que representan conjuntos de decisiones. Estas decisiones generan reglas para la clasificación de un conjunto de datos.</li><li>Redes neuronales artificiales: Modelos predecibles no lineales que aprenden a través del entrenamiento y semejan la estructura de una red neuronal biológica.</li><li>Series temporales.</li></ul><p><strong>Modelos de Descubrimiento del Conocimiento</strong></p><p>El objetivo de estos modelos es establecer algún tipo de relación entre todas las variables.</p><p>En estos modelos se utiliza la herramienta de minería para descubrir nueva información que no estaba anteriormente en el almacén de forma explícita. Según este modelo es la propia herramienta quien se plantea sus propias preguntas, sin necesidad de que el usuario establezca hipótesis o realice preguntas concretas, aunque, éste puede intervenir para guiar los caminos a explorar.</p><p>Habitualmente esta búsqueda se dirige hacia la categorización de los registros en grupos para detectar patrones aplicables o extraer relaciones implícitas en los datos. También es común la búsqueda de elementos extraños o fuera de lo normal.</p><p>Ejemplo: Un cliente que compra productos dietéticos es tres veces más probable que compre caramelos.</p><p>Algunas técnicas asociadas a los modelos de descubrimiento del conocimiento:</p><ul><li>Asociación: Permite establecer las posibles relaciones entre acciones o sucesos aparentemente independientes.</li><li>Reconocimiento de patrones: Permite la asociación de una señal o información de entrada con aquella o aquellas con las que guarda mayor similitud, y que ya están catalogadas en el sistema.</li><li>Segmentación o agrupamiento: Esta herramienta posibilita la identificación de tipologías o grupos en los cuales los elementos guardan similitud entre sí y se diferencian de los de otros grupos.</li><li>Clustering: Es la tarea de segmentar un grupo diverso en un número de subgrupos más similar (denominados clusters). Lo que distingue el clustering de la clasificación es que éste no requiere un conjunto predefinido de clases.</li><li>Reglas de asociación: Se trata del agrupamiento por afinidad que tiene como objetivo determinar qué cosas van juntas.</li><li>Detección de desviaciones.</li></ul><h3 id="Clasificacion"><a href="#Clasificacion" class="headerlink" title="Clasificación"></a>Clasificación</h3><p>Dentro de los modelos de predicción, una de las técnicas más importantes es la clasificación. En este apartado vamos a describir qué es la clasificación, a estudiar técnicas para la creación de un tipo de clasificadores, denominados clasificadores de árboles de decisión y se analizarán otras técnicas de predicción.</p><p>De manera abstracta, el problema de la clasificación es el siguiente: dado que los elementos pertenecen a una de las clases y dados los casos pasados de los elementos junto con las clases a las que pertenecen, el problema es predecir la clase a la que pertenece un elemento nuevo.</p><p>La clasificación se puede llevar a cabo hallando reglas que dividan los datos dados en grupos disjuntos. Continuando con el ejemplo de un banco tiene que decidir si debe conceder una tarjeta de crédito a un solicitante. El banco tiene diversa información sobre esa persona, la cual puede utilizar para adoptar una decisión. Para adoptar la decisión el banco asigna un nivel de valor de crédito de: excelente, bueno, mediano o malo a cada integrante de un conjunto de muestras de clientes actuales según su historial de pagos. Luego, el banco intenta hallar reglas que clasifiquen a sus clientes como excelentes, buenos, medianos o malos.</p><p>El proceso de creación de clasificadores comienza con un muestra de los datos, denominada <em>conjunto de formación</em> . Para cada tupla del conjunto de formación ya se conoce la clase a la que pertenece. Existen diversas maneras de crear clasificadores. Una de las técnicas más utilizadas para este fin son los clasificadores de árboles de decisión.</p><p><strong>Clasificadores de árboles de decisión</strong></p><p>Los clasificadores de árboles de decisión son una técnica muy utilizada para la clasificación. Como sugiere su nombre estos clasificadores utilizan un árbol. Cada nodo hoja tiene una clase asociada, y cada nodo interno tiene un predicado o función asociado.</p><p>Continuando con el ejemplo, para concretar las reglas que clasifican los clientes en excelentes, buenos, medianos o malos, vamos a considerar dos atributos: titulación e ingresos. En la siguiente figura se muestra un árbol de decisión que establece las reglas concretas de clasificación.</p><p><img src="https://gsitic.files.wordpress.com/2018/01/arboles_decision.png?w=825" alt=""></p><p>Para clasificar un nuevo caso se empieza por la raíz y se recorre el árbol hasta alcanzar una hoja. En los nodos internos se evalúa el predicado o función, para hallar a que nodo hijo hay que ir. El proceso continúa hasta llegar a un nodo hoja.</p><p><strong>Creación de Clasificadores de árboles de decisión</strong></p><p>La pregunta que se plantea es el modo de crear un clasificador de árboles de decisión, dado un conjunto de casos de formación. La manera más frecuente de hacerlos es utilizar un algoritmo <em>impaciente</em> , que trabaja de manera recursiva, comenzando por la raíz y construyendo el árbol hacia abajo. Inicialmente solo hay un nodo, la raíz, y todos los casos de formación están asociados con este nodo.</p><p>En cada nodo, si todos o casi todos los ejemplos de formación asociados con el nodo pertenecen a la misma clase, el nodo se convierte en un nodo hoja a esa clase. En caso contrario, hay que seleccionar un <em>atributo de partición</em> o <em>condiciones de partición</em> para crear nodos hijos. En el ejemplo elegido, se escoge el atributo titulación y se crean cuatro hijos, uno por cada valor de la titulación.</p><p>Las particiones en menor número de conjuntos son preferibles a las particiones en muchos conjuntos, ya que llevan a árboles de decisión más sencillos y significativos.</p><p>Hay que averiguar el modo de hallar la mejor partición para un atributo. El modo de dividir un atributo depende del tipo de atributo. Los atributos pueden tener dos tipos de valores:</p><ul><li><em>Valores continuos</em> : Los valores se pueden ordenar de manera significativa para la clasificación, como la edad o los ingresos.</li><li><em>Valores categóricos</em> : No tienen ningún orden significativo para la clasificación, como los nombres de los departamentos o de los paises.</li></ul><p>Generalmente los atributos que son números se tratan como valores continuos, y los atributos de cadenas de caracteres se tratan como categóricos. En el ejemplo escogido se ha tratado el atributo titulación como categórico y el atributo ingresos como valor continuo.</p><p>En primer lugar se considera el modo de hallar las mejores particiones para los atributos continuos. Por sencillez solo se consideran <em>particiones binarias</em> de los atributos con valores continuos, es decir, particiones que den lugar a dos hijos. En caso de las <em>particiones múltiples</em> ya es más complicado y se pueden dar con valores continuos o categóricos.</p><p>Para los atributos categóricos se pueden tener particiones múltiples, con un hijo para cada valor del atributo. Esto funciona muy bien para los atributos categóricos con pocos valores diferentes, como la titulación o el sexo.</p><p>La idea principal de construcción de árboles de decisión es la evaluación de los diferentes atributos y de las distintas condiciones de partición y la selección del atributo y de la condición de partición que generen el índice máximo de ganancia de información. El mismo procedimiento funciona de manera recursiva en cada uno de los conjuntos resultantes de la partición, lo que hace que se construya de manera recursiva el árbol de decisión.</p><p><strong>Otros Tipos de Clasificadores</strong></p><p>Hay varios tipos de clasificadores a parte de los clasificadores de árbol. Dos tipos que han resultado bastante útiles son:</p><ul><li><em>Clasificadores de redes neuronales</em> : Utilizan los datos de formación para adiestrar redes neuronales artificiales.</li><li><em>Clasificadores bayesianos</em> : Hallan la distribución de los valores de los atributos para cada clase de los datos de formación.</li></ul><p><strong>Regresión</strong></p><p>La regresión trata la predicción de valores, no de clases. Dados los valores de un conjunto de variables, X1, X2, …, Xn se desea predecir el valor de una variable Y. Por ejemplo se puede tratar el nivel educativo con un número y los ingresos con otro número, y con base a estas dos variables, querer predecir la posibilidad de impago, que podría ser un porcentaje de probabilidad de impago o el importe impagado.</p><h3 id="Asociaciones"><a href="#Asociaciones" class="headerlink" title="Asociaciones"></a>Asociaciones</h3><p>Como ya se dijo, las asociaciones permiten establecer las posibles relaciones entre acciones o sucesos aparentemente independientes. Así, se puede reconocer cómo la ocurrencia de un determinado suceso puede inducir la aparición de otro u otros. Este tipo de herramientas son particularmente útiles, por ejemplo, para comprender los hábitos de compra de los clientes y para la concepción de ofertas, de ventas cruzadas y del “merchandising”.</p><p>Los comercios en general suelen estar interesados en las asociaciones entre los diferentes artículos que compra la gente. Ejemplos de estas asociaciones son:</p><ul><li>Alguien que compra pan es bastante probable que compre también leche.</li><li>Una persona que compró un libro X es bastante probable que también compre el libro Y.</li></ul><p><strong>Reglas de Asociación</strong></p><p>Un ejemplo de regla de asociación es: <em>pan =&gt; leche</em> . En el contexto de las compras de alimentación, la regla dice que los clientes que compran pan también tienden a comprar leche con una probabilidad elevada.</p><p>Una regla de asociación debe tener una población asociada: la población consiste en un conjunto de casos. En el ejemplo de la tienda de alimentación, la población puede consistir en todas las compras en la tienda de alimentación, cada compra es un caso.</p><p>Las reglas tienen un soporte, así como una confianza asociados. Los dos se definen en el contexto de la población:</p><ul><li><em>El soporte</em> : Es una medida de la fracción de la población que satisface tanto el antecedente como el consecuente de la regla. Por ejemplo, supongamos que solo el 0,001% de todas las compras incluyen leche y clavos. El soporte de la regla <em>leche =&gt; clavos</em> es bajo. Las empresas no suelen estar interesadas en reglas que tienen un soporte bajo, ya que afectan a pocos clientes y no merece la pena prestarles atención.</li><li><em>La confianza</em> : Es una medida de la frecuencia con que el consecuente es cierto, cuando lo es el antecedente. Por ejemplo la regla <em>pan =&gt; leche</em> tiene una confianza del 80% si el 80% de las compras que incluyen pan incluyen también leche. Hay que tener en cuenta que la confianza de <em>pan =&gt; leche</em> puede ser muy diferente de la confianza <em>leche =&gt; pan</em> , aunque las dos tiene el mismo soporte.</li></ul><p><strong>Otros Tipos de Asociación</strong></p><p>El uso de meras reglas de asociación tiene varios inconvenientes. Uno de los principales es que muchas asociaciones no son muy interesantes, ya que pueden predecirse. Por ejemplo, si mucha gente compra cereales y mucha gente compra pan, se puede predecir que un número bastante grande de personas comprará las dos cosas, aunque no haya ninguna relación entre las dos compras. Lo que resultaría interesante es una desviación de la ocurrencia conjunta de las dos compras. O dicho en términos estadísticos, lo que se busca son <em>correlaciones</em> entre los artículos.</p><p>Otro tipo importante son las asociaciones de secuencias. Las series de datos temporales, como las cotizaciones bursátiles en una serie de días, constituyen un ejemplo de datos de secuencias.</p><h2 id="Bases-de-Datos-Multidimensionales"><a href="#Bases-de-Datos-Multidimensionales" class="headerlink" title="Bases de Datos Multidimensionales"></a>Bases de Datos Multidimensionales</h2><p>La idea básica empleada por las BD multidimensionales (BDM) es muy sencilla: en lugar de utilizar tablas bidimensionales para almacenar los datos, como se hace en una BD relacional (BDR), emplea tablas n-dimensionales (o hipercubos). Es algo parecido a utilizar una hoja de cálculo para el tratamiento de datos, solo que, se podrán utilizar más de dos dimensiones y se dispondrá de otras capacidades adicionales.</p><p>Una BDM está diseñada para los sistemas de soporte de decisiones en la cual los datos tienen una estructura matricial (multidimensional) para su almacenamiento. Este tipo de organización admite consultas más complejas.</p><h3 id="Analisis-Multidimensional"><a href="#Analisis-Multidimensional" class="headerlink" title="Análisis Multidimensional"></a>Análisis Multidimensional</h3><p>El análisis multidimensional consiste en analizar hechos económicos o, de otros tipos, desde la perspectiva de sus dimensiones, abarcando los diferentes niveles de éstas.</p><p>Con el análisis multidimensional se da respuesta a las consultas complicadas de los usuarios, que reflejan los diversos componentes que tienen sus organizaciones. Estos componentes puedes ser de dos tipos: cuantitativos y cualitativos.</p><p>A estos componentes también se les llama dimensiones, y a los valores de los componentes (o dimensiones) se les llama atributos. Además, el detalle con el que se muestran los atributos puede variar, cada dimensión se puede descomponer en diferentes niveles de detalle, y éstos dependen de las necesidades del usuario.</p><p>Las dimensiones definen dominios como geografía, producto, tiempo, cliente, …</p><p>Los miembros de una dimensión se agrupan de forma jerárquica (dimensión geográfica: ciudad, provincia, autonomía, país, …).</p><p><strong>El Esquema Multidimensional</strong></p><p>La realización del análisis multidimensional a partir de trozos de información no sería nada práctica, lo que se pretende es tener disponible toda la información formando un solo conjunto, al que llamaremos esquema multidimensional.</p><p>Una de las características principales del esquema multidimensional es la agregabilidad, gracias a la cual se pueden presentar los valores de una determinada dimensión según sus distintos niveles de detalle. Como es lógico para poder realizar agregación es necesario tener datos en el nivel más bajo de cada dimensión, y los niveles superiores se calcularán a partir de éstos.</p><p>Para un óptimo análisis este esquema se soporta en las BBDD multidimensionales, éstas almacenan los datos en estructuras llamadas hipercubos (más de tres dimensiones). En la práctica estos hipercubos no son grandes matrices, sino que son matrices más reducidas que aparecen como una sola matriz. Esto reduce el espacio de índice requerido.</p><p>El esquema multidimensional puede ser soportado encima de un SGBD relacional (ROLAP: OLAP sobre BD Relacionales). Para ello el esquema multidimensional deberá ser transformado para poder implementarse sobre un SGBD relacional (que solo soporta tablas planas). Una de las formas de hacer esta transformación es utilizar el “esquema en estrella”, que estudiaremos más adelante.</p><p><strong>Características del Análisis Multidimensional</strong></p><ul><li>Navegabilidad: Cuando se habla de navegar se refiere a que se puede pasar de un punto a otro del esquema multidimensional. Estos movimientos son:<ul><li>Perforación (drill-down): Consiste en variar el nivel de detalle de los datos, desde los datos más resumidos a los más detallados. Se dice que drill-down es desagregar y Roll-up es agregar.</li><li>Segmentación (slice and dice): Consiste en “recortar” un subconjunto de los datos moviéndose por los distintos datos de una misma dimensión o cambiando de dimensión. Es decir, es la capacidad de ver la BD desde diferentes puntos de vistas. El corte suele hacerse a lo largo del eje del tiempo para analizar tendencias. Se dice que <em>slice</em> es proyección y que <em>dice</em> es selección.</li></ul></li><li>Visualización: La presentación de los resultados se suele hacer en forma de cuadros o tablas de dos dimensiones, con el cálculo de totales parciales y generales. Se suelen fijar un conjunto de valores de dimensiones y mostrar en la tabla de dos dimensiones los valores en función de esas dimensiones.</li><li>Representación gráfica: Suele ser un gráfico de dos dimensiones, donde los valores de las dimensiones fijadas aparecen como comentarios y las dimensiones variables son los ejes de coordenadas. Con este tipo de representaciones se suele perder una dimensión.</li><li>Representación mediante mapas: Muy utilizada para dimensiones geográficas, donde se realizan perforaciones seleccionando la zona deseada.</li><li>Cálculos dinámicos.</li></ul><h3 id="Modelo-de-Datos-Multidimensional-MDM"><a href="#Modelo-de-Datos-Multidimensional-MDM" class="headerlink" title="Modelo de Datos Multidimensional (MDM)"></a>Modelo de Datos Multidimensional (MDM)</h3><p>Se define un modelo de datos multidimensional como la disciplina específica para modelizar datos que es una alternativa a la modelización E/R. Es un modelo de datos (estático y dinámico) basado en estructuras multidimensionales.</p><p>Un modelo multidimensional contiene la misma información que un modelo E/R pero agrupa la información en un formato simétrico cuyos objetivos serían:</p><ul><li>Que el usuario entienda mejor el modelo.</li><li>Que el rendimiento y tiempo de respuesta de las consultas sea el óptimo.</li><li>Que los cambios en el modelo se hagan con menos impacto y mayor facilidad.</li></ul><p>Veamos ahora los elementos que componen la visión estática de un modelo de datos multidimensional:</p><ul><li>Esquema de hecho (esquema de cubo): Es el objeto a analizar. Ejemplos: empleados, ventas, stocks, …</li><li>Atributos de hecho o de medida: Atributos de tipo cuantitativo cuyos valores (cantidades) se obtienen generalmente por aplicación de una función estadística que resume un conjunto de valores en un único valor. Ejemplos: nº de empleados, cantidad vendida, precio medio, …</li><li>Funciones resumen: Funciones de tipo estadístico que se aplican a los atributos de hecho. Ejemplos: frecuencia, suma, media, máximo, etc.</li><li>Dimensiones: Cada uno de los ejes en un espacio multidimensional. Ejemplos: tiempo, espacio, productos, intervalos del nº de empleados, departamentos, etc.</li><li>Atributos de dimensión o de clasificación: Atributos de tipo cualitativo (sus valores son modalidades) que suministran el contexto en el que se obtienen las medidas en un esquema de hecho. Ejemplos: días, semanas, ciudades, provincias, etc.</li><li>Jerarquías: Varios atributos de dimensión unidos mediante una relación de tipo jerárquico. Ejemplos: día -&gt; semana -&gt; mes -&gt; año.</li><li>Series temporales: Una de las dimensiones más habituales de cualquier BDM es el tiempo. Para guardar datos en función del tiempo, se utilizan las series temporales, que son tratadas como una dimensión más.</li></ul><p>Vamos a estudiar ahora con más detalle dos de los elementos fundamentales en las BDM: las dimensiones y las jerarquías. Utilizaremos para ello una serie de ejemplos que nos van a ayudar a entender mejor estos dos elementos.</p><h3 id="Dimensiones"><a href="#Dimensiones" class="headerlink" title="Dimensiones"></a>Dimensiones</h3><p><strong>Ejemplo 1</strong></p><p>Supongamos que queremos implementar una sencilla BD para almacenar la cantidad de dinero que se gasta en el pago de las pensiones atendiendo al tipo de pensión y a la comunidad autónoma en que se paga.</p><p>En el caso de que hubiera dos tipos de pensiones, se podría establecer una BDM con una estructura similar a la de una hoja de cálculo, empleando tantas filas como tipos de pensiones y tantas columnas como comunidades. El gasto correspondiente a cada comunidad y pensión se almacenaría en la celdilla correspondiente, tal como se muestra a continuación:</p><p><img src="https://gsitic.files.wordpress.com/2018/01/bdm1.png?w=825" alt=""></p><p>El equivalente relacional sería una tabla de 34 filas y 3 columnas: tipo de pensión, comunidad autónoma y gasto.</p><p>En este ejemplo sencillo, el espacio de almacenamiento utilizado en ambos casos es el mismo, pero, ¿qué ocurre con los tiempos de acceso a la información?</p><p>Si se quiere acceder al gasto en un tipo de pensión y una comunidad determinados (una sola fila), el tiempo de acceso será similar, siempre que la tabla relacional esté ordenada o tenga definido un índice por tipo de pensión y comunidad autónoma.</p><p>Si se quiere obtener el gasto en pensiones de tipo 1 (P1) para todas las comunidades, entonces el tiempo de respuesta de la BDM es mejor, ya que solo tiene que sumar una fila de la matriz (17 sumas). En cambio en la BDR se debe recorrer todos los registros de la tabla para localizar aquellos que cumplan la condición definida (34 registros) o crear más índices.</p><p><strong>Ejemplo 2</strong></p><p>Supongamos ahora, que también es necesario almacenar la forma de pago de las pensiones y que dicha forma de pago puede ser en efectivo, por talón o transferencia. La BDM tendría el aspecto siguiente:</p><p><img src="https://gsitic.files.wordpress.com/2018/01/bdm2.png?w=825" alt=""></p><p>En esta estructura se emplea cada una de las tres dimensiones del cubo para representar cada uno de los campos que se utilizarían en el modelo relacional. Las celdas resultantes se emplean para almacenar el gasto para cada tripleta (CA, TP, FP).</p><p>El equivalente relacional sería una tabla con 102 filas y 4 columnas: tipo de pensión, comunidad autónoma, forma de pago y gasto.</p><p>De nuevo, las consultas de agregados (totales) serían más costosas en la BDR que en la BDM.</p><h3 id="Jerarquias"><a href="#Jerarquias" class="headerlink" title="Jerarquías"></a>Jerarquías</h3><p>Otro aspecto fundamental de las BDM es la posibilidad de jerarquizar las dimensiones. Vamos a ver esto con otro ejemplo.</p><p><strong>Ejemplo 3</strong></p><p>Supongamos que, además de conocer el gasto por comunidades, se quiere saber también el gasto por localidades dentro de cada comunidad.</p><p>La manera inmediata de representar esto consiste en añadir una nueva dimensión para crear un hipercubo de cuatro dimensiones. Sin embargo esta solución no es eficiente, ya que para cada fila de cada localidad, solo una de las celdillas contendrá el valor. Dicha celdilla será la correspondiente a la comunidad a la que pertenece la localidad.</p><p>Con esta estructura se gasta mucho espacio de almacenamiento en celdillas que jamás van a contener datos, por lo tanto hay que buscar otro mecanismo que lo evite. La solución a este problema es crear una jerarquía de niveles en cada dimensión para representar los diversos grados de detalle.</p><p>Si se dispone de este mecanismo, la solución al caso de las localidades sería tan simple como jerarquizar la dimensión de las comunidades autónomas, estableciendo las localidades como escalón inferior en la jerarquía.</p><p>Para ofrecer esta alternativa el gestor debe ser capaz, de operar con las celdillas, de reconocer si el valor almacenado corresponde a una comunidad o a una localidad, de forma que al hallar totales o realizar cualquier otro tipo de operación no mezcle valores correspondientes a diferentes niveles jerárquicos.</p><p>Por lo tanto, una celda es una posición formada por la intersección de cada uno de los elementos de las dimensiones que forman el cubo. La celda puede contener cero, uno o varios datos (cantidades).</p><p>Este concepto de jerarquía es extensible a más de dos niveles, por lo que se puede afinar el grado de detalle obtenido al realizar las consultas.</p><h3 id="BD-Multidimensionales-vs-BD-Relacionales"><a href="#BD-Multidimensionales-vs-BD-Relacionales" class="headerlink" title="BD Multidimensionales vs BD Relacionales"></a>BD Multidimensionales vs BD Relacionales</h3><p>Terminamos este apartado de BDM realizando una comparación entre estas BD y las BDR que son más conocidas.</p><p>La utilización de BDM ofrece ventajas sobre las BDR siempre que se vaya a trabajar sobre datos agregados, totales, subtotales, etc. También son superiores a la hora de trabajar con series temporales, obtener vistas de unos datos en función de otros (vistas bidimensionales del hipercubo que forma la BDM) y manejar diversos grados de detalle. En resumen son unas BD adecuadas para el estudio de alto nivel de los datos, al ofrecer una mayor flexibilidad y rapidez de acceso para el análisis de los mismos.</p><p>Por otra parte, si lo que se quiere es acceder a un dato individual básico, la ventaja de las BDM desaparece a favor de las BDR. Estas son capaces de recuperar un dato individual con la misma eficiencia que las multidimensionales, suelen ser capaces de almacenar mayor cantidad de información y además, dada su utilización masiva en sistemas OLTP, están optimizadas para la inserción de registros y el control concurrente de usuarios.</p><p>La utilización de ambos tipos de BD no es excluyente. De hecho es frecuente utilizar una BDR para almacenar los datos de nivel más bajo de la jerarquía de una BDM, de forma que si se desea obtener un dato básico, se excava a través de la jerarquía multidimensional hasta acceder a la BDR.</p><h2 id="Procesamiento-Analitico-en-Linea-OLAP"><a href="#Procesamiento-Analitico-en-Linea-OLAP" class="headerlink" title="Procesamiento Analítico en Línea (OLAP)"></a>Procesamiento Analítico en Línea (OLAP)</h2><p>Dado que el volumen de datos almacenados en las BD suele ser elevado, hay que resumirlos de algún modo si se quiere obtener información que puedan utilizar los usuarios. Las herramientas OLAP soportan el análisis interactivo de la información de resumen.</p><h3 id="Definicion-de-OLAP"><a href="#Definicion-de-OLAP" class="headerlink" title="Definición de OLAP"></a>Definición de OLAP</h3><p>El acrónimo OLAP significa Procesamiento Analítico en Línea (On-Line Analytical Processing), y se utiliza para hacer referencia a sistemas y herramientas de minería de datos que usan técnicas multidimensionales para la extracción y el análisis de los datos.</p><p>Según E.F. Codd, que fue quién acuñó el término, OLAP es: la síntesis, el análisis y la consolidación dinámica de grandes volúmenes de datos multidimensionales.</p><p>Según otra definición de OLAP: se trata de un término inventado para describir una aproximación dimensional interactiva al soporte de toma de decisiones (análisis desde la perspectiva de sus componentes o dimensiones, contemplando también los distintos niveles o jerarquías que éstas poseen).</p><p>Siempre que se habla de tecnología OLAP el adjetivo más utilizado es “multidimensional”, ya sea para referirse a los datos, a su estructura, a la BD que se emplea o a casi cualquier otro aspecto del OLAP. Esta caracterización llega hasta el punto de identificar el OLAP y las BD multidimensionales como una misma cosa. Aunque indudablemente ambas tecnologías están relacionadas, la utilización de OLAP no implica necesariamente la utilización de BD multidimensionales.</p><p>La pregunta que debemos respondes es, ¿qué requiere el usuario de OLAP? La respuesta es:</p><ul><li>Conceptos familiares para el usuario final: Dimensiones, medidas y jerarquías.</li><li>Acceso inmediato a los datos.</li><li>Información consistente.</li><li>Navegación y consulta sencillas.</li><li>Capacidades de generación de informes.</li><li>Datos precalculados.</li><li>Soporte de grandes volúmenes de datos.</li><li>Flexibilidad de manejo y presentación.</li><li>Potentes capacidades de análisis: Agregaciones, comparaciones, ratios, correlaciones, análisis de situaciones, contraste de hipótesis, descubrimiento de patrones y tendencias, previsiones, series temporales, etc.</li></ul><h3 id="Caracteristicas-de-los-Sistemas-OLAP"><a href="#Caracteristicas-de-los-Sistemas-OLAP" class="headerlink" title="Características de los Sistemas OLAP"></a>Características de los Sistemas OLAP</h3><p>Las características básicas de los sistemas OLAP son las siguientes:</p><ul><li>Ofrecen una visión multidimensional y jerarquizada de los datos.</li><li>Son capaces de analizar tendencias a lo largo del tiempo.</li><li>Pueden presentar vistas de un número reducido de dimensiones elegido por el usuario.</li><li>Permiten ahondar en la jerarquía de los datos para acceder a los de más bajo nivel.</li><li>Son interactivos y soportan múltiples usuarios concurrentes.</li></ul><p>Resulta ahora claro, vistas sus características, como los sistemas OLAP pueden beneficiarse de las funcionalidades de una BDM:</p><ul><li>La visión multidimensional y la jerarquizada van explícitas en la propia estructura de la BD. La herramienta OLAP, que posiblemente esté integrada en la BDM, solo tiene que ocuparse del manejo del cubo hiperdimensional para extraer los datos conforme a los criterios establecidos por el usuario.</li><li>El estudio de tendencias se puede realizar aprovechando las series temporales de la BDM o, si no se dispone de dicho tipo de datos, realizando las operaciones y conversiones necesarias para manejar el tiempo como una dimensión adicional de la BD.</li><li>La presentación de vistas se conoce en la jerga OLAP como “slice and dice” (cortar y trocear) y se podría traducir en algo así como segmentación. Esta característica de una herramienta OLAP consiste en la capacidad de extraer “rodajas” del hipercubo que forma la BDM. Estas rodajas se extraen dado un valor fijo para una o varias dimensiones y tomando el hipercubo resultante.</li><li>La capacidad de perforar en los niveles de jerarquía se realiza, de nuevo, aprovechando la propia estructura de la BDM subyacente. En el caso de que se utilice una BDR como escalón inferior de la jerarquía, la herramienta OLAP debe ocuparse de que el acceso a dicho nivel sea transparente para el usuario.</li><li>La interactividad y el soporte de múltiples usuarios simultáneos son capacidades que dependen en gran medida de los tiempos de respuesta del gestor de BD empleado, por lo que se puede utilizar como criterio orientativo a la hora de elegir el producto que se va a adquirir para construir el sistema.</li></ul><h3 id="Implementacion-de-Sistemas-OLAP"><a href="#Implementacion-de-Sistemas-OLAP" class="headerlink" title="Implementación de Sistemas OLAP"></a>Implementación de Sistemas OLAP</h3><p>Como ya hemos comentado, debido a su orientación hacia el manejo de los datos organizados en dimensiones, el entorno natural de trabajo de los sistemas OLAP son las bases de datos multimensionales. No obstante también pueden trabajar sobre BD Relacionales, aunque en este caso sus prestaciones se ven disminuidas. Atendiendo a este criterio, los sistemas OLAP se pueden dividir en tres tipos principales, que estudiamos a continuación.</p><p><strong>MOLAP (Multidimensional-OLAP)</strong></p><p>Los primeros sistemas OLAP utilizaban arrays de memoria multidimensionales para almacenar los cubos de datos y se denominan OLAP multidimensional (MOLAP).</p><p>Por lo tanto, funcionan sobre BD multidimensionales. Requieren un esfuerzo previo de modelización y construcción de la BD multidimensional y de otro continuo consistente en migrar los datos en formato relacional al nuevo formato multidimensional. A cambio ofrecen un rendimiento muy superior a la hora de realizar la extracción y el análisis de los datos, puesto que los datos a los que acceden están organizados en dimensiones y jerarquías.</p><p>Los datos se almacenan en un sistema de matrices (hipercubo) en donde cada eje es una dimensión.</p><p><strong>ROLAP (Relational-OLAP)</strong></p><p>Posteriormente, los servicios OLAP se integraron en los sistemas relacionales y los datos se almacenaron en las BD relacionales. Estos sistemas se denominan sistemas OLAP relacionales (ROLAP).</p><p>Estos sistemas permiten trabajar sobre las BD corporativas ya establecidas, ahorrando así el trabajo de crear y mantener nuevas BD multidimensionales. A cambio deben ocuparse de realizar la conversión entre la visión relacional de los datos mantenida por el SGDBR y el manejo multidimensional y jerárquico que debe ofrecer al usuario, lo cual acarrea un coste en tiempo y recursos de máquina.</p><p>El almacenamiento se suele realizar en un esquema en estrella (no normalizado) o copo de nieve (normalizado), que vamos a estudiar posteriormente con detalle.</p><p>Las tendencias actuales en estos sistemas ROLAP son:</p><ul><li>Desarrollo de técnicas específicas para el almacenamiento (índices join, bitmap, …) y optimización de consultas.</li><li>Crear servidores SQL ampliado especializados en funcionar como Almacén de Datos.</li></ul><p>A su vez, estas tendencias dan lugar a dos tipos de modelos ROLAP:</p><ul><li>SGBD especializados de SQL: Proporcionan un lenguaje de consulta avanzado y soporte para el proceso de consultas SQL sobre esquemas en estrella y copo de nieve en entornos de solo lectura.</li><li>Servidores ROLAP: Servidores intermedios que se sitúan entre el SGBDR y las herramientas cliente. Este middleware está especializado en el soporte de consultas OLAP multidimensionales que se optimizan para servidores relacionales específicos.</li></ul><p>Respecto a la elección entre MOLAP y ROLAP, en la práctica resulta mucho más habitual encontrar sistemas de almacén de datos, junto con sus correspondientes herramientas OLAP y de minería de datos, implementadas mediante BD relacionales. Esto es debido a la mayor experiencia de que se dispone para trabajar sobre BD Relacionales, a la gran cantidad de productos ya disponibles en el mercado y a la confianza que las organizaciones tienen en este tipo de BD.</p><p><strong>HOLAP (Hybrid-OLAP)</strong></p><p>Además de los dos sistemas descritos, aparecen los sistemas híbridos, que almacenan algunos resúmenes en la memoria y los datos básicos y otros resúmenes en las BD Relacionales, se denominan sistemas OLAP híbridos (HOLAP).</p><p>Dicho de otra forma, los sistemas HOLAP proporcionan análisis multidimensional accediendo indistintamente a BD Multidimensionales o Relacionales.</p><p>Muchos sistemas OLAP se implementan como sistemas cliente-servidor. El servidor contiene la BD Relacional y los cubos de datos MOLAP. Los sistemas clientes obtienen vistas de los datos comunicándose con el servidor.</p><h3 id="ROLAP-Tipos-de-Diseno"><a href="#ROLAP-Tipos-de-Diseno" class="headerlink" title="ROLAP: Tipos de Diseño"></a>ROLAP: Tipos de Diseño</h3><p>Nos detenemos ahora en los sistemas ROLAP, que a pesar de no ser los que mejor se adaptan a una herramienta OLAP, si son muy utilizados. Veamos los diferentes tipos de diseño que se deben realizar para que estos sistemas puedan dar una respuesta eficiente.</p><p><strong>Esquema en Estrella</strong></p><p>Esquema relacional adaptado a la representación de datos multidimensionales. Se basa en una serie de tablas que representan dimensiones unidas mediante claves ajenas, a una principal que actúa como nexo llamada tabla de hechos y que almacena datos agregados y precalculados (tablas no normalizadas).</p><p><strong>Tabla de Hechos</strong></p><p>El contenido de una tabla de hechos está formado por:</p><ul><li>Clave principal: Concatenación de las claves de todas las tablas de dimensión asociadas a la tabla de hechos.</li><li>Claves ajenas: Que referencian a las claves de las correspondientes dimensiones.</li><li>Atributos de Hecho: atributos de tipo cuantitativo cuyos valores (cantidades) se obtienen generalmente por aplicación de una función estadística que resume un conjunto de valores en un único valor. Ejemplos: nº de empleados, cantidad vendida, precio medio, et.</li></ul><p>Por otro lado, las características principales de una tabla de hechos son:</p><ul><li>Filas con pocas columnas (pocos atributos).</li><li>Nº de filas: Desde millones a más de miles de millones (tantas como celdas tenga el cubo).</li><li>Acceso, en general, vía dimensiones.</li></ul><p><strong>Tablas de Dimensión</strong></p><p>Las características de las tablas de dimensión son:</p><ul><li>Definen las dimensiones de negocio en términos familiares para los usuarios.</li><li>Filas con numerosas columnas de texto, altamente descriptivas.</li><li>Normalmente menos de un millón de filas.</li><li>Combinadas con las tablas de hecho mediante claves ajenas.</li><li>Altamente indexadas.</li><li>No están relacionadas entre sí.</li><li>Se utilizan como puntos de acceso a los datos detallados de la tabla de hechos.</li><li>A veces se tienen que desnormalizar.</li></ul><p><strong>Figura de Tabla de Hechos con Tabla de Dimensiones</strong></p><p><img src="https://gsitic.files.wordpress.com/2018/01/tabla_dimension_hechos.png?w=825" alt=""></p><p>Al igual que sucede al manejar un hipercubo multidimensional, las consultas típicas en un esquema en estrella consisten en fijar un valor o rango de ellos para las dimensiones y, a continuación, obtener la información solicitada. La respuesta se encuentra realizando operaciones de unión natural (join) entre tablas de dimensiones y la tabla de hechos. Para optimizar las consultas, el gestor de BD debe ser capaz de reconocer que está trabajando con un esquema en estrella y hacer en primer lugar los join entre las tablas de dimensiones y, con el resultado, hacer un único join con la tabla de hechos, minimizando el número de accesos físicos.</p><p><strong>Esquema en Copo de Nieve</strong></p><p>El esquema en copo de nieve es una variante del esquema en estrella que presenta las tablas de dimensión estructuradas a más de un nivel (tablas normalizadas). Se utiliza cuando hay jerarquías en las dimensiones, lo que supone más claves ajenas. Ejemplo:</p><p><img src="https://gsitic.files.wordpress.com/2018/01/copo_nieve.png?w=825" alt=""></p><p><strong>Constelación de Estrellas</strong></p><p>La constelación de estrellas la forman varios esquemas en estrella y/o en copo de nieve que comparten dimensiones. Ejemplo:</p><p><img src="https://gsitic.files.wordpress.com/2018/01/constelacion_estrellas.png?w=825" alt=""></p><p><strong>Índices Bitmap</strong></p><p>Para poder conseguir una cierta eficiencia en los accesos, hay que considerar una serie de aspectos en el diseño físico, tales como:</p><ul><li>Estructuras de índices (mapas de bits, índices de combinación, índices textuales).</li><li>Vistas materializadas:<ul><li>Identificación de las vistas a materializar.</li><li>Explotación de la vista materializada durante la consulta.</li><li>Actualización de las vistas materializadas durante la carga y refresco.</li></ul></li></ul><p>En este apartado vamos a estudiar cómo es la estructura de los índices bitmap.</p><p>Los índices bitmap son un tipo especial de índice que almacena la información en bits en vez de múltiplos de bit (byte, doble byte) y que sirve para acelerar el acceso a filas con atributos de baja cardinalidad.</p><p>Se dice que un atributo es de baja cardinalidad si su dominio está formado por pocos elementos. Ejemplo: el atributo sexo (H o M).</p><p>Se trata de guardar un mapa de bits para cada posible valor del atributo, por lo que, como se dijo anteriormente, no es eficiente usar estos índices para valorares de alta cardinalidad. Ejemplo: el índice para sexo tendrá dos bitmaps.</p><p>Para responder a consultas que se realicen sobre esquemas relacionales con índices bitmap, basta con hacer las operaciones lógicas apropiadas (AND, OR, NOT) sobre los bits de cada índice implicado en la consulta, lo cual es una operación muy rápida, mucho más que la comparación de cadenas o números que implica la utilización de índices de otro tipo.</p><p>Este tipo de índices son útiles para indexar las tablas de dimensiones en esquemas en estrella o en copo de nieve, ya que muchas de estas dimensiones suelen tener su clave principal formada por un atributo de baja cardinalidad. Ejemplo: código de provincia, sexo, estado civil, etc.</p><h3 id="Eleccion-de-una-Herramienta-OLAP"><a href="#Eleccion-de-una-Herramienta-OLAP" class="headerlink" title="Elección de una Herramienta OLAP"></a>Elección de una Herramienta OLAP</h3><p>A la hora de elegir una herramienta OLAP hay que tener en cuenta, entre otros, los puntos siguientes:</p><ul><li>Si obliga a trabajar con una BD multidimensional (MOLAP), relacional (ROLAP) o si soporta ambas.</li><li>En el caso de herramientas MOLAP es conveniente estudiar las capacidades de la BDM subyacente. Además hay que fijarse en su capacidad de aceptar accesos concurrentes y la carga de usuarios que admite, ya que el objetivo del OLAP es permitir el análisis interactivo.</li><li>En el caso de herramientas ROLAP, la penalización en que se incurre al no utilizar BD multidimensional, y las facilidades que ofrece la herramienta para ofrecer una vista multidimensional de los datos (optimización de accesos a esquemas en estrella, en copo de nieve e índices bitmap).</li><li>El límite en cuanto al número de dimensiones y de celdillas que puede manejar, sea o no multidimensional la BD subyacente. También la profundidad de los niveles de jerarquías y el manejo de series temporales.</li><li>La capacidad de cálculo y la facilidad para especificar qué métodos y operaciones hay que aplicar a los datos. También debe disponer de herramientas y presentación de informes.</li><li>El mantenimiento de las dimensiones y las jerarquías mediante herramientas automatizadas. Facilidad a la hora de modificar cualquiera de ambos elementos.</li></ul><h3 id="Comparativa-de-OLAP-y-Otros-Sistemas"><a href="#Comparativa-de-OLAP-y-Otros-Sistemas" class="headerlink" title="Comparativa de OLAP y Otros Sistemas"></a>Comparativa de OLAP y Otros Sistemas</h3><p>Terminamos el estudio de los sistemas OLAP haciendo una comparativa de los mismos frente a otros. Por un lado sistemas muy relacionados, como son los Sistemas de Soporte a las Decisiones y la propia Minería de Datos, y por otros, sistemas antagónicos como los sistemas OLTP.</p><p><strong>Minería de Datos frente a OLAP y DSS</strong></p><p>Los sistemas de ayuda a la decisión (DSS) son herramientas sobre las que se apoyan los responsables de una empresa, directivos y gestores, en la toma de decisiones. Para ello, utilizan:</p><ul><li>Un Data Warehouse, en el que se almacena la información de interés para la empresa.</li><li>Herramientas de análisis multidimensional (OLAP).</li></ul><p>Los DSS permiten al responsable de la toma de decisiones consultar y utilizar de manera rápida y económica las enormes cantidades de datos operacionales y de mercado que se generan en una empresa. Gracias al análisis OLAP, pueden verificarse hipótesis y resolverse consultas complejas. Además, en el curso del análisis, la interpretación de los datos puede dar lugar a nuevas ideas y enfoques del problema, sugiriendo nuevas posibilidades de análisis.</p><p>Sin embargo, el análisis OLAP depende de un usuario que plantee una consulta o hipótesis. Es el usuario el que lo dirige y, por tanto, el análisis queda limitado por las ideas preconcebidas que aquél pueda tener.</p><p>La minería de datos constituye un paso más en el análisis de los datos de la empresa para apoyar la toma de decisiones. No se trata de un técnica que sustituya los DSS ni el análisis OLAP, sino que los complementa, permitiendo realizar un análisis más avanzado de los datos y extraer más información de ellos.</p><p>Como ya se ha comentado anteriormente, utilizando minería de datos es el propio sistema el que descubre nuevas hipótesis y relaciones. De este modo, el conocimiento obtenido con estas técnicas no queda limitado por la visión que el usuario tiene del problema.</p><p>Las diferencias entre minería de datos y OLAP radican esencialmente en que el enfoque desde el que se aborda el análisis con cada una de ellas es completamente distinto. Fundamentalmente:</p><ul><li>El análisis que realizan las herramientas OLAP es dirigido por el usuario, deductivo, parte de una hipótesis o de una pregunta del usuario y se analizan los datos para resolver esa consulta concreta. Por el contrario, la minería de datos permite razonar de forma inductiva a partir de los datos para llegar a una hipótesis general.</li><li>Además, las aplicaciones OLAP trabajan generalmente con datos agregados, para obtener una visión global del negocio. Por el contrario, la minería de datos trabaja con datos individuales, concretos, descubriendo las regularidades y patrones que presentan entre sí y generalizando a partir de ellos.</li></ul><p>Un ejemplo clarificará la diferencia entre ambas técnicas es el siguiente:</p><p>Una pregunta típica de un sistema OLAP/DSS sería: “El año pasado, ¿se compraron más furgonetas en Cataluña o en Madrid?”. La respuesta de sistema sería del tipo “En Cataluña se compraron 12.000 furgonetas, mientras que, durante el mismo intervalo, en Madrid se compraron 10.000”. Obviamente es una información interesante y útil, pero restringida por la hipótesis realizada a priori.</p><p>En cambio, un problema típico para resolver utilizando minería de datos sería, por ejemplo: “Hallar un modelo que determine las características más relevantes de las personas que compran furgonetas”. A partir de los datos del pasado, el sistema de minería de datos proporcionaría una respuesta del tipo: “Depende de la época del año y la situación geográfica. En invierno, los habitantes de Madrid que pertenecen a un cierto grupo de edad y nivel de ingresos probablemente comprarán más furgonetas que gente de las mismas características en Cataluña”.</p><p>Como puede verse, se trata de problemas distintos, de modo que según los objetivos perseguidos deberá utilizarse una técnica u otra. Además, puesto que sus conclusiones son complementarias, en general será conveniente combinar ambas para obtener los mejores resultados.</p><p><strong>Sistemas OLTP vs Sistemas OLAP</strong></p><p>Como ya sabemos OLAP (On-Line Analytical Processing) se define como análisis rápido de información multidimensional compartida. El término OLAP aparece en contraposición al concepto tradicional OLTP (On-Line Transactional Processing), de designa el procesamiento operacional de los datos, orientado a conseguir la máxima eficacia y rapidez en las transacciones (actualizaciones) individuales de los datos, y no su análisis de forma agregada.</p><p>Existen, por lo tanto, dos grupos de aplicaciones que se realizan en una empresa:</p><ul><li>Aplicaciones que ejecutan operaciones del día a día (compra, inventario, nóminas, …). Son los Sistemas de Procesamiento de transacciones en línea (OLTP).</li><li>Aplicaciones que se encargan de analizar el negocio, interpretar lo que ha ocurrido y tomar decisiones (para mejorar los servicios al cliente, incrementar ventas,…). Son los Sistemas de Procesamiento analítico en línea (OLAP).</li></ul><p>Los dos son sistemas de procesamiento muy diferentes. Veamos las diferencias principales entre los dos sistemas:</p><ul><li>OLAP permite que una compañía decida qué debe hacer y OLTP ayuda a llevar a cabo la decisión.</li><li>OLTP representa una “imagen” de los asuntos de la organización que se actualiza constantemente (con cada operación realizada). Los sistemas OLAP son estáticos, refrescándose periódicamente (cada semana, cada mes, …) a partir de las fuentes OLTP.</li><li>El diseño de los sistemas OLTP elimina redundancias, y se piensa más en la eficiencia (transacciones rápidas) que en el usuario (dificultad para navegar). Los sistemas OLAP almacenan datos redundantes para conseguir un acceso sencillo al usuario y buenos tiempos de respuesta.</li><li>OLTP proporciona capacidades muy limitadas para la toma de decisiones (los usuarios examinan la BD registro a registro). OLAP trabaja con un resumen de miles de registros “condensados” en una respuesta.</li><li>Los sistemas transaccionales (u operacionales) automatizan el día a día del negocio, buscando la eficiencia. Los sistemas analíticos se centran en la estrategia a largo plazo y están dirigidos por el negocio.</li><li>En cuanto a la implementación de OLTP y OLAP:<ul><li>Surgen los sistemas EIS y DSS (basados en OLAP) para soportar la toma de decisiones. Presentan problemas para recuperar datos de la BD Operacionales.</li><li>No se puede implementar OLTP y OLAP en una sola BD. Actuando el SGBD como interfaz entre datos y usuarios.</li><li>Se necesita una arquitectura dual de BD.</li></ul></li></ul><p>En el siguiente cuadro, se observa de forma resumida, las características de los sistemas OLTP y OLAP, quedando así más claras sus diferencias.</p><p><img src="https://gsitic.files.wordpress.com/2018/01/oltp_vs_olap.png?w=825" alt=""></p><h2 id="Big-Data"><a href="#Big-Data" class="headerlink" title="Big Data"></a>Big Data</h2><p>Con la irrupción de internet, llegaron nuevos conceptos que con el tiempo se han vuelto de uso cotidiano y que nos acompañan en nuestro día a día. Han repercutido para bien en nuestras vidas y casi no podemos entender las nuevas tecnologías sin estas geniales ideas. Uno de estos conceptos que han resonado mucho últimamente es <strong>Big Data</strong> ; aunque como ya ha pasado en anteriores ocasiones, el halo de escepticismo y desconfianza ha planeado en torno a todo lo que lo rodea. Hay muchas dudas (fundadas) en cuanto a su concepto, uso y alcance; de esta manera se crea un ambiente de recelo aparejado a algo que parece intangible, incontrolable y sobre todo, que puede atentar nuestra privacidad.</p><h3 id="Que-significa-Big-Data"><a href="#Que-significa-Big-Data" class="headerlink" title="Qué significa Big Data"></a>Qué significa Big Data</h3><p><strong>Big Data</strong> ( <em>datos masivos</em> en español, aunque apenas se utiliza la traducción) es el proceso de recolección de grades cantidades de datos y su inmediato análisis para encontrar información oculta, patrones recurrentes, nuevas correlaciones, etc; el conjunto de datos es tan grande y complejo que los medios tradicionales de procesamiento son ineficaces. Y es que estamos hablando de desafíos como analizar, capturar, recolectar, buscar, compartir, almacenar, transferir, visualizar, etc, ingentes cantidades de información, obtener conocimiento en tiempo real y poner todos los sentidos en la protección de datos personales. El tamaño para albergar todo el proceso ha ido aumentando constantemente para poder recopilar e integrar toda la información.</p><p>La recolección de datos ha existido casi desde siempre, cuando en el amanecer el hombre hacía muescas en piedras o huesos para hacer seguimiento de las actividades cotidianas o de los suministros esenciales para subsistir. La invención de ábaco supuso un determinante empuje al cálculo y análisis que tanto necesitábamos cuando los dedos y la memoria no eran suficientes, y las primeras bibliotecas representaron además un primer intento de almacenar datos. En la época actual, todo lo que hacemos está continuamente dejando un rastro digital que se puede utilizar y analizar; los avances en tecnología, junto a la expansión de Internet y el almacenamiento en la nube, han provocado que crezca la cantidad de datos que podemos almacenar.</p><p>Para resumir, se puede utilizar <strong>5 V’s</strong> como definición de <strong>Big Data</strong> (empezaron siendo 3), que es lo que caracteriza al sistema y al mismo tiempo explica sus ventajas:</p><ol><li><strong>Volumen</strong> . La más evidente y la que hace honor al nombre; captar y organizar absolutamente toda la información que nos llega es esencial para tener registros completos e insesgados, y que las conclusiones que obtengamos sirvan eficientemente a la hora de la toma de decisiones. Es el Business Intelligence que todos conocemos, pero a lo grande; aunque la diferencia con la clásica inteligencia de negocio viene marcada por el resto de V’s.</li><li><strong>Velocidad</strong> . Siempre es importante el tiempo si afrontamos tanto la necesidad de generar información (y recordemos que estamos hablando de muchos datos) como de analizarla, pero lo es más si necesitamos reaccionar inmediatamente; todo el proceso pide agilidad para extraer valor de negocio a la información que se estudia y que no se pierda la oportunidad.</li><li><strong>Variedad</strong> . Hay que dar uniformidad a toda la información, que tendrá su origen en datos de lo más heterogéneos, tal como veremos en el siguiente apartado. Una de las fortalezas del <strong>Big Data</strong> reside en poder conjugar y combinar cada tipo de información y su tratamiento específico para alcanzar un todo homogéneo.</li><li><strong>Veracidad</strong> . Se refiere a la calidad del dato y su disponibilidad; en un entorno descrito por la anterior <em>V, Variedad</em> , hay que encontrar herramientas para comprobar la información recibida; las tecnologías creadas al servicio del <strong>Big Data</strong> se muestran imprescindibles y eficientes para afrontar los retos.</li><li><strong>Valor</strong> . Trabajar con <strong>Big Data</strong> tiene que servier para aportar valor a la sociedad, las empresas, los gobiernos, en definitiva, a las personas; todo el proceso tiene que ayudar a impulsar el desarrollo, la innovación y la competitividad, pero también mejorar la calidad de vida de las personas.</li></ol><h3 id="Tipos-de-datos-en-Big-Data"><a href="#Tipos-de-datos-en-Big-Data" class="headerlink" title="Tipos de datos en Big Data"></a>Tipos de datos en Big Data</h3><p>Para aclarar qué es lo que se recoge para el análisis, podemos dividirlos en dos grandes categorías:</p><ul><li><strong>Datos estructurados</strong> . Aquellos que tienen longitud y formato (por ejemplo fechas) y que pueden ser almacenados en tablas (como las BDR). En esta categoría entran los que se compilan en los censos de población, los diferentes tipos de encuestas, los datos de transacciones bancarias, las compras en tiendas online, etc.</li><li><strong>Datos no estructurados</strong> . Son los que carecen de un formato determinado y no pueden ser almacenados en una tabla. Pueden ser de <em>tipo texto</em> (los que generan los usuarios de los foros, redes sociales, documentos de Word), y los de <em>tipo no-texto</em> (cualquier fichero de imagen, audio, vídeo). Dentro de esta categoría, podemos añadir los <strong>Datos semiestructurados</strong> , que son los que no pertenecen a BDR ya que no se limitan a campos determinados, aunque poseen organización interna o marcadores que facilita el tratamiento de sus elementos; estaríamos hablando de documentos XML, HTML o los datos almacenados en BD NoSQL.</li></ul><h3 id="El-uso-del-analisis-de-datos"><a href="#El-uso-del-analisis-de-datos" class="headerlink" title="El uso del análisis de datos"></a>El uso del análisis de datos</h3><p>Para poder analizar todo esto, se precisa de técnicas potentes y avanzada; las clásicas medias o varianzas no son por sí solas suficientes para extraer toda esa cantidad de información, ni para entender los diferentes tipos de datos que hemos descrito.</p><p>Antes de la irrupción <strong>Big Data</strong> , ya existían algoritmos matemáticos que nos facilitaban descubrir información oculta en los datos, como todos los que engloban el <strong>Data Mining</strong> (minería de datos): k-medias, árboles de decisión, redes neuronales, etc, que con la llegada de la potencia de cálculo de los ordenadores permitieron acortar el tiempo que se tardaba en obtener resultados. Aunque no se pensó para ser en tiempo real si no a posteriori, permite analizar datos para encontrar correlaciones entre ellos y de este modo desarrollar por ejemplo una estrategia de marketing adaptada a las conclusiones.</p><p>Por eso el análisis de datos siempre ha tenido un gran peso en el marketing, un mejor conocimiento del consumidor y sus necesidades propicia saber cómo aumentar las ventas; el análisis de datos nos permite establecer relaciones entre variables, predecir comportamientos, realizar agrupaciones (clustering) de grupos homogéneos, e incluso analizar textos para extraer información. Ahora con <strong>Big Data</strong> , todo esto se consigue en tiempo real y con cada nueva actualización de nuestro repositorio de datos es posible ver los cambios en las estadísticas inmediatamente.</p><h3 id="Que-utilidad-puede-tener"><a href="#Que-utilidad-puede-tener" class="headerlink" title="Qué utilidad puede tener"></a>Qué utilidad puede tener</h3><p>Como todas las cosas en esta vida, puede tener un buen uso o usarse para propósitos “malvados”. Lo primero que llama la atención es el tema de la privacidad, ya que cada vez más detalles de nuestras vidas son almacenados y analizados por empresas y gobiernos; por supuesto, no es algo que nos debamos tomar a la ligera, pero a medida que siga avanzando la tecnología, habrá que ir adaptando las leyes y regulaciones para proteger a las personas. Por ahora, no hay más rastro de nosotros que los que ya estamos dejando día a día, y que ya están siendo analizados por terceros; a partir de este momento, todos esos registros se unen para formar un todo. Sí, podemos hablar de una representación de nosotros, pero no deja de ser un número entre millones de números, sin cara ni alma. Lo único que va a contar para estudiar es el comportamiento de grupos homogéneos tratados como tendencias en un segundo, para que al siguiente empiece de nuevo el proceso.</p><p>En cambio los beneficios son muchos, y muy importantes. Veamos ejemplos.</p><ul><li>Una eCommerce puede optimizar el stock de sus almacenes a través de la información extraída de lo que busca la gente en su web o analizando las tendencias en redes sociales y foros; también fijar precios dinámicos en sus productos extrayendo datos de múltiples fuentes (las acciones de los clientes, preferencias de los proveedores o recopilación de precios de la competencia).</li><li>El sector de las telecomunicaciones es una industria privilegiada, gracias a sus redes y a la proliferación de dispositivos móviles; la oportunidad más evidente es extraer información de la experiencia del usuario gracias al tráfico de voz y datos, y así poder ofrecer altas en contratos personalizados, ampliar la batalla por la competencia e incluso crear nuevas fuentes de ingresos.</li><li>La banca tiene ante si un reto, y una oportunidad, de poner medios para luchar contra el fraude, los delitos financieros y las brechas de seguridad, mediante <strong>Big Data</strong> . Las entidades financieras están invirtiendo enormes cantidades de dinero en perfeccionar algoritmos y la tecnología de análisis para minimizar riesgos y fortalecer su imagen de cara al cliente.</li><li>La Federación Alemana de Fútbol empezó a usar el análisis de grandes volúmenes de datos para mejorar el rendimiento de sus jugadores, y con los deberes bien hechos se presentaron en el Mundial de Brasil 2014.</li><li>Si piensas que todo lo que puede dar de sí <strong>Big Data</strong> es sólo aprovechable por grandes corporaciones, vas mal encaminado; por ejemplo, las fuerzas de seguridad utilizan estas herramientas para perseguir criminales y luchar contra el terrorismo de cualquier tipo. En materia de sanidad, el cruce de información de historiales clínicos, antecedentes familiares, clima y entorno, junto a los hábitos de consumo, permitirá un modelo predictivo personal para cada paciente, y de esta manera ayudar en la detención precoz de enfermedades y estrategias más efectivas para combatirlas. En muchas ciudades, ya se usa el análisis de datos para transformarse en más modernas e inteligentes: transportes públicos interconectados para minimizar los tiempos de espera, o semáforos que ante la previsión de un aumento del tráfico e regulan para minimizar los atascos.</li><li>Y por supuesto, las pymes también pueden subirse al carro del <strong>Big Data</strong> , ya que no es necesaria una gran inversión. Es suficiente con tener un CRM y a un analista de datos para extraer conclusiones de la información que utiliza una pyme, aunque siempre cabe la posibilidad de externalizarlo.</li></ul><h3 id="Big-Data-modelando-el-futuro"><a href="#Big-Data-modelando-el-futuro" class="headerlink" title="Big Data, modelando el futuro"></a>Big Data, modelando el futuro</h3><p>Todo el mundo habla cada día más, es una tendencia en aumento y ha llegado para quedarse. A medida que las herramientas se hagan más accesibles, se integrará poco a poco en nuestras vidas y pasará de ser algo desconocido o temido, a una forma más de comprender el comportamiento humano y nuestra relación con el entorno.</p><p>Es como el Social Media, al principio las empresas lo veía como algo ajeno a ellas, que no debían destinar recursos porque creían que no reportaría ningún beneficio; ahora, lo más normal es hacer <em>Social Marketing</em> y elaborar informes exhaustivos con las estadísticas derivadas de su presencia online. Pues ahora es el momento de cruzar esos datos con el resto de aspectos de la organización, como ventas, tráfico web, interacción con distribuidores, etc, para encontrar nuevas vías de negocio y crear nuevas estrategias.</p><p>Y por supuesto, para analizar toda esta información, es necesario contar con profesionales que tengan parte analista y parte creativa; estos “ <em>científicos de datos</em> ” serán muy demandados por las empresas y organizaciones, por lo que se abre un interesantísimo campo laboral para los amantes de los números.</p><h2 id="Bibliografia"><a href="#Bibliografia" class="headerlink" title="Bibliografía"></a>Bibliografía</h2><ul><li><a href="https://es.scribd.com/document/78295368/TICB1-Mineria-de-Datos" rel="external nofollow noopener noreferrer" target="_blank">Scribd (Roger Fabian Molina)</a></li><li><a href="https://mibloguel.com/big-data-significado-y-su-utilidad-en-la-sociedad/" rel="external nofollow noopener noreferrer" target="_blank">MiBloguel</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Mineria-de-datos-Aplicacion-a-la-resolucion-de-problemas-de-gestion-Tecnologia-y-algoritmos-Procesamiento-analitico-en-linea-OLAP-Bi
      
    
    </summary>
    
      <category term="B3" scheme="http://localhost:4000/categories/B3/"/>
    
    
  </entry>
  
  <entry>
    <title>B2-T15</title>
    <link href="http://localhost:4000/wiki/B2/b2-t16/"/>
    <id>http://localhost:4000/wiki/B2/b2-t16/</id>
    <published>2019-01-17T15:11:00.000Z</published>
    <updated>2019-01-18T10:45:16.603Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Documatica-Gestion-y-archivo-electronico-de-documentos-Sistemas-de-gestion-documental-y-de-contenidos-Sindicacion-de-contenido-Sistemas-de-gestion-de-flujos-de-trabajos-Busqueda-de-informacion-robots-spiders-otros-Posicionamiento-y-buscadores-SEO"><a href="#Documatica-Gestion-y-archivo-electronico-de-documentos-Sistemas-de-gestion-documental-y-de-contenidos-Sindicacion-de-contenido-Sistemas-de-gestion-de-flujos-de-trabajos-Busqueda-de-informacion-robots-spiders-otros-Posicionamiento-y-buscadores-SEO" class="headerlink" title="Documática. Gestión y archivo electrónico de documentos. Sistemas de gestión documental y de contenidos. Sindicación de contenido. Sistemas de gestión de flujos de trabajos. Búsqueda de información: robots, spiders, otros. Posicionamiento y buscadores (SEO)"></a>Documática. Gestión y archivo electrónico de documentos. Sistemas de gestión documental y de contenidos. Sindicación de contenido. Sistemas de gestión de flujos de trabajos. Búsqueda de información: robots, spiders, otros. Posicionamiento y buscadores (SEO)</h1><h2 id="Introduccion"><a href="#Introduccion" class="headerlink" title="Introducción"></a>Introducción</h2><p>En una organización, la información susceptible de almacenamiento crece a un ritmo exponencial. Dicho crecimiento hace necesario solucionar el problema de su adecuada gestión, ya que a partir de un cierto volumen se hace imprescindible un sistema organizativo que posibilite la localización de la información que se precise en cualquier momento.</p><p>Podemos clasificar la información que es necesario manejar de la siguiente manera:</p><ul><li>Información estructurada: se trata de información que se puede subdividir en campos. Nos estamos refiriendo por ejemplo a los registros de las tablas de las BDR.</li><li>Información no estructurada: es información en la que no se puede encontrar una estructura interna. Hablamos por ejemplo de fotos, archivos de texto, archivos de vídeo, páginas web, etc. Incluimos en este apartado los documentos de cualquier tipo.</li></ul><p>El ámbito de este tema se circunscribe al segundo tipo de información.</p><p>El desarrollo de los sistemas automatizados de recuperación de información se inició con el objetivo de facilitar el manejo de la enorme cantidad de literatura científica surgida des de los años 40; posteriormente esta disciplina se extendió a otros ámbitos fuera de los científicos.</p><p>Otlet es considerado el precursor de la gestión de documentación automática (documática) con su obra <em>Traité de Documentation</em> , publicada en 1934, en la que expone los principios y relaciones de la Tecnología documental. Otlet identifica los componentes fundamentales del moderno concepto de Documentación Automática (o Automatizada), distinguiendo estas tres premisas principales:</p><ul><li>Establece una teoría sobre la organización, las herramientas y los soportes tecnológicos para sustentar esta nueva disciplina.</li><li>Aplicación práctica del proceso documental: la Documentación ocupa un lugar preponderante en la organización.</li><li>Objetivo: satisfacer las necesidades informativas del usuario.</li></ul><p>Posteriormente en los años 50, los especialistas se centran en el problema de la búsqueda y recuperación de información, acuñándose el término Information Retrieval (recuperación de información). La recuperación de información es el conjunto de tareas mediante las cuales el usuario localiza y accede a los recursos de información que son pertinentes para la resolución del problema planteado. En un sistema documático, el proceso de recuperación de la información sigue en general el esquema siguiente:</p><ul><li>El usuario formula una necesidad de conocimiento.</li><li>Se interroga al sistema gestor documental (SGD).</li><li>El SGD devuelve una lista de referencias.</li><li>Si lo que buscamos no está en la lista se realiza una segunda búsqueda y empieza el proceso de nuevo.</li></ul><p>A finales de los años 60 se da un nuevo paso en la evolución de la documática, con la introducción de la Information Science (Ciencia de la Información) como ciencia integradora de la teoría, proceso y práctica documental con otras ciencias complementarias, como la cibernética, la informática, la teoría de la información y la comunicación, etc.</p><p>El desarrollo de nuevas teorías ha traído, de la mano de la Ciencia de la Información, la aparición de la disciplina Information Management (Gestión de la Información y la Documentación en las Organizaciones), en la que desempeñan un papel fundamental las telecomunicaciones y la informática, íntimamente relacionadas con los sistemas de información, en el marco de redes complejas de información.</p><h2 id="Archivo-Electronico-de-Documentos"><a href="#Archivo-Electronico-de-Documentos" class="headerlink" title="Archivo Electrónico de Documentos"></a>Archivo Electrónico de Documentos</h2><p>Como ya hemos visto, el archivo electrónico de documentos o documentación automática consiste en la gestión de grandes volúmenes de información no estructurada (texto, imágenes, gráficos, sonidos, etc).</p><p>Adicionalmente, será necesario gestionar cierta información que permita localizar el documento cuando sea necesario; así, los documentos han de ser sometidos a un proceso de <strong>indización</strong> .</p><p>El otro gran proceso involucrado en un sistema de gestión documental es la <strong>recuperación de la información</strong> . Abarca el conjunto de tareas mediante las que un usuario recupera la información relevante en respuesta de una necesidad cognitiva.</p><h3 id="Indizacion"><a href="#Indizacion" class="headerlink" title="Indización"></a>Indización</h3><p>Consiste en extraer los conceptos clave del texto de un documento. Su objetivo es definir el contenido de un documento mediante un conjunto de conceptos que especifican el tema o temas de que trata.</p><p>La indización conlleva dos procesos fundamentales:</p><ol><li>Extraer los conceptos informativos de cada documento.</li><li>Traducirlos a un lenguaje documental.</li></ol><p>El lenguaje documental es el que se usa para la interrogación del SGD. En función del lenguaje documental que utilice, podemos clasificar los SGD en dos grandes grupos:</p><ul><li>Sistemas de lenguaje libre o free-text. Permiten hacer búsquedas en lenguaje natural. Un ejemplo es el buscador de Internet Google.</li><li>Sistemas basados en lenguajes controlados. En este caso, los términos que contiene un lenguaje documental son de dos clases:<ul><li>Términos preferentes o descriptores (descriptors, keywords): son aquellos que deben utilizarse en la indización y en la recuperación. Representan términos precios y unívocos.</li><li>Términos no preferentes (no-descriptors): no pueden asignarse a los documentos ni la indización, ni realizar consultas utilizándolos.</li></ul></li></ul><p>En cuanto a la indización, hay que tener en cuenta que la cantidad de términos que representen a un documento no indica la calidad de la indización; no por muchos términos es más precisa, cuántos más términos representan a un documento aumenta la <strong>exhaustividad</strong> (mayor probabilidad de que se seleccione ese documento) y disminuye la <strong>precisión</strong> (conceptos que realmente identifican al documento).</p><p>Si se cae en excesiva exhaustividad o precisión, se pueden producir dos fallos a la hora de realizar una búsqueda documental:</p><ul><li><strong>Ruido</strong> : documentos que el sistema ha seleccionado y que en realidad no responden a la pregunta. Esto es consecuencia de indicar los documentos con más términos de los que se debiera.</li><li><strong>Silencio</strong> : documentos que al hacer la búsqueda no han sido seleccionados y sin embargo responden a la pregunta formulada. Es consecuencia de la falta de precisión, es decir, no indizar los términos correctos.</li></ul><p><strong>Etapas de la indización</strong></p><p>Hablamos de sistema indizador como el encargado de realizar el proceso de indización. Existen aplicaciones en que este proceso es manual, realizado por un operador, pero en otras el operador es ayudado por un sistema informático, por ser un proceso totalmente automático.</p><p>Las distintas fases de las que consta el proceso de indización son las siguientes:</p><p><strong>1. Examen del documento</strong> . El examen será más o menos extenso según el tipo de documento y su forma física; en general, el sistema indizador tendrá que asegurarse de leer toda la información y no olvidar ninguna parte. En el caso de un documento de texto, éstas son las partes del texto que habrá de tener en cuenta por orden de importancia:</p><ul><li>titulo</li><li>resumen</li><li>introducción, capítulos y conclusiones</li><li>ilustraciones y gráficos</li><li>palabras subrayadas o impresas en otra tipografía</li></ul><p><strong>2. Identificación del documento</strong> . El sistema indizador aplicará una serie de criterios para identificar los conceptos esenciales para la descripción del tema, eligiendo los más acordes con las necesidades del centro o servicio en que se esté indizando.</p><p>En la selección de los conceptos se persiguen dos objetivos principales:</p><ul><li>Exhaustividad: no dejar de indizar nada que pueda ser importante.</li><li>Pertinencia: la información ha de ser representativa del documento.</li></ul><p>Para la identificación de los conceptos esenciales se pueden emplear los siguientes métodos:</p><ul><li>Sistema full-text: consiste en extraer todas las palabras clave, a excepción de aquellas que se encuentren en una lista de palabras vacías (aquellas que no aportan información, como los determinantes, preposiciones, etc). Es el sistema que se utiliza habitualmente para los sistemas documentales free-text.</li><li>Indización mediante lenguajes controlados: el universo de las palabras a indizar está restringido, utilizándose una lista de descriptores.</li><li>El método estadístico: seleccionar los conceptos más significativos mediante el análisis de las frecuencias de los términos del documento.</li><li>El método sintáctico: utiliza técnicas de análisis morfológico y semántico para captar la estructura del texto. Utilizado sobre todo en la investigación sobre el procesamiento de lenguaje natural.</li></ul><p><strong>3. Traducción de los términos</strong> . Consiste en la traducción de los conceptos extraídos del documento al lenguaje documental utilizado, es decir, a términos de indización:</p><ul><li>Si utilizamos un lenguaje documental controlado, habrán de traducirse a los convenientes descriptores.</li><li>Si utilizamos texto libre, habrá que comprobar que los conceptos extraídos están aceptados en las distintas fuentes de referencia:<ul><li>diccionarios y enciclopedias</li><li>libros de texto y manuales</li><li>tesauros</li><li>etc</li></ul></li></ul><p><em><strong>Los tesauros</strong></em></p><p>Los tesauros que se acaban de citar son diccionarios que muestran la equivalencia entre los términos o expresiones del lenguaje natural ylos términos normalizados del lenguaje documental, así como las relaciones semánticas que existen entre ellos.</p><p>Los tesauros en España están definidos en la norma UNE 50-106-90, la cual no es de obligado cumplimiento, pero proporciona un marco para la comunicación entre centros y para facilitar el trabajo en equipo.</p><p>Los elementos principales de un tesauro son los siguientes:</p><ul><li>Unidades lexicales. A su vez de subdividen en varios tipos:<ul><li>descriptores</li><li>términos equivalentes o sinónimos. Son aquellos cuya presencia es útil en el tesauro, pero que no se pueden utilizar en la indización, pues remiten o envían a un descriptor. Pueden ser de dos clases:<ul><li>sinónimos lingüisticos: se traducen directamente por un descriptor y tienen exactamente el mismo significado que el descriptor elegido.</li><li>sinónimos documentales o cuasi-sinónimos: agrupan en un solo descriptor varios términos que tienen un significado próximo, aunque no es exactamente el mismo.</li></ul></li><li>infraconceptos: términos que no tienen sentido por sí solos y que se añaden a los descriptores para formar nuevos descriptores. Ejemplo: infra, multi, super, etc.</li><li>palabras herrmienta o instrumento: descriptores que no tienen significado exacto si van solos. Son términos como: comparación, evaluación, método.</li></ul></li><li>Relaciones entre unidades lexicales. Existen las siguientes clases de relaciones:<ul><li>Relaciones de equivalencia o sustitución: son aquellas que relacionan un sinónimo con un descriptor.</li><li>Relaciones de jerarquía: expresan relaciones de superioridad y subordinación entre descriptores. A su vez pueden ser:<ul><li>relaciones genéricas: en las que existe un término genérico que representa un concepto en el que están contenidos los términos específicos.</li><li>relaciones partitivas o relaciones todo-parte: en las que se expresa que un término se compone de otros.</li></ul></li><li>Relaciones asociativas o de vecindad: indican las analogías que pueden existir entre dos descriptores.</li><li>Relaciones de definición: que relacionan un descriptor con su uso o aplicación.</li></ul></li></ul><p>Los tesauros se utilizan para eliminar ambigüedades y facilitar la indización, pero también son utilizdos en el proceso de recuperación de la información que se verá posteriormente.</p><p><strong>Sistemas de Indización</strong></p><p>En función de cuál es el resultado de la indización, es decir, cómo se organiza la información resultado de la indización de los documentos, podemos establecer las siguientes categorías:</p><ul><li><strong>Ficheros planos</strong> : (a) la información referente a la indización de uno o más documentos son almacenados en un fichero (generalmente en formato de texto ASCII). La búsqueda sobre estos ficheros planos se llevan a cabo generalmente por medio de la localización de patrones de texto.</li><li><strong>Ficheros inversos</strong> : (b) son un tipo de fichero índice donde la estructura de cada ítem (emtrada) del fichero es, generalmente: descriptor, identificador de documento, identificador de campo, donde el identificador de documento es único para cada documento y el identificador de campo es un término que nos indica dentro de qué campo del documento aparece el descriptor. Algunos sistemas incluyen también información acerca de la localización en el documento del párrafo y frase de los términos utilizados para proceder a interrogar la BD. La búsqueda se realiza, corrientemente, por medio de la localización de los términos solicitados en el fichero inverso.</li></ul><p><img src="https://gsitic.files.wordpress.com/2018/01/text_inverter.png?w=825" alt=""></p><ul><li>Los ficheros de patrones de bits contienen hileras de dígitos binarios, patrones de bits que representan a los documentos. Existen varias formas de construir estos patrones de bits. Un método común consiste en la división de los documentos en bloques lógicos, e identificar los términos de indización que contiene cada bloque. Cada palabra es desglosada para traducirse en una hilera de bits (es decir, un patrón de bits con algunos de los bits “puesto a 1”). Los patrones de bits de cada palabra en un bloque son agrupados para crear un bloque de patrones. Los bloques de signaturas se concatenen posteriormente para producir el patrón de bits del documento. La búsqueda se lleva a cabo por medio de la comparación entre los patrones de bits de las interrogaciones con los patrones de bits de los documentos de la BD.</li><li>Los grafos (redes) son colecciones ordenads de nodos conectados por arcos y se usan para representar documentos de diversas formas y maneras. Un ejemplo es el grafo denominado <strong>red semántica</strong> , que representa las relaciones semánticas que se establecen en el texto, relaciones que se pierden a menudo en otros sistemas de indización. Aunque constituyen un campo interesante para el estudio, resultan bastante difíciles de llevar a la práctica y requieren excesivo esfuerzo manual para el proceso de la representación de las colecciones de documentos.</li></ul><h3 id="Recuperacion-de-la-Informacion"><a href="#Recuperacion-de-la-Informacion" class="headerlink" title="Recuperación de la Información"></a>Recuperación de la Información</h3><p>La recuperación de la información es el conjunto de tareas mediante las cuales un usuario recupera la información <strong>relevante</strong> , para dar respuesta a su necesidad cognitiva. Es decir, un documento será relevante, si satisface la necesidad de conocimiento del usuario. Esto supone una gran diferencia con los sistemas gestores de BD, en los que el criterio de éxito de una interrogación a la BD es la exactitud y corrección de los datos, en ningún caso depende de las subjetividad del usuario.</p><p>Uno de los problemas con los que nos encontramos, al interrogar un SGD, es que el usuario concibe su necesidad de conocimiento en “lenguaje natural”, el cual ha de ser traducido al lenguaje documental que entiende el sistema. Por lo tanto, puede producirse una pérdida de eficiencia en la traducción. Por ello se dice que el tipo de recuperación que se puede producir en la interrogación a un SGD es <strong>aproximada o probabilística</strong> , es decir, ante una misma necesidad de conocimiento se pueden obtener múltiples respuestas dependiendo de la habilidad ante una misma necesidad de conocimiento se pueden obtener múltiples respuestas dependiendo de la habilidad del usuario para traducirla al lenguaje documental que entiende el sistema. Hay que hacer notar que esto supone otra diferencia relevante con los SGBD tradicionales, en los que la información que devuelve el sistema es <strong>determinista</strong> , ya que ante una misma necesidad de información siempre devolverá el mismo resultado.</p><p><strong>Métricas de Eficiencia</strong></p><p>Al igual que ocurría en el proceso de indización, a la hora de la recuperación de la información no se puede ser exhaustivo y preciso al mismo tiempo, ya que si uno de los parámetros aumenta el otro disminuye, como podemos representar gráficamente de la siguiente manera:</p><p><img src="https://gsitic.files.wordpress.com/2018/01/metrica_eficiencia1.png?w=825" alt=""></p><p>Por ello, para medir la eficiencia de un sistema de recuperación de la información se establecen una serie de parámetros, que enunciaremos a continuación basándonos en la tabla siguiente:</p><p><img src="https://gsitic.files.wordpress.com/2018/01/metrica_eficiencia2.png?w=825" alt=""></p><p>La tabla pretende reflejar, para una consulta a un SGD:</p><ul><li>A: documentos relevantes que han sido devueltos por el SGD.</li><li>B: documentos no relevantes que han sido devueltos por el SGD,lo que hemos definido anteriormente como ruido.</li><li>C: documentos relevantes que no han sido devueltos y que deberían haber sido extraídos, lo que hemos llamado silencio.</li><li>D: documentos no relevantes y que no han sido extraidos.</li></ul><p>Definimos entonces las siguientes métricas:</p><ul><li>Indice de pertinencia o precisión: mide cuantos documentos devueltos son los considerados relevantes por el usuario: A / (A + B). Es en definitiva una medida de la calidad de la información obtenida.</li><li>Indice de exhaustividad o de respueta: mide el porcentaje de documentos que han sido devueltos sobre el total de la base documental: A / (A + C). Es una medida e la cantidad de la información obtenida.</li><li>Tasa de ruido: mide el porcentaje de documentos que carecen de interés y han sido devueltos por el sistema: B / (A + B).</li></ul><p><strong>El Proceso de Recuperación de la Información</strong></p><p>Un proceso de recuperación, al que podríamos considerar “genérico”, seguiría las siguientes fases:</p><ol><li>Definición de las necesidades informativas del usuario.</li><li>Selección y ordenación de las fuentes a utilizar.</li><li>Traslación de las necesidades del usuario al lenguaje documental propio de la fuente a utilizar en cada caso. Es posible, además, encontrar fuentes en las que no se utilice ningún tipo de vocabulario controlado, en cuyo caso resultará necesario afinar el trabajo terminológico.</li><li>Traducción de la expresión de lenguaje documental al lenguaje de interrogación propio de cada sistema.</li><li>Ejecución de las expresiones del lenguaje de interrogación obtenidas.</li><li>Consulta de las respuesta obtenidas, para analizar su pertinencia o no a la cuestión planteada.</li><li>Replanteamiento, si procede, de las expresiones utilizadas, si los resultados obtenidos no son pertinentes.</li><li>Selección y obtención de los documentos que respondan a las necesidades manifestadas por el usuario.</li><li>Transmisión del resultado, preparado adecuadamente, al usuario.</li></ol><p>Este proceso se puede plasmar gráficamente como aparece en la figura:</p><p><img src="https://gsitic.files.wordpress.com/2018/01/proceso_recuperacion.png?w=825" alt=""></p><h2 id="Organizacion-Funcional-de-los-Sistemas-Documaticos"><a href="#Organizacion-Funcional-de-los-Sistemas-Documaticos" class="headerlink" title="Organización Funcional de los Sistemas Documáticos"></a>Organización Funcional de los Sistemas Documáticos</h2><p>En los Sistemas de Gestión Documental (SGD) se pueden identificar una serie de subsistemas funcionales. Un SGD puede incorporar todos ellos o sólo algunos. Además, hay SGD’s que permiten integrar subsistemas de otros fabricantes:</p><ul><li><strong>Sistemas de Gestión de Bases de Datos Documentales (SGBDD)</strong> : son sistemas que incorporan todas las características de los SGBD tradicionales, incluyendo la creación y mantenimiento de BD Documentales (adecuadas para información no estructurada), usuarios, controles de seguridad, e incluso lenguajes propios de programación. Estos sistemas están basados en sistemas de archivo y ficheros inversos, los cuales son una modalidad de organización de los datos especialmente apropiada para la información documental. Los rasgos más característicos de un SGBDD son:<ul><li>capacidad para almacenar información textual de longitud grande y variable.</li><li>capacidad para recuperar con rapidez registros que responden a un criterio de búsqueda.</li><li>capacidad para realizar búsquedas multicriterio sobre ficheros inversos utilizando lógica booleana.</li><li>capacidad para administrar tesauros y diccionarios terminológicos.</li></ul></li></ul><p>Como ejemplos de sistemas de gestión de BD más representativos, podemos citar: BRS/Search de BRS Information Techonologies (uno de los más completos),Inmagic, CDS-Isis y su interfaz Winslsis, …</p><ul><li><strong>Sistemas de indización</strong> : anteriormente hemos visto el proceso de indización documental. Estos sistemas por lo tanto son aquellos encargados de realizar dicho proceso.</li><li><strong>Sistemas de exploración o escáneres</strong> : se trata de aplicaciones que son capaces de acceder a ficheros con diferentes formatos y buscar dentro de los mismos las cadenas de caracteres que respondan a lo expresado en la ecuación de búsqueda. Pueden encontrarse aplicaciones que combinen la exploración con la indexación, como dtSearch.</li><li><strong>Sistemas de gestión bibliográfica</strong> : sistema especializado para la gestión y mantenimiento de bibliografías especializadas. Es una aplicación específica de los sistemas de gestión de bases documentales que permite, no sólo el almacenamiento y la recuperación de referencias bibliográficas, sino también la exportación de estas referencias en diferentes formatos de cita bibliográfica a diferentes procesadores de textos, sistemas de gestión de BD, etc.</li><li><strong>Sistemas de recuperación de información (SRI)</strong> : son aplicaciones que se encargan exclusivamente de recuperar información de BD documentales no modificables. Ponen a disposición del usuario potentes herramientas de búsqueda y de apoyo a la búsqueda, pero su funcionalidad queda reducida a la consulta y exportación de documentos.</li></ul><p>Los SRI incorporan un <strong>gestor de interrogación o motor de búsqueda</strong> , el cual realiza búsquedas dentro de una BD de documentos. El motor de búsqueda recibe la interrogación del usuario (query), que consiste en una o varias palabras, realiza la búsqueda en la BD y extrae una lista ordenada de documentos que cumplen entera o parcialmente con la interrogación. El orden depende de una puntuación (score) que asocia el programa a cada documento cuando realiza la búsqueda y en cada caso varía. Un criterio para puntuar los resultados que usualmente se aplica es que cuanto más próximos en el documento aparecen los términos de búsqueda, mayor es la puntuación del documento.</p><p>Un SRI debe permitir la recuperación de la información contenida en los documentos de la BD a la que accede, a través de cualquier término existente en ella, mediante la formulación de ecuaciones de búsqueda que permitan combinar los términos según diferentes criterios. Existen sistemas que ofrecen la posibilidad de ejecutar las consultas sobre una o varias BD simultáneamente. Los documentos resultantes se agrupan en sets o conjuntos, susceptibles de combinación posterior.</p><p>El SRI ha de poseer algún tipo de mecanismo para la salida de la información, generalmente mediante edición en pantalla, impresión y redirección a ficheros de los documentos de interés para el usuario. Las órdenes de salida de información deben ofrecer la posibilidad de enviar ésta a diferentes destinos, así como los formatos de presentación de los datos a utilizar (tamaño, campos, …). Deben incluirse aquí las capacidades para ordenar, según diferentes criterios, los documentos resultantes. Otra función a considerar es la posibilidad de crear nuevas BD, tomando como base los documentos recuperados en un búsqueda previa.</p><p>Es interesante que el SRI incluya también herramientas que permitan analizar y procesar la respuesta obtenida, utilizando herramientas de análisis de frecuencias de los términos (es decir, cuántas veces aparece el término buscado en los documentos recuperados) o de coocurrencias (frecuencia con la que aparecen dos o más términos de búsqueda en los documentos recuperados).</p><p>Otro posible subsistema de un SRI es aquel que permita definir los perfiles de búsqueda de los usuarios, así como realizar un seguimiento de las ecuaciones que ejecuten. Por ejemplo, la posibilidad de almacenar las ecuaciones de búsqueda que usualmente ejecutan, de manera que puedan ejecutarse en cualquier momento, se les llama normalmente “macros”. Estas macros son ficheros susceptibles de edición y modificación, lo que facilita la recuperación de información con un mínimo esfuerzo de tiempo y coste.</p><p>Un elemento fundamental de un SRI es que incluya algún mecanismo de control terminológico, tanto para la entrada de datos como para su recuperación. Puede tratarse de un tesauro, de un glosario o de un diccionario terminológico.</p><p>Además se puede incluir una ayuda al usuario en todo momento, a través de mensajes y líneas de estado, especialmente durante el proceso de interrogación (interrogación asistida). En sistemas de recuperación en línea (teledocumentación), el sistema informa al usuario del tiempo de conexión, tareas ejecutadas, coste de la sesión, etc. Los mecanismos de ayuda al usuario, especialmente aquellos referidos a la evaluación y refinamiento de las búsquedas, son una de las principales áreas de investigación.</p><p>Por último, dependiendo de la configuración del sistema, éste puede ofrecer opciones de acceso multiusuario, niveles de seguridad, reorganización y recuperación de ficheros, etc.</p><p><img src="https://gsitic.files.wordpress.com/2018/01/sri.png?w=825" alt=""></p><ul><li>Sistemas hipertextuales: en su origen, los hipertextos e hipermedias eran una forma de organizar, acceder y explorar documentos de diferentes tipos, que posteriormente se han popularizado como motor y parte de tutoriales y presentaciones. Actualmente estos sistemas están volviendo a ser considerados como una forma válida y muy avanzada de gestionar documentación. Para que sea posible una existencia real de los conceptos de hipertexto e hipermedia, deben utilizarse aplicaciones que sean capaces de crear los vínculos y asociaciones entre los documentos. Las aplicaciones ofrecen unos elementos particulares que facilitan la creación y navegación por las estructuras hipertextuales:<ul><li>Un conjunto de ficheros que contienen los documentos relacionados.</li><li>Ventanas de presentación de los documentos, las cuales son modificables en tamaño y posición.</li><li>Punteros o enlaces, que generalmente utilizan una representación gráfica distinta a la del resto del material informativo, en forma de color, iconos, botones… Así como dispositivos señaladores, que facilitan la selección y el acceso a los documentos mostrados en las ventanas.</li><li>Herramientas de creación de enlaces y anotación de la navegación, lo que da al usuario la posibilidad de crear sus propias asociaciones y documentos.</li></ul></li></ul><p>Estas funcionalidades se integran en una herramienta que en el entorno hipertextual es conocida como “browser”, navegador o visualizador. El visualizador actúa como una interfaz, que muestra al usuario el contenido informativo de los documentos que selecciona, mediante la selección de enlaces. Suele completarse con la posibilidad de ejecutar búsquedas en el texto completo que contienen los documentos y/o búsquedas más rígidas utilizando lenguajes clásicos de interrogación. La interrogación, sea de texto, imágenes o sonidos, suele realizarse a través de la ejecución de patrones, que representan una necesidad dada de información por parte del usuario. Además, una completa aplicación para este ámbito debería ser capaz de generar mapas gráficos de la estructura hipertextual y utilizar estas representaciones para acceder directamente a los documentos deseados.</p><p>La visión que obtiene el usuario mediante el visualizador es una visión transparente, integrada, en la que no resulta complicado navegar de un documento a otro. Esta aparente facilidad no debe ocultar que los documentos pueden encontrarse en diferentes ficheros informáticos, e incluso en diferentes ordenadores, formando lo que se llama repositorio de información, que será tratado con más detalle en el próximo capítulo, por su relación con las BD multimedia.</p><p>Los sistemas y estructuras de hipermedia pueden además incorporar inteligencia embebida, es decir, ser capaces de ejecutar otras aplicaciones o de tomar decisiones con la actividad desarrollada por el usuario, tanto en la utilización de los enlaces como en el acceso a los contenedores.</p><ul><li><strong>Sistemas de Gestión Documental o de Gestión Electrónica de Documentos (GED)</strong> : se trata de sistemas que pretenden ofrecer una solución integral para la documentación, especialmente administrativa y de gestión, que se utiliza en una organización dada (PRAX, 1994; LASSOURY, 1994). Incorporan funciones clásicas de gestión de BD y utilizan esquemas de obtención de una copia del documento original mediante escáner, almacenamiento óptico o magneto-óptico y un nivel básico de descripción textual del documento y de su contenido.</li><li><strong>Sistemas o Gestores de Información Personal (Personal Infromation Systems/Managers)</strong> : son aquellos que integran, en un único entorno, todos los documentos, ficheros y relaciones entre ellos que son de interés para el trabajo de un usuario. Numerosos sistemas integrados de informatización ofrecen a sus usuarios un acceso homogéneo a los diferentes tipos de documentos y ficheros que manejan en su trabajo diario.</li><li><strong>Sistemas compuestos</strong> : se denomina así a aquellos que dan soporte a todas las tares que se realizan en una unidad informativa, sea ésta un archivo, biblioteca o centro de documentación. Esto significa que cubren tanto la cadena documental como la gestión administrativa. Sirvan como ejemplo las aplicaciones de automatización de bibliotecas, como Absys o Libertas, o las aplicaciones de automatización de archivos, como la desarrollada para el Archivo de Indias de Sevilla. Normalmente, integran un motor documental, encargado de gestionar las BD documentales que cubren los catálogos, y un motor relacional, que cubre las tareas administrativas.</li></ul><h2 id="Optimizacion-de-Consultas-y-Recuperacion-de-la-Informacion"><a href="#Optimizacion-de-Consultas-y-Recuperacion-de-la-Informacion" class="headerlink" title="Optimización de Consultas y Recuperación de la Información"></a>Optimización de Consultas y Recuperación de la Información</h2><h3 id="Lenguajes-de-Interrogacion-y-Operadores"><a href="#Lenguajes-de-Interrogacion-y-Operadores" class="headerlink" title="Lenguajes de Interrogación y Operadores"></a>Lenguajes de Interrogación y Operadores</h3><p>Un lenguaje de interrogación puede definirse como un conjunto de órdenes, operadores y estructuras que, organizados conforme a unas normas lógicas, permiten la consulta de fuentes y recursos de información electrónica.</p><p>El resultado de la combinación de estos elementos, siguiendo las normas establecidas, es una expresión a la que se conoce con el nombre “ecuación”, capaz de interrogar el contenido de la fuente de información. La definición mínima de un lenguaje de interrogación y de sus componentes puede encontrarse en el borrador del la norma ISO 8777-1988.</p><p>Las normas lógicas que rigen un lenguaje de interrogación responden a cuestiones relacionadas con la coordinación de los elementos, es decir, con la formulación de ecuaciones. Estas normas funcionan como la sintaxis del lenguaje, es decir, especificarán el orden de los elementos, la disposición de las estructuras, sus posibilidades combinatorias, las prioridades en la ejecución y todo tipo de posibles funciones. Las órdenes serán aquellas palabras o abreviaturas que le indicarán al sistema las acciones a ejecutar (buscar la expresión, mostrar los documentos o registros resultantes, consultar el tesauro o los ficheros inversos, ejecutar un perfil de usuario, …). Sin embargo, no todos los lenguajes de interrogación utilizan las mismas palabras como órdenes, aunque las órdenes ejecuten las mismas funciones. Existen intentos para homogeneizar la interrogación de las BD, como el lenguaje CCL (Common Command Language) promovido por la Unión Europea, que aún no han alcanzado el objetivo para el que fueron desarrollados. A este panorama se une la proliferación de interfaces gráficos de usuario, que sustituyen a las órdenes y las sintaxis tradicional, dejando al usuario (si éste lo desea) sólo la labor de introducir los términos y los operadores que expresan las relaciones existentes entre ellos.</p><p>En un lenguaje de interrogación, los operadores son los encargados de expresar las relaciones que mantienen entre sí los términos que definen (más adecuado sería decir que pueden definir) las necesidades informativas del usuario.</p><p>Pueden distinguirse diferentes tipos de operadores que se analizan a continuación.</p><p><strong>Operadores Lógicos o Booleanos</strong></p><p>Los operadores lógicos, también llamados booleanos en honor a George Boole, precursor de la lógica simbólica y del álgebra de conjuntos, son los más utilizados en numerosos sistemas. El principio que rige la utilización de este tipo de operadores es que las relaciones entre conceptos pueden expresarse como relaciones entre conjuntos. Las ecuaciones de búsqueda pueden transformarse en ecuaciones matemáticas, que ejecutan operaciones sobre los conjuntos, lo que da como resultado otro conjunto. Los tres operadores básicos son el operador suma/unión (generalmente identificado como O/OR), el operador producto/intersección (identificado como Y/AND) y el operador resta/negación (identificado como NO/NOT). A su vez, estos operadores pueden combinarse entre sí generando operaciones más complejas, como el O exclusivo (elimina la intersección), etc.</p><p>No deben obviarse los problemas que plantean los operadores booleanos, independientemente de su potencia. En primer lugar, siempre se plantean en términos absolutos (es decir, selecciona el documento en función de si las palabras de búsqueda están o no están presentes, sin considerar el peso específico de cada término en el contexto). Por esa misma razón, es necesario un alto valor de precisión en los términos de búsqueda utilizados. En segundo lugar, requieren claridad en la composición de las expresiones a buscar.</p><p><img src="https://gsitic.files.wordpress.com/2018/01/operadores_booleanos.png?w=825" alt=""></p><p><strong>Operadores posicionales</strong></p><p>La utilización de operadores posicionales pretende superar algunas de las limitaciones anteriormente citadas que ofrecen los operadores booleanos. Toman como punto de partida la consideración del valor de cada término dentro del contexto, es decir, de su relación con el resto. En definitiva lo que quiere decir es que la posición de los términos de búsqueda dentro del documento es significativa para valorar su utilidad. Los operadores posicionales pueden dividirse en dos tipos:</p><ul><li>Posicionales absolutos: Son aquellos que permiten buscar un término en un lugar dado del documento o registro. Por regla general, son operadores de campo, es decir, permiten al usuario fijar en qué campo o campos presentes en la estructura de BD debe aparecer el término buscado. La presencia del término en un campo dado (por ejemplo, en el campo título) puede ser una garantía de la adecuación del documento a los objetivos, en la mayor parte de las situaciones.</li><li>Posicionales relativos: También llamados de proximidad, se trata de operadores que permiten establecer la posición de un término respecto a otro dado. Se considera que la cercanía entre los dos términos puede reflejar una íntima relación entre los conceptos reflejados por los mismos. Estos operadores permiten definir el nivel de proximidad entre los términos (mismo campo, línea, frase, número de términos significativos que los separa …).</li></ul><p><strong>Operadores de Comparación</strong></p><p>Especifican el rango de búsqueda, fijando unos límites para la misma. Estos límites pueden ser tanto numéricos como alfabéticos, correspondiendo los operadores a formas del tipo “mayor que”, “menor o igual que”. Se utilizan principalmente en documentos que pueden contener datos numéricos.</p><p><strong>Operadores de Truncamiento</strong></p><p>Pueden darse situaciones en las cuales sea necesario utilizar no un término simple, sino también sus derivados, determinados por prefijación o sufijación, mínimas variantes léxicas, etc. Para facilitar este tipo de búsqueda se han introducido operadores de truncamiento, a los que también se llama máscaras. Se trata de operadores (normalmente se emplean símbolos como *, $) cuya presencia puede sustituir a un carácter o a un conjunto de caracteres, situados a la izquierda, dentro o a la derecha del término en cuestión.</p><p>En los actuales sistemas de recuperación de información es posible encontrar todos estos tipos de operadores, que pueden combinarse entre sí, permitiendo crear ecuaciones complejas que reflejan con bastante precisión los conceptos y sus relaciones. La combinación de los operadores debe respetar un conjunto de reglas básicas en todos los sistemas, que establecen las prioridades y formas de ejecución de ecuaciones complejas, cuando éstas combinan más de dos conceptos. En primer lugar, los sistemas tienden a resolver, o ejecutar en primer lugar, aquellas expresiones que se relacionan utilizando el operador más restrictivo o prioritario. Por ejemplo, un operador posicional absoluto posee un nivel de restricción (una prioridad) mayor que un operador booleano, lo que significa que el sistema ejecutará antes la expresión cuyo operador es el posicional absoluto, combinando posteriormente el resultado con el operador booleano y su término relacionado.</p><p>Sin embargo, pueden darse expresiones en las cuales sea necesario variar estas prioridades y ordenar al sistema que ejecute en primer lugar expresiones con operadores de menor nivel de restricción, relacionando luego su resultado con términos a través de operadores más restrictivos. Para estas situaciones, se utilizan paréntesis, los cuales engloban a las expresiones que deben ejecutarse en primer lugar, independientemente de las prioridades fijadas por el sistema. La utilización de expresiones entre paréntesis hace posible, por ejemplo, que el resultado de una expresión con un operador booleano pueda ser combinada con un operador posicional absoluto. Además, los paréntesis pueden anidarse, resolviéndose las ecuaciones planteadas desde dentro hacia fuera, de la misma forma que las igualdades y polinomios matemáticos.</p><h3 id="Estrategia-de-la-Interrogacion"><a href="#Estrategia-de-la-Interrogacion" class="headerlink" title="Estrategia de la Interrogación"></a>Estrategia de la Interrogación</h3><p>Los lenguajes, sus órdenes y operadores son utilizados dentro del proceso de recuperación de información, la cual se encuentra almacenada en un repositorio, que suele ofrecer la forma de BD. La BD es consultada mediante la ejecución de búsquedas, expresiones que reúnen los elementos citados con anterioridad, y cuya resolución da como resultado aquellos elementos que responden a la lógica expresada en la búsqueda.</p><p>Con el concepto “estrategia de la interrogación” nos referimos a los posibles enfoques que se le puede dar a la planificación del proceso de recuperación de la información, tanto de la visión general de cómo se va a afrontar la búsqueda hasta la formulación de la ecuación concreta.</p><p>La estrategia debe ser un plan ideal de interrogación de la BD que incluya el objetivo de la búsqueda, el plan general y el plan específico de operación. El objetivo de la búsqueda se obtiene identificando qué tipo de información se necesita y sus características. Una vez definido el objetivo, debe establecerse un plan general de operación, que incluya una selección de la base o BD a consultar, las primeras aproximaciones a los términos a utilizar en las ecuaciones, así como las posibles relaciones lógicas. El plan específico de operación se pone en marcha una vez obtenidos los resultados del anterior y debe formular ecuaciones y utilizar términos con el mayor grado de precisión, establecer una secuencia lógica con todo ello y redefinirlo si es preciso. Independientemente de ambos planes, resulta necesario conocer con anterioridad la respuesta a varias cuestiones que afectan a la interrogación de la BD, tales como el contenido y alcance de la BD, coste de consulta, lenguaje y operadores a utilizar durante las consultas, límites preestablecidos (por el usuario o el sistema)… Todas ellas afectan y modifican el enfoque del interrogador.</p><p><strong>Tipos de Estrategia</strong></p><p>En el momento actual, parece más adecuado utilizar el término para identificar el plan general de búsqueda. No existe una única ni perfecta aproximación a las estrategias de interrogación de BD. En la mayor parte de las ocasiones depende de la experiencia del usuario y de la calidad del contenido de los registros existentes en la BD, especialmente en lo que corresponde a su control terminológico. La estrategia depende, en gran manera, de la formación, intuición y experiencia del usuario. Tomando en consideración la intención del interrogador, la bibliografía señala que pueden existir varios tipos principales de búsqueda, que pueden clasificarse en dos grandes grupos, sin perjuicio de que puedan darse situaciones en las que se combinen:</p><ul><li>Categorización por objetivo:<ul><li>Búsqueda de elemento conocido: se trata de búsquedas en las cuales el interrogador sabe cuál será la respuesta. Por ejemplo, en una biblioteca en la que estamos buscando un libro concreto (documento respuesta conocido) y realizamos la búsqueda por su ISBN.</li><li>Búsqueda de información específica: el interrogador busca una información específica dada, generalmente sobre un tema concreto y limitado, como trabajos publicados en un año o por un autor.</li><li>Búsqueda de información general: intenta buscar la información sobre una materia o asunto, de forma general, que obtenga una visión global del estado de la misma.</li><li>Exploración de la BD: se trata de conocer qué tipos de información y/o documentos se encuentran almacenados en la BD, a qué pueden responder y cómo pueden utilizarse.</li></ul></li><li>Categorización por plan de operación:<ul><li>Búsqueda directa: se trata de una aproximación expeditiva, en la que se intenta resolver el problema con la formulación de una única consulta. Como puede deducirse, resulta difícil obtener buenos resultados con la misma.</li><li>Búsqueda “breve”: es una evolución de la anterior, en la que se trata de recuperar unos ítems significativos entre un gran número obtenido tras una sola ecuación.</li><li>Ampliación: comienza con ecuaciones muy restrictivas, que ofrezcan documentos pertinentes. Tras analizar la respuesta, el usuario puede ampliar o expandir las ecuaciones de búsqueda hasta recuperar toda la información existente. Puede ofrecer problemas si la ecuación inicial no es adecuada.</li><li>Restricción: opuesta a la anterior, formula ecuaciones que ofrecen resultados muy amplios, para posteriormente utilizar ecuaciones más restrictivas, hasta delimitar los documentos pertinentes.</li><li>Construcción de bloques: intenta establecer bloques de información que se correspondan con el objetivo de la búsqueda, para combinarlos entre sí de manera que se responda a la necesidad planteada de manera óptima.</li></ul></li></ul><h3 id="La-Exploracion-como-Mecanismo-de-Recuperacion"><a href="#La-Exploracion-como-Mecanismo-de-Recuperacion" class="headerlink" title="La Exploración como Mecanismo de Recuperación"></a>La Exploración como Mecanismo de Recuperación</h3><p>Las limitaciones inherentes al proceso de recuperación mediante ecuaciones han conducido a experimentar otras aproximaciones. Una de las más utilizadas es aquella que emplea la exploración, es decir, el acceso a los documentos mediante técnicas de visualización de parte de su contenido que puede ser relevante, y la posterior asociación con otros documentos de perfil similar. El usuario accede a un listado o enumeración de elementos descriptivos y, mediante un proceso de selección de elementos, va centrando el objetivo de su búsqueda. Los criterios utilizados por el usuario se basan en la deducción y la asociación de conceptos (aproximación ésta similar a la que utiliza un sistema hipertextual) frente a la lógica de conjuntos que se plantea en un sistema de ecuaciones. Este tipo de representación es más adecuada para reflejar la polirepresentación que un concepto puede tener para un usuario individual. En cambio, la utilización de la exploración suele realizarse en entornos en los cuales el usuario no posee una idea clara de cuál debería ser la mejor táctica para aproximarse a la información que precisa. Por lo tanto, la cuestión clave a considerar en un sistema de exploración es combinar las ideas y esquemas del usuario con el esquema de organización de la información que ofrece el sistema. Ésta es la aproximación que pretenden desarrollar los enfoques cognitivos,poniendo su énfasis en el intermediario que debe existir entre el modelo del usuario y el modelo del sistema.</p><h3 id="Revision-y-Analisis-de-Resultados"><a href="#Revision-y-Analisis-de-Resultados" class="headerlink" title="Revisión y Análisis de Resultados"></a>Revisión y Análisis de Resultados</h3><p>El resultado de la ejecución de una ecuación de búsqueda es un conjunto de documentos que cumplen las condiciones expresadas en la ecuación. Se trata, a su vez, de un subconjunto del conjunto total de documentos existentes en el recurso o fuente de información consultado. Sin embargo, puede darse el caso de que la respuesta sea un número excesivamente elevado de documentos, o un número mínimo. Por otra parte, los documentos resultantes responden a la lógica y a las condiciones expresadas en la ecuación de búsqueda, lo cual no supone, como ya se ha señalado, que sean pertinentes a las necesidades del usuario. En realidad, es posible ejecutar ecuaciones perfectas,desde un punto de vista funcional (operadores, términos, …), sin que los documentos resultantes reúnan las características que los harían deseables para el usuario.</p><p>Para superar esta posible distorsión en los resultados es necesario valorar y evaluar la respuesta a las ecuaciones planteadas. La primera modificación a realizar en la formulación de las ecuaciones afecta al número de respuestas obtenidas. En el caso de un excesivo número, se utilizan técnicas de restricción mediante la introducción de términos más específicos, se desechan términos generalistas o se limitan los truncamientos. En el caso de un número muy reducido, las acciones a tomar son las contrarias, es decir, utilización de términos más generales, incluyendo derivados y relacionados, limitación de los operadores más restrictivos, introducción de truncamientos, etc. Si se da la situación de ecuaciones correctas funcionalmente, pero sin respuesta adecuada, sería necesario replantear el proceso de recuperación, especialmente en la utilización de los lenguajes documentales y en la selección de fuentes.</p><h2 id="Gestores-de-Contenido"><a href="#Gestores-de-Contenido" class="headerlink" title="Gestores de Contenido"></a>Gestores de Contenido</h2><p>Un <strong>CMS (Content Management System), Sistema de Gestión de Contenidos o Gestor de Contenidos</strong> , es una aplicación web a la que podremos acceder a través de un navegador tras ser instalada en un servidor. A través de su panel de administración podremos crear, eliminar, modificar y en definitiva, gestionar el contenido de la “página web” (sitio web).</p><p>Por lo que también podríamos definirlo como una herramienta que nos permite la creación de una “página web” (sitio web) y su gestión por perfiles no técnicos.</p><h3 id="¿Por-que-surgieron-los-CMS"><a href="#¿Por-que-surgieron-los-CMS" class="headerlink" title="¿Por qué surgieron los CMS?"></a>¿Por qué surgieron los CMS?</h3><p>No hace muchos años los sitios web estaban formados por páginas web estáticas codificadas en html. Existía la figura del webmaster, que era un técnico que se encargaba del mantenimiento de las páginas web del sitio. Por fortuna, las páginas web se modificaban pocas veces al año ya que todavía no se hacían blogs ni periódicos online que requieren una alta frecuencia de gestión del contenido. Además, modificar el contenido era tedioso, pues había que abrir el archivo html correspondiente a la página web en cuestión que había que modificar y “bucear” entre el código html para realizar los oportunos cambios.</p><p>Un día surgió la necesidad de crear blogs, periódicos online y otros tipos de páginas web (sitios web) que requerían de frecuentes modificaciones. No se podían encargar todas las modificaciones al webmaster, había que encontrar alguna manera de que personas no técnicas pudieran crear y gestionar contenido de la página web (sitio web). Así aparecieron los CMS o Gestores de Contenidos.</p><h3 id="Problemas-Beneficios-y-Ventajas-de-un-CMS"><a href="#Problemas-Beneficios-y-Ventajas-de-un-CMS" class="headerlink" title="Problemas, Beneficios y Ventajas de un CMS"></a>Problemas, Beneficios y Ventajas de un CMS</h3><p><strong>Problemas de no usar un CMS</strong></p><ul><li>Poca usabilidad de la interfaz.</li><li>Pérdida de tiempo. Los tiempos para encontrar y editar una página son más largos.</li><li>Solo pueden modificar contenidos personal con conocimientos HTML.</li><li>Desorganización: Con una página sin CMS y con muchos contenidos puede ser un desastre localizar una página concreta de forma rápida.</li><li>Necesidad de usar manuales de Dreamweaver, Frontpage, …</li></ul><p>Gracias al CMS podemos solucionar todos estos problemas, agilizando nuestro trabajo y permitiendo, sin muchos conocimientos técnicos, a cualquier persona a poder hacer uso de la página web de la empresa.</p><p><strong>Beneficios del uso de un CMS</strong></p><ul><li>Proceso de creación rápido y dinámico.</li><li>Tiempo de ejecución más rápido para crear nuevas páginas y editar contenidos.</li><li>Mayor consistencia del sitio web. Todo al alcance de tu mano.</li><li>Mejora de la navegación del sitio.</li><li>Mayor flexibilidad.</li><li>Mayor seguridad.</li><li>Menos contenido duplicado.</li><li>Facilidad en la escalabilidad de la página web.</li><li>Reducción de los costes de mantenimiento.</li></ul><p><strong>Ventajas</strong></p><ul><li><strong>Ahorro de tiempo</strong> : una de las mejores ventajas del uso de estos gestores es que tenemos la oportunidad de ahorrar tiempo en la creación, edición y administración de los contenidos. Sin necesidad de emplear otras herramientas para poder hacerlo.</li><li><strong>Facilidad</strong> : los gestores de contenido tienen la enorme ventaja de que pueden ser utilizados por las personas sin la necesidad de que tengan conocimientos en áreas del lenguaje de programación o diseño. La interfaz está hecha para que los usuarios empleen una herramienta con la cual puedan encontrar todo lo que necesitan al alcance de un solo click y de la forma más sencilla.</li><li><strong>Creación</strong> : los CMS permiten que las personas aún sin conocimientos en programación tengan la oportunidad de crear desde cero sus contenidos sin ayuda de nadie y de la forma que desean.</li><li><strong>Diseño</strong> : otra de las muchas ventajas que te ofrecen los gestores de contenidos es que tienes la posibilidad de elegir plantillas de diseño. Entre muchas que se encuentran para elegir según sean tus necesidades o gustos. No es necesario tampoco conocer sobre programación o diseño para tener un espacio web realmente estético e impactante, lo cual es muy importante.</li></ul><p>Otra de las muchas ventajas que ofrecen, es que tienes la posibilidad de trabajar el SEO con ellos. Recordemos que para que un sitio web sea visible requiere de trabajo y posicionamiento para lograr el tráfico que necesita.</p><h3 id="Front-Office-y-Back-Office-del-CMS"><a href="#Front-Office-y-Back-Office-del-CMS" class="headerlink" title="Front Office y Back Office del CMS"></a>Front Office y Back Office del CMS</h3><p>Los CMS se caracterizan por tener dos entornos:</p><ul><li><strong>Front Office</strong> : es la <strong>parte pública</strong> de la página web (sitio web), a la que accedemos escribiendo la URL del sitio en la barra de direcciones del navegador web.</li><li><strong>Back Office</strong> : es la <strong>parte privada</strong> de la página web (sitio web) o lo que también se conoce como el <strong>panel de administración</strong> del sitio web. Desde aquí se puede gestionar el contenido del sitio web, su estructura, diseño y los diferentes elementos de configuración.</li></ul><p>Para acceder al Back Office de un CMS habrá que escribir una url especial que dependerá del CMS utilizado. En el caso de WordPress habrá que añadir al nombre de dominio la palabra “wp-admin”, por ejemplo: <a href="http://www.mipagina.es/wp-admin" rel="external nofollow noopener noreferrer" target="_blank">http://www.mipagina.es/wp-admin</a> .</p><p><img src="https://gsitic.files.wordpress.com/2018/01/cms.jpg?w=825" alt=""></p><h3 id="Clasificacion-y-Caracteristicas-de-los-CMS-o-Gestores-de-Contenidos"><a href="#Clasificacion-y-Caracteristicas-de-los-CMS-o-Gestores-de-Contenidos" class="headerlink" title="Clasificación y Características de los CMS o Gestores de Contenidos"></a>Clasificación y Características de los CMS o Gestores de Contenidos</h3><p><strong>Los Gestores de Contenidos o CMS son aplicaciones web</strong></p><p>Los Gestores de Contenidos son aplicaciones web especialmente diseñadas para crear páginas web. Las aplicaciones web son aquellas aplicaciones a las que se accede a través de un navegador web. Los Gestores de Contenidos o CMS como aplicaciones web que son, habitualmente necesitan de la compañía de una serie de elementos:</p><ol><li><strong>Un servidor web</strong> : Encargado de recibir las peticiones de los navegadores web de los clientes cuando solicitan una página web, de comunicarse con el módulo encargado de la ejecución del código y de enviar las páginas web resultado de la ejecución del código al navegador del cliente. El servidor web más utilizado es <strong>Apache</strong> .</li><li><strong>Módulo</strong> encargado de ejecutar el código escrito en un lenguaje de programación y de enviar la página web resultante al servidor web (para la mayoría de CMS se utiliza el <strong>módulo PHP</strong> del servidor Apache).</li><li><strong>Un servidor de base de datos</strong> . Encargado de almacenar los datos del sitio web. El más utilizado en los Gestores de Contenidos es sin duda el servidor de BD <strong>MySQL</strong> .</li><li><strong>Un lenguaje de programación</strong> . El lenguaje de programación más utilizado para los Gestores de contenido más populares es <strong>PHP</strong> .</li></ol><p><strong>Clasificación de los CMS o Gestores de Contenidos por sus características</strong></p><ol><li><strong>Según el lenguaje de programación</strong> empleado por el CMS para crear la página web, como por ejemplo Java, PHP, ASP.NET, Python, PERL. Tanto WordPress como los más conocidos gestores de contenidos están codificados en el Lenguaje de programación del lado del servidor PHP.</li><li><strong>Según la licencia</strong> : Código abierto o Software propietario. Tanto el CMS WordPress como el resto de aplicaciones para crear páginas web más conocidas (Drupal, Joomla, Prestashop, etc) son Software abierto y gratuito.</li></ol><p><strong>Clasificación de los CMS o Gestores de Contenidos por su uso y funcionalidad</strong></p><ol><li><strong>Genéricos</strong> : Tienen muchos posibles usos. Crear una página web corporativa, un blog, una tienda online, etc. Aquí podemos incluir CMS como: Joomla, Drupal, … Y desde hace algún tiempo WordPress (comenzó siendo un Gestor de contenidos específico para la creación de Blogs).</li><li><strong>Blogs</strong> : Son los CMS especialmente creados para la gestión de diarios personales. Son CMS de blogs WordPress, B2Evolution, Movable Type, Blogger, …</li><li><strong>Comercio electrónico</strong> : Son CMS creados específicamente para crear tiendas online. Algunos ejemplos son Magento, PrestaShop, Opencart, etc.</li><li>Existen <strong>CMS específicos</strong> para crear Foros, Wikis, CMS para cursos online como Moodle, etc.</li></ol><p><strong>Lista de los mejores CMS más utilizados</strong></p><ul><li><strong>CMS WordPress</strong> : Es el CMS más utilizado y mejor valorado para creación de blogs y webs. Está hecho en PHP y es gratuito.</li><li><strong>CMS Drupal</strong> : Es uno de los CMS más conocidos, es gratuito y open source. Está construido en PHP.</li><li><strong>CMS Joomla</strong> : Es otro CMS popular de código abierto y también creado en PHP. Es una evolución del CMS Mambo.</li><li><strong>Prestashop CMS</strong> : Es el CMS de ecommerce más conocido y mejor valorado. Podemos decir que es el WordPress de los ecommerce.</li><li><strong>Magento CMS</strong> : Es otro CMS para ecommerce de los más populares y mejor valorados. Ofrece muchos niveles de configuración. A diferencia de Prestashop, se requiere de conocimientos técnicos avanzados para utilizarlo.</li><li><strong>Blogger</strong> : aun hoy se sigue utilizando esta plataforma de gestión de contenidos, fue una de las primeras en hacer presencia en la red. Su forma de uso es gratuita y bastante sencilla, por lo que crear contenidos no genera ningún tipo de problemas.</li><li><strong>LiveJournal</strong> : dedicado a todas las personas que no cuentan con toda la expericencia requerida en el manejo de sitios web. Este gestor de contenidos permite que se puedan conectar blogs dependiendo de su temática, así como la clasificación de los mismos.</li></ul><p><img src="https://gsitic.files.wordpress.com/2018/01/cms2.png?w=825" alt=""></p><h2 id="Sindicacion-de-Contenido"><a href="#Sindicacion-de-Contenido" class="headerlink" title="Sindicación de Contenido"></a>Sindicación de Contenido</h2><p>Se denomina Sindicación a la distribución masiva de contenidos en la web. A partir de la inclusión de algún nuevo contenido en un sitio, lo que se distribuye es una lista de enlaces junto con cierta cantidad de información adicional o metadata.</p><p>Los enlaces apuntarán a esos nuevos contenidos y la información adicional permitirá a los receptores evaluar si los contenidos son de su interés, en cuyo caso accederá a la versión completa simplemente siguiendo el enlace.</p><p>Los primeros sindicadores de contenido en línea fueron mega sitios de la magnitud de Yahoo y Excite. Su propuesta era muy clara: que sus visitantes pudieran acceder a información de orígenes muy diversos desde un lugar único.</p><p>Durante un tiempo, la sindicación resultó demasiado cara y trabajosa ya que se realizaba en base a la recuperación del título de cada página y la revisión de todo el HTML (que está concebido para mostrar contenidos pero no para organizarlos) para detectar los encabezados y enlaces para luego categorizarlos. Semejante tarea no estaba al alcance de cualquiera.</p><p>La gran novedad para la sindicación surgió de la utilización de archivos <strong>XML</strong> .</p><h3 id="Conceptos"><a href="#Conceptos" class="headerlink" title="Conceptos"></a>Conceptos</h3><ul><li><strong>RSS</strong> : Se corresponde con las siglas de Really Simply Syndication. Es un formato XML para la sindicación de contenidos. Es el más extendido, y permite distribuir contenidos sin necesidad de un navegador, utilizando un agregador de contenidos. <img src="https://gsitic.files.wordpress.com/2018/01/rss.png?w=825" alt=""></li><li><strong>Agregador de contenidos</strong> : Es el software que permite suscribirse a fuentes de noticias en RSS, por ello es también conocido como lector RSS o agregador de noticias.</li><li><strong>Feed</strong> : Es la fuente o canal web propiamente dicho, al que pueden suscribirse los usuarios.</li></ul><h3 id="Los-archivos-RSS"><a href="#Los-archivos-RSS" class="headerlink" title="Los archivos RSS"></a>Los archivos RSS</h3><p>Un archivo RSS es la descripción estructural de un sitio web en formato XML.</p><p>RSS es un lenguaje surgido de la aplicación del metalenguaje XML. Por lo tanto, un archivo RSS no será más que un documento de texto compuesto por etiquetas acotadas entre los símbolos de mayor y menor, similares a las utilizadas XHTML.</p><p>El término RSS corresponde a <strong>Rich Site Summary</strong> o <strong>Really Simple Syndication</strong> .</p><p><strong>Sindicación de Contenidos</strong> : Es el término técnico utilizado para designar un método o proceso que permite la notificación y envío de información recientemente publicada en la web. Por tanto, su principal objetivo es la organización y difusión de esta nueva información de un modo rápido y fiable. Parte del principio de suscripción, y se apoya en un conjunto de programas que permiten interpretar sus formatos.</p><p><strong>Wikipedia dice</strong> : RSS son las siglas Really Simple Syndication (Sindicación Realmente Simple), un formato XML para sindicar o compartir contenido en la web. Se utiliza para difundir información actualizada frecuentemente a usuarios que se han suscrito a la fuente de contenidos. El formato permite distribuir contenidos sin necesidad de un navegador, utilizando un software diseñado para leer estos contenidos RSS tales como Internet Explorer, entre otros (agregador).</p><p>Es interesante destacar que se trata de un formato que no está concebido para su visualización (como el HTML) sino para la interacción entre computadoras, ofreciendo la información en un formato estandarizado.</p><p>Para que este proceso resulte posible, un sitio web debe generar un feed o canal (el archivo RSS) que permanecerá alojado en el servidor tal como los demás archivos que lo componen.</p><p>Una vez que el feed está disponible, otros sistemas podrán accederlo y así enterarse de los nuevos contenidos que el sitio ofrece.</p><p>Hoy en día los sitios que permiten la creación y mantenimiento de blogs personales como Blogger y las aplicaciones que lo facilitan en cualquier dominio como WordPress han automatizado la generación de feeds, por lo que los usuarios solo deben manejar sus contenidos.</p><p>Sin demasiado misterio, los contenidos estarán entonces sindicados.</p><p>Para leer los feeds o canales RSS es necesario utilizar un tipo de programa denominado genéricamente agregador.</p><h3 id="Los-Lectores-o-Agregadores-de-feeds"><a href="#Los-Lectores-o-Agregadores-de-feeds" class="headerlink" title="Los Lectores o Agregadores de feeds"></a>Los Lectores o Agregadores de feeds</h3><p>Los archivos RSS, a diferencia de los XHTML, no son interpretados por los navegadores web y al abrirlos lo que hacen es mostrar el código XML que los compone.</p><p>Para visualizar directamente un feed es necesario utilizar un programa lector o agregador de feeds.</p><p>Hay distintos tipos de agregadores.</p><p>Las basados en web (usualmente denominados Portales) permiten la visualización en una página web. Un ejemplo típico de este tipo de agregador es Yahoo con su agregador MiYahoo! o el agregador de Bloglines.</p><p>Otros agregadores están integrados a clientes de correo o son clientes RSS exclusivamente.</p><p>Los agregadores ofrecen variedad de prestaciones especiales, tales como la inclusión de varios feeds relacionados en una única vista, el ocultamiento de entradas que ya han sido leídas y la categorización de feeds en áreas temáticas.</p><h3 id=""><a href="#" class="headerlink" title=""></a><img src="https://gsitic.files.wordpress.com/2018/01/rss1.jpg?w=825" alt=""></h3><h2 id="Sistemas-de-Gestion-de-Flujos-de-Trabajos"><a href="#Sistemas-de-Gestion-de-Flujos-de-Trabajos" class="headerlink" title="Sistemas de Gestión de Flujos de Trabajos"></a>Sistemas de Gestión de Flujos de Trabajos</h2><p><strong>Workflow o flujo de trabajo</strong> consiste en el estudio de aspectos operacionales de una actividad de trabajo, esto es, cómo se realizan y estructuran las tareas, cuál es su orden correlativo, cómo se sincronizan, cómo fluye la información y cómo se hace su seguimiento.</p><p>Una de las <strong>aplicaciones de workflow</strong> consiste en automatizar la secuencia de tareas, acciones o actividades para ejecutar el proceso, con el consiguiente seguimiento del estado de las etapas y las herramientas que son necesarias para gestionar esto. Esto a nivel real es muy sencillo y por eso es muy utilizado por las empresas.</p><p>Existen <strong>tres tipos de actividad en los flujos de trabajo</strong> : <em>actividades cooperativas, actividades colaborativas y actividades de coordinación</em> . También existen dos tipos de workflow principales: <em>workflow ad hoc</em> y <em>workflow procedimental</em> .</p><p>El principal <strong>objetivo de los flujos de trabajo</strong> consiste en reducir el tiempo y acelerar la realización de un trabajo mediante el acercamiento de procesos, personas y máquinas, incluso permitiendo trabajar en equipo desde diferentes lugares. Además de esto, puede facilitar la movilidad del personal, mecanizar y automatizar métodos y organización en la información, ofrecer mecanismos de control y seguimiento de procedimientos de la empresa, agilizar el proceso de intercambio de información y toma de decisiones de la empresa, independizar el flujo de trabajo y método de quien lo realiza, etc. Puede ser muy interesante en el trabajo de <em>gestión de stocks</em> o control de existencias así como también en la <em>gestión documental</em> .</p><p>Principalmente, el <strong>workflow</strong> busca seguir la realización y consecución de las tareas o trabajos por medio de una secuencia de tareas del proceso de negocio. De esta manera organiza y controla recursos, tareas y las reglas para completar este proceso buscando una mayor agilidad y la descentralización de actividades comerciales y administrativas principalmente.</p><p>Con esto se puede conseguir un control de todas las etapas a la vez que la <strong>automatización de los procesos de trabajo</strong> , por lo cual las tareas, información y documentos pasan por los participantes mediante unos procedimientos que se han establecido. Para ello en muchos casos se recurre a muchas aplicaciones informáticas y software que ayudan a controlar el flujo de trabajo en todos sus aspectos.</p><h3 id="¿Que-es-el-flujo-de-trabajo-y-por-que-es-importante-en-un-gestor-documental"><a href="#¿Que-es-el-flujo-de-trabajo-y-por-que-es-importante-en-un-gestor-documental" class="headerlink" title="¿Qué es el flujo de trabajo y por qué es importante en un gestor documental?"></a>¿Qué es el flujo de trabajo y por qué es importante en un gestor documental?</h3><p>En el contexto de los gestores documentales, se refiere al <strong>movimiento automatizado de documentos</strong> a través de una correlación de acciones relacionadas con el proceso empresarial. Dicho de una forma más sencilla, con un gestor documental que controla los flujos de trabajo cada documento queda ligado al estado en el que se encuentre en todo momento. Por ejemplo, una factura puede estar en diversos estados (recibida, aprobada, pagada, etc) y el administrador determinado podrá controlar en todo momento la situación de la misma.</p><p><img src="https://gsitic.files.wordpress.com/2018/01/flujo-de-trabajo-documental-ejemplo.jpg?w=825" alt=""></p><p>El control de los flujos de trabajo supone la máxima automatización de los procesos empresariales y el control de las etapas, durante las cuales los documentos pasan de un empleado a otro, según procedimientos previamente definidos. La etapa previa al control de flujos de trabajo es el control de flujos de información. Las empresas deben analizar <strong>cómo la información llega, se almacena y se distribuye</strong> por la compañía para generar un flujo de trabajo eficiente.</p><h3 id="Beneficios-del-workflow-management"><a href="#Beneficios-del-workflow-management" class="headerlink" title="Beneficios del workflow management"></a>Beneficios del workflow management</h3><p>No existen flujos de trabajo que funcionen de igual manera para todas las empresas. Sin embargo, muchas experimentan beneficios similares derivados.</p><ul><li>Mejora de la productividad del trabajo de los empleados con la automatización de procesos.</li><li>Normalización de los métodos de trabajo mediante procedimientos preestablecidos.</li><li>Optimización de la circulación de información interna.</li><li>Ahorro de tiempo en tareas poco necesarias u obsoletas.</li></ul><h3 id="Sistemas-de-flujo-de-trabajo-o-workflow-management-system"><a href="#Sistemas-de-flujo-de-trabajo-o-workflow-management-system" class="headerlink" title="Sistemas de flujo de trabajo o workflow management system"></a>Sistemas de flujo de trabajo o workflow management system</h3><p>Del mismo modo que el workflow management puede encontrarse dentro de un gestor documental, también se ha desarrollado como un sistema individual. Los sistemas de flujo de trabajo permiten automatizar y mejorar los procesos empresariales con el propósito de ahorrar tiempo y eliminar errores.</p><p>Entre las características esenciales que suelen presentar este tipo de sistemas destacan:</p><ul><li>Notificaciones por email: a través de la notificaciones por email, los administradores reciben información detallada del punto en el que se encuentra una tarea.</li><li>SLA control status: se trata de una representación gráfica del estado de una tarea. Gracias a un código de colores se enfoca la importancia en aquellas etapas del proceso que necesitan de mayor atención o están experimentando algún problema.</li><li>Formularios pre-completados: con el fin de evitar las pérdidas de tiempo a la hora de rellenar formularios repetitivos, se aconseja la distribución de formularios parcialmente completos.</li><li>Reasignación de tareas: no todos los procesos terminan funcionando de la forma en la que se planean. Por ello, y para evitar gastos económicos, el software de flujo de trabajo permite la reasignación de tareas.</li></ul><h3 id="Objetivos-de-los-sistemas-de-flujo-de-trabajo-workflow"><a href="#Objetivos-de-los-sistemas-de-flujo-de-trabajo-workflow" class="headerlink" title="Objetivos de los sistemas de flujo de trabajo (workflow)"></a>Objetivos de los sistemas de flujo de trabajo (workflow)</h3><p><strong>Métodos y organización en el sistema de información</strong></p><p>Uno de los principales objetivos de los sistemas de flujo de trabajo es reflejar, mecanizar y automatizar los métodos y la organización en el sistema de información. Y es que hay que tener en cuenta que hoy en día es esencial poder acceder a la información de forma fácil y eficaz y lo normal es que ésta esté en diferentes formatos, lo que puede provocar un problema de accesibilidad.</p><p><strong>Procedimientos organizativos</strong></p><p>El segundo objetivo de este tipo de sistemas es establecer los mecanismos de control y seguimiento de los procedimientos organizativos, algo que se consigue gracias a una normalización en la metodología de trabajo.</p><p><strong>Método y flujo de trabajo</strong></p><p>Por otro lado, los sistemas de flujo de trabajo tienen el objetivo de independizar el método y el flujo de trabajo de las personas que lo ejecutan.</p><p><strong>Movilidad del personal</strong></p><p>El cuarto objetivo de los sistemas de flujo de trabajo es facilitar la movilidad del personal. De hecho, permiten trabajar en equipo desde distintos lugares físicos.</p><p><strong>Reingeniería de negocio</strong></p><p>Otro de los objetivos es soportar procesos de reingeniería de negocio que es un método mediante el cual, en función de las necesidades del cliente, se rediseñan radicalmente los procesos principales de negocios, de principio a fin, con el objetivo de alcanzar mejoras espectaculares en medidas críticas de rendimiento, tales como costes, calidad, servicio y rapidez.</p><p><strong>Toma de decisiones</strong></p><p>El sexto objetivo es agilizar el proceso de intercambio de información y agilizar la toma de decisiones de una empresa, organización o institución. De hecho, con la implementación de este tipo de sistemas las decisiones son rápidas, ágiles y oportunas.</p><p><strong>Servicio</strong></p><p>También es importante tener en cuenta que con este tipo de sistemas se optimiza el servicio. En este sentido, hay que señalar que supone dar una respuesta más rápida a los clientes, además de transmitir una sensación de apuesta por la tecnología, lo que contribuye a motivar a los trabajadores.</p><p><strong>Gestión del conocimiento</strong></p><p>El último objetivo es la mejora de la gestión del conocimiento, una nueva cultura empresarial que se basa en gestionar las organizaciones situando los recursos humanos como el principal activo.</p><h3 id="Aplicaciones-Sistemas-Workflow-flujos-de-trabajo"><a href="#Aplicaciones-Sistemas-Workflow-flujos-de-trabajo" class="headerlink" title="Aplicaciones/Sistemas Workflow, flujos de trabajo"></a>Aplicaciones/Sistemas Workflow, flujos de trabajo</h3><p>Las aplicaciones Workflow automatizan la secuencia de acciones, actividades o tareas en la ejecución del proceso, permiten realizar un seguimiento de cada etapa del mismo y aportan las herramientas necesarias para su control o gestión del flujo de trabajo.</p><p>Un sistema Workflow va más allá y se caracteriza, principalmente, por una adecuada integración con sistemas de información actuales: BD, gestión documental, mensajería, ERP, etc, permitiendo la ampliación de un workflow, de un simple proceso a la integración de varios procesos de negocio interrelacionados.</p><p>En el mercado existen diversos tipos de herramientas Workflow, las principales son: <strong>Workflow Corporativo, Workflow de Aplicación, Workflow Documental y Workflow de Producción</strong> . Algunos de ellas se limitan a su área en particular y otras permiten la comunicación con aplicaciones externas de manera <em>síncrona</em> (esperando la respuesta antes de proseguir) y/o <em>asíncrona</em> (solamente deja un “mensaje” y recupera la respuesta más adelante).</p><h3 id="Lenguajes-de-especificacion-de-workflow"><a href="#Lenguajes-de-especificacion-de-workflow" class="headerlink" title="Lenguajes de especificación de workflow"></a>Lenguajes de especificación de workflow</h3><ul><li><strong>BPMN</strong> (Business Proccess Model and Notation): Modelo y Notación de Procesos de Negocio.</li><li><strong>BPEL / WS-BPEL</strong> ( <em>Web Services</em> Business Process Execution Language): Lenguaje de ejecución de Procesos de Negocio <em>con Servicios Web</em> .</li><li><strong>XPDL</strong> (XML Process Definition Language): Lenguaje para la Definición de un Flujo de Trabajo.</li><li><strong>YAML</strong> (Yet Another Workflow Language): Lenguaje de workflow basado en patrones de Workflow.</li></ul><h2 id="Busqueda-de-informacion-robots-spiders-otros"><a href="#Busqueda-de-informacion-robots-spiders-otros" class="headerlink" title="Búsqueda de información: robots, spiders, otros"></a>Búsqueda de información: robots, spiders, otros</h2><p>Un motor de búsqueda, también conocido como buscador, es un sistema informático que busca archivos almacenados en servidores web gracias a su “spider” (Web crawler). Un ejemplo son los buscadores de Internet (algunos buscan únicamente en la web, pero otros lo hacen además en noticias, servicios como Gopher, FTP, etc) cuando se pide información sobre algún tema. Las búsquedas se hacen con palabras clave o con árboles jerárquicos por temas; el resultado de la búsqueda es un listado de direcciones web en los que se mencionan temas relacionados con las palabras claves buscadas.</p><p>Como operan de forma automática, los motores de búsqueda contienen generalmente más información que los directorios. Sin embargo, estos últimos también han de construirse a partir de búsquedas (no automatizadas) o bien partir de avisos dados por los creadores de páginas (lo cual puede ser muy limitante). Los buenos directorios combinan ambos sistemas. Hoy en día Internet se ha convertido en una herramienta, para la búsqueda de información, rápida, para ello han surgido los buscadores que son un motor de búsqueda que nos facilita encontrar información rápida de cualquier tema de interés, en cualquier área de las ciencias, y de cualquier parte del mundo.</p><p>Se pueden clasificar en dos tipos:</p><ol><li><strong>Índices temáticos</strong> : Son sistemas de búsqueda por temas o categorías jerarquizados (aunque también suelen incluir sistemas de búsqueda por palabras clave). Se trata de BD de direcciones Web elaboradas “manualmente”, es decir, hay personas que se encargan de asignar cada página web a una categoría o tema determinado. Por ejemplo existen buscadores de fauna, flora, educación, música y de diferentes áreas.</li><li><strong>Motores de búsqueda</strong> : Son sistemas de búsqueda por palabras clave. Son BD que incorporan automáticamente páginas web mediante “robots” de búsqueda en la red.</li></ol><p>Clases de buscadores:</p><p><strong>Buscadores jerárquicos (Arañas o Spiders)</strong></p><p>Recorren las páginas recopilando información sobre los contenidos de las páginas. Cuando se busca una información en los motores, ellos consultan su BD y presentan resultados clasificados por su relevancia. De las webs, los buscadores pueden almacenar desde la página de entrada, a todas las páginas que residan en el servidor.</p><p>Si se busca una palabra, por ejemplo, “ordenadores”. En los resultados que ofrecerá el motor de búsqueda, aparecerán las páginas que contengan esta palabra en alguna parte de su texto.</p><p>Si consideran que un sitio web es importante para el usuario, tienden a registrarlas todas. Si no la consideran importante, sólo almacenan una o más páginas.</p><p>Cada cierto tiempo, los motores revisan los sitios, para actualizar los contenidos de su BD, por tanto puede que los resultados de la búsqueda estén desactualizados.</p><p>Los buscadores jerárquicos tienen una colección de programas simples y potentes con diferentes cometidos. Se suelen dividir en tres partes. Los programas que exploran la red -arañas (spiders)-, los que construyen la BD y los que utiliza el usuario, el programa que explota la BD.</p><p>Si se paga, se puede aparecer en las primeras páginas de resultados, aunque los principales buscadores delimitan estos resultados e indican al usuario que se trata de resultados esponsorizados o patrocinados. Hasta el momento, aparentemente, esta forma de publicidad es indicada explícitamente. Los buscadores jerárquicos se han visto obligados a comercializar este tipo de publicidad para poder seguir ofreciendo a los usuarios el servicio de forma gratuita.</p><p>Ejemplo de arañas: Google, Bing, Hotbot.</p><p><strong>Directorios</strong></p><p>Una tecnología barata, ampliamente utilizada por gran cantidad de scripts en el mercado. No se requieren muchos recursos de informática. En cambio, se requiere más soporte humano y mantenimiento.</p><p>Los algoritmos son muchos más sencillos, presentando la información sobre los sitios registrados como una colección de directorios. No recorren los sitios web ni almacenan sus contenidos. Solo registran algunos de los datos de nuestra página, como el título y la descripción que se introduzcan al momento de registrar el sitio en el directorio.</p><p>Los resultados de la búsqueda, estarán determinados por la información que se haya suministrado al directorio cuando se registra el sitio. En cambio, a diferencia de los motores, son revisadas por operadores humanos, y clasificadas según categorías, de forma que es más fácil encontrar páginas del tema de nuestro interés.</p><p>Más que buscar información sobre contenidos de la página, los resultados serán presentados haciendo referencia a los contenidos y temática del sitio.</p><p>Su tecnología es muy barata y sencilla.</p><p>Ejemplo de directorios: Antiguos directorios, Open Directory Project, Yahoo!, Terra (antiguo Olé). Ahora, ambos utilizan tecnología de búsqueda jerárquica, y Yahoo! conserva su directorio.</p><p><strong>Metabuscador</strong></p><p>Permite lanzar varias búsquedas en motores seleccionados respetando el formato original de los buscadores. Lo que hacen, es realizar búsquedas en auténticos buscadores, analizan los resultados de la página, y presentan sus propios resultados, según un orden definido por el sistema estructural del metabuscador.</p><p><strong>FFA – Enlaces gratuitos para todos</strong></p><p>FFA (Free For All). Cualquiera puede inscribir su página durante un tiempo limitado en estos pequeños directorios. Los enlaces no son permanentes.</p><p><strong>Buscadores verticales</strong></p><p>Buscadores especializados en un sector concreto, lo que les permite analizar la información con mayor profundidad, disponer de resultados más actualizados y ofrecer al usuario herramientas de búsqueda avanzadas. Es importante resaltar que utilizan índices especializados de esta manera para acceder a la información de una manera más específica y fácil.</p><p>Ejemplos de este tipo de buscadores son: Trovit, Nestoria.</p><h3 id="¿Que-es-un-crawler-o-aranas-de-la-web-y-que-hacen"><a href="#¿Que-es-un-crawler-o-aranas-de-la-web-y-que-hacen" class="headerlink" title="¿Qué es un crawler o arañas de la web y qué hacen?"></a>¿Qué es un crawler o arañas de la web y qué hacen?</h3><p><strong>¿Qué es un crawler?</strong></p><p>El crawler, también conocido como araña de la web, es un software o webbot que se encarga de recorrer los enlaces de las páginas webs de una forma automática y sistemática.</p><p><strong>¿Qué hace un crawler y cómo funciona?</strong></p><p>Normalmente, un crawler dispone de un conjunto de inicial de URLs, conocidas como semillas, y va descargando las páginas web asociadas a las semillas y buscando dentro de éstas otras URLs.</p><p>Cada nueva URL encontrada se añade a la lista de URLs que la araña web debe visitar. Es decir, recoleta URL’s para posteriormente procesarlas. Así, el motor de búsqueda creará un índice de las páginas descargadas para proporcionar búsquedas más rápidas.</p><p>Cuando un crawler visita un sitio web opta por una de estas dos alternativas:</p><ul><li>Buscar el archivo robots.txt y la meta etiqueta robots para ver las reglas que se han estipulado.</li><li>Elaborar un índice de las páginas web que hay en su sitio. ¿Cómo? Explorando el contenido del texto visible, de varias etiquetas HTML y los hipervínculos en listados en la página.</li></ul><p>Ejemplo: Googlebot</p><h3 id="Diferencia-entre-los-robots-spider-y-crawler"><a href="#Diferencia-entre-los-robots-spider-y-crawler" class="headerlink" title="Diferencia entre los robots, spider y crawler"></a>Diferencia entre los robots, spider y crawler</h3><p>El ranking de los motores de búsqueda está basado en robots (arañas o crawlers).</p><p><strong>Crawler</strong></p><p>Se trata de un <strong>software desarrollado para realizar una exploración en Internet</strong> de una manera sistemática a través de la información percibida como relevante para su función. Capturan el texto de las páginas y los enlaces encontrados y por lo tanto permiten encontrar nuevas páginas. Es una de las bases de los motores de búsqueda, que son responsables de la indexación de sitios web, almacenarlos en la BD de los buscadores. Es también conocio como araña o Bot (robot).</p><p><strong>El proceso que ejecuta un rastreador web se llama Web Crawler o rastreador</strong> . Muchos sitios, en particular los motores de búsqueda utilizan rastreadores para mantener una BD actualizada. Los rastreadores web son usados básicamente para realizar una copia de todas las páginas visitadas para post-procesamiento por un motor de búsqueda que indexa las páginas descargadas para proporcionar búsquedas rápidas. Los rastreadores también se pueden utilizar para tareas de mantenimiento automatizadas en un sitio web, como la comprobación de enlaces o la validación de código HTML. Las spiders también pueden ser utilizadas para obtener los tipos específicos de información de páginas web, como direcciones de correo electrónico (más comúnmente como spam).</p><p>Los rastreadores de motores de búsqueda por lo general buscan información acerca de los permisos sobre el contenido. En especial hay dos maneras de bloquear un rastreador que indexe una página en particular (y los enlaces contenidos en ella). La primera, y más común, es a través del archivo robots.txt. La otra forma es a través de la etiqueta meta robots con el valor “noindex” o “nofollow”, que sirve para no indexar (la página sí) y no por debajo (los enlaces en la página), respectivamente. También hay una tercera posibilidad, mucho menos explotado, que está utilizando el ‘rel=”nofollow”‘ para los enlaces, lo que indica que el rastreador que enlazan, en particular, no se debe seguir.</p><p><strong>Araña</strong></p><p><strong>También conocido como Robot, Bot o Cadenas</strong> . Estos son los programas utilizados por los motores de búsqueda para navegar por Internet y descargar automáticamente contenido de sitios web. Metódicamente, expone el contenido que estime pertinente en el código fuente de los sitios, y almacena el resto en su BD. Por lo tanto, los motores de búsqueda robots basados (arañas o crawlers) buscan en Internet después de la búsqueda de información y lo clasifican de acuerdo a los vínculos y también al contenido que se encuentra en las páginas de búsqueda, como el principal portal de búsqueda web, Google. Por lo tanto, cualquier página necesita ser trazada por el robot y por lo tanto pueden aparecer los resultados de búsqueda de los mecanismos implicados.</p><h2 id="Posicionamiento-y-Buscadores-SEO"><a href="#Posicionamiento-y-Buscadores-SEO" class="headerlink" title="Posicionamiento y Buscadores (SEO)"></a>Posicionamiento y Buscadores (SEO)</h2><p><strong>¿Qué es?</strong></p><p>Posicionamiento web, posicionamiento en buscadores o posicionamiento SEO se refiere a las técnicas que buscan que una página web aparezca en las primeras posiciones de los resultados en buscadores (Google, Yahoo, …) para una serie de palabras o frases.</p><p><strong>Conceptos</strong></p><ul><li><strong>SEO</strong> (Search Engine Optimization) o posicionamiento orgánico/natural.</li><li><strong>SEM</strong> (Search Engine Marketing) o posicionamiento de pago/publicitario.</li><li><strong>SERPs</strong> (Search Engine Results Page) o Página de resultados del Buscador.</li></ul><p><img src="https://gsitic.files.wordpress.com/2018/01/seo.jpg?w=825" alt=""></p><p><strong>Posicionamiento web natural u orgánico</strong></p><p>Los buscadores proporcionan dos tipos de resultados: <strong>enlaces patrocinados</strong> o anuncios y <strong>resultados orgánicos</strong> o naturales:</p><ul><li><strong>Resultados Orgánicos, Posicionamiento “Gratuito” o Posicionamiento Natural en Buscadores (SEO)</strong> : los buscadores como Google aplican cierto criterio para decidir en qué orden deben aparecer los resultados de una búsqueda. Algunas de las características valoradas por los buscadores son, por ejemplo, la popularidad de la página web, su contenido, su velocidad de carga y otras cuestiones técnicas.</li><li><strong>Enlaces Patrocinados, Posicionamiento “de Pago” o Marketing en Buscadores (SEM)</strong> : la presencia de una página web en los resultados patrocinados se consigue con la compra de palabras clave al buscador (Google, Yahoo!, Bing, …). Es importante destacar que el anunciante no paga por mostrar su anuncio, sólo paga cuando el usuario hace clic en él. A este tipo de publicidad se le llama también <strong>PPC (Pago Por Clic)</strong> .</li></ul><p><strong>Diferencias entre SEO y SEM</strong></p><ul><li>Funcionamiento:<ul><li>El criterio utilizado por los buscadores para mostrar los resultados naturales (SEO) es desconocido y las técnicas para mejorar el SEO están en las recomendaciones que de vez en cuando dan los propios buscadores y en la experiencia de quienes trabajan haciendo SEO.</li><li>Existen certificaciones oficiales de SEM, expedidas por los propios buscadores, que permiten formarse oficialmente en esta disciplina.</li></ul></li><li>Tiempo en obtener resultados:<ul><li>Los resultados de las acciones para mejorar el SEO son observables a largo plazo.</li><li>Con el SEM se obtienen resultados de forma más inmediata.</li></ul></li><li>Garantías en la obtención de resultados:<ul><li>En el SEO es imposible estimar, y mucho menos garantizar resultados.</li><li>En el SEM se puede estimar resultados.</li></ul></li><li>Costes:<ul><li>La competencia en el SEO es tan alta que intentar aparecer en la primera página de resultados puede ser inútil, sobre todo para términos genéricos.</li><li>En el SEM, el precio de las palabras clave cambia en cada instante dependiendo de varios factores: competencia, país, idioma, …</li></ul></li><li>Medición de resultados:<ul><li>Es difícil medir con rigurosidad los resultados de las acciones para mejorar el SEO.</li><li>Los resultados del SEM se pueden medir con total precisión.</li></ul></li></ul><p><strong>Objetivos del SEO</strong></p><ul><li><strong>Definir las palabras claves</strong> que son importantes para nuestra página, pues serán lo términos utilizados por los usuarios para buscar información sobre contenido y soluciones que nosotros proveemos. Tenemos que tener en cuenta la Teoría del Long Tail aplicada a las búsquedas en la red; ya que, a pesar de que exista un número de búsquedas muy frecuentes, la mayoría de ellas son muy diferentes entre sí, y buscadores como Google se centraron en las pequeñas pero variadas búsquedas para obtener beneficios y componer su sistema de búsqueda.</li><li><strong>Mejorar la visibilidad de la página web</strong> . Los algoritmos empleados que emplean los buscadores para posicionar las páginas webs no son conocidos y van modificándose continuamente; consecuentemente, nadie puede tener la certeza de saber cómo posicionar en primer lugar una web en los SERPs, aunque se pueda trabajar para intentar aparecer en los primeros puestos. No obstante, se conocen algunos de los aspectos que influyen en los algoritmos y que darán visibilidad a la web:<ul><li>Los propios de la programación de la página, que son “manipulables” y tenidos en cuenta para valorar la relevancia de la web, llamados <strong>factores de relevancia on-page</strong> .</li><li>Los que están relacionados con otras páginas webs a través de una estructura de vínculos que permiten navegar por toda la red de internet, llamados f <strong>actores de relevancia off-page</strong> . En estos se incluye el <strong>Social SEO</strong> , que mayoritariamente está centrado en la capacidad de aportar enlaces entrantes desde los medios sociales hacia la web.</li></ul></li><li><strong>Aumentar el número de visitas</strong> que están buscando lo que puede ofrecerle nuestra página; es decir, incrementar el tráfico cualificado que llega de los buscadores a la web.</li></ul><h3 id="Link-Building"><a href="#Link-Building" class="headerlink" title="Link Building"></a>Link Building</h3><p>Linkbuilding o construcción de enlaces, es una técnica de SEO que consiste en conseguir que otras páginas web enlacen a la página que interesa que los buscadores consideren relevantes y la posicionen mejor en sus rankings. La técnica puede hacerse de manera natural, cuando otras webs enlazan sin previo acuerdo por algún hecho o dicho, o bien de manera artificial, cuando se simula que los enlaces se han conseguido de manera natural.</p><p>Esta se basa en el concepto de que uno de los factores que se incluyen dentro de la evaluación del ranking de una página es la cantidad de enlaces entrantes que tiene una página, concepto basado en el hecho de que el número de enlaces entrantes constituía uno de los factores evaluados en PageRank en 1999 por Google.</p><p>Las ventajas son:</p><ul><li>Posibilidad de medir la demanda y cantidad de personas que están buscando a través de una palabra clave.</li><li>Efectividad del posicionamiento.</li><li>Posicionamiento de la marca o branding.</li></ul><p><strong>Técnicas</strong></p><ul><li><strong>Alta en directorios</strong> : consiste en dar de alta la web en diferentes directorios, ya sean generales o temáticos.</li><li><strong>Directorios de artículos</strong> : consiste en escribir artículos para publicarlos en directorios que, a cambio del contenido, permiten incluir enlaces hacia una web.</li><li><strong>Bookmarking</strong> : se trata de guardar aquello que interesa posicionar en los buscadores en las diferentes webs de bookmarking.</li><li><strong>Link baiting</strong> : es una de las técnicas más valoradas por los buscadores pero una de las más difíciles de conseguir, ya que solo se consiguen cientos de enlaces a un artículo si este realmente aporta valor.</li><li><strong>Intercambio de enlaces</strong> : una buena forma de conseguir enlaces y una de las primeras que se empezaron a utilizar.</li><li><strong>Compra de enlaces</strong> : Más efectiva que el intercambio de enlaces pero también más cara. Para Google esta forma de conseguir enlaces es penalizable.</li><li><strong>Enlaces desde foros</strong> : otra forma para construir enlaces es de foros, agregando el link o enlace desde la firma del foro.</li><li><strong>Otras técnicas</strong> : envío de enlaces a bloggers, redes sociales, escribir revisiones, notas de prensa, entre otros.</li></ul><h3 id="Pasos-para-SEO-y-posicionamiento-web"><a href="#Pasos-para-SEO-y-posicionamiento-web" class="headerlink" title="Pasos para SEO y posicionamiento web"></a>Pasos para SEO y posicionamiento web</h3><p><strong>Posicionamiento a través de las Palabras clave</strong></p><ul><li>Elige bien tus palabras clave.</li><li>Comprueba la competencia.</li><li>Mide la densidad de las palabras.</li><li>Usa las palabras clave.</li><li>Palabras clave en títulos y negrita.</li><li>Mide y analiza tu posicionamiento natural para distintas palabras clave.</li></ul><p><strong>Configuración del Sitio</strong></p><ul><li>Meta description y title.</li><li>Url amigables y editadas.</li><li>Creación y envío de sitemap a buscadores.</li><li>Automatiza el envío de sitemaps.</li><li>Transcribe el contenido audiovisual.</li><li>Favicon.</li><li>Evita el uso de cookies.</li><li>Utiliza rel=”autor”.</li></ul><p><strong>Las imágenes</strong></p><ul><li>Título y descripción.</li><li>Especifica su tamaño.</li><li>No escalar imágenes en Html.</li><li>Optimización de imágenes para la web.</li><li>Combinar imágenes usando CSS sprites.</li></ul><p><strong>Cuida los enlaces</strong></p><ul><li>Anchor text diversificados.</li><li>Comprueba los links rotos.</li><li>Evita las redirecciones.</li><li>Automatizar la búsqueda de links rotos.</li><li>Conoce el PageRank.</li><li>No enlaces contenido malicioso o ilegal.</li><li>Busca en donde enlazan a tu competencia.</li><li>Utiliza enlaces internos.</li></ul><p><strong>Evitar contenido duplicado</strong></p><ul><li>Textos originales.</li><li>No-index a nuestro contenido duplicado.</li><li>Página inicial con sólo muestra.</li><li>Descripción y Título Meta sin repetir.</li><li>URL Canónica.</li><li>Un mismo diseño para web y móvil.</li></ul><p><strong>Guía de Estilo</strong></p><ul><li>Crear contenido divertidos y originales.</li><li>Contenidos largos.</li><li>Cuida a tus visitantes desde dispositivos.</li><li>Publica periódicamente.</li><li>Participa y conecta con tu comunidad.</li><li>Protocolo después de cada artículo.</li><li>Guest Blogging.</li><li>Ofrece algún contenido de valor.</li><li>Landing Page.</li><li>Cuida al lector.</li></ul><p><strong>Evitar penalizaciones</strong></p><ul><li>No poner palabras clave fuera de contexto.</li><li>No poner texto escondido.</li><li>Evita los errores de código que puedas.</li><li>No te pases con el intercambio de enlaces.</li></ul><p><strong>Reduce el tiempo de carga de tu página</strong></p><ul><li>Mide y mejora la velocidad de tu página.</li><li>No abusar de los códigos en javascript.</li><li>Elimina plugins de WordPress que no utilices.</li><li>Pon javascript al final del código.</li><li>Retrasar o diferir la carga de javascript.</li><li>Ahorra y limpia tu código.</li><li>Minimiza tu Css y Javascript.</li><li>Combina tus Javascript.</li><li>Usa la paginación.</li><li>Reduce el número de consultas de DNS.</li><li>Pocas llamadas http.</li><li>Comprimir en gzip.</li><li>Usar cache de la página.</li><li>Usar cache para Javascript.</li><li>Determinar una fecha de caducidad de la cache.</li><li>Usar un CDN.</li><li>No usar tablas anidadas en html.</li><li>CSS externo.</li><li>Javascript externo.</li><li>Comprueba los tiempos de carga de cada página.</li></ul><p><strong>Herramientas imprescindibles</strong></p><ul><li>Woorank.</li><li>Web Ceo.</li><li>Screaming Frog.</li><li>All in One SEO Pack.</li><li>SEO by Yoast.</li><li>W3 Total Cache.</li><li>SEO Chat Seo Tools.</li></ul><h2 id="Bibliografia"><a href="#Bibliografia" class="headerlink" title="Bibliografía"></a>Bibliografía</h2><ul><li><a href="https://es.scribd.com/document/357349668/TICB3-Documatica" rel="external nofollow noopener noreferrer" target="_blank">Scribd (Ibiza Ales)</a></li><li><a href="http://www.xn--diseowebmurcia1-1qb.es/gestor-contenidos-cms/" rel="external nofollow noopener noreferrer" target="_blank">Horizonweb</a></li><li><a href="https://nocionesunidas.com/blog/tecnologia/gestor-contenidos-cms-cuales-los-mas-usados/#.WmXN4qjiZph" rel="external nofollow noopener noreferrer" target="_blank">NocionesUnidas</a></li><li><a href="https://www.coguan.com/tipos-de-gestores-de-contenidos/" rel="external nofollow noopener noreferrer" target="_blank">Coguan</a></li><li><a href="https://www.neosoft.es/blog/que-es-un-cms-o-gestor-de-contenidos/" rel="external nofollow noopener noreferrer" target="_blank">Neosoft</a></li><li><a href="https://desarrolloweb.com/articulos/que-es-la-sindicacion.html" rel="external nofollow noopener noreferrer" target="_blank">DesarrolloWeb</a></li><li><a href="https://mariaelena-sindicacion.weebly.com/definicioacuten.html" rel="external nofollow noopener noreferrer" target="_blank">mariaelena</a></li><li><a href="https://www.bibliopos.es/la-sindicacion-contenidos/" rel="external nofollow noopener noreferrer" target="_blank">biblipos</a></li><li><a href="https://www.gestion.org/economia-empresa/gestion-administrativa/29867/que-es-workflow-o-flujo-de-trabajo/" rel="external nofollow noopener noreferrer" target="_blank">gestion.org</a></li><li><a href="https://www.ticportal.es/noticias/sistemas-gestion-documental/flujo-de-trabajo" rel="external nofollow noopener noreferrer" target="_blank">tic.portal</a></li><li><a href="https://www.eaeprogramas.es/blog/los-ocho-objetivos-de-los-sistemas-de-flujo-de-trabajo-workflowhttps://www.eaeprogramas.es/blog/los-ocho-objetivos-de-los-sistemas-de-flujo-de-trabajo-workflow" rel="external nofollow noopener noreferrer" target="_blank">EAE Business School</a></li><li><a href="http://pixelware.com/workflow-flujo-trabajo/" rel="external nofollow noopener noreferrer" target="_blank">Pixelware</a></li><li><a href="https://es.wikipedia.org/wiki/Flujo_de_trabajo" rel="external nofollow noopener noreferrer" target="_blank">wikipedia</a></li><li><a href="https://www.tiendasvirtualesycomercioweb.com/ique-son-los-spiders-o-motores-de-busqueda" rel="external nofollow noopener noreferrer" target="_blank">Tiendas Virtuales y Comercio Web</a></li><li><a href="http://seocoaching.co/que-es-un-crawler-o-aranas-de-la-web-y-que-hacen/" rel="external nofollow noopener noreferrer" target="_blank">Seo Coaching</a></li><li><a href="http://seo-basico.blogspot.com.es/2013/08/cual-es-la-diferencia-entre-los-robots.html" rel="external nofollow noopener noreferrer" target="_blank">Seo Básico</a></li><li><a href="http://www.arumeinformatica.es/dudas/posicionamiento-web-seo/" rel="external nofollow noopener noreferrer" target="_blank">Arume</a></li><li><a href="https://mongemalo.es/que-es-el-posicionamiento-en-buscadores-seo-y-sem-conceptos-super-basicos/" rel="external nofollow noopener noreferrer" target="_blank">mongemalo</a></li><li><a href="https://marketingdigitaldesdecero.com/2013/05/02/que-es-el-seo-posicionamiento-natural-en-buscadores/" rel="external nofollow noopener noreferrer" target="_blank">Marketing Digital desde 0</a></li><li><a href="http://brunovd.com/75-pasos-para-seo-y-posicionamiento-en-buscadores/" rel="external nofollow noopener noreferrer" target="_blank">Bruno VD</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Documatica-Gestion-y-archivo-electronico-de-documentos-Sistemas-de-gestion-documental-y-de-contenidos-Sindicacion-de-contenido-Siste
      
    
    </summary>
    
      <category term="B2" scheme="http://localhost:4000/categories/B2/"/>
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://localhost:4000/wiki/Web/index/"/>
    <id>http://localhost:4000/wiki/Web/index/</id>
    <published>2019-01-17T10:10:24.000Z</published>
    <updated>2019-01-18T10:45:16.900Z</updated>
    
    <content type="html"><![CDATA[<p>Index</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Index&lt;/p&gt;

      
    
    </summary>
    
      <category term="Web" scheme="http://localhost:4000/categories/Web/"/>
    
    
  </entry>
  
  <entry>
    <title>B1</title>
    <link href="http://localhost:4000/wiki/B1/b1-index/"/>
    <id>http://localhost:4000/wiki/B1/b1-index/</id>
    <published>2019-01-17T10:10:08.000Z</published>
    <updated>2019-01-18T10:45:16.566Z</updated>
    
    <content type="html"><![CDATA[<p>Bloque 1</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Bloque 1&lt;/p&gt;

      
    
    </summary>
    
      <category term="B1" scheme="http://localhost:4000/categories/B1/"/>
    
    
  </entry>
  
  <entry>
    <title>Temario</title>
    <link href="http://localhost:4000/wiki/B0/index/"/>
    <id>http://localhost:4000/wiki/B0/index/</id>
    <published>2019-01-16T15:22:58.000Z</published>
    <updated>2019-01-18T10:45:16.564Z</updated>
    
    <content type="html"><![CDATA[<p>Temario GSI    </p><h1 id="Organizacion-del-Estado-y-Administracion-electronica"><a href="#Organizacion-del-Estado-y-Administracion-electronica" class="headerlink" title="Organización del Estado y Administración electrónica."></a>Organización del Estado y Administración electrónica.</h1><ol><li>La Constitución Española de 1978. Derechos y deberes fundamentales. Su garantía y suspensión. La Jefatura del Estado. La Corona. Funciones constitucionales del Rey.</li><li>Las Cortes Generales. Atribuciones del Congreso de los Diputados y del Senado. El Tribunal Constitucional: composición y atribuciones. El Defensor del Pueblo.</li><li>El Gobierno. Su composición. Nombramiento y cese. Las funciones del Gobierno. Relaciones entre el Gobierno y las Cortes Generales.</li><li>El Gobierno Abierto. Concepto y principios informadores: colaboración, participación, transparencia y rendición de cuentas. La Alianza para el Gobierno Abierto y los planes de acción de España. La Ley 19/2013, de 9 de diciembre, de transparencia, acceso a la información pública y buen gobierno. El Consejo de Transparencia y Buen Gobierno: Real Decreto 919/2014, de 31 de octubre, por el que se aprueba su estatuto. Funciones. El Portal de Transparencia. Las Unidades de Información y Transparencia (UITS).</li><li>La Administración pública: principios constitucionales informadores. La Administración General del Estado: organización y personal a su servicio. El texto refundido del Estatuto Básico del Empleado Público y demás normativa vigente. Las Comunidades Autónomas y la Administración local: regulación constitucional.</li><li>Las fuentes del derecho administrativo. La jerarquía de las fuentes. La ley. Las Disposiciones del Gobierno con fuerza de ley: decreto-ley y decreto legislativo. El reglamento: concepto, clases y límites. Otras fuentes del derecho administrativo.</li><li>Políticas de igualdad de género. La Ley Orgánica 3/2007, de 22 de marzo, para la igualdad efectiva de mujeres y hombres. Políticas contra la violencia de género. La Ley Orgánica 1/2004, de 28 de diciembre, de medidas de protección integral contra la violencia de género. Discapacidad y dependencia.</li><li>La sociedad de la información. La Agenda Digital para España. Identidad y firma electrónica: régimen jurídico. Reglamento eIDAS. El DNI electrónico.</li><li>La protección de datos personales. Régimen jurídico. El Reglamento (UE) 2016/679, de 27 de abril, relativo a la protección de las personas físicas en lo que respecta al tratamiento de datos personales y a la libre circulación de estos datos. Principios y derechos. Obligaciones. El Delegado de Protección de Datos en las Administraciones Públicas. La Agencia Española de Protección de Datos.</li><li>Las Leyes de Procedimiento Administrativo Común de las Administraciones Públicas y de Régimen Jurídico del Sector Público y su normativa de desarrollo. La gestión electrónica de los procedimientos administrativos. Esquema Nacional de Seguridad (ENS). Esquema Nacional de Interoperabilidad (ENI). Normas técnicas de interoperabilidad. Guías CCN-STIC serie 800.</li><li>Instrumentos para el acceso electrónico a las Administraciones públicas: sedes electrónicas, canales y punto de acceso, identificación y autenticación. Datos abiertos. Normativa vigente de reutilización de la información del sector público.</li><li>Instrumentos y órganos para la cooperación entre Administraciones públicas en materia de Administración electrónica. Infraestructuras y servicios comunes. Plataformas de validación e interconexión de redes.</li></ol><h1 id="Tecnologia-basica"><a href="#Tecnologia-basica" class="headerlink" title="Tecnología básica."></a>Tecnología básica.</h1><ol><li>Tecnologías actuales de ordenadores: de los dispositivos móviles a los superordenadores y arquitecturas escalables y de altas prestaciones. Computación en la nube. Base tecnológica. Componentes, funcionalidades y capacidades.</li><li>Conceptos de sistemas operativos: Características, evolución y tendencias. Estructura, componentes y funciones. Sistemas operativos multiprocesador.</li><li>Características técnicas y funcionales de los sistemas operativos: Windows, Linux, Unix y otros. Sistemas operativos para dispositivos móviles.</li><li>Características técnicas de los lenguajes y paradigmas actuales de programación.</li><li>Inteligencia de negocios: cuadros de mando integral, sistemas de soporte a las decisiones, sistemas de información ejecutiva y almacenes de datos. OLTP y OLAP.</li><li>Sistemas de gestión de bases de datos relacionales: características y elementos constitutivos. Antecedentes históricos. El lenguaje SQL. Estándares de conectividad: ODBC y JDBC.</li><li>Arquitectura de sistemas cliente-servidor y multicapas: tipología. Componentes. Interoperabilidad de componentes. Ventajas e inconvenientes. Arquitectura de servicios web.</li><li>El modelo TCP/IP y el modelo de referencia de interconexión de sistemas abiertos (OSI) de ISO: arquitectura, capas, interfaces, protocolos, direccionamiento y encaminamiento.</li><li>Lenguajes de marca o etiqueta. Características y funcionalidades. SGML, HTML, XML y sus derivaciones. Lenguajes de script.</li><li>Análisis y gestión de riesgos de los sistemas de información. La metodología MAGERIT: método, elementos y técnicas.</li><li>Auditoría Informática: objetivos, alcance y metodología. Técnicas y herramientas. Normas y estándares. Auditoría del ENS y de protección de datos. Auditoría de seguridad física.</li><li>Gestión de la atención a clientes y usuarios: centros de contacto, CRM. Arquitectura multicanal. Sistemas de respuesta de voz interactiva (IVR). Voice XML.</li><li>Seguridad física y lógica de un sistema de información. Herramientas en ciberseguridad. Gestión de incidentes. Informática forense.</li><li>Software libre y software propietario. Características y tipos de licencias. La protección jurídica de los programas de ordenador. Tecnologías de protección de derechos digitales.</li><li>Técnicas de evaluación de alternativas y análisis de viabilidad. Personal, procedimientos, datos, software y hardware. Presupuestación y control de costes de un proyecto informático.</li><li>Documática. Gestión y archivo electrónico de documentos. Sistemas de gestión documental y de contenidos. Sindicación de contenido. Sistemas de gestión de flujos de trabajos. Búsqueda de información: robots, spiders, otros. Posicionamiento y buscadores (SEO).</li></ol><h1 id="Desarrollo-de-sistemas"><a href="#Desarrollo-de-sistemas" class="headerlink" title="Desarrollo de sistemas."></a>Desarrollo de sistemas.</h1><ol><li>Concepto del ciclo de vida de los sistemas y fases. Modelos de ciclo de vida.</li><li>Gestión del proceso de desarrollo: objetivos, actores y actividades. Técnicas y prácticas de gestión de proyectos.</li><li>Planificación del desarrollo. Técnicas de planificación. Metodologías de desarrollo. La metodología Métrica.</li><li>Estrategias de determinación de requerimientos: entrevistas, derivación de sistemas existentes, análisis y prototipos. La especificación de requisitos de software.</li><li>Análisis estructurado. Diagramas de flujo de datos. Diagramas de estructura. Diccionario de datos. Flujogramas.</li><li>Modelización conceptual. El modelo Entidad/Relación extendido (E/R): elementos. Reglas de modelización. Validación y construcción de modelos de datos.</li><li>Diseño de bases de datos. La arquitectura ANSI/SPARC. El modelo lógico relacional. Normalización. Diseño lógico. Diseño físico. Problemas de concurrencia de acceso. Mecanismos de resolución de conflictos.</li><li>Tipos abstractos de datos y estructuras de datos. Grafos. Tipos de algoritmos: ordenación y búsqueda. Estrategias de diseño de algoritmos. Organizaciones de ficheros.</li><li>Diseño de programas. Diseño estructurado. Análisis de transformación y de transacción. Cohesión y acoplamiento.</li><li>Construcción del sistema. Entornos de construcción y generación de código. Estándares de documentación. Manuales de usuario y manuales técnicos. Formación de usuarios y personal técnico: métodos y materiales.</li><li>Pruebas. Planificación y documentación. Utilización de datos de prueba. Pruebas de software, hardware, procedimientos y datos.</li><li>Instalación y cambio. Estrategias de sustitución. Recepción e instalación. Evaluación post-implementación. Mantenimiento.</li><li>Análisis y diseño orientado a objetos. Elementos. El proceso unificado de software. El lenguaje de modelado unificado (UML). Patrones de diseño.</li><li>La arquitectura Java EE. Características de funcionamiento. Elementos constitutivos. Productos y herramientas. Persistencia. Seguridad.</li><li>La plataforma.Net. Modelo de programación. Servicios. Herramientas. Persistencia. Seguridad.</li><li>Aplicaciones web. Diseño web multiplataforma/multidispositivo. Desarrollo web front-end y en servidor. Tecnologías de programación: JavaScript, applets, servlets, ASP, JSP y PHP. Servicios web: estándares, protocolos asociados, interoperabilidad y seguridad. Internacionalización y localización.</li><li>La calidad del software y su medida. Modelos, métricas, normas y estándares.</li><li>Accesibilidad, diseño universal y usabilidad. Accesibilidad y usabilidad de las tecnologías, productos y servicios relacionados con la sociedad de la información. Experiencia de Usuario o UX. La Guía de comunicación digital de la Administración del Estado.</li><li>Minería de datos. Aplicación a la resolución de problemas de gestión. Tecnología y algoritmos. Procesamiento analítico en línea (OLAP). Big data. Bases de datos NoSQL.</li></ol><h1 id="Sistemas-y-comunicaciones"><a href="#Sistemas-y-comunicaciones" class="headerlink" title="Sistemas y comunicaciones."></a>Sistemas y comunicaciones.</h1><ol><li>Administración del Sistema operativo y software de base. Funciones y responsabilidades.</li><li>Administración de sistemas de gestión de bases de datos. Funciones Y responsabilidades. Administración de datos.</li><li>Prácticas de mantenimiento de equipos e instalaciones. Tipos de mantenimiento. Monitorización y gestión de capacidad.</li><li>Gestión de la configuración. Gestión de librerías de programas y de medios magnéticos. Control de cambios y de versiones. Los lenguajes de control de trabajos. Las técnicas y herramientas de operación automática.</li><li>Control de la ejecución de los trabajos. Evaluación del rendimiento. Planificación de la capacidad. Análisis de la carga. Herramientas y técnicas utilizables.</li><li>Almacenamiento masivo de datos. Sistemas SAN, NAS y DAS: componentes, protocolos, gestión y administración. Virtualización del almacenamiento. Gestión de volúmenes.</li><li>Medios de transmisión guiados y no guiados (inalámbricos). Cables metálicos. Cable coaxial. Fibra óptica. Tipología de redes de cable. Sistemas de transmisión por satélite.</li><li>Redes locales. Tipología. Técnicas de transmisión. Métodos de acceso. Dispositivos de interconexión.</li><li>Administración de redes locales. Gestión de usuarios. Gestión de dispositivos. Monitorización y control de tráfico. Gestión SNMP. Gestión de incidencias.</li><li>Principales protocolos de la arquitectura de comunicaciones TCP/IP.</li><li>Planificación física de un centro de tratamiento de la información. Vulnerabilidades, riesgo y protección. Dimensionamiento de equipos. Factores a considerar. Virtualización de plataforma y de recursos. Virtualización de puestos de trabajo.</li><li>Redes conmutadas y de difusión. Conmutación de circuitos y de paquetes. Integración voz-datos. Protocolos de encaminamiento. Ethernet conmutada. MPLS. Calidad de servicio (QOS).</li><li>La seguridad en redes. Seguridad perimetral. Control de accesos. Técnicas criptográficas y protocolos seguros. Mecanismos de firma digital. Redes privadas virtuales. Seguridad en el puesto del usuario.</li><li>La red Internet: arquitectura de red. Principios de funcionamiento. Servicios: evolución, estado actual y perspectivas de futuro. La web 2.0. La web semántica. Internet de las Cosas (IoT).</li><li>Tecnología XDSL y telecomunicaciones por cable: concepto, características y normativa reguladora.</li><li>de nueva generación y servicios convergentes (NGN/IMS). VoIP, ToIP y comunicaciones unificadas. Convergencia telefonía fija-telefonía móvil.</li><li>Sistemas de comunicaciones móviles. Generaciones. Telefonía sin hilos y DECT. Paging. Radiotelefonía privada. Sistemas celulares. Trunking. Soluciones de gestión de dispositivos móviles (MDM).</li><li>Redes inalámbricas. Protocolos. Características funcionales y técnicas. Sistemas de expansión del espectro. Sistemas de acceso. Modos de operación. Seguridad. Normativa reguladora.</li><li>IP móvil y PLC (Power Line Comunications). Características técnicas. Modos de operación. Seguridad. Normativa reguladora. Ventajas e inconvenientes. Televisión digital. Servicios de televisión (IPTV y OTT). Radiodifusión sonora digital.</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Temario GSI    &lt;/p&gt;
&lt;h1 id=&quot;Organizacion-del-Estado-y-Administracion-electronica&quot;&gt;&lt;a href=&quot;#Organizacion-del-Estado-y-Administracion-elec
      
    
    </summary>
    
      <category term="B0" scheme="http://localhost:4000/categories/B0/"/>
    
    
  </entry>
  
  <entry>
    <title>B4</title>
    <link href="http://localhost:4000/wiki/B4/b4-index/"/>
    <id>http://localhost:4000/wiki/B4/b4-index/</id>
    <published>2019-01-16T15:22:00.000Z</published>
    <updated>2019-01-18T10:45:16.879Z</updated>
    
    <content type="html"><![CDATA[<p>B4 Sistemas y comunicaciones      </p><p>03 Prácticas de mantenimiento de equipos e instalaciones. Tipos de mantenimiento. Monitorización y gestión de capacidad.</p><p>04 Gestión de la configuración. Gestión de librerías de programas y de medios magnéticos. Controles de cambios y de versiones. Los lenguajes de control de trabajos. Las técnicas y herramientas de operación automática.</p><p>09 Administración de redes locales. Gestión de usuarios. Gestión de dispositivos. Monitorización y control de tráfico. Gestión SNMP. Gestión de incidencias.</p><p>11 Planificación física de un centro de tratamiento de la información. Vulnerabilidades, riesgo y protección. Dimensionamiento de equipos. Factores a considerar. Virtualización de plataforma y de recursos. Virtualización de puestos de trabajo.</p><p>12 Redes conmutadas y de difusión. Conmutación de circuitos y de paquetes. Integración voz-datos. Protocolos de encaminamiento. Ethernet conmutada. MPLS. Calidad de servicios (QOS).</p><p>13 La seguridad en redes. Seguridad perimetral. Control de accesos. Técnicas criptográficas y protocolos seguros. Mecanismos de firma digital. Redes privadas virtuales. Seguridad en el puesto del usuario.</p><p>18  Redes inalámbricas. Protocolos. Características funcionales y técnicas. Sistemas de expansión del espectro. Sistemas de acceso. Modos de operación. Seguridad. Normativa reguladora.</p><p>19 IP móvil y PLC (Power Line Comunications). Características técnicas. Modos de operación. Seguridad. Normativa reguladora. Ventajas e inconvenientes. Televisión digital. Servicios de televisión (IPTV y OTT). Radiodifusión sonora Digital.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;B4 Sistemas y comunicaciones      &lt;/p&gt;
&lt;p&gt;03 Prácticas de mantenimiento de equipos e instalaciones. Tipos de mantenimiento. Monitorizació
      
    
    </summary>
    
      <category term="B4" scheme="http://localhost:4000/categories/B4/"/>
    
    
  </entry>
  
  <entry>
    <title>B2-T12</title>
    <link href="http://localhost:4000/wiki/B2/b2-t12/"/>
    <id>http://localhost:4000/wiki/B2/b2-t12/</id>
    <published>2019-01-16T15:11:23.000Z</published>
    <updated>2019-01-18T10:45:16.597Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Gestion-de-la-atencion-a-clientes-y-usuarios-centros-de-contacto-CRM-Arquitectura-multicanal-Sistemas-de-respuesta-de-voz-interactiva-IVR-Voice-XML"><a href="#Gestion-de-la-atencion-a-clientes-y-usuarios-centros-de-contacto-CRM-Arquitectura-multicanal-Sistemas-de-respuesta-de-voz-interactiva-IVR-Voice-XML" class="headerlink" title="Gestión de la atención a clientes y usuarios: centros de contacto, CRM. Arquitectura multicanal. Sistemas de respuesta de voz interactiva (IVR). Voice XML."></a>Gestión de la atención a clientes y usuarios: centros de contacto, CRM. Arquitectura multicanal. Sistemas de respuesta de voz interactiva (IVR). Voice XML.</h1><h2 id="Gestion-de-la-atencion-a-clientes-y-usuarios-centros-de-contacto-CRM"><a href="#Gestion-de-la-atencion-a-clientes-y-usuarios-centros-de-contacto-CRM" class="headerlink" title="Gestión de la atención a clientes y usuarios: centros de contacto, CRM."></a>Gestión de la atención a clientes y usuarios: centros de contacto, CRM.</h2><h3 id="Introduccion"><a href="#Introduccion" class="headerlink" title="Introducción"></a>Introducción</h3><p>La <strong><em>customer relationship management</em></strong> , más conocida por sus siglas <strong>CRM</strong> , puede tener varios significados:</p><ul><li><strong>Administración basada en la relación con los clientes</strong> , un modelo de gestión de toda la organización, basada en la satisfacción del cliente (u orientación al mercado según otros autores). El concepto más cercano es <em>marketing relacional</em> (según se usa en España) y tiene mucha relación con otros conceptos como: <em>clienting, marketing 1×1, marketing directo de base de datos</em> , etc.</li><li><strong>Software para la administración de la relación con los cliente</strong> . Sistemas informáticos de apoyo a la gestión de las relaciones con los clientes, a la venta y al marketing, y que se integran en los llamados <em>Sistemas de Gestión Empresarial (SGE</em> ), y que incluyen <em>CRM, ERP, PLM, SCM, y SRM</em> . El software de CRM puede comprender varias funcionalidades para gestionar las ventas y los clientes de la empresa: automatización y promoción de ventas, tecnologías “data warehouse” (Almacén de datos) para agregar la información transaccional y proporcionar capa de reporting, dashboards e indicadores claves de negocio, funcionalidades para seguimiento de campañas de marketing y gestión de oportunidades de negocio, capacidades predictivas y de proyección de ventas.</li></ul><p>Customer relationship management (CRM) es un enfoque para gestionar la interacción de una empresa con sus clientes actuales y potenciales. Utiliza el análisis de datos de la historia de los clientes con la empresa y para mejorar las relaciones comerciales con dichos clientes, centrándose específicamente en la retención de los mismos y, en última instancia, impulsando el crecimiento de las ventas.</p><p>Un aspecto importante del enfoque de CRM son los sistemas informáticos de CRM que recopilan datos de una variedad de canales de comunicación diferentes, incluidos el sitio web, el teléfono, el correo electrónico, el chat en vivo, los materiales de marketing y, más reciéntemente, las redes sociales de la compañía. A través del enfoque de CRM y los sistemas utilizados para facilitarlo, las empresas aprenden más sobre sus audiencias objetivo y cómo atender mejor sus necesidades. Sin embargo, la adopción del enfoque de CRM también puede ocasionalmente generar favoritismo entre una audiencia de consumidores, lo que resulta en insatisfacción entre los clientes y en derrotar el propósito de CRM.</p><h3 id="Funciones"><a href="#Funciones" class="headerlink" title="Funciones"></a>Funciones</h3><p>Cuando el software CRM está separado para gestionar el negocio, la gestión del ciclo de vida de las ventas y clientes es difícil o imposible. Y la gestión de ciclo de vida es muy importante ya que muchas empresas hoy en día interactúan con el cliente mucho tiempo después de que se realizó la venta, colaborando con ellos en la ingeniería bajo pedido (ETO), configurar a pedido (CTO) o procesos de gestión de servicios. Cada vez más el CRM debe ser extensible para apoyar a la planificación de recursos empresariales funcionalidades como la ingeniería, fabricación, compras, finanzas y gestión de servicios. Debido a que el CRM de empresa – o el CRM estratégico – es una parte integral del ERP, aporta información completa del cliente sobre el proyecto, las facturas, inventario, etc.</p><h3 id="CRM-como-modelo-de-gestion"><a href="#CRM-como-modelo-de-gestion" class="headerlink" title="CRM como modelo de gestión"></a>CRM como modelo de gestión</h3><p>De acuerdo con Peppers y Rogers, “una empresa que se vuelca a sus clientes es una empresa que utiliza la información para obtener una ventaja competitiva y alcanzar el crecimiento y la rentabilidad. En su forma más generalizada, CRM puede ser considerado un conjunto de prácticas diseñadas, simplemente, para poner a una empresa en un contacto mucho más cercano con sus clientes. De este modo, aprender más acerca de cada uno, con el objetivo más amplio de que cada uno sea más valioso incrementando el valor de la empresa”.</p><h3 id="CRM-social"><a href="#CRM-social" class="headerlink" title="CRM social"></a>CRM social</h3><p>CRM es una forma de pensar y actuar de una empresa hacia los clientes/consumidores. A partir de la formación de grandes corporaciones, el contacto 1 a 1 se va perdiendo y se despersonaliza cualquier transacción, dejando de lado la relación de los clientes con la marca.</p><p>El CRM, y especialmente el CRM Social nacen de la necesidad de recuperar los vínculos personales con los clientes, especialmente en la era de las <em>Redes Sociales</em> , en donde cada opinión se multiplica de forma viral y afecta significativamente la imagen de la marca. Por eso el Social CRM difiere del tradicional agregando la posibilidad de intercambio y conversación con los clientes.</p><p>Mediante la conexión constante y el registro de la información de la actividad, la empresa lleva un seguimiento de cada uno de sus contactos. Se les provee de información y soporte, se les avisa de nuevas activaciones y propuestas, y se les recompensa por producir contenido positivo. Esto conduce a una constante realimentación, pues los clientes tienen la posibilidad de opinar y compartir mediante redes sociales como <em>Facebook y Twitter</em> , que también permiten identificar prospectos y conocer sus gustos y preferencias. Así la producción de contenidos se vuelve cada vez más personalizada y relevante, profundizando la relación.</p><p>Un CRM abarca a los sistema que mantienen datos específicos con el fin de mantener la relación de los clientes con la empresa en todo momento.</p><h3 id="Modulo-de-ventas"><a href="#Modulo-de-ventas" class="headerlink" title="Módulo de ventas"></a>Módulo de ventas</h3><p>Automatización de la parte o eslabón final: entre el cliente y el punto de venta. Un módulo de ventas es incluido en la mayoría de los CRM para poder tomar estas acciones dentro del almacén de datos. Por medio de esto se asigna oportunidades potenciales y tareas de manera automática según reglas predefinidas analizadas por medio de la información recaudada por los puntos de ventas automatizados.</p><h3 id="Modulo-de-mercado"><a href="#Modulo-de-mercado" class="headerlink" title="Módulo de mercado"></a>Módulo de mercado</h3><p>CRM que sea flexible, fácil de usar y que esté diseñada para la empresa. Transforma cada punto de contacto en una oportunidad de marketing y aprovecha el potencial oculto dentro de la base de datos de los clientes. Con las capacidades de marketing familiares y afines pueden comercializar productos de manera más eficaz, mejorar la productividad y obtener conocimientos accionables con los esfuerzos de marketing. Señala esfuerzos de marketing. Amplía la captura de pantalla. Usa consultas en idioma natural para segmentar de manera instantánea clientes o clientes potenciales. Crear listas altamente dirigidas y asociarlas con campañas y compañías. Configurar vistas personales o públicas para reutilización. Compartir fácilmente listas dirigidas con colegas y proveedores. Exportar listas en varios formatos para comunicaciones por correo electrónico masivo o correo directo. Planear actividades, tareas, presupuestos y detalles para cada actividad de marketing, y realizar su seguimiento. Coordinar de mejor manera las ventas al hacer un seguimiento de las oportunidades potenciales en un sistema centralizado. Asignar o clasificar oportunidades potenciales de manera automática según los flujos de trabajo predefinidos. El cliente o consumidor es el corazón de toda organización.</p><h3 id="Caracteristicas-de-programacion"><a href="#Caracteristicas-de-programacion" class="headerlink" title="Características de programación"></a>Características de programación</h3><p>Los sistemas CRM tienen distintos módulos y categorías de programación, Plugins que funcionan de manera sincrónica realizando acciones durante la pre y post creación y actualización de registros y workflow que realiza tareas de manera asincrónica.</p><h3 id="Software-CRM"><a href="#Software-CRM" class="headerlink" title="Software CRM"></a>Software CRM</h3><p>Se muestran algunos programas CRM:</p><ul><li>CiviCRM</li><li>Cligraphcrm screenshots</li><li>Hypos CRM</li><li>IDempiere</li><li>Microsoft Dynamics CRM</li><li>Odoo</li><li>OpenERP</li><li>OpenZ</li><li>Salesforce.com</li><li>SAP CRM</li><li>SugarCRM</li></ul><h2 id="Sistemas-de-respuesta-de-voz-interactiva-IVR"><a href="#Sistemas-de-respuesta-de-voz-interactiva-IVR" class="headerlink" title="Sistemas de respuesta de voz interactiva (IVR)"></a>Sistemas de respuesta de voz interactiva (IVR)</h2><h3 id="Introduccion-1"><a href="#Introduccion-1" class="headerlink" title="Introducción"></a>Introducción</h3><p><strong>La respuesta de voz interactiva</strong> o <strong>IVR</strong> ( <em>Interactive Voice Response</em> ) consiste en un sistema telefónico que es capaz de recibir una llamada e interactuar con el humano a través de grabaciones de voz y el reconocimiento de respuestas simples, como “sí”, “no” u otras. Es un sistema automatizado de respuesta interactiva, orientado a entregar o capturar información a través del teléfono, permitiendo el acceso a servicios de información u otras operaciones. Los sistemas de IVR implementados en la red tienen capacidad para administrar grandes volúmenes de llamadas y también se usan para llamadas salientes, ya que estos sistema son más inteligentes que muchos sistemas de marcación predictiva.</p><p><strong>IVR</strong> se puede utilizar para compras con dispositivos móviles, pagos y servicios bancarios, pedidos minoristas, servicios públicos, información sobre viajes y condiciones meteorológicas. Un concepto erróneo común hace referencia a un asistente automático como un sistema de IVR. Los términos son distintos y significan cosas diferentes para los profesionales tradicionales del ámbito de las telecomunicaciones: el propósito de un sistema de IVR es tomar la entrada, procesarla y devolver un resultado, mientras que la tarea de un asistente automático consiste en redirigir las llamadas. En ocasiones, también se utiliza el término <strong>unidad de respuesta de voz</strong> o <strong>VRU</strong> ( <em>Voice Response Unit</em> ).</p><h3 id="Historia"><a href="#Historia" class="headerlink" title="Historia"></a>Historia</h3><p>A pesar del crecimiento de la tecnología IVR durante la década de 1970, la tecnología se consideraba compleja y costosa para la automatización de tareas en los centros de llamadas. Los primeros sistemas de respuesta de voz se basaban en la tecnología DSP y estaban limitados a vocabularios reducidos. A principios de 1980, Perception Technology de Leon Ferber se convirtió en el primer competidor del mercado principal, después de que la tecnología de discos duros (del acceso aleatorio de lectura/escritura a datos de voz digitalizados) alcanzara un nivel de precio rentable. En aquel momento, un sistema podía guardar palabras digitalizadas en un disco, reproducir el mensaje hablado apropiado y procesar la respuesta DTMF humana.</p><p>Se utilizan dos variantes principales del reconocimiento de voz en IVR: una basada en gramáticas predefinidas (utilizadas en diálogos “dirigidos”) y otra basada en modelos de lenguaje preparados estadísticamente (utilizada en diálogos de “lenguaje natural”). Los diálogos dirigidos presentan a la persona que llama preguntas u opciones específicas. Los diálogos de lenguaje natural utilizan preguntas abiertas (por ejemplo, “¿En qué puedo ayudarlo?”), son más coloquiales y pueden interpretar respuestas de formato libre.</p><p>A menudo, un distribuidor automático de llamadas o ACD (Automatic Call Distributor) es el primer punto de contacto al llamar a muchas grandes empresas. Un ACD utiliza dispositivos de almacenamiento digital para reproducir saludos o anuncios, pero comúnmente redirige a la persona que llama sin solicitar ninguna entrada. Un sistema de IVR puede reproducir anuncios y solicitar una entrada a la persona que llama. Esta información se puede usar para obtener el perfil de la persona que llama y redirigir la llamada a un agente con un conjunto de aptitudes específico. (Un conjunto de aptitudes es una función que se aplica a un grupo de agentes de un centro de llamadas con una habilidad en concreto).</p><p>La respuesta de voz interactiva se puede utilizar para establecer la interfaz inicial de las operaciones de un centro de llamadas mediante la identificación de las necesidades de la persona que llama. Se puede obtener información de la persona que llama, como por ejemplo, un número de cuenta. Asimismo, se pueden brindar respuestas a preguntas simples, como saldos de cuentas o información previamente grabada, sin necesidad de que intervenga el operador. Con frecuencia, los números de cuenta obtenidos del sistema de IVR se comparan con los datos de identificación de la llamada por cuestiones de seguridad y, si la identificación de la llamada no coincide con el registro de la cuenta, se requieren respuestas de IVR adicionales.</p><h3 id="Servicios"><a href="#Servicios" class="headerlink" title="Servicios"></a>Servicios</h3><p>El IVR se implementa habitualmente en empresas o entidades que reciben gran cantidad de llamadas, a fin de reducir la necesidad de personal y los costes que el servicio ofrecido representan para dicha entidad. Entre otras, podemos mencionar a las bancas telefónicas.</p><p>Las empresas suelen usar la tecnología IVR para dirigir una llamada entrante hacia un departamento u otro, sin la necesidad de intervención humana, así reduciendo el tiempo de espera de sus clientes.</p><p>En los centros de atención telefónica al cliente, se utiliza la tecnología IVR para dirigir las llamadas hacia los agentes con mayor conocimiento de una materia específica, reduciendo así el tiempo de la llamada y evitando la necesidad de hacer transferencias entre agentes.</p><p>Se está implementando también en empresas de taxis, en las que la identificación del número que llama permite conocer dónde se encuentra el pasajero y generar el viaje rápidamente sin la intervención de un telefonista físico.</p><p>Puede combinarse con SMS para prestar cualquier clase de servicio: televotación, encuestas, sorteos, acceso a bases de datos, servicios informativos, etc.</p><h3 id="Uso"><a href="#Uso" class="headerlink" title="Uso"></a>Uso</h3><p>Los sistemas de IVR se utilizan para atender gran cantidad de llamadas, reducir los costos y mejorar la experiencia del cliente. El uso de IVR y la automatización de voz permiten resolver las consultas de quienes llaman sin necesidad de colocar las llamadas en cola ni incurrir en el costo de un agente real. Si las personas que llaman no encuentran la información que necesitan o requieren asistencia adicional, las llamadas se suelen transferir a un agente. Esto da lugar a un sistema eficiente, que permite a los agentes tener más tiempo para abordar interacciones complejas. Cuando un sistema de IVR responde llamadas de varios números de teléfono, el uso del Servicio de identificación de número marcado (DNIS) garantiza la ejecución de la aplicación y el idioma correcto. Un único sistema de IVR grande puede atender llamadas para miles de aplicaciones, cada una con sus propios números de teléfono y guiones.</p><h4 id="Sector-bancario"><a href="#Sector-bancario" class="headerlink" title="Sector bancario"></a>Sector bancario</h4><p>Las instituciones bancarias dependen de los sistema de IVR para mantener las relaciones con los clientes y ampliar el horario comercial para ofrecer servicios las 24 horas de los 7 días de la semana. El servicio de Banca telefónica permite a los clientes consultar saldos e historiales de transacciones, así como realizar pagos y transferencias. A medida que han surgido los canales en línea, la satisfacción del cliente bancario ha disminuido.</p><h4 id="Sector-medico"><a href="#Sector-medico" class="headerlink" title="Sector médico"></a>Sector médico</h4><p>Las empresas farmacéuticas y las organizaciones de investigación por contrato utilizan los sistemas de IVR para realizar ensayos clínicos y administrar el gran volumen de datos que se genera. La persona que llama responde a las preguntas en el idioma de su preferencia y las respuestas se ingresan en una base de datos y, posiblemente, se registran al mismo tiempo para confirmar la autenticidad. Entre las aplicaciones se incluyen la asignación aleatoria de pacientes y la gestión del suministro de medicamentos. También se emplean para registrar los diarios y cuestionarios del paciente.</p><p>Los sistemas de IVR permiten a quienes llaman obtener datos de manera relativamente anónima. En hospitales y clínicas, los sistemas de IVR se han utilizado para que quienes llaman puedan obtener acceso anónimo a los resultados de las pruebas. Este tipo de información podría ser fácilmente gestionada por una persona, pero se emplea el sistema de IVR para preservar la privacidad y evitar la posible incomodidad que puede suponer la información sensible o los resultados de las pruebas. Los usuarios reciben una clave de ingreso para poder acceder a sus resultados.</p><h4 id="Encuestas"><a href="#Encuestas" class="headerlink" title="Encuestas"></a>Encuestas</h4><p>Alguna de las mayores plataformas de IVR instaladas se utilizan para la “televotación” en concursos televisivos, como Pop Idol y Gran Hermano, que pueden generar enormes picos de llamada. A menudo, el proveedor de red implementará un método de bloqueo de destinos (call gapping) en la red telefónica pública conmutada (PSTN) para evitar la saturación de la red. Las organizaciones de sondeo también pueden usar sistemas de IVR para formular preguntas más sensibles cuando los investigadores tienen que un participante podría sentirse incómodo al dar sus respuestas a un interlocutor humano (por ejemplo, preguntas sobre consumo de drogas o comportamiento sexual). En algunos casos, se puede usar un sistema de IVR en la misma encuesta junto con un encuestador humano.</p><h3 id="Tecnologia-involucrada"><a href="#Tecnologia-involucrada" class="headerlink" title="Tecnología involucrada"></a>Tecnología involucrada</h3><p>El IVR para brindar mejores servicios involucra otras tecnologías como, por ejemplo:</p><ul><li><strong>DTMF (Dual Tone Multi Frecuency)</strong> : Propia de la telefonía, es la tecnología de tonos utilizada para el marcado.</li><li><strong>TTS (Text To Speech)</strong> : Iniciada en la informática, le da capacidad de transformar texto a audio que escucha el operador.</li><li><strong>ASR (Reconocimiento de Voz)</strong> : Iniciada por la informática. Le da la capacidad de reconocer palabras del usuario y aceptarlas como órdenes.</li></ul><h2 id="Voice-XML"><a href="#Voice-XML" class="headerlink" title="Voice XML"></a>Voice XML</h2><h3 id="Introduccion-2"><a href="#Introduccion-2" class="headerlink" title="Introducción"></a>Introducción</h3><p>Muchos usuarios encuentran mucho más práctico los servicios automatizados por voz, y en la constante evolución de la web no ha podido faltar VoiceXML, que se ha convertido en un estandard W3C capaz de darnos la oportunidad de navegar interactuando con el ordenador utilizando exclusivamente nuestra voz, se deja de lado los periféricos como el ratón y el teclado para dar lugar al micrófono.</p><p>Como si se tratara de una conversación se establecen los roles de emisor y receptor, alternándose entre ordenador y usuario.</p><h3 id="Historia-1"><a href="#Historia-1" class="headerlink" title="Historia"></a>Historia</h3><p>AT&amp;T, IBM, Lucent, y Motorola creó el foro de VoiceXML en 1999, antes de septiembre de 1999 el foro lanzó VoiceXML 0.9 y en 2000 publicaron VoiceXML 1.0.</p><p>El W3C lo aceptó como “estándard” en marzo de 2004 en su versión 2.0, algo más tarde surgió la 2.1 añadiendo algunas pequeñas mejoras, las cuales se convirtieron en recomendación W3C en 2007.</p><p>Actualmente se está trabajando en VoiceXML 3.0, el cual utilizará un nuevo idioma descriptivo del statechart de XML llamado SCXML.</p><h3 id="¿Que-es"><a href="#¿Que-es" class="headerlink" title="¿Qué es?"></a>¿Qué es?</h3><p>VoiceXML, es un lenguaje destinado al manejo y creación de aplicaciones de voz, que son empleadas para navegar, de forma auditiva en vez de utilizar la forma visual, más convencional y extendida hasta el momento.</p><p>VoiceXML es un lenguaje de etiquetas basado en XML que permite describir servicios de voz con independencia de la aplicación en la que corran. De esta manera no es necesario conocer detalles específicos de una plataforma para entender el funcionamiento del sistema de diálogo.</p><p>Los documentos que origina, son los llamados XML (eXtensible Markup Languaje), que admiten y poseen las características necesarias para dar lugar a la reproducción de sonidos digitales y sintetizados.</p><p>Posee un tipo de arquitectura no delimitada y de alto nivel de compatibilidades con respecto a las distintas salidas o recursos de la informática e internet.</p><p>El lenguaje VoiceXML describe la interacción hombre-máquina a partir de los siguientes elementos:</p><ul><li>Salida de texto-a-voz</li><li>Salida de audio grabado</li><li>Reconocimiento de entrada hablada</li><li>Reconocimiento de tonos DTMF</li><li>Grabación de entrada hablada</li><li>Control de flujo de diálogo</li><li>Funciones de telefonía (transferencia de llamada, desconexión, ect).</li></ul><h3 id="Componentes"><a href="#Componentes" class="headerlink" title="Componentes"></a>Componentes</h3><p>Las aplicaciones de VoiceXML, contienen ciertos componentes, normalmente comunes entre ellos como:</p><p>El Servidor de aplicaciones que es el encargado al igual que cualquier función de un servidor, de proporcionar y almacenar datos de las aplicaciones e interfaces, para poder facilitarlas a otras externas.</p><p>Por otra parte, el Servidor de VoiceXML de Telefonía que es una plataforma que actúa como cliente frente al servidor de aplicaciones acabado de mencionar. Éste controla los diálogos producidos en VoiceXML, y los entiende para su control del habla y los diferentes recursos que posee (como ADR o TTS).</p><p>También posee una red de paquetes TCP/IP basada en la conexión del servidor de aplicaciones y el servidor de telefonía a través de protocolos HTTP.</p><p>Y a su vez, contiene una red telefónica comúnmente pública (PSTN), aunque no descarta la posibilidad de ser privada (PBX).</p><h3 id="Funcionamiento"><a href="#Funcionamiento" class="headerlink" title="Funcionamiento"></a>Funcionamiento</h3><p>El usuario utiliza su voz para empezar a dar órdenes, de modo VoiceXML pone en marcha su ASR (un sistema encargado de reconocer la voz humana) transformando así la voz en una señal digital formada por 0’s y 1’s.</p><p>Una vez se procesa y si es necesario, la máquina puede contestar también mediante voz al usuario, poniendo en marcha el TTS y mediante éste se crean los documentos XML nombrados con anterioridad.</p><p>Para la creación de estos documentos, se utiliza ésta tecnología específica denominada TTS, que es referente a tecnologías de síntesis de voz.</p><p>Y la síntesis de voz consiste en la reproducción de manera no natural, es decir, artificial, del lenguaje natural y su origen proviene de las señales de voz que son generadas por el ordenador, que da lugar a un proceso inverso al ASR, es decir, transforma la señal digital que crea (respuesta) en voz entendible para el usuario.</p><p><img src="https://gsitic.files.wordpress.com/2018/06/voicexml.png?w=825" alt=""></p><h3 id="Aplicaciones"><a href="#Aplicaciones" class="headerlink" title="Aplicaciones"></a>Aplicaciones</h3><p>VoiceXML está en expansión, y seguramente tenga cabida en multitud de entornos, actualmente es más usado en servicios telefónicos, un ejemplo claro lo encontramos cuando hacemos llamadas a nuestro operador telefónico, donde una voz nos va pidiendo datos para poder emparejarnos después con una persona real.</p><p>Otra aplicación importante es en los sistemas de información, incluso en el ámbito turístico, dando la opción de comunicarse con la máquina en múltiples idiomas.</p><p>Pero además de la comodidad que nos puede proporcionar una navegación mediante VoiceXML nos encontramos con una muy buena opción para dotar a cualquier página web de más usabilidad para gente con problemas de movilidad, incapaces de moverse con la soltura necesaria mediante los periféricos como el ratón y el teclado.</p><h3 id="Ejemplo-de-sintaxis"><a href="#Ejemplo-de-sintaxis" class="headerlink" title="Ejemplo de sintaxis"></a>Ejemplo de sintaxis</h3><p>Como ya sabemos, una de las primeras pruebas a la hora de empezar con un lenguaje es el famoso “Hola mundo”.</p><p>Así quedaría en <strong>VXML</strong> (es la extensión de los ficheros VoiceXML):</p><p>&lt;?xml version=”1.0” encoding=”iso-8859-1”?&gt;</p><p><vxml xmlns="http://www.w3.org/2001/vxml" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemalocation="http://www.w3.org/2001/vxml                           http://www.w3.org/TR/voicexml20/vxml.xsd" version="2.0"></vxml></p><p><property name="xml:lang" value="es"></property></p><form id="saludo"><br>    <block><br>        <prompt>¡Hola mundo!</prompt><br>        <disconnect><br>    </disconnect></block><br></form><h3 id="Conclusiones"><a href="#Conclusiones" class="headerlink" title="Conclusiones"></a>Conclusiones</h3><p>VoiceXML, utilizado de manera conjunta con otros estándares, proporciona una base sólida para la definición de sistemas de voz. Las constantes revisiones y ampliaciones del estándar aseguran su continuidad y progresiva incorporación en las herramientas para la construcción de aplicaciones de voz.</p><p>El aumento de los sistemas de telefonía a través de Internet y los progresos en los campos del reconocimiento de voz y las herramientas digitales para la lecturas así como la progresiva incorporación de los estándares propuestos por el W3C, señalan la gran importancia que sin duda VoiceXML y el resto de estándares de voz tendrán en un futuro muy próximo.</p><h2 id="Bibliografia"><a href="#Bibliografia" class="headerlink" title="Bibliografía"></a>Bibliografía</h2><ul><li><a href="https://es.wikipedia.org/wiki/Customer_relationship_management" rel="external nofollow noopener noreferrer" target="_blank">Wikipedia (CRM)</a></li><li><a href="https://es.wikipedia.org/wiki/Respuesta_de_voz_interactiva" rel="external nofollow noopener noreferrer" target="_blank">Wikipedia (IVR)</a></li><li><a href="https://es.scribd.com/doc/139997173/VoiceXML" rel="external nofollow noopener noreferrer" target="_blank">Scribd VoiceXML (Alex Ice)</a></li><li><a href="http://di002.edv.uniovi.es/~cueva/asignaturas/doctorado/2006/trabajos/VoiceXML.pdf" rel="external nofollow noopener noreferrer" target="_blank">Universidad de Oviedo</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Gestion-de-la-atencion-a-clientes-y-usuarios-centros-de-contacto-CRM-Arquitectura-multicanal-Sistemas-de-respuesta-de-voz-interactiv
      
    
    </summary>
    
      <category term="B2" scheme="http://localhost:4000/categories/B2/"/>
    
    
  </entry>
  
  <entry>
    <title>B2-T08</title>
    <link href="http://localhost:4000/wiki/B2/b2-t08/"/>
    <id>http://localhost:4000/wiki/B2/b2-t08/</id>
    <published>2019-01-16T15:11:23.000Z</published>
    <updated>2019-01-18T10:45:16.588Z</updated>
    
    <content type="html"><![CDATA[<h1 id="El-modelo-TCP-IP-y-el-modelo-de-referencia-de-interconexion-de-sistemas-abiertos-OSI-de-ISO-arquitectura-capas-interfaces-protocolos-direccionamiento-y-encaminamiento"><a href="#El-modelo-TCP-IP-y-el-modelo-de-referencia-de-interconexion-de-sistemas-abiertos-OSI-de-ISO-arquitectura-capas-interfaces-protocolos-direccionamiento-y-encaminamiento" class="headerlink" title="El modelo TCP/IP y el modelo de referencia de interconexión de sistemas abiertos (OSI) de ISO: arquitectura, capas, interfaces, protocolos, direccionamiento y encaminamiento."></a>El modelo TCP/IP y el modelo de referencia de interconexión de sistemas abiertos (OSI) de ISO: arquitectura, capas, interfaces, protocolos, direccionamiento y encaminamiento.</h1><h2 id="El-modelo-OSI-y-los-protocolos-de-red"><a href="#El-modelo-OSI-y-los-protocolos-de-red" class="headerlink" title="El modelo OSI y los protocolos de red"></a>El modelo OSI y los protocolos de red</h2><h3 id="OSI-la-pila-teorica-de-protocolos-de-red"><a href="#OSI-la-pila-teorica-de-protocolos-de-red" class="headerlink" title="OSI, la pila teórica de protocolos de red"></a>OSI, la pila teórica de protocolos de red</h3><p>A finales de la década de los setenta, la Organización Internacional para la Normalización (ISO) empezó a desarrollar un modelo conceptual para la conexión en red al que bautizó con el nombre de <em>Open Systems Interconnection Reference Model</em> o Modelo de Referencia de Interconexión de Sistemas Abiertos. En los entornos de trabajo con redes se les conoce más comúnmente como el modelo OSI. En 1984 este modelo pasó a ser el estándar internacional para las comunicaciones en red al ofrecer un marco de trabajo conceptual que permitía explicar el modo en que los datos se desplazan dentro de una red.</p><p>El modelo OSI divide en siete capas el proceso de transmisión de la información entre equipos informáticos, donde cada capa se encarga de ejecutar una determinada parte del proceso global. Este marco de trabajo estructurado en capas, aun siendo puramente conceptual, puede utilizarse para describir y explicar el conjunto de protocolos reales que, como veremos, se utilizan para la conexión de sistemas. Por ejemplo, TCP/IP y AppleTalk son dos de las pilas de protoclos sque se utilizan en el mundo real para transmitir datos; los protocolos que, de hecho, sirven como capas o niveles dentro de un conjunto de protocolos como TCP/IP pueden, por tanto, explicarse de acuerdo con su correlación con el modelo teórico de capas o niveles de red que conforma OSI.</p><blockquote><p><strong>¿Qué es exactamente una pila de protocolos?</strong></p><p>Las pilas o suite (o capas) de protocolos no son más que una jerarquía de pequeños protocolos que trabajan juntos para llevar a cabo la transmisión de los datos de un nodo a otro de la red. Las pilas de protocolos se asemejan mucho a las carreras de relevos, pero, en vez de pasarse un testigo se transmiten paquetes de datos de un protocolo a otro hasta que éstos revisten la forma adecuada (una secuencia única de bits) para transmitirse por el entorno físico de la red.</p></blockquote><p>El modelo OSI abarca una serie de eventos importantes que se producen durante la comunicación entre sistemas. Proporciona las normal básicas empíricas para un serie de procesos distintos de conexión en red:</p><ul><li>El modo en que los datos se traducen a un formato apropiado para la arquitectura de red que se está utilizando. Cuando se envía un mensaje de correo electrónico o un archivo a otra computadora, se está trabajando, en realidad, con una determinada aplicación, como un cliente de correo electrónico o un cliente FTP. Los datos que se transmiten utilizando dicha aplicación tienen que convertirse a un formato más genérico si van a viajar por la red hasta llegar a su destino.</li><li>El modo en que los PC u otro tipo de dispositivos de la red se comunican. Cuando se envían datos desde un PC, tiene que existir algún tipo de mecanismo que proporcione un canal de comunicación entre el remitente y el destinatario. Lo mismo que cuando se desea hablar por teléfono, para lo cual hay que descolgar el teléfono y marcar el número.</li><li>El modo en que los datos se transmiten entre los distintos dispositivos y la forma en que se resuelve la secuenciación y comprobación de errores. Una vez establecida la sesión de comunicación entre dos computadoras, tiene que existir un conjunto de reglas que controlen la forma en que los datos van de una a otra.</li><li>El modo en que el direccionamiento lógico de los paquetes pasa a convertirse en el direccionamiento físico que proporciona la red. Las redes informáticas utilizan esquemas de direccionamiento lógico, como direcciones IP. Por tanto, dichas direcciones lógicas tienen que convertirse en las direcciones relaes de hardware que determinan las NIC instaladas en las distintas computadoras.</li></ul><p>El modelo OSI ofrece los mecanismos y reglas que permiten resolver todas las cuestiones que acabamos de referir. Comprender las distintas capas del modelo OSI n o sólo permite internarse en los conjuntos de protocolos de red que actualmente se utilizan, sino que también proporciona un marco de trabajo conceptual del que puede servirse cualquiera para comprender el funcionamiento de dispositivos de red complejos, como conmutadores, puentes y routers.</p><h3 id="Las-capas-OSI"><a href="#Las-capas-OSI" class="headerlink" title="Las capas OSI"></a>Las capas OSI</h3><p>Las capas del modelo OSI describen el proceso de transmisión de los datos dentro de una red. Las dos únicas capas del modelo con las que, de hecho, interactúa el usuario son la primera capa, la capa Física, y la última capa, la capa de Aplicación.</p><ul><li>La <strong>capa física</strong> abarca los aspectos físicos de la red (es decir, los cables, <em>hubs</em> y el resto de dispositivos que conforman el entorno físico de la red). Seguramente ya habrá interactuado más de una vez con la capa Física, por ejemplo al ajustar un cable mal conectado.</li><li>La <strong>capa de aplicación</strong> proporciona la interfaz que utiliza el usuario en su computadora para enviar mensajes de correo electrónico o ubicar un archivo en la red.</li></ul><p>La figura presenta la estructura de capas que conforman el modelo OSI de arriba abajo. La pirámide invertida es uno de los modos que mejor ilustran la estructura de este modelo, en el que los datos con un formato bastante complejo pasan a convertirse en una secuencia simple de bits cuando alcanzan el cable de la red. Como verá, las capas vienen numeradas de abajo arriba, cuando lo lógico sería que vinieran numeradas de arriba abajo. Éste es el sistema adoptado y, de hecho, muchas veces se alude al mismo para referirse a una de las capas de la red. Pero, tanto si se usa el nombre como el número, lo importante es que recuerde siempre el papel que desarrollan cada una de las capas en el proceso global de transmisión de los datos.</p><p><img src="https://gsitic.files.wordpress.com/2018/05/modelo-osi.png?w=825" alt=""></p><blockquote><p>El modelo OSI ofrece un modelo teórico que explica el modo en que se desplazan los datos desde una computadora emisora a otra computadora receptora.</p></blockquote><p>Antes de explicar cada una de las capas que componen la pila, conviene hacerse una idea general de lo que ocurre cuando los datos se mueven por el modelo OSI. Supongamos que un usuario decide enviar un mensaje de correo electrónico a otro usuario de la red. El usuario que envía el mensaje utilizará un cliente o programa de correo (como Outlook o Eudora) como herramienta de interfaz para escribir y enviar el mensaje. Esta actividad del usuario se produce en la capa de aplicación.</p><p>Cuando los datos abandonan la capa de aplicación (la capa insertará un encabezado de capa de aplicación en el paquete de datos), éstos pasan por las restantes capas del modelo OSI. Cada capa proporcionará servicios específicos relacionados con el enlace de comunicación que debe establecerse, o bien formateará los datos de una determinada forma.</p><p>Al margen de la función específica que tenga asignada cada capa, todas adjuntan un encabezado a los datos. Puesto que la capa física está integrada por dispositivos de hardware (un cable, por ejemplo) nunca añade un encabezado de datos.</p><p><img src="https://gsitic.files.wordpress.com/2018/05/encabezadososi.png?w=825" alt=""></p><blockquote><p>Los datos bajan por la pila OSI de la computadora emisora y suben por la pila OSI de la computadora receptora.</p></blockquote><p>Los datos llegan así a la capa física (en entorno tangible de la red, como los cables de par trenzado y hubs que conectan las computadoras entre sí) de la computadora del destinatario, desplazándose por el entorno físico de la red hasta alcanzar su destino final, el usuario al que iba dirigido el mensaje de correo electrónico.</p><p>Los datos se reciben en la capa física de la computadora del destinatario y pasan a subir por la pila OSI. A medida que los datos van pasando por cada una de las capas, el encabezado pertinente se va suprimiendo de los datos. Cuando los datos finalmente alcanzan la capa de aplicación, el destinatario puede utilizar su cliente de correo electrónico para leer el mensaje que ha recibido.</p><p>A continuación pasamos a explicar cada una de las capas que componen el modelo OSI, de arriba abajo (es decir, desde la capa de aplicación hasta la capa física).</p><p><strong>La capa de aplicación</strong></p><p>La capa de aplicación proporciona la interfaz y servicios que soportan las aplicaciones de usuario. También se encarga de ofrecer acceso general a la red.</p><p>Esta capa suministra las herramientas que el usuario, de hecho ve. También ofrece los servicios de red relacionados con estas aplicaciones de usuario, como la gestión de mensajes, la transferencia de archivos y las consultas de bases de datos. La capa de aplicación suministra cada uno de estos servicios a los distintos programas de aplicación con los que cuenta el usuario en su computadora. Entre los servicios de intercambio de información que gestiona la capa de aplicación se encuentran la Web, los servicios de correo electrónico (como el Protocolo Simple de Transferencia de Correo, comúnmente conocido como SMTP – <em>Simple Mail Transfer Protocol</em> – incluido en TCP/IP), así como aplicaciones especiales de bases de datos clientes/servidor.</p><p><strong>La capa de presentación</strong></p><p>La capa de presentación puede considerarse el traductor del modelo OSI. Esta capa toma los paquetes (la creación del paquete para la transmisión de los datos por la red empieza en realidad en la capa de aplicación) de la capa de aplicación y los convierte a un formato genérico que pueden leer todas las computadoras. Por ejemplo, los datos escritos en caracteres ASCII se traducirán a un formato más básico y genérico.</p><p>La capa de presentación también se encarga de cifrar los datos (si así lo requiere la aplicación utilizada en la capa de aplicación) así como de comprimirlos para reducir su tamaño. El paquete que crea la capa de presentación contiene los datos prácticamente con el formato con el que viajarán por las restantes capas de la pila OSI (aunque las capas siguientes irán añadiendo elementos al paquete, lo cual puede dividir los datos en paquetes más pequeños).</p><blockquote><p><strong>La comunicación se produce directamente entre capas</strong></p><p>A medida que los datos bajan por la pila de protocolos de la computadora emisora (por ejemplo, un mensaje de correo electrónico) hasta llegar al cable físico y de ahí pasan a subir por la pila de protocolos de la computadora receptora, la comunicación entre ambas máquinas se está produciendo en realidad entre capas complementarias. Por ejemplo, cuando se envía un mensaje entre dos computadoras existe entre ellas una comunicación virtual en la capa de sesión. Lo cual es del todo lógico, ya que ésta es la capa que controla la comunicación entre ambas computadoras por el entorno físico de la red (ya sean cables coaxiales, de par trenzado o de fibra óptica).</p></blockquote><p><strong>La capa de sesión</strong></p><p>La capa de sesión es la encargada de establecer el enlace de comunicación o sesión entre las computadoras emisora y receptora. Esta capa también gestiona la sesión que se establece entre ambos nodos.</p><p><img src="https://gsitic.files.wordpress.com/2018/05/capa_sesion.png?w=825" alt=""></p><p>Una vez establecida la sesión entre los nodos participantes, la capa de sesión pasa a encargarse de ubicar puntos de control en la secuencia de datos. De esta forma, se proporciona cierta tolerancia a fallos dentro de la sesión de comunicación. Si una sesión falla y se pierde la comunicación entre los nodos, cuando después se restablezca la sesión sólo tendrán que volver a enviarse los datos situados detrás del último punto de control recibido. Así se evita el tener que enviar de nuevo todos los paquetes que incluía la sesión.</p><p>Los protocolos que operan en la capa de sesión pueden proporcionar dos tipos distintos de enfoques para que los datos vayan del emisor al receptor: la comunicación orientada a la conexión y la comunicación sin conexión.</p><blockquote><p><strong>Para comunicarse, los usuarios tienen que ejecutar el mismo conjunto de protocolos</strong></p><p>En el ejemplo anterior del envío y recepción de un mensaje de correo electrónico, dimos por sentado que tanto el remitente como el destinatario estaban ejecutando la misma pila de protocolos (la pila teórica OSI) en sus computadoras clientes. De hecho, las computadoras que ejecuten sistemas operativos distintos pueden comunicarse entre sí si utilizan el mismo conjunto de protocolos de red. Esto es lo que explica que una máquina UNIX, un Macintosh o un PC que esté ejecutando Windows utilicen el TCP/IP para comunicarse en Internet. Un ejemplo en el que dos computadoras no podrían comunicarse sería aquél en que una computadora ejecutara TCP/IP y la otra IPX/SPX. Estos dos protocolos de red del mundo real utilizan reglas distintas y formatos de datos diferentes que hacen que la comunicación resulte imposible.</p></blockquote><p>Los protocolos orientados a la conexión que operan en la capa de sesión proporcionan un entorno donde las computadoras conectadas se ponen de acuerdo sobre los parámetros relativos a la creación de los puntos de control en los datos, mantienen un diálogo durante la transferencia de los mismos, y después terminan de forma simultánea la sesión de transferencia.</p><p>Los protocolos orientados a la conexión operan de forma parecida a una llamada telefónica: en este caso, la sesión se establece llamando a la persona con la que se desea hablar. La persona que llama y la que se encuentra al otro lado del teléfono mantienen una conexión directa. Y, cuando la conversación termina, ambos se ponen de acuerdo para dar por terminada la sesión y cuelgan el teléfono a la par.</p><p>El funcionamiento de los protocolos sin conexión se parece más bien a un sistema de correo regular. Proporciona las direcciones pertinentes para el envío de los paquetes y éstos pasan a enviarse como si se echaran a un buzón de correos. Se supone que la dirección que incluyen permitirá que los paquetes lleguen a su destino, sin necesidad de un permiso previo de la computadora que va a recibirlos.</p><p><strong>La capa de transporte</strong></p><p>La capa de transporte es la encargada de controlar el flujo de datos entre los nodos que establecen una comunicación; los datos no sólo deben entregarse sin errores, sino además en la secuencia que proceda. La capa de transporte se ocupa también de evaluar el tamaño de los paquetes con el fin de que éstos tengan el tamaño requerido por las capas inferiores del conjunto de protocolos. El tamaño de los paquetes lo dicta la arquitectura de red que se utilice.</p><p>La comunicación también se establece entre computadoras del mismo nivel (el emisor y el receptor); la aceptación por parte del nodo receptor se recibe cuando el nodo emisor ha enviado el número acordado de paquetes. Por ejemplo, el nodo emisor puede enviar de un solo golpe tres paquetes al nodo receptor y después recibir la aceptación por parte del nodo receptor. El emisor puede entonces volver a enviar otros tres paquetes de datos de una sola vez.</p><p>Esta comunicación en la capa de transporte resulta muy útil cuando la computadora emisora manda demasiados datos a la computadora receptora. En este caso, el nodo receptor tomará todos los datos que pueda aceptar de una sola vez y pasará a enviar una señal de “ocupado” si se envían más datos. Una vez que la computadora receptora haya procesado los datos y esté lista para recibir más paquetes, enviará a la computadora emisora un mensaje de “luz verde” para que envíe los restantes.</p><blockquote><p><strong>Cada capa ejecuta funciones de entrada y salida de datos</strong></p><p>No debe olvidarse que cada capa del modelo OSI (o de un conjunto real de protocolos de red, como IPX/SPX o TCP/IP) ejecutan funciones relativas a la entrada y salida de información. Cuando los datos bajan por la pila de protocolos en una computadora emisora, la capa de presentación convierte la información procedente de una determinada aplicación a un formato más genérico. En la computadora receptora, la capa de presentación se ocupará de tomar dicha información genérica y de convertirla al formato que utilice el programa que se esté ejecutando en la capa de aplicación de la computadora receptora.</p></blockquote><p><strong>La capa de red</strong></p><p>La capa de red encamina los paquetes además de ocuparse de entregarlos. La determinación de la ruta que deben seguir los datos se produce en esta capa, lo mismo que el intercambio efectivo de los mismos dentro de dicha ruta. La Capa 3 es donde las direcciones lógicas (como las direcciones IP de una computadora de red) pasan a convertirse en direcciones físicas (las direcciones de hardware de la NIC, la Tarjeta de Interfaz para Red, para esa computadora específica).</p><p>Los <em>routers</em> operan precisamente en la capa de red y utilizan los protocolos de encaminamiento de la Capa 3 para determinar la ruta que deben seguir los paquetes de datos.</p><p><strong>La capa de enlace de datos</strong></p><p>Cuando los paquetes de datos llegan a la capa de enlace de datos, éstos pasan a ubicarse en tramas (unidades de datos), que vienen definidas por la arquitectura de red que se está utilizando (como Ethernet, Token Ring, etc). La capa de enlace de datos se encarga de desplazar los datos por el enlace físico de comunicación hasta el nodo receptor, e identifica cada computadora incluida en la red de acuerdo con su dirección de hardware, que viene codificada en la NIC.</p><blockquote><p><strong>Los protocolos reales utilizan ambos métodos de comunicación: sin conexión y orientados a la conexión</strong></p><p>En los conjuntos de protocolos de red, como TCP/IP e IPX/SPX, se utilizan ambas estrategias de comunicación, la que precisa de una conexión y la que no, para desplazar los datos por la red. Por lo general, en la capa de sesión opera más de un protocolo para gestionar estas estrategias distintas de comunicación.</p></blockquote><p>La información de encabezamiento se añade a cada trama que contenga las direcciones de envío y recepción. La capa de enlace de datos también se asegura de que las tramas enviadas por le enlace físico se reciben sin error alguno. Por ello, los protocolos que operan en esta capa adjuntarán un Chequeo de Redundancia Cíclica ( <em>Cyclical Redundancy Check</em> o CRC) al final de cada trama. El CRC es básicamente un valor que se calcula tanto en la computadora emisora como en la receptora. Si los dos valores CRC coinciden, significa que la trama se recibió correcta e íntegramente, y no sufrió error alguno durante su transferencia.</p><p>Una vez más, y tal y como dijimos anteriormente, el tipo de trama que genera la capa de enlace de datos dependerá de la arquitectura de red que se esté utilizando, como Ethernet, Token Ring de IBM o FDDI.</p><p>La siguiente figura muestra una trama Ethernet 802.2:</p><p><img src="https://gsitic.files.wordpress.com/2018/05/tramaethernet.png?w=825" alt=""></p><p>Descripción de cada uno de los componentes:</p><p><img src="https://gsitic.files.wordpress.com/2018/05/descripciontrama1.png?w=825" alt=""> <img src="https://gsitic.files.wordpress.com/2018/05/descripciontrama2.png?w=825" alt=""></p><p>La trama se compone básicamente de un encabezado que la describe, de los datos que incluye, y de la información referente a la capa de enlace de datos (como los Puntos de Acceso al Servicio de Destino, <em>Destination Service Access Points</em> , y Puntos de Acceso al Servicio, <em>Service Access Points</em> ), que no sólo definen el tipo de trama de que se trata (en este caso, Ethernet), sino que también contribuyen a que la trama llegue a la computadora receptora.</p><p>La capa de enlace de datos también controla la forma en que las computadoras acceden a las conexiones físicas de la red.</p><p><strong>La capa física</strong></p><p>En la capa física las tramas procedentes de la capa de enlace de datos se convierten en una secuencia única de bits que puede transmitirse por el entorno físico de la red. La capa física también determina los aspectos físicos sobre la forma en que el cableado está enganchado a la NIC de la computadora. En la computadora receptora de datos, la capa física es la encargada de recibir la secuencia única de bits (es decir, información formada por 1 y 0).</p><h3 id="Las-subcapas-del-enlace-de-datos"><a href="#Las-subcapas-del-enlace-de-datos" class="headerlink" title="Las subcapas del enlace de datos"></a>Las subcapas del enlace de datos</h3><p>La especificación IEEE 802 dividía la capa de enlace de datos en dos subcapas, el Control Lógico del Enlace ( <em>Logical Link Control</em> o LLC) y el Control de Acceso al Medio ( <em>Media Access Control</em> o MAC).</p><p>La subcapa de Control Lógico del Enlace establece y mantiene el enlace entre las computadoras emisora y receptora cuando los datos se desplazan por el entorno físico de la red. La subcapa LLC también proporciona Puntos de Acceso al Servicio ( <em>Service Access Point</em> o SAP), que no son más que puntos de referencia a los que otras computadoras que envíen información pueden referirse y utilizar para comunicarse con las capas superiores del conjunto de protocolos OSI dentro de un determinado nodo receptor. La especificación IEEE que define la capa LLC es la 802.2.</p><p>La subcapa de Control de Acceso al Medio determina la forma en que las computadoras se comunican dentro de la red, y cómo y dónde una computadora puede acceder, de hecho, al entorno físico de la red y enviar datos. La especificación 802 divide a su vez la subcapa MAC en una serie de categorías (que no son más que formas de acceder al entorno físico de la red), directamente relacionadas con la arquitectura específica de la red, como Ethernet y Token Ring.</p><p>La capa de enlace de datos está compuesta por dos subcapas: la subcapa LLC y la subcapa MAC:</p><p><img src="https://gsitic.files.wordpress.com/2018/05/capa_enlace_datos.png?w=825" alt=""></p><h2 id="Protocolos-de-red-del-mundo-real"><a href="#Protocolos-de-red-del-mundo-real" class="headerlink" title="Protocolos de red del mundo real"></a>Protocolos de red del mundo real</h2><p>Después de repasar el modelo teórico que determina la forma en que los datos van de una computadora a otra dentro de una red, pasando por las distintas capas que conforman el modelo OSI, podemos pasar a explicar algunos de los conjuntos de protocolos de red más utilizados hoy en día y cotejar las capas que los integran con las del modelo OSI. De esta forma, lograremos una visión clara y sencilla del modo en que operan estas pilas de protocolos reales y de la forma en que transportan los datos por la red.</p><p>También veremos qué protocolos de un determinado conjunto participan en la capa de red del modelo OSI. Estos protocolos son de suma importancia ya que contribuyen a encaminar los paquetes en una conexión entre redes.</p><h3 id="NetBEUI"><a href="#NetBEUI" class="headerlink" title="NetBEUI"></a>NetBEUI</h3><p>NetBeUI ( <em>NetBios Extended User Interface</em> o Interfaz Ampliada de Usuario para NetBIOS) e sun protocolo de red rápido y sencillo que fue diseñado para se utilizado junto con el protocolo NetBIOS ( <em>Network Basic Input Output System</em> o Sistema Básico de Entrada/Salida para Red) desarrollado por Microsoft e IBM para redes pequeñas NetBEUI opera en las capas de transporte y red del modelo OSI.</p><p>Puesto que NetBEUI sólo proporciona los servicios que se requieren en las capas de transporte y red de OSI, necesita funcionar con NetBIOS, que opera en la capa de sesión del modelo OSI, y se encarga de establecer la sesión de comunicación entre las dos computadoras conectadas a la red. Las redes Microsoft incluyen además otros dos componentes: el redirector y el Bloque de Mensajes del Servidor ( <em>Server Message Block</em> ). El redirector opera en la capa de aplicación y hace que una computadora cliente perciba todos los recursos de la red como si fueran locales. El Bloque de Mensajes del Servidor ( <em>Server Message Block</em> o SMB), por su parte, proporciona comunicación de mismo nivel entre los redirectores incluidos en las máquinas cliente y servidor de la red. El Bloque de Mensajes del Servidor opera en la capa de presentación del modelo OSI.</p><p>Aunque resulta un excelente protocolo de transporte de bajo coste, NetBEUI no es un protocolo que pueda encaminarse por medio de routers, por lo que no puede utilizarse en las interconexiones de redes. Por tanto, si bien NetBEUI es una opción de protocolo de red para redes pequeñas y sencillas, no resulta válida para redes más amplias que requieren el uso de <em>routers</em> .</p><blockquote><p><strong>Un apunte sobre direcciones hardware</strong></p><p>Las direcciones NIC de hardware también se denominan <strong>direcciones MAC</strong> . Esta sigla procede de la expresión ingles <em>Media Access Control</em> o Control de Acceso al Medio, y es una de las subcapas de la capa de enlace de datos. Las direcciones de hardware están grabadas en los chips de la memoria ROM en las tarjetas de interfaz para red y cada una de ellas proporciona una dirección única. El esquema de direccionamiento lo desarrolló en su día el Instituto de Ingenieros Eléctricos y Electrónicos (IEEE). De acuerdo con este esquema, cada dirección reviste la forma de una cadena de 48 bits escrita en formato hexadecimal. Un ejemplo de dirección MAC sería 00-00-B3-83-B3-3F.</p><p><strong>Tramas Ethernet</strong></p><p>La trama Ethernet que utilizaban las primeras versiones de NetWare de Novell (NetWare 2.x y 3.x) se creó antes de que el IEEE completara sus especificaciones. Esto hace que el tipo de trama Ethernet 802.3 no se ajuste estrictamente a las normas que ha dictado el IEEE. Las versiones más recientes de NetWare y de otros sistemas operativos de red utilizan la trama Ethernet 802.2, que cumple con todos los requisitos especificados por el IEEE.</p></blockquote><h3 id="TCP-IP"><a href="#TCP-IP" class="headerlink" title="TCP/IP"></a>TCP/IP</h3><p>A menudo referido como el “protocolo de baja puja”, TCP/IP se ha convertido en el estándar <em>de-facto</em> para la conexión en red corporativa. Las redes TCP/IP son ampliamente escalables, por lo que TCP/IP puede utilizarse tanto para redes pequeñas como grandes.</p><p>TCP/IP es un conjunto de protocolos encaminados que puede ejecutarse en distintas plataformas de software (Windows, UNIX, etc.) y casi todos los sistemas operativos de red lo soportan como protocolo de red predeterminado. TCP/IP consta de una serie de protocolos “miembro” que componen de hecho la pila TCP/IP. Y puesto que el conjunto de protocolos TCP/IP se desarrolló antes de que terminara de desarrollarse el modelo de referencia OSI, los protocolos que lo conforman no se corresponden perfectamente con las distintas capas del modelo.</p><p>TCP/IP es un amplio conjunto de protocolos que utiliza una serie de protocolos miembro en varias de las capas del modelo OSI.</p><p>Correlación entre el conjunto de protocolos TCP/IP y las capas OSI:</p><p><img src="https://gsitic.files.wordpress.com/2018/05/tcp-osi.png?w=825" alt=""></p><p>La siguiente tabla describe los protocolos que aparecen en la figura:</p><p><img src="https://gsitic.files.wordpress.com/2018/05/tcp1.png?w=825" alt=""> <img src="https://gsitic.files.wordpress.com/2018/05/tcp2.png?w=825" alt=""></p><p>TCP/IP no sólo proporciona un amplio conjunto de características referidas a la conexión en red (lo cual significa que TCP/IP requiere de una gran carga general para ejecutarse) sino también un sistema de direccionamiento lógico y único. Cualquier usuario que se conecte a Internet estará familiarizado con las direcciones IP de 32 bits, que normalmente se escriben en 4 octetos (un octeto equivale a 8 bits de información). El formato de una dirección es del tipo 129.30.20.4, donde cada uno de los cuatro valores decimales separados por un punto representa 8 bits de información binaria.</p><blockquote><p><strong>Especificaciones 802 del IEEE</strong></p><p>Las especificaciones IEEE 802 proporcionan categorías que definen la Capa del Enlace Lógico así como las distintas arquitecturas de red que puede utilizar la subcapa MAC. A continuación se incluye el listado de las categorías 802:</p><p><img src="https://gsitic.files.wordpress.com/2018/05/802.png?w=377&amp;h=310" alt=""></p><p><strong>Orígenes de TCP/IP</strong></p><p>TCP/IP lo desarrolló la Agencia de Defensa de Proyectos Avanzados de Investigación (DARPA) a petición del Departamento de Defensa de Estados Unidos. Dicho departamento necesitaba un conjunto de protocolos que pudieran utilizarse en cualquier sistema operativo, ya que no existía uniformidad alguna entre los sistemas informáticos de sus oficinas. Y ello por la forma misma en que funcionaba el Departamento, que licitaba todos sus proyectos y servicios. De ahí que de forma coloquial se conozca TCP/IP como protocolo de baja puja, ya que surgió a raíz de la práctica del gobierno estadounidense por pujar.</p></blockquote><h3 id="IPX-SPX"><a href="#IPX-SPX" class="headerlink" title="IPX/SPX"></a>IPX/SPX</h3><p>IPX/SPX ( <em>Internetwork Packet Exchange/Sequenced Packet Exchange</em> o Intercambio de Paquetes entre Redes/Intercambio Secuenciado de Paquetes) es un conjunto de protocolos de red desarrollado por Novell para ser utilizado en su sistema operativo de red NewWare. IPX/SPX agrupa menos protocolos que TCP/IP, por lo que no requiere la misma carga general que TCP/IP necesita. IPX/SPX puede utilizarse tanto en redes pequeñas como grandes y también permite el encaminamiento de datos.</p><p>Correlación entre la pila IPX/SPX y las capas del modelo OSI:</p><p><img src="https://gsitic.files.wordpress.com/2018/05/ipx-spx1.png?w=825" alt=""></p><p>IPX/SPX es un conjunto de protocolos eficaz que se utiliza tanto en redes grandes como pequeñas.</p><p>Descripción breve de cada uno de los protocolos que lo componen:</p><p><img src="https://gsitic.files.wordpress.com/2018/05/ipx-spx2.png?w=825" alt=""></p><p>Lo que más nos interesa acerca de IPX/SPX es la forma en que debe encaminarse este conjunto de protocolos dentro de una conexión entre redes.</p><h3 id="AppleTalk"><a href="#AppleTalk" class="headerlink" title="AppleTalk"></a>AppleTalk</h3><p>Aunque muchos administradores de red no consideran AppleTalk un protocolo de red corporativo o de interconexión, AppleTalk permite el encaminamiento de datos mediante <em>routers</em> . De hecho, con el tipo apropiado de NIC (los Macintosh de Apple pueden conectarse a una red Ethernet si cuentan con tarjetas EtherTalk u otro tipo de adaptadores) AppleTalk puede soportar arquitecturas Ethernet, Token Ring y FDDI. Las computadoras Macintosh suelen utilizarse en los entornos empresariales para la manipulación de gráficos y otras tareas de tipo multimedia, por lo que no resulta nada descabellado incluir AppleTalk como otro protocolo encaminado a la red corporativa.</p><p>AppleTalk es una arquitectura de red, pero lo cierto es que también se trata de un conjunto de protocolos.</p><p>Correlación entre los protocolos que integra AppleTalk y las capas del modelo OSI:</p><p><img src="https://gsitic.files.wordpress.com/2018/05/appletalk1.png?w=825" alt=""></p><p>AppleTalk es un conjunto de protocolos encaminados para las redes Macintosh que pueden comunicarse con rede Ethernet, Token Ring y FDDI.</p><p>La siguiente tabla describe brevemente cada uno de estos protocolos:</p><p><img src="https://gsitic.files.wordpress.com/2018/05/appletalk2.png?w=825" alt=""> <img src="https://gsitic.files.wordpress.com/2018/05/appletalk3.png?w=825" alt=""></p><h2 id="Bibliografia"><a href="#Bibliografia" class="headerlink" title="Bibliografía"></a>Bibliografía</h2><ul><li><a href="https://blyx.com/" rel="external nofollow noopener noreferrer" target="_blank">::blyx::Blog::Toni de la Fuente::</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;El-modelo-TCP-IP-y-el-modelo-de-referencia-de-interconexion-de-sistemas-abiertos-OSI-de-ISO-arquitectura-capas-interfaces-protocolos
      
    
    </summary>
    
      <category term="B2" scheme="http://localhost:4000/categories/B2/"/>
    
    
  </entry>
  
  <entry>
    <title>B2-T03</title>
    <link href="http://localhost:4000/wiki/B2/b2-t03/"/>
    <id>http://localhost:4000/wiki/B2/b2-t03/</id>
    <published>2019-01-16T15:11:23.000Z</published>
    <updated>2019-01-18T10:45:16.574Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Caracteristicas-tecnicas-y-funcionales-de-los-sistemas-operativos-Windows-Linux-Unix-y-otros-Sistemas-operativos-para-dispositivos-moviles"><a href="#Caracteristicas-tecnicas-y-funcionales-de-los-sistemas-operativos-Windows-Linux-Unix-y-otros-Sistemas-operativos-para-dispositivos-moviles" class="headerlink" title="Características técnicas y funcionales de los sistemas operativos: Windows, Linux, Unix y otros. Sistemas operativos para dispositivos móviles."></a>Características técnicas y funcionales de los sistemas operativos: Windows, Linux, Unix y otros. Sistemas operativos para dispositivos móviles.</h1><h2 id="Sistemas-Windows"><a href="#Sistemas-Windows" class="headerlink" title="Sistemas Windows"></a>Sistemas Windows</h2><p>Los SO Windows han ido evolucionando desde 1981, en que empezó a comercializarse MS-DOS. Era un SO monotarea, monousuario y monoprocesador. El interfaz gráfico de usuario (GUI) se empezó a probar con Windows 1.0 en 1985 y se lanzaba desde MS-DOS. En 1990 aparece Windows 3.0, evolucionando hasta el famoso Windows 3.1.</p><p>Windows NT aparece en 1993 y representa un SO de 32 bits para el Intel 60386. La versión NT 4.0 (1996) incluía el GUI de Windows 95 en que los componentes gráficos, anteriormente en modo usuario, pasaron a modo núcleo (NT Executive). Windows 2000 heredó la arquitectura NT incluyendo el servicio de directorio (AD, Active Directory). Case en paralelo, Windows 95 evolucionó a Windows 98 y Windows Me, que mantenían el código de 16 bits lo que no les hacía tan eficientes en procesadores 386 y posteriores. No soportan NTFS. La tecnología NT y el interfaz mejorado de Windows 95 se fusionan en Windows XP (2001), evolucionando a Windows Vista (2006), Windows 7, Windows 8 y Windows 10.</p><p>Las caracterísiticas de la tecnología NT se aplica a los SO profesionales de Microsoft, destacando:</p><ul><li>SO de 32 bits: No compatible hacia atrás. Por tanto supone una ruptura con Windows Me. Las versiones Windows 2000 y XP son la evolución del código original de Windows NT.</li><li>Independencia de memoria separada: La ejecución de un programa se hace en regiones de memoria distintas, lo que evita que las inestabilidades afecten al resto. El SO gestiona el uso de la memoria, evitando perder el control de la máquina.</li><li>Multitarea apropiativa (preemptive): O ejecución simultánea de aplicaciones. El SO asigna los recursos evitando inanición. Se opone a la multitarea colaborativa (no apropiativa) tipo Windows 95.</li><li>Multiusurio y multiprocesador: Se gestiona la concurrencia al sistema de distintos usuarios en red y se pueden usar varios procesadores en la misma máquina, asignándoles distintas tareas.</li><li>Portabilidad: Se refiere a la independencia del hardware, implementado con una capa HAL (Hardware Abstraction Layer). El resto de código es común a cualquier sistema.</li><li>Seguridad de dominio: Consiste en la inclusión de autenticación de usuarios para el acceso a recursos de red. Los controladores de dominio se encargan de validar usuarios de alta en la BBDD llamada SAM (Security Account Manager). A partir de Windows 2000 Server, los dominios se integran en el servicio de directorio Microsoft, el AD.</li><li>NTFS: La nueva tecnología de sistema de ficheros (NTFS) incluye seguridad y se basa en la creación de listas de control de acceso (ACL) para cada archivo o directorio. NT también incluye soporte para FAT y HPFS (OS/2).</li><li>Tolerancia a fallos: Se incluyen mecanismos de continuidad en presencia de fallos y soporte RAID.</li></ul><p><strong>Usuarios, Grupos y Dominios</strong></p><p>Cada usuario necesita ser identificado, es decir, disponer de una cuenta para iniciar sesión en el sistema. La identificación de una cuenta de usuario se realiza con un nombre y se asocia una contraseña. La cuenta de máximo privilegio es la de Administrador, similar a root en entornos Unix.</p><p>Para la gestión de cuentas, usuarios, se agrupan en Grupos, en general con criterios de privilegios o perfiles comunes. Los tipos de grupos que se distinguen en entornos Windows son:</p><ul><li>globales: pueden contener usuarios de un mismo dominio</li><li>locales: con usuario y grupos globales de distintos dominios</li><li>universales: que incluyen usuarios, grupos globales y universales de distintos dominios. No soportado en Windows NT.</li></ul><p>NTFS incorpora seguridad a nivel de archivo y carpeta. Con las ACL se definen permisos de usuario o grupo independientemente. Los permisos de Windows son más completos que los nativos de Unix, que también permite el uso de ACL.</p><p>Cuando los usuarios de una red son de escala, se hace necesaria una gestión centralizada. Es la razón de ser de la idea de Dominio. Los entornos servidores Windows permiten implementar la arquitectura cliente-servidor, en lo que se da en llamar Dominio. Un dominio es entonces un conjunto de equipos que comparten un servicio de directorio (BBDD de usuarios, recursos y permisos). El directorio se soporta con controladores de dominio (DC, Domain Controller) y lo forman cuentas de usuario y directivas de seguridad.</p><p>Cuando un usuario inicia sesión en un equipo cliente, debe indicar nombre, contraseña y dominio. Un controlador del dominio verificará las credenciales, permitiendo, o no, el acceso. Un servidor en un dominio puede desempeñar 3 roles:</p><ul><li>Controlador de dominio principal (PDC): Servidor SAM. Todo dominio NT tiene que tener un controlador principal de dominio.</li><li>Controlador de reserva (BDC): Es una copia de seguridad del SAM. No es obligatoria su presencia, pero sí muy recomendable. Pueden existir varios controladores de reserva, que se sincronizan con el PDC.</li><li>Servidor miembro: Es un servidor específico. No contiene copias del SAM. Participa en el dominio para ofrecer recursos y servicios.</li></ul><p>Si un servidor no pertenece a un dominio entonces es independiente, como pueda ser un servidor web público. El controlador de reserva puede cambiar su función a PDC si éste cae. En Windows 2003 Server no se distingue entre PDC y BDC, se denominan controladores de dominio. Para configurar un servidor comp PDC se ejecuta el comando DCPROMO (Asistente de instalación del directorio activo). Los nombre de dominio siguen la sintaxis del sistema DNS.</p><p>AD es una estructura basada en el servicio de directorio LDAP (Lightweight Directory Access Protocol) que almacena información sobre recursos facilitando su acceso. Los componentes del directorio se llaman objetos y se almacenan en contenedores, siguiendo una estructura jerárquica. La información del AD se replica en los controladores de dominio para mantener consistencia. Requiere un servidor DNS dinámico.</p><p>Otras estructuras del modelo de dominio Windows son:</p><ul><li>Sitio: Lugar físico de un controlador de dominio. Los clientes tratan de iniciar sesión en controladores de dominio de su mismo sitio para acelerar y optimizar el uso de la red.</li><li>Árbol: Conjunto de dominios en una misma jerarquía DNS.</li><li>Bosque: Conjunto de árboles con distintas jerarquías DNS.</li><li>OU (Unidad Organizativa): Conjunto de recursos agrupados para facilitar su administración.</li></ul><p>Por fin, para que los usuarios de un dominio accedan a recursos de otro dominio hay que definir una relación de confianza entre dominios. Un sistema tipo Unix puede participar en una red Microsoft, actuando incluso como controlador de dominio. Para ello hay que instalar y configurar samba en un sistema tipo Unix.</p><p><strong>Administración</strong></p><p>La administración de servidores Windows se realiza con consolas administrativas del Menú Inicio/Programas.</p><p>Destacan las siguientes:</p><ul><li>Usuarios y equipos de AD: Menú que permite gestionar cuentas de usuarios en el dominio.</li><li>Administración de equipos: Para administrar equipos locales o remotos. Permite administrar servicios iniciados, dispositivos, visor de sucesos y recursos compartidos.</li><li>Administrador de servicios de Internet (IIS): Para configurar servidores web, FTP, SMTP y NNTP de Windows.</li><li>DHCP, DNS y WINS: Son las herramientas de administración del servidor DHCP, DNS y el servicio WINS, de resolución de nombres Windows.</li><li>Directivas de seguridad: Herramienta de gestión de los privilegios de seguridad a nivel de dominio, de controlador de dominio y local.</li><li>Dominios y confianzas de AD: En particular, para definir las relaciones de confianza entre dominios.</li><li>Enrutamiento y acceso remoto: Permite definir opciones de enrutamiento, acceso remoto (RAS) y redes privadas virtuales (VPN).</li><li>Rendimiento y visor de sucesos: Es la herramienta que ofrece información gráfica del rendimiento de los componentes del sistema. Permite definir alertas de rendimiento. El visor de sucesos registra la actividad del sistema de ficheros de registro (logs).</li><li>Servicios: Permite iniciar y detener servicios.</li><li>Sistema de archivos distribuidos (DFS): Configura DFS para acceder a recursos compartidos.</li><li>Sitios y servicios de AD: Define los servidores que integran cada sitio y la comunicación entre ellos.</li></ul><p><strong>El registro de Windows</strong></p><p>El registro de Windows es una BBDD jerárquica centralizada dispuesta para almacenar la información de configuración del sistema para usuarios, aplicaciones y dispositivos hardware. La información del registro es la referencia que usa el SO Windows continuamente, como puedan ser perfiles de usuario, aplicaciones instaladas, tipos de documentos que gestiona cada aplicación, elementos hardware del sistema, etc.</p><p>El registro reemplaza a la mayoría de archivos .ini basados en texto usados en versiones anteriores de Windows como autoexec.bat y config.sys. Aunque es común a distintas versiones de Windows, existen diferencias.</p><p>Una sección del registro es un grupo de claves, subclaves y valores que cuentan con archivos auxiliares con copias de seguridad de sus datos. Los archivos auxiliares de cada sección excepto HKEY_CURRENT_USER suelen estar en la carpeta %SystemRoot%\System32\Config.</p><p>Para la clave HKEY_CURRENT_USER suelen disponerse en %SystemRoot%\Profiles\nombreDeUsuario.</p><p>Las extensiones de los archivos de estas carpetas indican el tipo de datos que contienen. A veces, la falta de extensión también puede indicar el tipo de datos que contienen. Los tipos de valores más importantes usados en el registro para almacenar la información se resumen en la siguiente tabla.</p><p><img src="https://gsitic.files.wordpress.com/2017/12/claves-windows.png?w=825" alt=""></p><p>La siguiente tabla enumera las claves predefinidas que usa el sistema. El tamaño máximo del nombre de una clave es de 255 caracteres.</p><p><img src="https://gsitic.files.wordpress.com/2017/12/claves_windows.png?w=825" alt=""></p><p><strong>Comandos DOS</strong></p><p>A continuación se muestra un resumen de los comandos de administración DOS habituales.</p><p><img src="https://gsitic.files.wordpress.com/2017/12/comandos_dos.png?w=825" alt=""></p><p><img src="https://gsitic.files.wordpress.com/2017/12/comandos_net.png?w=825" alt=""></p><h2 id="Sistemas-Unix-y-Linux"><a href="#Sistemas-Unix-y-Linux" class="headerlink" title="Sistemas Unix y Linux"></a>Sistemas Unix y Linux</h2><p>Los sistemas informáticos, en origen sólo permitían el proceso por lotes. Por tanto, se hizo necesaria la evolución (década de los 60) a sistema de proceso de tiempo compartido. Así, se permitía la interacción con la máquina. El primer sistema de tiempo compartido fue CTSS (Compatible Time-Sharing System), desarrollado en el MIT.</p><p>El MIT, Bell Laboratories y General Electrics diseñaron el SO MULTICS (Multiplexed Information and Computing Service), programado en PL/1. MULTICS sirvió de base a Ken Thompson, para desarrollar otro SO en lenguaje ensamblador, para una máquina PDP-7: UNICS, por oposición a MULTICS, que acabó por llamarse “UNIX” (1970).</p><p>Dennis Ritchie y Ken Thompson reescribieron Unix en lenguaje B, para otra máquina, la PDP-11. Así, se evitaba reescribir el código fuente cuando el sistema se migraba, consiguiendo portabilidad. El lenguaje B fue mejorado y evolucionó al lenguaje C, reescribiendo Unix en C, que sigue empleándose y evolucionando.</p><p>Unix fue proporcionado por AT&amp;T a universidades, con su código fuente. Esto generó mejoras en el código y su amplia difusión. La universidad de Berkeley incluyó memoria virtual, mejoró el sistema de archivos, incorporó el editor de texto vi, el shell csh y la pila de protocolos TCP/IP.</p><p>Sus SO se llamaron BSD. AT&amp;T terminó comercializando Unix, en particular su versión más conocida, Unix System V. Las distintas versiones de Unix generaron problemas de compatibilidad de programas, lo que originó su estandarización. El IEEE abrió el proyecto POSIX (Portable Operating System IX) para dicha tarea, lo que materializó en el estándar IEEE 1003.</p><p>Linux es un SO de código libre basado en Unix. Fue desarrollado por Linus Torvalds. Actualmente su desarrollo lo coordina la FSF (Free Software Foundation) y su proyecto GNU. El código libre usa licencias GPL (General Public License), que básicamente obliga a proporcionar el código fuente modificado y mantener la licencia GPL para el software desarrollado a partir de otro software protegido con GPL.</p><p>Las versiones de Linux se denominan distribuciones. Sus variaciones se refieren a aspectos como el GUI, la instalación, etc. El núcleo del sistema es común. Ejemplos son Ubuntu, Red Hat, Fedora, Suse, etc.</p><p>El proyecto GNU define software libre como el que dispone de libertad de ejecución, de modificación, de distribución y mejora. Si se incluye código GPL en un proyecto, todo el código pasará a ser libre. Esta condición evita que el software comercial use código GPL. La aplicación estricta de esta licencia generaría problemas con las bibliotecas del compilador, para programas comerciales. Para evitarlo, se dispone la licencia GNU LGPL (Lesser GPL), menos restrictiva que GPL, que permite integrar partes LGPL sin que todo el código pase a ser software libre.</p><p>Los entornos Unix/Linux permiten al usuario elegir el intérprete de comandos (shell). Las Shell difieren en la definición de instrucciones y la programación de scripts. Destacan entre las comunes bsh (Bourne Shell, /bin/sh), csh (C-Shell, /bin/csh, basada en C), ksh (Korn Shell, /bin/ksh), bash (Bourne Again Shell, /bin/bash, mejora csh y ksh) o tcsh (Tab C-Shell, /bin/tcsh, una mejora de csh).</p><p><strong>Sistema de archivos</strong></p><p>En entornos Unix, el sistema de archivos sigue el estándar de jerarquía de ficheros (FHS, Filesystem Hierarchy Standard, 1993). FHS define la estructura de directorios y sus contenidos. Comenzó en 1994 con el FSSTND (Filesystem Stardard), que ha sufrido varias revisiones hasta el actual FHS (1996). FHS es mantenido por el Free Stardards Group, una organización constituida por compañías como Hewlett Packard, Dell, IBM o Red Hat. La mayoría de las distribuciones Linux, no lo aplican de forma estricta.</p><p>La estructura de directorios es tal que todos los ficheros y directorios aparecen bajo el directorio raíz (/), aun si están almacenados en dispositivos físicos diferentes.</p><p>La estructura es la siguiente:</p><p><img src="https://gsitic.files.wordpress.com/2017/12/directorio_linux.png?w=825" alt=""></p><p>Para instalar un sistema Linux, suele ser habitual la recomendación de usar al menos tres particiones: /, /boot y swap (a la que no se asigna punto de montaje).</p><p><strong>Archivos, permisos e inodos</strong></p><p>Los archivos de un sistema de archivos Unix distinguen los tipos ordinarios (datos o programas), directorios (lista de archivos con punteros a sus inodos), especiales (dispositivos tales como puertos y discos) y tuberías con nombre (named pipes, comunican dos procesos).</p><p>Los nombres de archivos pueden tener hasta 255 caracteres. Se pueden crear archivos ocultos con un punto como primer carácter del nombre. Un enlace o vínculo (link) permite que un mismo archivo pueda llamarse desde varios directorios).</p><p>Sólo existirá una copia del archivo, aunque podrá accederse desde varios directorios. Si se borra el archivo en un directorio sólo se borra el enlace. El archivo sólo se borra si se borra en todos los directorios en que posee enlace. En general los enlaces se refieren a enlaces duros (físicos o hard link), en oposición a los enlaces simbólicos, archivos que apuntan a otro (similar a un acceso directo en Windows).</p><p>Todos los directorios y subdirectorios se tratan como archivos. El directorio actual se nota con un punto y el directorio padre con dos.</p><p>En entornos Unix se definen 3 tipos de permisos básicos:</p><ul><li>lectura (r)</li><li>escritura <img src="https://s1.wp.com/wp-content/mu-plugins/wpcom-smileys/wordpress.svg" alt=""></li><li>ejecución (x)</li></ul><p>Se definen tres perfiles de usuario:</p><ul><li>el propietario del archivo (user, u)</li><li>usuario del grupo del propietario (group, g)</li><li>usuario que no pertenece al grupo del usuario (other, o)</li></ul><p>Los permisos se suelen representar con 10 bits: -rwxrwxrwx. El primer carácter corresponde al tipo de fichero (‘-‘, fichero ordinario; ‘d’, directorio; ‘c’, fichero especial tipo carácter; ‘b’, fichero especial tipo bloque; …). Dependiendo del tipo de Unix hay otras opciones (‘l’, ‘s’, ‘=’). El resto de caracteres, en bloques de tres, especifican qué tipo de usuario puede realizar qué operación.</p><p>Por ejemplo, la respuesta -rwxr-x-r– indica un fichero ordinario, los tres bits del propietario (rwx), le dan permiso de lectura, escritura y ejecución, los tres segundos (r-x), del grupo, le permiten leer y ejecutar el fichero y los tres últimos (r–) permiten al resto, solo lectura.</p><p>Aparte de los anteriores bits de permisos, hay un cuarto tipo más especial, en el que se engloban setuid, setgid y sticky bit. Setuid o modo “s”, significa que la identidad efectiva de usuario con la que se ejecuta el programa es la del propietario. Este permiso no tiene sentido en ficheros no ejecutables.</p><p>Por ejemplo, la salida -rwsr-x— 1 usuario 1499 Jun 6 10:17 fichero, indica un fichero modo s. Setgid, o modo s del grupo es similar al anterior, referido al grupo. Ejemplo, -r-xr-sr-x 1 usuario grupo 9984 Jul 16 1994 fichero. Por fin, el sticky bit, o modo “t”, cuando está activado indica que el fichero nunca se elimina del área de swap. Suele ser útil para programas ejecutados a menudo y por diferentes usuarios. Sobre un directorio el comportamiento es distinto, permitiendo que sólo el propietario del fichero, el propietario del directorio o el superusuario “root”, puedan renombrar o borrar los ficheros contenidos en él. Es útil para áreas compartidas. Por ejemplo, en el directorio /tmp al hacer ls -ald, se puede obtener la salida drwxrwxrwt 5 root 309 Jun 7 11: 41 ./.</p><p>Los permisos suelen indicarse también mediante un código octal de 3 números. Cada número codifica una terna. Así,la terna rw- se codificaría como 110 en binario, que en octal es 6.</p><p>En entornos Unix los archivos se gestionan con nodos índice o inodos, estructuras de 64B con información del tipo de archivo y permisos, número de referencias del archivo en directorios (enlaces), identificador del propietario y su grupo, tamaño del archivo en Bytes, fecha de último acceso y modificación del archivo e inodo y dirección, formada por 39B divididos en 13 punteros de 3B.</p><p>En la dirección, los 10B primeros son directos. Contienen direcciones de bloques de datos. Los 3B siguientes son punteros indirectos: indirecto simple (puntero a bloque de 256 punteros directos, 256 bloques), indirecto doble (puntero a bloque de 256 punteros indirectos simples, 2e8 · 2e8 = 2e16 bloques) o indirecto simple (puntero a bloque de 256 punteros indirectos dobles, 16 millones de bloques).</p><p>La asignación de bloques a un archivo es dinámica, según necesidad. Por eso, los bloques pueden no asignarse secuencialmente, generando fragmentación, lo que perjudica el rendimiento. En Unix System V se usan bloques de 1KB (en FAT pueden llegar a 32KB). Los bloques pequeños evitan desaprovechar espacio en disco. Los punteros de dirección de un archivo se van usando a medida que se necesitan, comenzando por los punteros directos (más rápidos).</p><p>Suponiendo bloques de 1KB las capacidades que ofrece cada sistema es, para direccionamiento directo 10KB (10 bloques); indirecto simple 256KB (256 bloques); indirecto doble 65MB (65536 bloques); indirecto triple 16GB (2e8 · 2e16 = 2e24 bloques). Así, el tamaño máximo teórico de un archivo sería la suma de la capacidad de un inodo total (los 16GB aprox.). Las ventajas de los inodos es que al ser pequeños pueden mantenerse en memoria, ofreciendo un rápido acceso y aprovechan mejor el espacio en disco.</p><p>En los entornos Unix tradicionales, la organización de un disco cuenta con un Bloque de arranque (bloque 0), con información para el arranque del SO; un Superbloque (bloque 1), con información de la organización del sistema de archivos; Inodos, tabla de inodos con la estructura expuesta dividida en Inodo 1 (reservado para gestión de bloques defectuosos) e Inodo 2 (gestionado por el directorio raíz) y Bloque de datos, que guarda el contenido de los archivos.</p><p><strong>Gestores de arranque, entornos de escritorio y editores de texto</strong></p><p>Un gestor de arranque es un programa que se instala en el sector de arranque del disco duro (MBR, Master Boot Record) y al encender la máquina, permite elegir el SO que ejecutar. Los más populares en entornos Unix son LILO (LInux LOader) y GRUB (GRand Unified Bootloader). El de Microsoft se llama NT Loader (NTLDR) instalado en el sector de arranque de la partición primaria de windows. Los dos tipos pueden convivir ya que se instalan en lugares distintos.</p><p>En cuanto a las GUI, en entornos Unix existen algunas típicas, como KDE, que usa Konqueror como gestor de archivos y navegador web; GNOME, que usa Nautilus como gestor de archivos, pudiéndose usar otro programa como navegador web y Xfce, que usa Thunar como gestor de archivos, típico en distribuciones de BSD y Solaris.</p><p>Debido a su importancia, a la hora de editar archivos de texto para la configuración, los entornos Unix suelen incluir editores de texto típicos como vi, emacs (de más fácil manejo), vim o xemacs.</p><p><strong>Cuentas de usuario</strong></p><p>Para acceder a un sistema tipo Unix, un usuario se modela con una cuenta del sistema. Un usuario tendrá además un perfil, que definirá, entre otras cosas, sus privilegios. Los entornos Unix definen un perfil de usuario de máximo privilegio llamado root o superusuario, y por añadidura, su cuenta se denomina cuenta de root. Sus privilegios le permiten realizar cualquier tarea administrativa.</p><p>Una cuenta de usuario se define con un nombre de usuario o login, un identificador (UID, User IDentificator), un identificador de su grupo (GID), una contraseña (password), su Shell (el CLI que ejecutará por defecto), su directorio particular (conocido como /home) y comentarios.</p><p>La información de una cuenta de usuario se almacena básicamente en tres archivos: passwd, shadow y group del directorio /etc. El primero posee el listado completo de usuarios con información para cada uno de su login, contraseña, uid, gid, comentario, directorio home y shell. El campo contraseña suele aparecer con “x”, lo que evita que se pueda ver directamente, porque se encripta en el archivo shadow.</p><p>El archivo shadow contiene las contraseñas encriptadas de los usuarios. Para cada usuario se almacena su login, contraseña encriptada, fecha de última modificación, mínimo y máximo de días entre modificaciones, días de aviso de expiración, máximo de días con la cuenta inactiva y fecha de expiración.</p><p>El archivo group lista los grupos de usuarios. Para cada grupo se tiene la información del nombre, contraseña, gid y lista de usuarios. La contraseña no se usa. Suele presentarse un asterisco o un espacio en blanco. La lista de usuario sindica los UID de los miembros secundarios del grupo. Como un usuario puede pertenecer a varios grupos, su grupo principal se indica en el archivo passwd y los secundarios se indican incluyendo su UID en la lista de usuario de cada grupo en el archivo group.</p><p><strong>Comandos UNIX</strong></p><p>A continuación se muestra un resumen de los comandos de administración UNIX habituales.</p><p><img src="https://gsitic.files.wordpress.com/2017/12/unix_archivos.png?w=825" alt=""></p><p><img src="https://gsitic.files.wordpress.com/2017/12/unix_procesos.png?w=825" alt=""></p><p><img src="https://gsitic.files.wordpress.com/2017/12/unix_red.png?w=825" alt=""></p><p><img src="https://gsitic.files.wordpress.com/2017/12/unix_herramientas.png?w=825" alt=""></p><p><img src="https://gsitic.files.wordpress.com/2017/12/unix_sistema.png?w=825" alt=""></p><h2 id="Sistemas-Operativos-para-dispositivos-moviles"><a href="#Sistemas-Operativos-para-dispositivos-moviles" class="headerlink" title="Sistemas Operativos para dispositivos móviles"></a>Sistemas Operativos para dispositivos móviles</h2><p>Un SO móvil es un conjunto de programas de bajo nivel que permite la abstracción de las peculiaridades del hardware específico del teléfono móvil y provee servicios a las aplicaciones móviles, que se ejecutan sobre él.</p><p><strong>Capas de un Sistema Operativo móvil</strong></p><ul><li><strong>Kernel</strong> . El núcleo o kernel proporciona el acceso a los distintos elementos del hardware del dispositivo. Ofrece distintos servicios a las capas superiores como son los controladores o drivers para el hardware, la gestión de procesos, el sistema de archivos y el acceso y gestión de la memoria.</li><li><strong>Middleware</strong> . El middleware es un conjunto de módulos que hacen posible la propia existencia de aplicaciones para móviles. Es totalmente transparente para el usuario y ofrece servicios claves como el motor de mensajería y comunicaciones, códecs multimedia, intérpretes de páginas web, gestión del dispositivo y seguridad.</li><li><strong>Entorno de ejecución de aplicaciones</strong> . El entorno de ejecución de aplicaciones consiste en un gestor de aplicaciones y un conjunto de interfaces programables abiertas y programables por parte de los desarrolladores para la creación de software.</li><li><strong>Interfaz de usuario</strong> . Las interfaces de usuario facilitan la interacción con el usuario y el diseño de la presentación visual de la aplicación. Los servicios que incluye son el de componentes gráficos (botones, pantallas, listas, …) y el marco de interacción.</li></ul><p>Aparte de estas capas también existe una familia de aplicaciones nativas del teléfono que suelen incluir los menús, el marcador de números de teléfono, …</p><p><strong>Sistemas Operativos móviles</strong></p><blockquote><p><strong>Android</strong></p></blockquote><p>Android Inc. es la empresa que creó el SO móvil. Se fundó en 2003 y fue comprada por Google en 2005 y en 2007 fue lanzado al mercado. Su nombre se debe a su inventor, Andy Rubin. Originalmente era un sistema pensado para las cámaras digitales.</p><p>Android está basado en Linux, disponiendo de un Kernel en este sistema y utilizando una máquina virtual sobre este Kernel que es la responsable de convertir el código escrito en Java a código capaz de comprender el Kernel.</p><p>Una de las grandes cualidades o características de este SO es su carácter abierto. Android se distribuye bajo dos tipos de licencias, una que abarca todo el código del Kernel y que es GNU GPLv2 (implica que su código se debe poner al alcance de todos y que todos podremos hacer con este código lo que nos parezca oportuno, modificarlo, ampliarlo, recortarlo, pero siempre estaremos en la obligación de volver a licenciarlo con la misma licencia). Google también tiene otra licencia para el resto de componentes del sistema que se licencia bajo APACHE v2, una licencia libre y de código abierto (implica que este código se pueda distribuir para ser modificado y usado a antojo del que lo utilice, pero a diferencia del primer caso, las modificaciones y el código resultante no es obligatorio licenciarlo bajo las mismas condiciones en las que se encontraba).</p><p>La estructura del SO Android se compone de aplicaciones que se ejecutan en un framework Java de aplicaciones orientadas a objetos sobre el núcleo de las bibliotecas de Java en una máquina Virtual Dalvik con compilación en tiempo de ejecución hasta la versión 5.0, luego cambió al entorno Android Runtime (ART).</p><p>Las bibliotecas escritas en lenguaje C incluyen un administrador de interfaz gráfica (surface manager), un framework OpenCore, una base de datos relacional SQLite, una interfaz de programación de API gráfica OpenGL ES 2.0 3D, un motor de renderizado WebKit, un motor gráfico SGL, SSL y una biblioteca estánde de C Bionic.</p><p>Las características y especificaciones son:</p><p><img src="https://gsitic.files.wordpress.com/2017/12/android1.png?w=825" alt=""></p><p><img src="https://gsitic.files.wordpress.com/2017/12/android2.png?w=825" alt=""></p><h3 id="Informacion-General"><a href="#Informacion-General" class="headerlink" title="Información General"></a>Información General</h3><p><img src="https://gsitic.files.wordpress.com/2017/12/android_info1.png?w=825" alt=""></p><h3 id="Arquitectura"><a href="#Arquitectura" class="headerlink" title="Arquitectura"></a>Arquitectura</h3><p>Los componentes principales del SO Android son:</p><ul><li><strong>Aplicaciones</strong> : las aplicaciones base incluyen un cliente de correo electrónico, programa de SMS, calendario, mapas, navegador, contactos y otros. Todas las aplicaciones están escritas en lenguaje de programación Java.</li><li><strong>Marco de trabajo de aplicaciones</strong> : los desarrolladores tienen acceso completo a las mismas API del entorno de trabajo usados por las aplicaciones base. La arquitectura está diseñada para simplificar la reutilización de componentes; cualquier aplicación puede publicar sus capacidades y cualquier otra aplicación puede luego hacer uso de esas capacidades (sujeto a reglas de seguridad del framework). Este mismo mecanismo permite que los componentes sean reemplazados por el usuario.</li><li><strong>Bibliotecas</strong> : Android incluye un conjunto de bibliotecas de C/C++ usadas por vaios componentes del sistema. Estas características se exponen a los desarrolladores a través del marco de trabajo de aplicaciones de Android. Algunas son: System C library (implementación biblioteca C estándar), bibliotecas de medios, bibliotecas de gráficos, 3D y SQLite, entre otras.</li><li><strong>Runtime de Android</strong> : Android incluye un set de bibliotecas base que proporcionan la mayor parte de las funciones disponibles en las bibliotecas base del lenguaje Java. Cada aplicación Android corre su propio proceso, con su propia instancia de la máquina virtual Dalvik. Dalvik ha sido escrito de forma que un dispositivo puede correr múltiples máquinas virtuales de forma eficiente. Dalvik ejecutaba hasta la versión 5.0 archivos en el formato de ejecutable Dalvik (.dex), el cual está optimizado para memoria mínima. La Máquina Virtual está basada en registros y corre clases compiladas por el compilador de Java que han sido transofrmadas al formato .dex por la herramienta incluida dx. Desde la versión 5.0 utiliza el ART, que compila totalmente al momento de la instalación de la aplicación.</li><li><strong>Núcleo Linux</strong> : Android depende de Linux para los servicios base del sistema como seguridad, gestión de memoria, gestión de procesos, pila de red y modelo de controladores. El núcleo también actúa como una capa de abstracción entre el hardware y el resto de la pila de software.</li></ul><p><strong>Versiones</strong></p><p><img src="https://gsitic.files.wordpress.com/2017/12/android_versione.png?w=825" alt=""></p><p><strong>Honeycomb</strong> fue la primera actualización exclusiva para TV y Tablet, no era apta para móviles.</p><blockquote><p><strong>iOS</strong></p></blockquote><p>iOS es un SO que da vida a dispositivos como el iPhone, el iPad, el iPod Touch o el Apple TV.</p><p>Anteriormente denominado iPhone OS creado por Apple originalmente para iPhone, siendo después usado en el iPod Touch e iPad. Es un derivado de Mac OS X que a su vez está basado en Darwin BSD y por lo tanto es un SO tipo Unix, se lanzó en el año 2007.</p><p>iOS cuenta con cuatro capas de abstracción:</p><ol><li>la capa del núcleo del SO</li><li>la capa de “Servicios Principales”</li><li>la capa de “Medios”</li><li>la capa de “Cocoa Touch”</li></ol><p><strong>Información General</strong></p><p><img src="https://gsitic.files.wordpress.com/2017/12/ios_info1.png?w=825" alt=""></p><p>Actualmente va por la versión iOS 11.</p><blockquote><p><strong>Windows Phone</strong></p></blockquote><p>Windows Phone (abreviado WP) es un SO móvil desarrollado por Microsoft, como sucesor de Windows Mobile. Con Windows Phone; Microsoft ofrece una nueva interfaz de usuario que integra varios de sus servicios propios como OneDrive, Skype y Xbox Live en el SO. Microsoft pasa a enfocarse en un único sistema denominado Windows 10 Mobile, disponible para todo tipo de plataformas (teléfonos inteligentes, tabletas y computadoras). Está diseñado para ser similar a las versiones de escritorio de Windows estéticamente.</p><p><strong>Información General</strong></p><p><img src="https://gsitic.files.wordpress.com/2017/12/info_windows1.png?w=825" alt=""></p><p><strong>Versiones</strong></p><ul><li>Windows Phone 7</li><li>Windows Phone 8</li><li>Windows Phone 8.1</li></ul><blockquote><p><strong>BlackBerry 6</strong></p></blockquote><p>El BlackBerry OS es un SO móvil de código cerrado desarrollado por BlackBerry, antigua Research In Motion (RIM).</p><p>El sistema permite multitarea y tiene soporte para diferentes métodos de entrada adoptados por RIM para su uso en computadoras de mano. Su desarrollo se remonta a la aparición de los primeros handleds en 1999.</p><p><strong>Información General</strong></p><p><img src="https://gsitic.files.wordpress.com/2017/12/blacberry_inf.png?w=825" alt=""></p><blockquote><p><strong>Symbian</strong></p></blockquote><p>Fue producto de la alianza de varias empresas de telefonía móvil, entre la que se encuentra Nokia como la más importante.</p><p>El SO Symbian es una colección compacta de código ejecutable y varios archivos, la mayoría de ellos son bibliotecas vinculadas dinámicamente (DLL) y otros datos requeridos, incluyendo archivos de configuración, de imágenes y de tipografía, entre otros recursos residentes. Symbian se almacena, generalmente, en un circuito flash dentro del dispositivo móvil.</p><p><strong>Información General</strong></p><p><img src="https://gsitic.files.wordpress.com/2017/12/symbian_inf1.png?w=825" alt=""></p><blockquote><p><strong>Firefox OS</strong></p></blockquote><p>Firefox OS es un SO móvil, basado en HTML5 con núcleo Linux, para smartphones y tabletas. Es desarrollado por Mozilla Corporation bajo el apoyo de empresas y voluntarios de todo el mundo. Este SO está enfocado especialmente en los dispositivos móviles. Está diseñado para permitir a las aplicaciones HTML5 comunicarse directamente con el hardware del dispositivo usando Javascript y Open Web APIs.</p><p><strong>Información General</strong></p><p><img src="https://gsitic.files.wordpress.com/2017/12/firefox_inf.png?w=825" alt=""></p><blockquote><p><strong>Ubuntu Touch</strong></p></blockquote><p>Ubuntu Touch es un SO móvil basado en Linux. Se caracteriza por ser un sistema diseñado para plataformas móviles.</p><p><strong>Información general</strong></p><p><img src="https://gsitic.files.wordpress.com/2017/12/ubuntu_inf.png?w=825" alt=""></p><blockquote><p><strong>Listado Sistemas Operativos Móviles</strong></p></blockquote><p><img src="https://gsitic.files.wordpress.com/2017/12/listadoso.png?w=825" alt=""></p><h2 id="Bibliografia"><a href="#Bibliografia" class="headerlink" title="Bibliografía"></a>Bibliografía</h2><ul><li><a href="http://apuntedecaramelo.blogspot.com.es/" rel="external nofollow noopener noreferrer" target="_blank">Apunte de caramelo</a></li><li><a href="https://rua.ua.es/dspace/" rel="external nofollow noopener noreferrer" target="_blank">RUA. Repositorio Institucional de la Universidad de Alicante</a></li><li><a href="https://es.wikipedia.org/wiki/Categor%C3%ADa:Sistemas_operativos_m%C3%B3viles" rel="external nofollow noopener noreferrer" target="_blank">Wikipedia. Sistemas operativos móviles</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Caracteristicas-tecnicas-y-funcionales-de-los-sistemas-operativos-Windows-Linux-Unix-y-otros-Sistemas-operativos-para-dispositivos-m
      
    
    </summary>
    
      <category term="B2" scheme="http://localhost:4000/categories/B2/"/>
    
    
  </entry>
  
  <entry>
    <title>B2-T04</title>
    <link href="http://localhost:4000/wiki/B2/b2-t04/"/>
    <id>http://localhost:4000/wiki/B2/b2-t04/</id>
    <published>2019-01-16T15:11:23.000Z</published>
    <updated>2019-01-18T10:45:16.577Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Caracteristicas-tecnicas-de-los-lenguajes-y-paradigmas-actuales-de-programacion"><a href="#Caracteristicas-tecnicas-de-los-lenguajes-y-paradigmas-actuales-de-programacion" class="headerlink" title="Características técnicas de los lenguajes y paradigmas actuales de programación."></a>Características técnicas de los lenguajes y paradigmas actuales de programación.</h1><h2 id="Lenguajes-y-paradigmas-actuales-de-programacion"><a href="#Lenguajes-y-paradigmas-actuales-de-programacion" class="headerlink" title="Lenguajes y paradigmas actuales de programación."></a>Lenguajes y paradigmas actuales de programación.</h2><h3 id="Categorias-de-Lenguajes-de-Programacion"><a href="#Categorias-de-Lenguajes-de-Programacion" class="headerlink" title="Categorías de Lenguajes de Programación"></a>Categorías de Lenguajes de Programación</h3><p>Los lenguajes de programación se pueden clasificar atendiendo a varios criterios:</p><ul><li>Según el nivel de abstracción</li><li>Según el paradigma de programación que posee cada uno de ellos</li><li>Según su campo de aplicación</li><li>Según su traducción</li></ul><p><strong>Según su nivel de abstracción</strong></p><p><strong>Lenguajes Máquina</strong></p><p>Están escritos en lenguajes directamente legibles por la máquina (computadora), ya que sus instrucciones son cadenas binarias (0 y 1). Da la posibilidad de cargar (transferir un programa a la memoria) sin necesidad de traducción posterior lo que supone na velocidad de ejecución superior, solo que con poca fiabilidad y dificultad de verificar y poner a punto los programas.</p><p><strong>Lenguajes de bajo nivel</strong></p><p>Los lenguajes de bajo nivel son lenguajes de programación que se acercan al funcionamiento de una computadora. El lenguaje por excelencia es el lenguaje ensamblador, éste trabaja con los registros de memoria de la computadora de forma directa.</p><p>La principal utilización de este tipo de lenguajes es para programar los microprocesadores, utilizando el lenguaje ensamblador correspondiente a dicho procesador.</p><p><strong>Lenguajes de medio nivel</strong></p><p>Hay lenguajes de programación que son considerados como lenguajes de medio nivel (como es el caso del C) al tener ciertas características que los acercan a los lenguajes de bajo nivel pero teniendo, al mismo tiempo, ciertas cualidades que lo hacen un lenguaje más cercano al humano y, por tanto, de alto nivel.</p><p><strong>Lenguajes de alto nivel</strong></p><p>Los lenguajes de alto nivel son normalmente fáciles de aprender porque están formados por elementos de lenguajes naturales, como el inglés. Esta forma de trabajar puede dar la sensación de que las computadoras parecen comprender un lenguaje natural; en realidad lo hacen de una forma rígida y sistemática, sin que haya cabida, por ejemplo, para ambigüedades o dobles sentidos.</p><p>Lenguajes utilizados Pascal, Basic, …</p><p><strong>Según el paradigma de programación</strong></p><p>Un <strong>paradigma de programación</strong> indica un método de realizar cómputos y la manera en que se deben estructurar y organizar las tareas que debe llevar a cabo un programa.</p><p>Un paradigma es un modelo que, a su vez, es una representación abstracta de la realidad.</p><p>Un paradigma de programación es un modelo de programación que representa un estilo o forma de programar o construir programas para realizar ciertas tareas o actividades. Cada modelo tiene sus propias estructuras y reglas de construcción. El modelo de programación por emplear depende del problema que se desee solucionar.</p><p>Los paradigmas fundamentales están asociados a determinados modelos de cómputo. También se asocian a un determinado estilo de programación. Los lenguajes de programación suelen interpretar, a menudo de forma parcial, varios paradigmas.</p><p>Existen muchos paradigmas de programación diferentes, cada uno de ellos tiene sus <strong>propias características</strong> y tratan de solucionar los problemas clásicos del desarrollo de software desde diferentes perspectivas y filosofías.</p><p>Los paradigmas de programación solo son <strong>propuestas tecnológicas</strong> adoptadas por la Comunidad de desarrolladores que se enfocan a resolver uno o varios problemas definidos y delimitados. Existen muchos paradigmas de programación diferentes, posiblemente el más ampliamente utilizado hoy en día sea el de la <strong>programación orientada a objetos</strong> .</p><p>Algunos lenguajes de programación pueden soportar <strong>múltiples paradigmas</strong> de programación. Por ejemplo, C++ puede ser empleado para desarrollar software utilizando para ello un modelo de programación puramente orientado a objetos o bien puramente estructurado.</p><p>Otros lenguajes han sido diseñados para soportar un <strong>único paradigma</strong> de programación, ese es el caso de <strong>Smalltalk</strong> que soporta únicamente la programación orientada a objetos o <strong>Haskell</strong> que solo soporta la <strong>programación funcional</strong> .</p><p>Es común el diseño de lenguajes que soporten múltiples paradigmas de programación. Estos lenguajes son aquellos que soportan al menos dos paradigmas:</p><ul><li><strong>Scala</strong> : Imperativo, orientado a objetos, funcional, genérico y concurrente</li><li><strong>Erlang</strong> : Funcional, orientado a objetos y funcional</li><li><strong>Perl</strong> : Imperativo, orientado a objetos y funcional</li><li><strong>PHP</strong> : Imperativo, orientado a objetos, funcional y reflexivo</li><li><strong>JavaScript</strong> : Imperativo, orientado a objetos (prototipos) y funcional</li><li><strong>Java</strong> : Imperativo, orientado a objetos, reflexivo y genérico</li><li><strong>Python</strong> y <strong>Ruby</strong> : Imperativo, orientado a objetos, reflexivo y funcional</li><li><strong>C++</strong> : Imperativo, orientado a objetos, funcional y genérico</li><li><strong>C#</strong> : Imperativo, orientado a objetos, funcional (lambda), reflexivo y genérico</li><li><strong>Lisp</strong> : Orientado a objetos, funcional y declarativo</li><li><strong>Prolog</strong> : Lógico y declarativo</li></ul><p>Estos son algunos ejemplos, existen lenguajes como <strong>Oz</strong> que soporta nueve paradigmas de programación.</p><p><strong>Paradigmas de programación</strong></p><p>Un paradigma define un conjunto de reglas, patrones y estilos de programación que son usados por un grupo de lenguajes de programación.</p><p>Cada lenguaje tiene sintaxis y semántica:</p><ul><li>La sintaxis de un lenguaje de programación está relacionada con la forma de los programas, por ejemplo, las expresiones, comandos, declaraciones, etc. son puestos juntos en un programa.</li><li>La semántica de un lenguaje de programación está relacionada con el significado de los programas, por ejemplo, cómo se comportarán cuando se ejecutan en una computadora.</li></ul><p>La sintaxis de un lenguaje influye en cómo los programas son escritos por el programador, leídos por otro programador y traducidos por el computador. La semántica de un lenguaje determina como los programas son compuestos por el programador, entendidos por otros programadores e interpretados por el computador.</p><p>Tipos de Paradigmas:</p><ul><li>Paradigma imperativo (por procedimientos)</li><li>Paradigma declarativo<ul><li>Programación funcional</li><li>Programación lógica</li><li>Programación Reactiva (Dataflow)</li></ul></li><li>Paradigma orientado a objetos</li></ul><p><strong>Paradigma imperativo (por procedimientos)</strong></p><p>En el paradigma por procedimientos, los programas se desarrollan a través de procedimientos. Pascal, C y BASIC son tres de los lenguajes imperativos más importantes. El paradigma se inició a principios de los años 50 cuando los diseñadores reconocieron que las variables y lo comandos o instrucciones de asignación constituían una simple pero útil abstracción del acceso a memoria y actualización del conjunto de instrucciones máquina.</p><ul><li>Describe cómo debe realizarse el cálculo, no el porqué</li><li>Un cómputo consiste en una serie de sentencias, ejecutadas según un control de flujo explícito, que modifican el estado del programa</li><li>Las variables son celdas de memoria que contienen datos (o referencias), pueden ser modificadas y representan el estado del programa</li><li>La sentencia principal es la asignación</li><li>Definición de procedimientos</li><li>Definición de tipos de datos</li><li>Chequeo de tipos en tiempo de compilación</li><li>Cambio de estado de variables</li><li>Pasos de ejecución de un proceso</li><li>Asociados al paradigma imperativo se encuentran los <strong>paradigmas procedural</strong> , <strong>modular</strong> y la <strong>programación estructurada</strong></li><li>Lenguajes: FORTRAN-77, COBOL, BASIC, PASCAL, C, ADA, …</li><li>También lo implementan: Java, C++, C#, Eiffel, Python, …</li></ul><p>La programación imperativa es una forma de escribir programas secuenciales; es decir, que tienes que ir indicando en el programa los pasos o tareas que debe realizar según las siguientes reglas:</p><p><img src="https://gsitic.files.wordpress.com/2017/12/paradigma_imperativo.png?w=825" alt=""></p><p><strong>Paradigma declarativo</strong></p><p>El paradigma declarativo o paradigma de programación lógica se basa en el hecho de que un programa implementa una relación antes que una correspondencia. Debido a que las relaciones son mas generales que las correspondencias (identificador – dirección de memoria), la programación lógica es potencialmente de más alto nivel que la programación funcional o la imperativa. El lenguaje más popular es el lenguaje PROLOG.</p><ul><li>Describe qué se debe calcular, sin explicar el cómo</li><li>No existe un orden de evaluación prefijado</li><li>Las variables son nombres asociados a definiciones, y una vez instanciadas son inmutables</li><li>No existe sentencia de asignación</li><li>El control de flujo suele estar asociado a la composición funcional, la recursividad y/o técnicas de reescritura y unificación</li><li>Existen distintos grados de pureza en las variantes del paradigma</li><li>Las principales variantes son los paradigmas <strong>funcional</strong> , <strong>lógico</strong> , la <strong>programación reactiva</strong> y los <strong>lenguajes descriptivos</strong></li></ul><p><strong>Programación funcional</strong></p><p>La programación funcional se caracteriza por el uso de expresiones y funciones. Un programa dentro del paradigma funcional, es una función o un grupo de funciones compuestas por funciones más simples estableciéndose que una función puede llamar a otra, o el resultado de una función puede ser usado como argumento de otra función. El lenguaje por excelencia es el LISP.</p><ul><li>Basado en los modelos de cómputo <strong>cálculo lambda</strong> (Lisp, Scheme) y <strong>lógica combinatoria</strong> (famila ML, Haskell)</li><li>Las funciones son elementos de primer orden</li><li>Evaluación por reducción funcional. Técnicas:<ul><li>recursividad</li><li>parámetros acumuladores</li><li>CPS</li><li>Mónadas</li></ul></li><li>Familia LISP (Common-Lisp, Sheme):<ul><li>Basados en s-expresiones</li><li>Tipado debil</li><li>Meta-programación</li></ul></li><li>Familia ML (Miranda, Haskell, Scala):<ul><li>Sistema estricto de tipos (tipado algebraico)</li><li>Concordancia de patrones</li><li>Transparencia referencial</li><li>Evaluación perezosa (estructuras de datos infinitas)</li></ul></li><li>La computación se realiza mediante la evaluación de expresiones</li><li>Definición de funciones</li><li>Funciones como datos primitivos</li><li>Valores sin efectos laterales, no existe la asignación</li><li>Programación declarativa</li><li>Lenguajes: LISP, Scheme, Haskell, Scala, …</li></ul><p>Las funciones matemáticas son una correspondencia entre un dominio y un rango.</p><p><img src="https://gsitic.files.wordpress.com/2017/12/funcional1.png?w=825" alt=""></p><p>Una definición de función especifica el dominio y el rango, de manera implícita o explicita, junto con una expresión que describe la correspondencia.</p><p>Las funciones son aplicadas a un elemento del dominio y devuelve uno del rango.</p><p><strong>Programación lógica</strong></p><ul><li>Basado en la <strong>lógica de predicados</strong> de primer orden</li><li>Los programas se componen de hechos, predicados y relaciones</li><li>Evaluación basada en resolución SLD: unificación + backtracking</li><li>La ejecución consiste en la resolución de un problema de decisión, los resultados se obtienen mediante la instanciación de las variables libres</li><li>Definición de reglas</li><li>Unificación como elemento de computación</li><li>Programación declarativa</li><li>Lenguajes: Prolog, Mercury, Oz, …</li></ul><p><strong>Programación Reactiva (Dataflow)</strong></p><ul><li>Basado en la <strong>teoría de grafos</strong></li><li>Un programa consiste en la especificación del flujo de datos entre operaciones</li><li>Las variables se encuentran ligadas a las operaciones que proporcionan sus valores. Un cambio de valor de una variable se propaga a todas las operaciones en que participa.</li><li>Las hojas de cálculo se basan en este modelo</li><li>Lenguajes representativos: Simulink, Oz, Clojure, …</li></ul><p><strong>Paradigma orientado a objetos</strong></p><p>El paradigma orientado a objetos, se basa en los conceptos de objetos y clases de objetos. Un objeto es una variable equipada con un conjunto de operaciones que le pertenecen o están definidas para ellos.</p><p>Los objetos pueden usarse una y otra vez para construir múltiples objetos con las mismas propiedades o modificarse para construir nuevos objetos con propiedades similares pero no exactamente iguales.</p><p>Los objetos y clases son conceptos fundamentales. Una clase es un conjunto de objetos que comparten las mismas operaciones.</p><p>Objetos (o al menos referencia a objetos) deben ser valores de la clase base. Así, cualquier operación puede tomar un objeto como un argumento y puede devolver un objeto como resultado. De esta manera el concepto de clase de objetos está relacionado con el concepto de tipo de dato.</p><p>Herencia es también vista como un concepto clave dentro del mundo de los objetos. En este contexto, la herencia es la habilidad para organizar las clases de objetos en una jerarquía de subclases y superclases y las operaciones dadas para una clase se pueden aplicar a los objetos de la subclase.</p><ul><li>Definición de clases y herencia</li><li>Objetos como abstracción de datos y procedimientos</li><li>Polimorfismo y chequeo de tipos en tiempo de ejecución</li><li>Lenguajes: Smalltalk, Java, …</li></ul><p>Las características más importantes de la programación orientada a objetos son las siguientes:</p><p><img src="https://gsitic.files.wordpress.com/2017/12/caracteristicas_oop.png?w=825" alt=""></p><ul><li><strong>Abstracción:</strong> Denota las características esenciales de un objeto, donde se captura su comportamiento. Cada objeto en el sistema sirve como modelo de un “agente” abstracto que puede realizar trabajo, informar y cambiar su estado, y “comunicarse” con otros objetos en el sistema sin revelar “cómo” se implementan estas características. Los procesos, las funciones o los métodos, pueden también ser abstraídos, y cuando sucede esto, una variedad de técnicas son requeridas para ampliar una abstracción.</li><li><strong>Encapsulamiento:</strong> Significa reunir a todos los elementos que pueden considerarse pertenecientes a una misma entidad, al mismo nivel de abstracción. Esto permite aumentar la cohesión de los componentes del sistema. Algunos autores confunden este concepto con el principio de ocultación, principalmente porque se suelen emplear conjuntamente.</li><li><strong>Principio de ocultación</strong> : Cada objeto está aislado del exterior, es un módulo natural, y cada tipo de objeto expone una “interfaz” a otros objetos, que especifica cómo pueden interactuar con los objetos de la clase. El aislamiento protege a las propiedades de un objeto contra su modificación por quien no tenga derecho a acceder a ellas, solamente los propios métodos internos del objeto pueden acceder a su estado. Esto asegura que otros objetos no pueden cambiar el estado interno de un objeto de maneras inesperadas, eliminando efectos secundarios e interacciones inesperadas. Algunos lenguajes relajan esto, permitiendo un acceso directo a los datos internos del objeto de una manera controlada y limitando el grado de abstracción. La aplicación entera se reduce a un agregado o rompecabezas de objetos.</li><li><strong>Polimorfismo</strong> : Comportamientos diferentes, asociados a objetos distintos, pueden compartir el mismo nombre; al llamarlos por ese nombre se utilizará el comportamiento correspondiente al objeto que se esté usando. Dicho de otro modo, las referencias y las colecciones de objetos pueden contener objetos de diferentes tipos y la invocación de un comportamiento en una referencia producirá el comportamiento correcto para el tipo real del objeto referenciado. Cuando esto ocurre en “tiempo de ejecución”, esta última característica se llama “asignación tardía” o “asignación dinámica”. Algunos lenguajes proporcionan medios más estáticos (en “tiempo de compilación”) de polimorfismo, tales como las plantillas y la [[ sobrecarga | sobrecarga de operadores ]] de C++.</li><li><strong>Herencia</strong> : Las clases no están aisladas, sino que se relacionan entre sí, formando una jerarquía de clasificación. Los objetos heredan las propiedades y el comportamiento de todas las clases a las que pertenecen. La herencia organiza y facilita el polimorfismo y el encapsulamiento, permitiendo a los objetos ser definidos y creados como tipos especializados de objetos preexistentes. Estos pueden compartir (y extender) su comportamiento sin tener que volver a implementarlo.</li><li><strong>Recolección de basura:</strong> La recolección de basura o Garbage Collection es la técnica por la cual el ambiente de Objetos se encarga de destruir automáticamente, y por tanto, desasignar de la memoria los Objetos que hayan quedado sin ninguna referencia a ellos. Esto significa que el programador no debe preocuparse por la asignación o liberación de memoria, ya que el entorno la asignará al crear un nuevo Objeto y la liberará cuando nadie lo esté usando. En la mayoría de los lenguajes híbridos que se extendieron para soportar el Paradigma de Programación Orientada a Objetos como C++ u Object Pascal, esta característica no existe y la memoria debe desasignarse manualmente.</li></ul><p><strong>Según su campo de aplicación</strong></p><p><strong>Aplicaciones científicas</strong></p><p>En este tipo de aplicaciones predominan las operaciones numéricas o matriciales propias de algoritmos matemáticos. Lenguajes adecuados son FORTRAN y PASCAL.</p><p><strong>Aplicaciones en procesamiento de datos</strong></p><p>En estas aplicaciones son frecuentes las operaciones de creación, mantenimiento y consulta sobre ficheros y bases de datos. Dentro de este campo estarían aplicaciones de gestión empresarial, como programas de nóminas, contabilidad, facturación, etc. Lenguajes adecuados son COBOL y SQL.</p><p><strong>Aplicaciones de tratamiento de textos</strong></p><p>Estas aplicaciones están asociadas al manejo de textos en lenguaje natural. Un lenguaje muy adecuado para este tipo de aplicaciones es el C.</p><p><strong>Aplicaciones en inteligencia artificial</strong></p><p>Dentro de este campo, destacan las aplicaciones en sistemas expertos, juegos, visión artificial, robótica. Los lenguajes más populares son LISP y PROLOG.</p><p><strong>Aplicaciones de programación de sistemas</strong></p><p>En este campo se incluirían la programación de software de interfaz entre el usuario y el hardware, como son los módulos de un SO y los traductores. Tradicionalmente para estas aplicaciones se utilizaba Ensamblador, en la actualidad ADA, MODULA-2 y C.</p><p><strong>Según su Traducción</strong></p><p><strong>Intérpretados</strong></p><p>Un intérprete es un programa que analiza y ejecuta un código fuente, toma un código, lo traduce y a continuación lo ejecuta; y así sucesivamente lo hace hasta llegar a la última instrucción del programa, siempre y cuando no se produzca un error en el proceso.</p><p>Como ejemplo de lenguajes interpretedos están PHP, Perl, Python, …</p><p><img src="https://gsitic.files.wordpress.com/2017/12/interprete.png?w=825" alt=""></p><p><strong>Compilados</strong></p><p><img src="https://gsitic.files.wordpress.com/2017/12/compilador.png?w=825" alt=""></p><p>Como ejemplo de lenguajes que utilizan un compilador tenemos a C, C++, Visual Basic, …</p><p>La compilación permite crear un programa de computadora que puede ser ejecutado por una computadora.</p><p>La compilación de un programa se hace en tres pasos:</p><p><img src="https://gsitic.files.wordpress.com/2017/12/compilacion1.png?w=825" alt=""></p><p>La forma en que se lleva a cabo el enlace variará entre distintos compiladores, pero la forma general es:</p><p><img src="https://gsitic.files.wordpress.com/2017/12/compilacion2.png?w=825" alt=""></p><p><strong>Principales Lenguajes de Programación</strong></p><ul><li><strong>Lenguaje Máquina.</strong> Es el sistema de códigos directamente interpretable por un circuito microprogramable, como el microprocesador de una computadora.</li><li><strong>Ensamblador</strong> . Es el que proporciona poca o ninguna abstracción del microprocesador de una computadora. Es fácil su traslado al lenguaje máquina.</li><li><strong>FORTRAN</strong> (FORmula TRANslation). Es un lenguaje de programación desarrollado en los años 50 y activamente utilizado desde entonces. Se utiliza principalmente en aplicaciones científicas y análisis numérico.</li><li>ALGOL (ALGOrithmic Language)</li><li>COBOL (COmmon Business Oriented Language)</li><li>BASIC</li><li>Visual BASIC</li><li>Visual BASIC Script</li><li>Pascal</li><li>Modula-2</li><li>COMAL (COMmon Algorithmic Language)</li><li>APL (A Programming Language)</li><li>LOGO</li><li>HYPERTALK</li><li>ADA</li><li>C</li><li><strong>C++.</strong> Es un lenguaje de programación, diseñado a mediados de los años 80, por Bjarne Stroustrup. Por otro lado, es un lenguaje que abarca dos paradigmas de la programación: la programación estructurada y la programación orientada a objetos.</li><li>Visual C++</li><li>C#</li><li>LISP (LISt Processing)</li><li>PROLOG (PROgramacion LOGica)</li><li>FORTH</li><li><strong>Perl</strong> . Lenguaje práctico para la extracción e informe. Es un lenguaje de programación diseñado por Larry Wall creado en 1987. Perl toma características de C, del lenguaje interpretado shell sh, AWK, sed, Lisp y, en un grado inferior, muchos otros lenguajes de programación.</li><li><strong>Python</strong> . Es un lenguaje de programación creado por Guido van Rossum en el año 1990. En la actualidad Python se desarrolla como un proyecto de código abierto, administrado por la Python Software Foundation.</li><li>Clipper</li><li>Delphi</li><li>HTML</li><li>XHTML</li><li>PHP</li><li>SQL</li><li>PL/1</li><li><strong>Java</strong> . Es un lenguaje de programación orientado a objetos desarrollado por Sun Microsystems a principios de los años 90. Las aplicaciones Java están típicamente compiladas en un bytecode, aunque la compilación en código máquina nativo también es posible.</li><li>Javascript</li><li>Otros</li></ul><h2 id="Caracteristicas"><a href="#Caracteristicas" class="headerlink" title="Características"></a>Características</h2><h3 id="Tipos-de-datos-elementales"><a href="#Tipos-de-datos-elementales" class="headerlink" title="Tipos de datos elementales"></a>Tipos de datos elementales</h3><p>Las formas de organizar datos están determinadas por los tipos de datos definidos en el lenguaje.</p><p>Un tipo de dato determina el rango de valores que puede tomar el objeto, las operaciones a que puede ser sometido y el formato de almacenamiento en memoria.</p><p>Los tipos de datos pueden ser:</p><ul><li>Predefinidos</li><li>Definidos por el usuario, a partir de los básicos</li></ul><p><strong>Tipos de datos elementales:</strong></p><p><img src="https://gsitic.files.wordpress.com/2017/12/tipos_elementales.png?w=825" alt=""></p><p><strong>Palabras reservadas</strong></p><p>Las palabras reservadas son símbolos cuyo significado está predefinido y no se pueden usar para otro fin; aquí tenemos algunas palabras reservadas en el lenguaje C.</p><p><img src="https://gsitic.files.wordpress.com/2017/12/palabras_reservadas.png?w=825" alt=""></p><p><strong>Identificadores</strong></p><p><img src="https://gsitic.files.wordpress.com/2017/12/identificadores.png?w=825" alt=""></p><p>Hay que decir que no todos los lenguajes distinguen entre mayúsculas y minúsculas.</p><p><strong>Operadores</strong></p><p>Existen diferentes tipos de operadores: asignación, aritméticos, relacionales, lógicos y de bits.</p><p><em>Asignación</em></p><p>Al utilizarlo se realiza esta acción: el operador destino (parte izquierda) debe ser siempre una variable, mientras que en la parte derecha puede estar cualquier expresión válida. Con esto el valor de la parte derecha se asigna a la variable de la derecha.</p><p><img src="https://gsitic.files.wordpress.com/2017/12/asignacion1.png?w=825" alt=""></p><p><img src="https://gsitic.files.wordpress.com/2017/12/sintaxis_asignacion.png?w=825" alt=""></p><p><img src="https://gsitic.files.wordpress.com/2017/12/operadores_asignacion.png?w=825" alt=""></p><p><em>Aritméticos</em></p><p>Los operadores aritméticos pueden aplicarse a todo tipo de expresiones. Son utilizados para realizar operaciones matemáticas sencillas, aunque uniéndolos se puede realizar cualquier tipo de operaciones.</p><p>En la siguiente tabla se muestran los operadores aritméticos:</p><p><img src="https://gsitic.files.wordpress.com/2017/12/operadores.png?w=825" alt=""></p><ul><li>Los operadores <strong>–</strong> , <strong>+</strong> , <strong>*</strong> , <strong>/</strong> , <strong>%</strong> se corresponden con operaciones matemáticas. Son binarios porque cada uno tiene dos operandos.</li><li>Hay un operador unario <strong>–</strong> , pero no hay un operador +.</li><li>La división de enteros devuelve el cociente entero y desecha la fracción restante.</li><li>El operador módulo se aplica así: con dos enteros positivos, devuelve el resto de la división. Ejemplos: 12%3 tiene el valor 0. 12%5 tiene el valor 2.</li><li>Los operadores <strong>—</strong> y <strong>++</strong> son unarios.<ul><li>Tienen la misma prioridad que el <strong>–</strong> unario.</li><li>Se asocian de derecha a izquierda.</li><li>Pueden aplicarse a variables, pero no a constantes ni a expresiones.</li><li>Se pueden presentar como prefijo o como sufijo.</li><li>Aplicados a variables enteras, su efecto es incrementar o decrementar el valor de la variable en una unidad.</li><li>++i es equivalente a i=i+1;</li><li>–i es equivalente a i=i-1;</li><li>Con ++a el valor de “a” se incrementa antes de evaluar la expresión.</li><li>Con a++ el valor de “a” se incrementa después de evaluar la expresión.</li></ul></li></ul><p><em>Relacionales</em></p><p>Los operadores relacionales hacen referencia a la relación entre unos valores y otros.</p><p><img src="https://gsitic.files.wordpress.com/2017/12/operadores_relacionales.png?w=825" alt=""></p><p><em>Lógicos</em></p><p>Los operadores lógicos hacen referencia a la forma en que las relaciones pueden conectarse entre sí.</p><p><img src="https://gsitic.files.wordpress.com/2017/12/operadores_logicos.png?w=825" alt=""></p><p><em>De Bits</em></p><p>Los operadores de bits son operadores binarios, excepto la negación que es unario. Se aplican a variables enteras, resultando otro entero aplicando operaciones lógicas correspondientes a los bits de los operandos. Al desplazar bits a la izquierda, suele rellenarse con 0 por la derecha y al desplazar a la derecha, se rellena por la izquierda con 0 si el dígito más significativo es 0, y con 1 si es 1. El tipo de variable es con signo.</p><p><img src="https://gsitic.files.wordpress.com/2017/12/operadores-de-bits.png?w=825" alt=""></p><p><strong>Expresiones y reglas de prioridad</strong></p><p>Una expresión se forma combinando constantes, variables, operadores y llamadas a funciones.</p><p>Una expresión representa un valor, el resultado de realizar las operaciones indicadas siguiendo las reglas de evaluación establecidas en el lenguaje.</p><p>Con expresiones se forman sentencias; con éstas, funciones, y con éstas últimas se construye un programa completo.</p><p>Cada expresión toma un valor que se determina tomando los valores de las variables y constantes implicadas y la ejecución de las operaciones indicadas.</p><p>Una expresión consta de operadores y operandos.</p><p>En la tabla de prioridades veremos operadores no estudiados, la línea de separación indica diferentes prioridades:</p><p><img src="https://gsitic.files.wordpress.com/2017/12/prioridad1.png?w=825" alt=""></p><p><img src="https://gsitic.files.wordpress.com/2017/12/prioridad2.png?w=825" alt=""></p><p><strong>Variables, constantes, conversión y ámbito de variables</strong></p><p>Todas las definiciones serán respecto al lenguaje C.</p><p><em>Variables</em></p><p><img src="https://gsitic.files.wordpress.com/2017/12/variables1.png?w=825" alt=""></p><p>No en todos los lenguajes hace falta declarar antes las variables, aunque siempre es recomendable.</p><p>Las variables, también conocidas como identificadores, deben cumplir las siguientes reglas:</p><p><img src="https://gsitic.files.wordpress.com/2017/12/variables2.png?w=825" alt=""></p><p><em>Constantes</em></p><p><img src="https://gsitic.files.wordpress.com/2017/12/constantes1.png?w=825" alt=""></p><p>Las constantes son entidades cuyo valor no se modifica durante la ejecución del programa.</p><p><img src="https://gsitic.files.wordpress.com/2017/12/constantes2.png?w=825" alt=""></p><p><em>Conversión</em></p><p><img src="https://gsitic.files.wordpress.com/2017/12/conversion1.png?w=825" alt=""></p><p>Este tipo de conversiones es temporal y la variable por convertir mantiene su valor.</p><p><img src="https://gsitic.files.wordpress.com/2017/12/conversion2.png?w=825" alt=""></p><p><em>Ámbito de variables</em></p><p><img src="https://gsitic.files.wordpress.com/2017/12/ambito.png?w=825" alt=""></p><p>Las variables pueden ser:</p><p><img src="https://gsitic.files.wordpress.com/2017/12/variables3.png?w=825" alt=""></p><p><strong>Estructura de un programa</strong></p><p>La estructura de un programa está compuesto de bibliotecas (#include), función principal (main), llaves ({}), y dentro de éstas, la declaración de variables y desarrollo del programa (conjunto de instrucciones).</p><h3 id="Control-de-flujo"><a href="#Control-de-flujo" class="headerlink" title="Control de flujo"></a>Control de flujo</h3><p>El teorema del programa estructurado, demostrado por Böhm-Jacopini, demuestra que todo programa puede escribirse utilizando únicamente las tres instrucciones de control siguientes:</p><p><img src="https://gsitic.files.wordpress.com/2017/12/control_flujo1.png?w=825" alt=""></p><p>Solamente con estas tres estructuras se pueden escribir cualquier tipo de programa.</p><p>La programación estructurada crea programas claros y fáciles de entender, además los bloques de código son auto explicativos, lo que facilita la documentación. No obstante, cabe destacar que en la medida que los programas aumentan en tamaño y complejidad, su mantenimiento también se va haciendo más difícil.</p><p><strong>Estructura secuencial</strong></p><p>El control de flujo se refiere al orden en que se ejecutan las sentencias del programa. A menos que se especifique expresamente, el flujo normal de control de todos los programas es secuencial.</p><p><img src="https://gsitic.files.wordpress.com/2017/12/estructura_secuencial.png?w=825" alt=""></p><p><strong>Estructura alternativa</strong></p><p><img src="https://gsitic.files.wordpress.com/2017/12/estructura_alternativa.png?w=825" alt=""></p><p>Las estructuras utilizadas son:</p><ul><li><strong>if-else</strong> . La cláusula else es opcional. Se pueden anidar varios if.</li><li><strong>switch.</strong> Realiza distintas operaciones con base en el valor de la única variable o expresión. El valor de la expresión se compara con cada uno de los literales de la sentencia, si coincide alguno, se ejecuta el código, si no se realiza la sentencia default (opcional), si no existe default no se ejecuta nada. La sentencia break realiza la salida de un bloque de código.</li></ul><p>Ejemplo:</p><p><img src="https://gsitic.files.wordpress.com/2017/12/switch_if_else.png?w=825" alt=""></p><p><strong>Estructuras repetitiva</strong></p><p><img src="https://gsitic.files.wordpress.com/2017/12/estructuras_repetitivas.png?w=825" alt=""></p><p><em>while</em></p><p><img src="https://gsitic.files.wordpress.com/2017/12/while1.png?w=825" alt=""></p><p><img src="https://gsitic.files.wordpress.com/2017/12/while2.png?w=825" alt=""></p><p><em>do-while</em></p><p><img src="https://gsitic.files.wordpress.com/2017/12/do-while.png?w=825" alt=""></p><p><em>for</em></p><p><img src="https://gsitic.files.wordpress.com/2017/12/for.png?w=825" alt=""></p><h3 id="Funciones"><a href="#Funciones" class="headerlink" title="Funciones"></a>Funciones</h3><p>En el ámbito de la programación, una función es el término para describir una secuencia de órdenes que hacen una tarea específica.</p><p>Características:</p><p><img src="https://gsitic.files.wordpress.com/2017/12/funciones1.png?w=825" alt=""></p><p>Las funciones son las que realizan las tareas principales de un programa. Las funciones realizan una tarea específica. Subdivide en varias tareas un programa, con pocas líneas y haciendo una tarea simple. Las funciones pueden o no devolver y recibir valores del programa.</p><p>Hay dos tipos de funciones:</p><ul><li>Funciones Internas. Funciones internas del lenguaje que realizan tareas específicas. Por ejemplo, hay funciones para el manejo de caracteres y cadenas, matemáticas, de conversión, …</li><li>Definidas por el el usuario. Primero hay que declarar el prototipo de la función, a continuación debemos hacer la llamada y por último desarrollar la función.</li></ul><p><img src="https://gsitic.files.wordpress.com/2017/12/funciones.png?w=825" alt=""></p><p><strong>Ámbito de las variables (locales y globales)</strong></p><p><img src="https://gsitic.files.wordpress.com/2017/12/ambito_variables.png?w=825" alt=""></p><p><strong>Recursividad</strong></p><p><img src="https://gsitic.files.wordpress.com/2017/12/recursividad.png?w=825" alt=""></p><p>La principal ventaja de las funciones recursivas es que se pueden usar para crear versiones de algoritmos más claros y sencillos. Cuando se escriben funciones recursivas, se debe tener una sentencia _if_ para forzar a la función a volver sin que se ejecute la llamada recursiva.</p><p>Las funciones recursivas pueden ahorrar la escritura de código, sin embargo, se deben usar con precaución, pues pueden generar un excesivo consumo de memoria.</p><h3 id="Tipos-de-datos-compuestos-estructuras"><a href="#Tipos-de-datos-compuestos-estructuras" class="headerlink" title="Tipos de datos compuestos (estructuras)"></a>Tipos de datos compuestos (estructuras)</h3><p>Un array es una colección de variables del mismo tipo que se referencian por un nombre en común. A un elemento específico de un array se accede mediante un índice. Todos los arrays constan de posiciones de memoria contiguas. La dirección más baja corresponde al primer elemento. Los arrays pueden tener una o varias dimensiones.</p><p>Una estructura es una colección de variables que se referencia bajo un único nombre, y a diferencia del array, puede combinar variables de tipos distintos.</p><p>Tanto los arrays como los registros son estructuras de datos que sirven para almacenar valores en memoria, la diferencia radica en que el array solo te permite almacenar un tipo específico de datos: entero, caracteres, fechas, … y los registros, como se ha indicado, admite diferentes tipos de datos.</p><p><strong>Arrays unidimensionales y bidimensionales</strong></p><p><img src="https://gsitic.files.wordpress.com/2017/12/arrays_unidimensionales.png?w=825" alt=""></p><p>La dirección más baja corresponde al primer elemento, y la más alta al último. Un array puede tener una o varias dimensiones. Para acceder a un elemento en particular de un array se usa un índice.</p><p><img src="https://gsitic.files.wordpress.com/2017/12/arrays_unidimensionales2.png?w=825" alt=""></p><ul><li>El formato para declarar un array unidimensional es:<ul><li>_tipo nombre_array[tamaño]_</li></ul></li><li>El formato para declarar un array bidimensional es :<ul><li>_tipo nombre_array[tamaño1][tamaño2]…[tamañoN]_</li></ul></li></ul><p>En la mayoría de los lenguajes los arrays usan el cero como índice para el primer elemento.</p><p><strong>Arrays multidimensionales</strong></p><p><img src="https://gsitic.files.wordpress.com/2017/12/array_multidimensional.png?w=825" alt=""></p><ul><li>El formato para declarar un array multidimensional es:<ul><li>_tipo nombre_array[fila][columna]_</li></ul></li></ul><p><strong>Estructuras</strong></p><p><img src="https://gsitic.files.wordpress.com/2017/12/estructura.png?w=825" alt=""></p><p>Una definición de estructura forma una plantilla que se puede usar para crear variables de estructura. Las variables que forman la estructura son llamados elementos estructurados.</p><h2 id="Bibliografia"><a href="#Bibliografia" class="headerlink" title="Bibliografía"></a>Bibliografía</h2><ul><li><a href="https://www.genbetadev.com/paradigmas-de-programacion/diferencias-entre-paradigmas-de-programacion" rel="external nofollow noopener noreferrer" target="_blank">genbetadev</a></li><li><a href="http://cursos.eie.ucr.ac.cr/claroline/backends/download.php?url=LzEgKEYuVywgUGFyYWRpZ21hcykvUGFyYWRpZ21hcyAxLnBkZg%3D%3D&amp;cidReset=true&amp;cidReq=IE0217_012" rel="external nofollow noopener noreferrer" target="_blank">Escuela de Ingeniería Eléctrica – UCR</a></li><li><a href="https://www.infor.uva.es/" rel="external nofollow noopener noreferrer" target="_blank">Departamento de Informática (Universidad de Valladolid)</a></li><li><a href="http://sisbib.unmsm.edu.pe/bibvirtual/publicaciones/indata/v04_n1/lenguajes.htm" rel="external nofollow noopener noreferrer" target="_blank">SISBIB (Sistema de bibliotecas)</a></li><li><a href="http://fcasua.contad.unam.mx/apuntes/interiores/docs/2016/informatica/2/apunte/apunte_1167.pdf" rel="external nofollow noopener noreferrer" target="_blank">Universidad Nacional Autónoma de México</a></li><li><a href="http://apuntedecaramelo.blogspot.com.es/p/oposiciones.html" rel="external nofollow noopener noreferrer" target="_blank">Apunte de Caramelo</a></li><li><a href="https://www.mhe.es/universidad/informatica/8448136640/archivos/apendice_general_2.pdf" rel="external nofollow noopener noreferrer" target="_blank">McGraw-Hill</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Caracteristicas-tecnicas-de-los-lenguajes-y-paradigmas-actuales-de-programacion&quot;&gt;&lt;a href=&quot;#Caracteristicas-tecnicas-de-los-lenguajes
      
    
    </summary>
    
      <category term="B2" scheme="http://localhost:4000/categories/B2/"/>
    
    
  </entry>
  
  <entry>
    <title>B4-T04</title>
    <link href="http://localhost:4000/wiki/B4/b4-t04/"/>
    <id>http://localhost:4000/wiki/B4/b4-t04/</id>
    <published>2019-01-16T15:11:23.000Z</published>
    <updated>2019-01-18T10:45:16.883Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Gestion-de-la-configuracion-Gestion-de-librerias-de-programas-y-de-medios-magneticos-Controles-de-cambios-y-de-versiones-Los-lenguajes-de-control-de-trabajos-Las-tecnicas-y-herramientas-de-operacion-automatica"><a href="#Gestion-de-la-configuracion-Gestion-de-librerias-de-programas-y-de-medios-magneticos-Controles-de-cambios-y-de-versiones-Los-lenguajes-de-control-de-trabajos-Las-tecnicas-y-herramientas-de-operacion-automatica" class="headerlink" title="Gestión de la configuración. Gestión de librerías de programas y de medios magnéticos. Controles de cambios y de versiones. Los lenguajes de control de trabajos. Las técnicas y herramientas de operación automática."></a>Gestión de la configuración. Gestión de librerías de programas y de medios magnéticos. Controles de cambios y de versiones. Los lenguajes de control de trabajos. Las técnicas y herramientas de operación automática.</h1><h2 id="Gestion-de-Librerias-de-Programas"><a href="#Gestion-de-Librerias-de-Programas" class="headerlink" title="Gestión de Librerías de Programas"></a>Gestión de Librerías de Programas</h2><p>Cuando hablamos de librerías nos referimos a conjuntos de programas, rutinas o funciones ya preparadas y a disposición de los programadores durante el desarrollo de aplicaciones. Su practicidad reside en que evitan la reescritura de algoritmos usados con frecuencia, ya que éstos pueden ser incluidos en librerías que posteriormente podrán ser llamadas desde los distintos programas a implementar.</p><h3 id="Gestion-de-Librerias-en-C"><a href="#Gestion-de-Librerias-en-C" class="headerlink" title="Gestión de Librerías en C"></a>Gestión de Librerías en C</h3><p>Propiedades de las librerías en C:</p><ul><li>Una librería es un archivo que agrupa a otros archivos denominados miembros de la librería.</li><li>La estructura de las librerías hace posible que puedan extraerse sus miembros.</li><li>Al agregar archivos a una librería, se introducirá en la misma tanto el contenido de aquellos como su información de gestión (fechas, propietarios, grupos, permisos, etc).</li></ul><p><strong>Librerías Estáticas y Dinámicas</strong></p><p><strong>Librerías Estáticas</strong></p><p>También denominadas librerías-objeto, son agrupaciones de archivos objeto (.obj) compilados en un solo archivo de extensión <strong>.OBJ</strong> o <strong>.LIB</strong> .</p><p>Los modelos de las funciones empleadas en estas librerías, junto con algunas constantes predefinidas y macros que facilitan su uso, constituyen los denominados archivos de cabecera, debido a que suelen ser llamados desde las primeras líneas (cabeceras) de los distintos archivos fuente.</p><p>Las librerías estáticas están constituidas por uno o varios archivos <strong>.lib</strong> , <strong>.obj</strong> o <strong>.bpi</strong> junto con uno o varios archivos de cabecera ( <strong>.h</strong> ). Al compilar un programa, el linkador agrega al ejecutable los módulos que incluyen a las funciones utilizadas en el programa, pasando aquellos a formar parte del ejecutable. Esta forma de enlazar las librerías con los programas es la que les da el nombre de estáticas.</p><p><strong>Librerías Dinámicas</strong></p><p>Las librerías de enlazado dinámico (DLL) son muy utilizadas en la programación para SO Windows; sistemas que incluyen multitud de librerías de este tipo en disposición de ser utilizadas por cualquier aplicación.</p><p>Aunque las librerías dinámicas se asocian generalmente a la extensión <strong>.DLL</strong> , también pueden estar definidas con extensiones del tipo <strong>.EXE</strong> , <strong>.BPI</strong> , <strong>.DRV</strong> , <strong>.FON</strong> , etc.</p><p>La programación de aplicaciones Windows consiste en la concatenación de llamadas a librerías dinámicas.</p><p><strong>Manejo de Librerías</strong></p><p>Para la programación en lenguaje C, el manejo de librerías presenta dos aspectos:</p><ul><li>La utilización de librerías.</li><li>La construcción de librerías.</li></ul><p>La utilización es segura para cualquier programa, ya que, como mínimo, habrá que hacer uso de alguna librería perteneciente a la Librería Estándar. En cuanto a la construcción, también podría darse en cualquier programa, pero dada la gran cantidad de librerías existentes, lo normal es que sólo se necesite crear una librería cuando el programa a desarrollar sea considerablemente extenso.</p><p>Evidentemente, tanto la utilización como la construcción de librerías serán diferentes dependiendo de si se trata de librerías estáticas o dinámicas.</p><h3 id="Librerias-de-Enlace-Dinamico-en-Windows"><a href="#Librerias-de-Enlace-Dinamico-en-Windows" class="headerlink" title="Librerías de Enlace Dinámico en Windows"></a>Librerías de Enlace Dinámico en Windows</h3><p>Como mencionábamos en un epígrafe anterior, las librerías dinámicas son archivos que contienen funciones y/o recursos que pueden ser requeridos por cualquier aplicación Windows. También indicábamos que podían tener tanto la extensión <strong>.DLL</strong> como extensiones del tipo <strong>.EXE</strong> (ejecutable), <strong>.DRV</strong> (controlador de dispositivo), <strong>.FON</strong> (fuente de Windows), etc. La diferencia entre las librerías cuyo archivo tiene extensión <strong>.DLL</strong> y las creadas sobre archivos <strong>.EXE</strong> , <strong>.DRV</strong> , <strong>.FON</strong> , etc, es que, mientras que las primeras se cargan porque son solicitadas por los programas al SO, el resto se cargan porque aparecen referenciadas (por el propio Windows o por un determinado programa) en archivos de inicialización de Windows.</p><p><strong>Ventajas e Inconvenientes del Empleo de DLL’s</strong></p><p>Ventajas:</p><ul><li>El contenido de una DLL puede ser usado por cualquier aplicación Windows.</li><li>La reutilización de las DLL’s implica una reducción en el tamaño de las aplicaciones.</li><li>Reducción del tiempo de compilación y/o carga de las aplicaciones, debido a la disminución del tamaño de las mismas.</li><li>Ahorro de espacio en disco.</li><li>Independencia de las DLL’s respecto de las aplicaciones.</li></ul><p>Inconvenientes:</p><ul><li>Tienen que almacenarse en la carpeta del sistema para poder ser utilizadas.</li><li>El tiempo que tarda la aplicación en acceder al código que necesita de la DLL es mayor del que emplearía si dicho código formara parte de la propia aplicación.</li></ul><p><strong>Estructura de una DLL de 32 Bits</strong></p><p>Podríamos dividir la DLL en los siguientes elementos:</p><ul><li>Archivo de cabecera. Conjunto de declaraciones y/o definiciones (de variables, funciones, procedimientos, etc) a usar por la librería.</li><li>Punto de entrada y salida de la DLL (DllEntryPoint). Función que se ocupa de la carga y descarga de la DLL en la memoria principal.</li><li>Funciones de la DLL. Aquellas especificadas e implementadas por el programador de la librería.</li></ul><p><strong>Creación de una DLL de 32 Bits</strong></p><p>Para la creación de una DLL podemos usar lenguajes del tipo Visual Basic, Delphi, Visual C++, etc.</p><p>Con cualquiera de los lenguajes deberemos crear varios archivos, cada uno de los cuales contendrá un tipo de elemento útil para la construcción de la librería. Por ejemplo, si empleásemos Visual C++, deberíamos crear:</p><ul><li>Un archivo con extensión .c que contendrá el código fuente de las funciones de la librería.</li><li>Un archivo con extensión .def que contendrá la información necesaria para el linkador.</li><li>Dos archivos con extensión .h que será los archivos de cabecera del archivo fuente (estos sólo serán necesarios para crear un programa que utilice la DLL, pero no para la creación de la DLL en sí).</li></ul><p><strong>Compilación y Linkado de la Librería</strong></p><p>Tras la compilación de los archivos anteriores, el compilador generará un archivo <strong>.lib</strong> . Después del linkado, se creará un archivo <strong>.dll</strong> (esta sería la librería en sí).</p><p>El acceso a esta DLL podrá hacerse mediante dos tipos de llamadas:</p><p><strong>Llamada Estática</strong></p><p>Este tipo de llamada va a utilizar el archivo creado por el compilador ( <strong>.lib</strong> ).</p><p>Con este método, el enlace entre el programa y los recursos de la DLL tiene lugar durante el linkado del programa. Es decir, será el linkador quien, utilizando los archivos objeto ( <strong>.obj</strong> ), los archivos librerías ( <strong>.lib</strong> ) y los archivos de recursos compilados (.res), cree la aplicación Windows ( <strong>.exe</strong> ).</p><p>Con este proceso, el código de la librería queda incluido en el ejecutable.</p><p>Ventajas:</p><ul><li>La librería se carga junto con el ejecutable (la contiene).</li><li>El enlace tiene lugar en tiempo de compilación.</li><li>Las funciones de la librería pueden ser utilizadas como funciones internas de la aplicación.</li></ul><p>Inconvenientes:</p><ul><li>La aplicación almacena en su interior el código de la librería, lo que hace que su tamaño sea mayor.</li><li>La librería tiene que incluirse en cada aplicación que la necesite.</li><li>El objetivo de la reutilización sólo se cumple en parte.</li><li>La memoria principal contiene a la librería durante todo el tiempo de ejecución de la aplicación.</li><li>La librería y la aplicación tienen una dependencia total.</li></ul><p><strong>Llamada Dinámica</strong></p><p>La llamada dinámica emplea el archivo creado por el linkador ( <strong>.dll</strong> ).</p><p>El enlace dinámico, como su nombre indica, se producirá en tiempo de ejecución; es decir, la librería se cargará en memoria cuando la aplicación la requiera al sistema. Este proceso utilizará las funciones LoadLibrary y FreeLibrary para la carga y descarga, respectivamente, de la dll en la memoria principal.</p><p>Ventajas:</p><ul><li>La aplicación no almacena junto con su código a la librería, lo que reduce el tamaño de la aplicación (la librería se almacena en un archivo aparte).</li><li>Ninguna aplicación que utilice a la librería deberá incluirla en su código.</li><li>Se utilizan los beneficios de la reutilización en su totalidad.</li><li>La librería sólo se carga en la memoria principal cuando va a utilizarse. Cuando deja de utilizarse podrá descargarse de la memoria.</li><li>La librería y la aplicación son independientes.</li></ul><p>Inconvenientes:</p><ul><li>Necesidad de solicitar al SO la carga de la librería.</li><li>El enlace se produce en tiempo de ejecución, hecho que dificulta la manipulación de la librería.</li><li>Las funciones de la librería deben ser llamadas mediante punteros.</li></ul><h2 id="Gestion-de-Medios-Magneticos"><a href="#Gestion-de-Medios-Magneticos" class="headerlink" title="Gestión de Medios Magnéticos"></a>Gestión de Medios Magnéticos</h2><h3 id="Discos-Magneticos"><a href="#Discos-Magneticos" class="headerlink" title="Discos Magnéticos"></a>Discos Magnéticos</h3><p><strong>Propiedades de los Discos Magnéticos</strong></p><p>Un disco magnético (rígido o flexible) consiste en un soporte de almacenamiento externo que complementa a la memoria principal (RAM) de una computadora.</p><p>Sus propiedades más significativas son:</p><ul><li>Capacidad de almacenamiento masivo de información en un espacio muy reducido, con el consiguiente bajo coste relativo por byte almacenado. El cliente realiza una llamada a un servicio como si fuera local.</li><li>El memoria no volátil, ya que mantiene la información almacenada aún a falta de suministro eléctrico.</li><li>Proporciona acceso casi directo al lugar donde se encuentra el bloque de datos a leer o escribir.</li><li>La información almacenada en un disco se agrupa en archivos o ficheros (files) identificables por su nombre.</li></ul><p>Actualmente, la mayoría de procesos de E/S de datos utilizan en su origen o destino los discos magnéticos:</p><ul><li>La inmensa mayoría de las aplicaciones se encuentran almacenadas en disco (en forma de archivos ‘ejecutables’). Cuando van a utilizarse estas aplicaciones, se copian (en parte) en la memoria principal y son ejecutadas desde ésta.</li><li>Después de procesar los datos que se encuentran en la memoria principal, los resultados de este proceso se almacenarán en disco.</li></ul><p>Por último, otra característica a indicar sobre los discos magnéticos (los ‘discos duros’ en este caso), es que se pueden utilizar como memoria virtual; es decir, como una extensión de la memoria principal del ordenador.</p><p><strong>Estructura Física de los Discos Magnéticos</strong></p><p>Físicamente, los discos magnéticos están fabricados con: mylard en el caso de los discos flexibles y aluminio o cristal cerámico en el caso de los discos rígidos.</p><p>La estructura física de un disco la forman unas superficies magnéticas denominadas <strong>caras</strong> , cada una de las cuales se divide en anillos concéntricos que constituyen las <strong>pistas</strong> , que a su vez agrupan a los <strong>sectores</strong> (unidades mínimas de almacenamiento cuya capacidad habitual suele ser de 512 bytes de información).</p><p>El proceso de grabación de los discos se logra, al igual que en un grabador de audio, por la acción de un campo magnético de polaridad reversible (N-S ó S-N), que imanta la pista al actuar sobre ella. Para este proceso, existe una cabeza para cada cara del disco. Los brazos que soportan a las cabezas se mueven juntos; es decir, que si la cabeza de la cara superior está sobre una determinada pista, la de la cara inferior se encontrará situada en la misma pista.</p><p>La lectura la realizan las mismas cabezas, mediante un proceso inverso al de grabación, a través del cual detectarán los campos magnéticos existentes a lo largo de la pista accedida.</p><p>En el proceso, tanto de grabación como de lectura, sólo podrá encontrarse activa una única cabeza de las existentes en el medio magnético (dos en los discos flexibles y múltiples en los rígidos).</p><p>En las propiedades indicadas en el epígrafe anterior se hacía referencia al acceso casi directo de los discos magnéticos. Conociendo ya la estructura física de estos discos podemos indicar que lo de directo se refiere a la forma de acceso a las pistas y lo de casi hace referencia a la forma de acceso a los sectores una vez situados en la pista correspondiente (este último es un acceso secuencial cuyo tiempo es tan reducido que se considera despreciable). Para esta operación de localización de un sector concreto dentro del disco se emplea lo que se conoce como su dirección o CHS (número de cilindro, número de cabeza, y número de sector).</p><p><strong>Importancia del concepto de cilindro</strong></p><p>El hecho de que un disco rígido sea en realidad una agrupación de discos (o platos) cada uno de los cuales dispone de dos caras, además de duplicar la capacidad de almacenamiento, permite la lectura o escritura del doble de datos antes de desplazar el cabezal a otra pista, accediendo a una cara y luego a la contraria. De esto surge el concepto de cilindro que no es más que el conjunto de pistas que se sitúan bajo las cabezas de lectura/escritura en un momento determinado (o conjunto de pistas de un disco que tienen el mismo radio). Este concepto también es aplicable a los discos flexibles, aunque, al disponer estos de dos caras únicamente, se suele asociar a los discos rígidos porque en estos el concepto de cilindro es gráficamente más evidente.</p><p>De lo anterior se deduce que la mejor forma de graba la información sobre los discos magnéticos es cilindro a cilindro acelerando con ello el proceso de escritura/lectura al minimiza los movimientos de los cabezales en búsqueda de las pistas.</p><p>El número de cilindros de un disco, por tanto, se corresponderá con el número de posiciones en las que pueden situarse los cabezales; enumerándose aquellos desde 0 (el más exterior) en forma creciente hacia el interior, correspondiendo el número mayor al más interno.</p><p><img src="https://gsitic.files.wordpress.com/2018/02/cilindros_hd.png?w=825" alt=""></p><p><strong>Posicionamiento, Latencia y Acceso en un Disco Rígido o Flexible</strong></p><p>El acceso a un sector situado en una determinada cara del disco, pasa por posicionar el cabezal sobre el cilindro donde se encuentra la pista que contiene el sector, y, posteriormente, esperar a que, mediante el giro del disco, el sector deseado se sitúe debajo de la cabeza. En esta operación intervienen dos tiempos:</p><ul><li><strong>Posicionamiento</strong> . Tiempo necesario para que el brazo con la cabeza correspondiente se coloque directamente sobre el cilindro seleccionado (pocos milisegundos).</li><li><strong>Latencia (demora rotacional)</strong> . Tiempo necesario para que el sector a localizar se sitúe bajo la cabeza lectora/escritora (en promedio es el tiempo de media vuelta).</li></ul><p>El tiempo de acceso resulta pues, la suma de los anteriores, o lo que sería igual, el tiempo que transcurre desde que la controladora envía la orden al cabezal de posicionarse sobre un cilindro, hasta que la cabeza correspondiente accede al sector buscado.</p><p><img src="https://gsitic.files.wordpress.com/2018/02/tiempo_acceso.png?w=825" alt=""></p><p><strong>Estructura Lógica de los Discos Magnéticos</strong></p><p>Desde el punto de vista de la estructura lógica de un disco duro, podríamos dividirlo en:</p><ul><li><strong>Sector de arranque (Master Boot Record)</strong> . Es el primer sector del disco (0, 0, 0), y en él se encuentra la tabla de particiones y un pequeño programa de inicialización. Este programa se ejecuta al encender la computadora, y su función es leer la tabla de particiones y ceder el control a la partición primaria activa.</li><li><strong>Espacio particionado</strong> . Zona del disco que contiene las particiones. Una partición es cada una de las divisiones de tamaño fijo de un disco que se asocia a una unidad lógica (C:, D:, etc, en el caso de los SO Windows). Cada partición ocupa un bloque de cilindros contiguos del disco duro, pudiendo establecerse distintos sistemas de archivos (FAT, NTFS, …) para las distintas particiones posibles.</li><li><strong>Espacio NO particionado.</strong> Se trata de la zona de disco que no ha sido particionada y que, por lo tanto, no puede ser utilizada.</li></ul><p>La tabla de particiones del disco duro puede contener hasta 4 entradas, lo que determina el número máximo de particiones primarias que se pueden crear en el disco. No obstante, este límite de particiones puede superarse empleando una de las entradas para almacenar una partición extendida (tendríamos 3 primarias y 1 extendida). La partición extendida podrá contener tantas unidades lógicas como necesitemos.</p><p>La principal diferencia entre las particiones primarias y las extendidas es que, mientras que las primeras son arrancables y pueden ser utilizadas para contener a los SO, las extendidas no son arrancables y se utilizan normalmente para almacenar datos. Además, de entre las distintas particiones primarias, habrá que indicar cuál es la activa, es decir, la verdaderamente arrancable.</p><p>Visto lo anterior, lo primero que hay que hacer con un disco duro antes de su utilización es:</p><ul><li><strong>Crear las particiones</strong> (utilizando herramientas del tipo FDISK).</li><li><strong>Formatear las particiones creadas</strong> . Este proceso consiste en la creación de la estructura que permita el almacenamiento de información utilizando un determinado sistema de archivos.</li></ul><p>En el sistema de archivos FAT (MS-DOS y sistemas Windows), la estructura lógica de una partición la forman: el sector de arranque, varias copias de la tabla de asignación de archivos, el directorio raíz y el área de datos. La FAT (tabla de asignación de archivos) es el índice del disco. En ella se indican los clusters (unidades de asignación) que utiliza cada archivo, así como los libres y los defectuosos.</p><p>La estructura lógica de una partición utilizada por un sistema UNIX tradicional está constituida: un bloque de arranque, un superbloque (contiene el número de inodos, el número de bloques, etc), un vector de inodos (similar a la FAT anterior) y los bloques de datos.</p><p><strong>Herramientas para la Gestión de Discos Magnéticos</strong></p><p>Considerando como herramientas de gestión las expuestas en el punto anterior (herramientas de particionado y formateo), en este punto vamos a centrarnos en otras herramientas no tan esenciales como aquellas, pero sí bastante comunes en la gestión de discos magnéticos:</p><ul><li><strong>Comprobador de errores</strong> . Su misión es analizar el contenido del disco en búsqueda de incoherencias en el sistema de archivos. Si, por ejemplo, en un sistema FAT existen dos archivos que apuntan al mismo contenido aparecerá un error de vínculos cruzados o si aparecen datos no asociados a ningún archivo se indicará el error de cadenas perdidas. Comprobadores de errores usuales son: chkdsk /f en MS-DOS, ScanDisk en Windows y fsck en UNIX.</li><li><strong>Desfragmentador de disco</strong> . Esta herramienta busca la agrupación física (sobre el disco) de toda la información concerniente a un mismo archivo, con el fin de acelerar la lectura de datos. La fragmentación se produce por la creación, modificación y eliminación de archivos. El sistema de archivos de UNIX no precisa de desfragmentador debido a que su velocidad de trabajo no se degrada con la creación, modificación y eliminación de archivos.</li><li><strong>Compresor de datos</strong> . Se trata de un método que busca maximizar la capacidad de las particiones mediante la compresión de la información que contienen. No obstante, esta metodología ralentiza el funcionamiento general del SO, debido a que deben ejecutarse continuamente algoritmos de compresión/descompresión. Además, tiene como inconveniente la dependencia de la información del programa de compresión, circunstancia que podría provocar problemas de incompatibilidad d futuros en caso de producirse errores.</li></ul><p>Normalmente, resulta más eficaz la compresión de ficheros de forma independiente (en lugar de particiones completas).</p><p>Los SO actuales incorporan sus propios métodos de compresión/descompresión (en UNIX: gzip -&gt; para archivos independientes, tar -&gt; para árboles de archivos). Además, existen herramientas ajenas a los SO para realizar estas operaciones (WinZip, WinRAR, IsoBuster, …)</p><ul><li><strong>Copias de seguridad</strong> . La realización de copias de seguridad del contenido del disco en otro medio de almacenamiento, es un método para garantizar la recuperación de datos destruidos por errores humanos, de situaciones imprevistas o de hardware.</li></ul><p><strong>Sistemas RAID (Redundant Array Of Independent Or Inexpensive Disks)</strong></p><p>Los sistemas de matriz de discos independientes (baratos) redundantes son utilizados para el control de errores en los discos. Emplean varios discos para evitar (o minimizar) la pérdida de información en caso de que se produzca algún error. La redundancia hace referencia a la información extra que no sería necesaria si no se produjesen errores.</p><p>La gestión de los sistemas RAID no es accesible por el usuario, pudiendo ser gestionada por hardware (tarjetas RAID) o por software (SO). como suele ocurrir, el método más eficiente (pero más costoso económicamente) es el que utiliza tarjetas hardware, debido a que desocupa a la CPU de las tareas RAID.</p><p>A continuación se enumeran los niveles RAID más habituales:</p><ul><li><strong>RAID 0</strong> (disk striping, discos en bandas). En este nivel, la información se distribuye entre todos los discos que forman el conjunto RAID, proporcionando una mayor velocidad en las transferencias debido al trabajo conjunto de todos los discos para acceder a un mismo archivo. No obstante, si falla alguno de los discos perderemos toda la información. La implementación de RAID 0 precisa de 2 discos como mínimo.</li><li><strong>RAID 1</strong> (disk mirroring, discos en espejo). Basado en el empleo de discos para duplicar la información. Con este método, cada vez que se escriba en un disco, deberá grabarse la información de su disco copia para mantener la coherencia. A diferencia del método anterior, si en éste falla un disco, el sistema podrá continuar funcionando sin detenerse. Es habitual implementar RAID 1 con 2 discos. Este sistema permite una capacidad de almacenamiento igual a la mitad de la capacidad total de los discos de que disponemos. Pueden combinarse RAID 0 y RAID 1 para formar el sistema RAID 10. Con RAID 10, la información se distribuye en bandas por varios discos y cada disco se duplica, lo que requiere un número par de discos (4, 6, 8, …).</li><li><strong>RAID 2</strong> . Ofrece detección y corrección de errores en los discos mediante la utilización de códigos de Hamming. Este nivel está incluido en la actualidad en los propios discos, por lo que ha dejado de ser un sistema a elegir por el usuario.</li><li><strong>RAID 3</strong> . Emplea un disco para almacenar la paridad. La información se distribuye a nivel de bits entre los distintos discos. Si un disco falla, la información se reconstruiría mediante la operación O-exclusiva (XOR) de los discos restantes. Son necesarios un mínimo de 3 discos para implementar un RAID 3. Todos los discos funcionan a la vez, lo que hace bajar el rendimiento con sistemas transaccionales (múltiples accesos sobre pequeñas cantidades de datos).</li><li><strong>RAID 4</strong> . Utiliza un disco para el almacenamiento de la paridad, al igual que el anterior; si embargo, los datos se distribuyen a nivel de bloque (en lugar de a nivel de bits) y se puede acceder a cada disco de forma individual. Este hecho mejora el rendimiento en sistemas transaccionales.</li><li><strong>RAID 5</strong> . La paridad se almacena entre todos los discos, eliminando el excesivo uso del disco de paridad que hacían los dos niveles anteriores. Este método es el más eficiente, ofreciendo la mayor tasa rendimiento/coste y el menos coste por megabyte de información. Se necesitan al menos 3 discos para su desarrollo; no obstante, el funcionamiento óptimo se alcanza a partir de los 7 discos.</li></ul><p>Los últimos tres niveles se denominan de discos en bandas con paridad (disk striping with parity), y en ellos, podremos calcular la capacidad máxima de información que pueden almacenar sumando la capacidad de todos los discos y restándoles la capacidad de uno (redundancia).</p><h3 id="Otros-Medios-Magneticos"><a href="#Otros-Medios-Magneticos" class="headerlink" title="Otros Medios Magnéticos"></a>Otros Medios Magnéticos</h3><p><strong>ZIP</strong></p><p>Tienen un tamaño similar a los floppys de 3,5″, lo que los hace fácilmente portables. Sus capacidades habituales son 100 y 250 Mb, aunque actualmente existen de 750 Mb.</p><p><strong>JAZZ</strong></p><p>Son discos similares a los anteriores (son compatibles) pero con capacidades de 1 y 2 Gb.</p><p><strong>Tecnología Magneto-Óptica</strong></p><p><strong>LS-120 Superdisk</strong></p><p>La tecnología Láser Servo fue desarrollada en 1996. Se trata de una tecnología mixta (magnética y óptica) compatible con la de los floppys tradicionales; es decir, un lector/grabador de este tipo puede leer y escribir sus propios discos de 120 Mb y los floppys convencionales de 1,44 Mb.</p><p>Este sistema es producto de una mezcla de tecnologías de los floppys, discos duros y CD-ROM’s.</p><p>Combina una medio magnético con un método óptico utilizado para el posicionamiento de las cabezas de lectura/escritura, lo que conduce a un aumento considerable de la capacidad del medio respecto de los floppys, y a lograr velocidades de transferencia de hasta 400 kb/s (la mitad de veloces que los ZIP).</p><p><strong>Discos Magneto Ópticos (MO)</strong></p><p>Emplean, para la grabación del medio, un láser que calienta la superficie del disco (302º F). Existen dos variantes de funcionamiento de esta tecnología:</p><ul><li>El calor provoca la oxidación del metal del medio, lo que permite la orientación de su magnetismo mediante un imán (es la técnica más empleada).</li><li>El calor cambia la estructura del medio, provocando que sea cristalino o amorfo.</li></ul><p>Existen discos de 5,25″ (650 Mb, 1.3 Gb, 2.6 Gb y 4.6 Gb) y de 3,5″ (128, 230 y 640 Mb).</p><p><strong>Cintas Magnéticas</strong></p><p>Ofrecen una gran capacidad de información junto con velocidades de transferencia muy bajas; motivo por el cual son empleadas casi exclusivamente para realizar copias de seguridad. Suponen un coste ínfimo por Mb.</p><p><img src="https://gsitic.files.wordpress.com/2018/02/cintas_magneticas.png?w=825" alt=""></p><h3 id="Copias-de-Seguridad-BACKUP"><a href="#Copias-de-Seguridad-BACKUP" class="headerlink" title="Copias de Seguridad (BACKUP)"></a>Copias de Seguridad (BACKUP)</h3><p>Las copias de seguridad o backups pueden definirse como copias de la información realizadas usando un medio de almacenamiento secundario, cuyo objetivo es salvaguardar la información ante posibles errores humanos, de hardware, etc.</p><p><strong>Pérdida de información</strong></p><p>Las pérdidas de datos pueden provenir de las circunstancias más variadas:</p><ul><li>Fallo del disco duro.</li><li>Error humano (eliminación no deseada).</li><li>Interrupción de una aplicación por fallo durante la grabación de la información en el disco.</li><li>Acción de un virus o troyano.</li><li>Accidente inevitable en el entorno del sistema informático (incendio, inundación, etc).</li></ul><p><strong>Frecuencia de Backups</strong></p><p>La frecuencia de ejecución de backups dependerá tanto de la frecuencia de actualización de la información del sistema como de la información que el administrador del mismo esté dispuesto a perder.</p><p>En sistemas relativamente importantes los backups son diarios.</p><p><strong>Medios empleados para las Backups</strong></p><p>Las copias de seguridad pueden hacerse, entre otros medios, sobre:</p><ul><li>Una partición dentro del mismo disco duro que contiene la información a proteger (mínima protección).</li><li>Un disco duro auxiliar, dentro del mismo equipo donde se encuentra el disco duro con la información a proteger.</li><li>Un disco duro en un equipo distinto al que contiene la información a proteger (backup por red).</li><li>Un CD-R, CD-RW, DVD-RW, DVD+RW, etc.</li><li>Una cinta magnética (tape backup).</li><li>Floppys, ZIP’s, JAZZ’s, etc. (para copias de pequeñas cantidades de información).</li></ul><p><strong>Tipos de Backups</strong></p><ul><li>Completa. Copia de toda la información a salvaguardar.</li><li>Progresiva o Incremental. Copia de la información nueva o modificada desde el último backup completo o progresivo (se necesitaría la última copia completa y todas las copias incrementales para restaurar la información).</li><li>Diferencial. Copia de la información nueva o modificada desde la última copia completa (la recuperación de los datos precisa de la última copia completa y la última diferencial).</li></ul><h2 id="Controles-de-Cambio"><a href="#Controles-de-Cambio" class="headerlink" title="Controles de Cambio"></a>Controles de Cambio</h2><h3 id="Controlar-el-Proyecto-y-Eliminar-los-Retrasos"><a href="#Controlar-el-Proyecto-y-Eliminar-los-Retrasos" class="headerlink" title="Controlar el Proyecto y Eliminar los Retrasos"></a>Controlar el Proyecto y Eliminar los Retrasos</h3><p>Los cambios son un pilar básico dentro de la vida del desarrollo de software. En la práctica, el trabajo requiere de una administración formal de los cambios. Si contamos con una administración de cambios del software realmente efectiva podremos conseguir que:</p><ul><li>Los equipos de desarrollo puedan entregar el software dentro del tiempo y presupuesto establecidos y con una calidad predecible.</li><li>Los líderes de proyecto conozcan en todo momento el estado y avance del desarrollo del software y tengan certeza del mismo dentro del tiempo prefijado.</li><li>Los desarrolladores utilicen y controlen con orden y seguridad sus colecciones de archivos y componentes diferentes para cada aplicación.</li><li>Los ‘probadores’ sepan cuándo una nueva construcción de software requiere ser sometida a un paquete de pruebas y las mejoras o correcciones que debe presentar.</li></ul><p>Las organizaciones de desarrollo exitosas consideran que el control de cambios durante todo el ciclo es la clave para asignar prioridades a las actividades del equipo, así como para controlar las dificultades que surjan durante el desarrollo. Si no implementamos dicho control, el caos de los cambios se apoderará del control del proyecto.</p><p>La Administración de la Configuración y Control de Cambios (SCM) es la disciplina de la ingeniería de software que agrupa las herramientas y técnicas de uso de las mismas que una compañía emplea para administrar los cambios de los componentes de software. Cuando la SCM se encuentra integrada en otras actividades del desarrollo (requerimientos, análisis y diseño, construcción, pruebas), se denomina Gestión de Cambio Unificada (UCM).</p><p>Existen guías que describen cómo controlar, dar seguimiento y monitorear los cambios para permitir un desarrollo iterativo exitoso; así como la forma de establecer espacios de trabajo seguros para cada desarrollador, aislándolo de los cambios realizados en otros espacios de trabajo y controlando los cambios de todos los artefactos de software (modelos, código, documentos, etc) Para llevar a cabo estas metodologías, se utilizan herramientas de ‘control de versiones y configuraciones’ y de ‘control de cambios’ que, por un lado, automatizan las metodologías, y por otro unen al equipo de desarrollo para conseguir un trabajo paralelo y coordinado. Estas herramientas permiten a cada desarrollador contar con un espacio de trabajo seguro donde puede realizar los cambios de manera independiente para que una vez probados puedan integrarse con el resto del desarrollo, garantizando de esta forma la calidad, el tiempo de entrega y la satisfacción del cliente con el producto desarrollado.</p><h3 id="Gestion-de-Cambios"><a href="#Gestion-de-Cambios" class="headerlink" title="Gestión de Cambios"></a>Gestión de Cambios</h3><p>Podemos distinguir dos enfoques diferentes dentro de la gestión de cambios, dependiendo del mayor o menor grado de modificación del producto.</p><p>Si el cambio a realizar afecta a gran parte de los componentes del producto, podrá plantearse como un nuevo desarrollo, y aplicar un nuevo ciclo de vida desde el principio, aunque aprovechando lo ya desarrollado de la misma forma que se reutilizan los prototipos.</p><p>Si el cambio afecta a una parte bastante localizada del producto, entonces se puede organizar como simple modificación de elementos. Hay que tener en cuenta que cualquier cambio en el código del producto software siempre implicará una revisión de los elementos de documentación afectados; es decir, cambiar el código de algunos módulos puede requerir, además, modificar los documentos de diseño o incluso, en el caso de mantenimiento perfectivo, modificar el documento de especificación de requisitos.</p><p>Tomando como referencia la gestión, la realización de cambios se puede controlar mediante dos clases de documentos, que en ocasiones pueden unirse para forma un único informe:</p><ul><li>Informe de problema: describe una dificultar en la utilización del software que precisa de alguna modificación para subsanarla.</li><li>Informe de cambio: describe la solución dada a un problema y el cambio realizado en el producto software.</li></ul><p>El primer documento puede ser originado por los propios usuarios. Este informe se pasa a un grupo de ingeniería para la comprobación y codificación del problema planteado, y posteriormente a un grupo de gestión para decidir la solución a adoptar. Este grupo de gestión da comienzo al informe de cambio, que se pasa de nuevo al grupo de ingeniería para su total desarrollo y ejecución.</p><h3 id="Comprobacion-de-los-Objetivos-del-Control-de-Cambios"><a href="#Comprobacion-de-los-Objetivos-del-Control-de-Cambios" class="headerlink" title="Comprobación de los Objetivos del Control de Cambios"></a>Comprobación de los Objetivos del Control de Cambios</h3><p>Los objetivos del control de cambios son comprobados al realizar entrevistas con:</p><ul><li>El Director de Tecnologías de Información.</li><li>La Administración de la Función de Servicios de Información.</li><li>La Administración de Desarrollo de Sistemas, Aseguramiento de la Calidad de Control de Cambios, Operaciones y Seguridad.</li><li>La Administración de Usuarios implicada en el diseño y manejo de aplicaciones de sistemas de información.</li></ul><p>De las que se obtienen:</p><ul><li>Procedimientos organizacionales relacionados con la planificación de sistemas de información, el control de cambios, la seguridad y el ciclo de vida de desarrollo de sistemas.</li><li>Procedimientos de la función de servicios de sistemas de información relacionados con la metodología del ciclo de vida de desarrollo de sistemas, el aseguramiento independiente de la calidad, los estándares de seguridad, la implementación, la distribución, el mantenimiento, la liberación del software, los cambios de emergencia y el control de versiones del sistema.</li><li>Un plan de desarrollo de aplicaciones.</li><li>Formato y bitácora de requisitos de control de cambios.</li><li>Contratos con proveedores relacionados con servicios de desarrollo de aplicaciones.</li></ul><h3 id="Evaluacion-de-los-Controles"><a href="#Evaluacion-de-los-Controles" class="headerlink" title="Evaluación de los Controles"></a>Evaluación de los Controles</h3><p>La evaluación de los controles de cambios deberá tener en cuenta si:</p><ul><li>La bitácora de control de cambios garantiza que cualquiera de los cambios mostrados han sido resueltos.</li><li>El control de cambios es un procedimiento formal tanto para los grupos de desarrollo como para los usuarios.</li><li>El usuario está conforme con el resultado de los cambios solicitados, el tiempo de realización de los mismos y los costes.</li><li>Para una muestra de cambios en la bitácora de control de cambios:<ul><li>la documentación actual refleja con exactitud el ambiente modificado,</li><li>los cambios hayan sido efectuados tal y como fueron documentados,</li><li>el cambio implicó modificaciones en los programas y operaciones.</li></ul></li><li>El proceso de cambios es controlado respecto de las mejoras en el conocimiento, la efectividad en el tiempo de respuesta y la satisfacción del usuario con el resultado del proceso.</li><li>El mantenimiento del sistema de Intercambio de Rama Privada (PBX) se incluye en los procedimientos de control de cambios.</li></ul><h3 id="Evaluacion-de-la-Suficiencia"><a href="#Evaluacion-de-la-Suficiencia" class="headerlink" title="Evaluación de la Suficiencia"></a>Evaluación de la Suficiencia</h3><p>La comprobación de la suficiencia del control se realizará probando que:</p><ul><li>Para una selección de cambios, la administración ha aprobado los siguientes puntos:<ul><li>petición del cambio,</li><li>descripción del cambio,</li><li>acceso al programa fuente,</li><li>terminación del cambio por parte del programador,</li><li>solicitud para trasladar el programa fuente al entorno de prueba,</li><li>finalización de las pruebas de aceptación,</li><li>solicitud de compilación y traslado al grupo de producción,</li><li>identificación y aceptación del impacto general y específico,</li><li>elaboración de un proceso de distribución,</li></ul></li></ul><p>y revisando el control de cambios en cuanto a la inclusión de:</p><ul><li>fecha del cambio solicitado,</li><li>persona o grupo que lo solicita,</li><li>petición aprobada de cambios,</li><li>aprobación del cambio efectuado (servicios de información),</li><li>aprobación del cambio efectuado (usuarios),</li><li>fecha de actualización de la documentación,</li><li>fecha del traslado al grupo de producción,</li><li>aprobación del cambio por parte del grupo de aseguramiento de la calidad,</li><li>aceptación por parte del grupo de operaciones.</li></ul><p>También se tendrán en cuenta, a la hora de evaluar esta suficiencia:</p><ul><li>Los tipos de análisis de cambios realizados sobre el sistema para la determinación de tendencias.</li><li>La valoración de la adecuación de las librerías de la función de servicios de información y la identificación de la existencia de niveles de código base para advertir y prevenir la ocurrencia de errores.</li><li>Si existen procedimientos de E/S (“check in/check out”) para cambios.</li><li>Si la totalidad de los cambios en la bitácora fueron resueltos con la conformidad de los usuarios y si no se llevaron a cabo cambios que no hayan sido anteriormente especificados en la bitácora.</li><li>Si los usuarios tienen conocimiento de la necesidad de procedimientos formales de control de cambios.</li><li>El proceso de reforzamiento del personal garantiza el cumplimiento de cada uno de los procedimientos de control de cambios.</li></ul><h3 id="Evaluacion-del-Riesgo-de-los-Objetivos-de-Control-NO-Alcanzados"><a href="#Evaluacion-del-Riesgo-de-los-Objetivos-de-Control-NO-Alcanzados" class="headerlink" title="Evaluación del Riesgo de los Objetivos de Control NO Alcanzados"></a>Evaluación del Riesgo de los Objetivos de Control NO Alcanzados</h3><p>Esta evaluación se realizará llevando a cabo mediciones (“benchmarking”) de la administración del control de cambios contra organizaciones similares o estándares internacionales de buenas prácticas reconocidas en la industria correspondiente.</p><p>Para sistemas seleccionados de la función de servicios de información, se ejecutará:</p><ul><li>Una verificación para comprobar si la documentación determina el requerimiento o si el cambio del sistema ha sido aprobado y priorizado por parte de la administración de las áreas usuarias afectadas y el proveedor de servicios.</li><li>La confirmación de la existencia y adecuación de evaluación del impacto en formas de control de cambios.</li><li>La obtención del conocimiento del cambio mediante una comunicación de la función de servicios de información.</li><li>La asignación del cambio a los correspondientes recursos de desarrollo.</li><li>La adecuación de los sistemas y los planes de prueba de los usuarios.</li><li>La migración formal de prueba a producción a través del grupo de aseguramiento de la calidad.</li><li>La puesta al día de los manuales de usuario y de operación para mostrar el cambio efectuado.</li><li>El reparto de la nueva versión a los usuarios correspondientes.</li></ul><p>Además, la evaluación de este riesgo concluirá determinando, para una selección de cambios de información, que:</p><ul><li>Sólo se efectuaron cambios que hayan sido aprobados por la función de servicios de información.</li><li>Todos los cambios han sido tenidos en cuenta.</li><li>Las librerías actuales (fuente y objeto) muestran los últimos cambios llevados a cabo.</li><li>Las modificaciones en el procedimiento de control de cambios de:<ul><li>aplicaciones internas y adquiridas,</li><li>software de sistemas y de aplicación,</li><li>gestión del control de cambios por parte del proveedor.</li></ul></li></ul><h2 id="Bibliografia"><a href="#Bibliografia" class="headerlink" title="Bibliografía"></a>Bibliografía</h2><ul><li><a href="https://es.scribd.com/document/357447350/TICB3-Gestion-de-Librerias-y-Medios-Magneticos" rel="external nofollow noopener noreferrer" target="_blank">Scribd (Ibiza Ales)</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Gestion-de-la-configuracion-Gestion-de-librerias-de-programas-y-de-medios-magneticos-Controles-de-cambios-y-de-versiones-Los-lenguaj
      
    
    </summary>
    
      <category term="B4" scheme="http://localhost:4000/categories/B4/"/>
    
    
  </entry>
  
  <entry>
    <title>B3-T06</title>
    <link href="http://localhost:4000/wiki/B3/b3-t06/"/>
    <id>http://localhost:4000/wiki/B3/b3-t06/</id>
    <published>2019-01-16T15:11:23.000Z</published>
    <updated>2019-01-18T10:45:16.864Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Modelizacion-conceptual-El-modelo-Entidad-Relacion-extendido-E-R-elementos-Reglas-de-modelizacion-Validacion-y-construccion-de-modelos-de-datos"><a href="#Modelizacion-conceptual-El-modelo-Entidad-Relacion-extendido-E-R-elementos-Reglas-de-modelizacion-Validacion-y-construccion-de-modelos-de-datos" class="headerlink" title="Modelización conceptual. El modelo Entidad/Relación extendido (E/R): elementos. Reglas de modelización. Validación y construcción de modelos de datos."></a>Modelización conceptual. El modelo Entidad/Relación extendido (E/R): elementos. Reglas de modelización. Validación y construcción de modelos de datos.</h1><h2 id="Modelo-Conceptual-de-Datos"><a href="#Modelo-Conceptual-de-Datos" class="headerlink" title="Modelo Conceptual de Datos"></a>Modelo Conceptual de Datos</h2><p>A la hora de determinar una BD debemos establecer un proceso partiendo del acotamiento de una parcela del mundo exterior (micromundo o universo del discurso), aquél que nos interesa representar en los datos. En este proceso se debe aprender, comprender y conceptualizar dicho mundo exterior transformándolo en un conjunto de ideas y definiciones que supongan una imagen fiel del comportamiento del mundo real. A esta imagen del mundo exterior la llamaremos <strong>Modelo Conceptual</strong> .</p><p>Una vez definido el modelo conceptual, éste se ha de transformar en una descripción de datos, atributos y relaciones que denominaremos Esquema Conceptual de datos. Por último, este esquema conceptual habrá que traducirlo a estructuras almacenables en soportes físicos. Por tanto es necesario distinguir entre Bases de Datos, que será el banco, el almacén de los valores (ocurrencias) de los datos. Los modelos de Datos, que son las herramientas para diseñar los datos y sus relaciones de forma que puedan soportar los valores correspondientes. Y finalmente los Sistemas Gestores de Bases de Datos (SGBD), que serán los encargados de las acciones que llevemos a cabo con las bases de datos, permitiendo también cumplimentar a los usuarios, mostrándoles los datos de acuerdo a sus necesidades. Con todo ello, se puede definir un Modelo de Datos como: Un grupo de herramientas conceptuales para describir los datos, sus relaciones, su semántica y sus limitaciones; de tal forma, que facilita la interpretación de nuestro mundo real y su representación en forma de datos, en nuestro sistema informático.</p><p>Definido el modelo de datos, pasamos a analizarlo. Para ello, partiremos de las propiedades que podemos diferenciar en dos tipos:</p><ul><li><strong>Estáticas</strong> : Son las propiedades invariantes en el tiempo. Quedan especificadas en el Modelo de Datos por ESTRUCTURAS. Esta se define mediante el ESQUEMA, con el lenguaje de definición de datos (DDL). El esquema, a su vez está constituido por Estructura y Restricciones. La Estructura queda definida por los Objetos del Modelo y las Restricciones inherentes, conformando un conjunto de reglas de definición de dichas Estructuras. Los objetos y Restricciones de la Estructura dependen de cada Modelo, pero en general son:<ul><li>Entidades.</li><li>Atributos.</li><li>Dominio.</li><li>Relaciones.</li><li>Representación.</li><li>Restricciones: Hay tres tipos de restricciones:<ul><li><em>Restricciones inherentes</em> : vienen impuestas por la propia naturaleza del Modelo introduciendo rigideces en la modelización.</li><li><em>Restricciones opcionales o de usuario</em> : restricciones propiamente dichas en el Esquema, son definidas por el usuario, pero el Modelo de Datos las reconoce y suministra herramientas para manejarlas.</li><li><em>Restricciones libres de usuarios</em> : son responsabilidad del usuario y el Modelo de Datos ni las reconoce, ni las maneja.</li></ul></li></ul></li><li><strong>Dinámicas</strong> : Son las propiedades que varían con el tiempo. En el modelo de datos son las OPERACIONES. Se define como un conjunto de Operaciones con el Lenguaje de Manipulación de Datos (DML). Las operaciones sobre un Modelo de Datos pueden ser de:<ul><li>Selección. Localización de los datos deseados.</li><li>Acción. Realización de una acción sobre los datos seleccionados. Dicha acción puede ser:<ul><li>Recuperación (obtención de los datos seleccionados).</li><li>Actualización, que a su vez pueden ser:<ul><li>Modificación.</li><li>Inserción.</li><li>Borrado.</li></ul></li></ul></li></ul></li></ul><p>Generalmente, toda operación de Actualización va precedida de una Recuperación, aunque no necesariamente.</p><h2 id="Modelo-Entidad-Relacion-Extendido"><a href="#Modelo-Entidad-Relacion-Extendido" class="headerlink" title="Modelo Entidad/Relación Extendido"></a>Modelo Entidad/Relación Extendido</h2><p>Se trata de una técnica cuyo objetivo es la representación y definición de todos los datos que se introducen, almacenan, transforman y producen dentro de un sistema de información, sin tener en cuenta las necesidades de la tecnología existente, ni otras restricciones.</p><p>Dado que el modelo de datos es un medio para comunicar el significado de los datos, las relaciones entre ellos y las reglas de negocio de un sistema de información, una organización puede obtener numerosos beneficios de la aplicación de esta técnica, pues la definición de los datos y la manera en que éstos operan son compartidos por todos los usuarios.</p><p>Las ventajas de realizar un modelo de datos son, entre otras:</p><ul><li>Comprensión de los datos de una organización y del funcionamiento de la organización.</li><li>Obtención de estructuras de datos independientes del entorno físico.</li><li>Control de los posibles errores desde el principio, o al menos, darse cuenta de las deficiencias lo antes posible.</li><li>Mejora del mantenimiento.</li></ul><p>Aunque la estructura de datos puede ser cambiante y dinámica, normalmente es mucho más estable que la estructura de procesos. Como resultado, una estructura de datos estable e integrada proporciona datos consistentes que puedan ser fácilmente accesibles según las necesidades de los usuarios, de manera que, aunque se produzcan cambios organizativos, los datos permanecerán estables.</p><p>Este diagrama se centra en los datos, independientemente del procesamiento que los transforma y sin entrar en consideraciones de eficiencia. Por ello, es independiente del entorno físico y debe ser una fiel representación del sistema de información objeto del estudio, proporcionando a los usuarios toda la información que necesiten y en la forma en que la necesiten.</p><h3 id="Descripcion"><a href="#Descripcion" class="headerlink" title="Descripción"></a>Descripción</h3><p>El modelo entidad/relación extendido describe con un alto nivel de abstracción la distribución de datos almacenados en un sistema. Existen dos elementos principales: las entidades y las relaciones. Las extensiones al modelo básico añaden además los atributos de las entidades y la jerarquía entre éstas. Estas extensiones tienen como finalidad aportar al modelo una mayor capacidad expresiva.</p><p>Los elementos fundamentales del modelo son los siguientes:</p><p><strong>Entidad</strong></p><p>Es aquel objeto, real o abstracto, acerca del cual se desea almacenar información en la base de datos. La estructura genérica de un conjunto de entidades con las mismas características se denomina tipo de entidad.</p><p>Existen dos clases de entidades:</p><ul><li>Regulares: tienen existencia por sí mismas.</li><li>Débiles: cuya existencia depende de otra entidad.</li></ul><p>Las entidades deben cumplir las siguientes tres reglas:</p><ul><li>Tienen que tener existencia propia.</li><li>Cada ocurrencia de un tipo de entidad debe poder distinguirse de las demás.</li><li>Todas las ocurrencias de un tipo de entidad deben tener los mismos atributos.</li></ul><p><strong>Relación</strong></p><p>Es una asociación o correspondencia existente entre una o varias entidades. La relación puede ser regular, si asocia tipos de entidad regulares, o débil, si asocia un tipo de entidad débil con un tipo de entidad regular. Dentro de las relaciones débiles se distinguen la <strong>dependencia en existencia</strong> y la <strong>dependencia en identificación</strong> .</p><p>Se dice que la dependencia es en existencia cuando las ocurrencias de un tipo de entidad débil no pueden existir sin la ocurrencia de la entidad regular de la que dependen. Se dice que la dependencia es en identificación cuando, además de lo anterior, las ocurrencias del tipo de entidad débil no se pueden identificar sólo mediante sus propios atributos, sino que se les tiene que añadir el identificador de la ocurrencia de la entidad regular de la cual dependen.</p><p>Además, se dice que una relación es <strong>exclusiva</strong> cuando la existencia de una relación entre dos tipos de entidades implica la no existencia de las otras relaciones.</p><p>Una relación se caracteriza por:</p><ul><li><strong>Nombre</strong> : que lo distingue unívocamente del resto de relaciones del modelo.</li><li><strong>Tipo de correspondencia</strong> : es el número máximo de ocurrencias de cada tipo de entidad que pueden intervenir en una ocurrencia de la relación que se está tratando. Conceptualmente se pueden identificar tres clases de relaciones:<ul><li><em>Relaciones 1:1</em> : Cada ocurrencia de una entidad se relaciona con una y sólo una ocurrencia de la otra entidad.</li><li><em>Relaciones 1:N</em> : Cada ocurrencia de una entidad puede estar relacionada con cero, una o varias ocurrencias de la otra entidad.</li><li><em>Relaciones M:N</em> : Cada ocurrencia de una entidad puede estar relacionada con cero, una o varias ocurrencias de la otra entidad y cada ocurrencia de la otra entidad puede corresponder a cero, una o varias ocurrencias de la primera.</li></ul></li><li><strong>Cardinalidad</strong> : representa la participación en la relación de cada una de las entidades afectadas, es decir, el número máximo y mínimo de ocurrencias de un tipo de entidad que pueden estar interrelacionadas con una ocurrencia de otro tipo de entidad. La cardinalidad máxima coincide con el tipo de correspondencia.<br>Según la cardinalidad, una relación es obligatoria, cuando para toda ocurrencia de un tipo de entidad existe al menos una ocurrencia del tipo de entidad asociado, y es opcional cuando, para toda ocurrencia de un tipo de entidad, puede existir o no una o varias ocurrencias del tipo de entidad asociado.</li></ul><p><strong>Dominio</strong></p><p>Es un conjunto nominado de valores homogéneos. El dominio tiene existencia propia con independencia de cualquier entidad, relación o atributo.</p><p><strong>Atributo</strong></p><p>Es una propiedad o característica de un tipo de entidad. Se trata de la unidad básica de información que sirve para identificar o describir la entidad. Un atributo se define sobre un dominio. Cada tipo de entidad ha de tener un conjunto mínimo de atributos que identifiquen unívocamente cada ocurrencia del tipo de entidad. Este atributo o atributos se denomina identificador principal. Se pueden definir restricciones sobre os atributos, según las cuales un atributo puede ser:</p><ul><li>Univaluado, atributo que sólo puede tomar el valor para todas y cada una de las ocurrencias del tipo de entidad al que pertenece.</li><li>Obligatorio, atributo que tiene que tomar al menos un valor para todas y cada una de las ocurrencias del tipo de entidad al que pertenece.</li></ul><p>Además de estos elementos, existen extensiones del modelo entidad/relación que incorporan determinados conceptos o mecanismos de abstracción para facilitar la representación de ciertas estructuras del mundo real:</p><ul><li>La <strong>generalización</strong> , permite abstraer un tipo de entidad de nivel superior (supertipo) a partir de varios tipos de entidad (subtipos); en estos casos los atributos comunes y relaciones de los subtipos se asignan al supertipo. Se pueden generalizar por ejemplo los tipos <em>profesor</em> y <em>estudiante</em> obteniendo el <em>supertipo</em> persona.</li><li>La <strong>especialización</strong> es la operación inversa a la generalización, en ella un supertipo se descompone en uno o varios subtipos, los cuales heredan todos los atributos y relaciones del supertipo, además de tener los suyos propios. Un ejemplo es el caso del tipo <em>empleado</em> , del que se pueden obtener los subtipos <em>secretaria</em> , <em>técnico</em> e <em>ingeniero</em> .</li><li><strong>Categorías</strong> . Se denomina categoría al subtipo que aparece como resultado de la unión de varios tipos de entidad. En este caso, hay varios supertipos y un sólo subtipo. Si por ejemplo se tienen los tipos <em>persona</em> y <em>compañía</em> y es necesario establecer una relación con <em>vehículo</em> , se puede crear <em>propietario</em> como un subtipo unión de los dos primeros.</li><li>La <strong>agregación</strong> , consiste en construir un nuevo tipo de entidad como composición de otros y su tipo de relación y así poder manejarlo en un nivel de abstracción mayor. Por ejemplo, se tienen los tipos de entidad <em>empresa</em> y <em>solicitante de empleo</em> relacionados mediante el tipo de relación <em>entrevista</em> ; pero es necesario que cada <em>entrevista</em> se corresponda con una determinada <em>oferta de empleo</em> . Como no se permite la relación entre tipos de relación, se puede crear un tipo de entidad compuesto por <em>empresa</em> , <em>entrevista</em> y <em>solicitante de empleo</em> y relacionarla con el tipo de entidad <em>oferta de empleo</em> . El proceso inverso se denomina desagregación.</li><li>La <strong>asociación</strong> , consiste en relacionar dos tipos de entidades que normalmente son de dominios independientes, pero coyunturalmente se asocian.</li></ul><p>La existencia de supertipos y subtipos, en uno o varios niveles, da lugar a una <strong>jerarquía</strong> , que permitirá representar una restricción del mundo real.</p><p>Una vez construido el modelo entidad/relación, hay que analizar si se presentan redundancias. Para poder asegurar su existencia se deben estudiar con mucho detenimiento las cardinalidades mínimas de las entidades, así como la semántica de las relaciones.</p><p>Los atributos redundantes, los que se derivan de otros elementos mediante algún cálculo, deben ser eliminados del modelo entidad/relación o marcarse como redundantes.</p><p>Igualmente, las relaciones redundantes deben eliminarse del modelo, comprobando que al eliminarlas sigue siendo posible el paso, tanto en un sentido como en el inverso, entre las dos entidades que unían.</p><h3 id="Notacion"><a href="#Notacion" class="headerlink" title="Notación"></a>Notación</h3><p><strong>Entidad</strong></p><p>La representación gráfica de un tipo de entidad regular es un rectángulo con el nombre del tipo de entidad. Un tipo de entidad débil se representa con dos rectángulos concéntricos con su nombre en el interior.</p><p><img src="https://gsitic.files.wordpress.com/2018/04/entidad.png?w=825" alt=""></p><p><strong>Relación</strong></p><p>Se representa por un rombo unido a las entidades relacionadas por dos líneas retas a los lados. El tipo de correspondencia se representa gráficamente con una etiqueta <em>1:1</em> , <em>1:N</em> o <em>M:N</em> , cerca de alguno de los vértices del rombo, o bien situando cada número o letra cerca de la entidad correspondiente, para mayor claridad.</p><p><img src="https://gsitic.files.wordpress.com/2018/04/relacion.png?w=825" alt=""></p><p>La representación gráfica de las cardinalidades se realiza mediante una etiqueta del tipo <em>(0,1)</em> , ( <em>1,1)</em> , <em>(0,n)</em> o <em>(1,n)</em> , que se coloca en el extremo de la entidad que corresponda. Si se representan las cardinalidades, la representación del tipo de correspondencia es redundante.</p><p><img src="https://gsitic.files.wordpress.com/2018/04/relacion1.png?w=825" alt=""></p><p><em>Relaciones del tipo M:N (Muchos a Muchos):</em></p><p>Si existe un concepto que puede sustituir la relación, tiene sentido como entidad y aporta una mejor comprensión al modelo (para usuarios y analistas) es conveniente deshacerlas mediante esta entidad y las relaciones uno a muchos adecuadas.</p><p><img src="https://gsitic.files.wordpress.com/2018/04/muchos_a_muchos.png?w=825" alt=""></p><p><em>Relaciones entre Tres o Más Entidades</em></p><p>Las relaciones entre tres o más entidades se reclasificarán mediante una entidad relacionada con cada una de ellas, si existe un concepto que puede ser representado como una entidad, y aporta mayor comprensión al problema.</p><p><img src="https://gsitic.files.wordpress.com/2018/04/relaciones_tres_o_mas.png?w=825" alt=""></p><p><em>Relaciones potencialmente redundantes</em></p><p>Pueden serlo o no, depende del significado de las relaciones y de las cardinalidades.</p><p>Deben ser eliminadas.</p><p><img src="https://gsitic.files.wordpress.com/2018/04/relaciones_redundantes.png?w=825" alt=""></p><p><em>Relaciones Recursivas o Autorrelaciones</em></p><p><img src="https://gsitic.files.wordpress.com/2018/04/relaciones_recursivas.png?w=825" alt=""></p><p><strong>Atributo</strong></p><p>Un atributo se representa mediante una elipse, con su nombre dentro, conectada por una línea al tipo de entidad o relación.</p><p>En lugar de una elipse puede utilizarse un círculo con el nombre dentro, o un círculo más pequeño con el nombre del atributo a un lado. También pueden representarse en una lista asociada a la entidad. El identificador aparece con el nombre marcada o subrayado, o bien con su círculo en negro.</p><p><img src="https://gsitic.files.wordpress.com/2018/04/atributo.png?w=825" alt=""></p><p><strong>Exclusividad</strong></p><p>En la representación de las relaciones exclusivas se incluye un arco sobre las líneas que conectan el tipo de entidad a los dos o más tipos de relación.</p><p><img src="https://gsitic.files.wordpress.com/2018/04/exclusividad.png?w=825" alt=""></p><p><strong>Jerarquía (tipos y subtipos)</strong></p><p>La representación de las jerarquías se realiza mediante un triángulo invertido, con la base paralela al rectángulo que representa el supertipo y conectando a éste y a los subtipos. Si la división en subtipos viene determinada en función de los valores de un atributo discriminante, éste se representará asociado al triángulo que representa la relación.</p><p><img src="https://gsitic.files.wordpress.com/2018/04/jerarquia.png?w=825" alt=""></p><p>En el triángulo se representará: con una letra <strong>d</strong> el hecho de que los subtipos sean disjuntos, con un círculo o una <strong>O</strong> si los subtipos pueden solaparse y con un <strong>U</strong> el caso de uniones por categorías. La presencia de una jerarquía total se representa con una doble línea entre el supertipo y el triángulo.</p><p><img src="https://gsitic.files.wordpress.com/2018/04/tipos_y_subtipos.png?w=825" alt=""></p><p><strong>Ejemplo</strong></p><p>Modelo entidad-relación extendido para un sistema de gestión de técnicos y su asignación a proyectos dentro de una empresa u organización.</p><p>Como se aprecia en el diagrama, TÉCNICO es un subtipo de EMPLEADO, generado por especialización, pues era necesario para establecer la relación <em>Trabaja en</em> con PROYECTO, ya que no todos los empleados de la empresas, como los administrativos, son susceptibles de trabajar en un proyecto. La entidad TÉCNICO tendrá los atributos de EMPLEADO más el atributo <em>nivel</em> .</p><p><img src="https://gsitic.files.wordpress.com/2018/04/ejemplo.png?w=825" alt=""></p><p>Los tipos de correspondencia son <em>1:N</em> entre DEPARTAMENTO y EMPLEADO, pues un departamento tienen 1 o varios empleados. Entre TÉCNICO y PROYECTO es <em>M:N</em> , pues un técnico puede trabajar en 1 o varios proyectos, y en un proyecto trabajan 1 o varios técnicos.</p><p>Por otro lado, se han incluido atributos que caracterizan la relación <em>Trabaja en</em> , como son <em>fecha de asignación</em> y <em>fecha de cese</em> , ya que un técnico no siempre estará trabajando en un proyecto, sino en determinado periodo. (Nota.- Esta notación es la más habitual, pero MÉTRICA Versión 3 no exige su utilización).</p><p><img src="https://gsitic.files.wordpress.com/2018/04/cardinalidad.png?w=825" alt=""></p><h2 id="Normalizacion"><a href="#Normalizacion" class="headerlink" title="Normalización"></a>Normalización</h2><p>La teoría de la normalización tiene por objetivo la eliminación de dependencias entre atributos que originen anomalías en la actualización de los datos, y proporcionar una estructura más regular para la representación de las tablas, constituyendo el soporte para el diseño de bases de datos relacionales.</p><p>Como resultado de la aplicación de esta técnica se obtiene un modelo lógico de datos normalizado.</p><h3 id="Descripcion-1"><a href="#Descripcion-1" class="headerlink" title="Descripción"></a>Descripción</h3><p>La teoría de la normalización, como técnica formal para organizar los datos, ayuda a encontrar fallos y a corregirlos, evitando así introducir anomalías en las operaciones de manipulación de datos.</p><p>Se dice que una relación está en una determinada forma normal si satisface un cierto conjunto de restricciones sobre los atributos. Cuanto más restricciones existan, menor será el número de relaciones que las satisfagan, así, por ejemplo, una relación en tercera forma normal estará también en segunda y en primera forma normal.</p><p>Antes de definir las distintas formas normales se explican, muy brevemente, algunos conceptos necesarios para su comprensión.</p><p><strong>Dependencia funcional</strong></p><p>Un atributo _Y_ se dice que depende funcionalmente de otro _X_ si, y sólo si, a cada valor de _X_ le corresponde un único valor de _Y_ , lo que se expresa de la siguiente forma: <em>X → Y</em> (también se dice que _X_ determina o implica a _Y_ ).</p><p>_X_ se denomina implicante o determinante e _Y_ es el implicado.</p><p><strong>Dependencia funcional completa</strong></p><p>Un atributo _Y_ tiene dependencia funcional completa respecto de otro _X_ , si depende funcionalmente de él en su totalidad, es decir, no depende de ninguno de los posibles atributos que formen parte de _X_ .</p><p><strong>Dependencia transitiva</strong></p><p>Un atributo depende transitivamente de otro si, y sólo si, depende de él a través de otro atributo. Así, _Z_ depende transitivamente de _X_ , si:</p><p>X → Y<br>Y —/→ X<br>Y → Z</p><p>Se dice que _X_ implica a _Z_ a través de _Y_ .</p><p>Una vez definidas las anteriores dependencias, se pueden enunciar las siguientes formas normales:</p><p><em>Primera Forma Normal (1FN)</em></p><p>Una entidad está en 1FN si no tiene grupos repetitivos, es decir, un atributo sólo puede tomar un único valor de un dominio simple.</p><p>Una vez identificados los atributos que no dependen funcionalmente de la clave principal, se formará con ellos una nueva entidad y se eliminarán de la antigua. La clave principal de la nueva entidad estará formada por la concatenación de uno o varios de sus atributos más la clave principal de la antigua entidad.</p><p><em>Segunda Forma Normal (2FN)</em></p><p>Una entidad está en 2FN si está en 1FN y todos los atributos que no forman parte de las claves candidatas (atributos no principales) tienen dependencia funcional completa respecto de éstas, es decir, no hay dependencias funcionales de atributos no principales respecto de una parte de las claves. Cada uno de los atributos de una entidad depende de toda la clave.</p><p>Una vez identificados los atributos que no dependen funcionalmente de toda la clave, sino sólo de parte de la misma, se formará con ellos una nueva entidad y se eliminarán de la antigua. La clave principal de la nueva entidad estará formada por la parte de la antigua de la que dependen funcionalmente.</p><p><em>Tercera Forma Normal (3FN)</em></p><p>Una entidad está en 3FN si está en 2FN y todos sus atributos no principales dependen directamente de la clave primaria, es decir, no hay dependencias funcionales transitivas de atributos no principales respecto de las claves.</p><p>Una vez identificados los atributos que dependen de otro atributo distinto de la clave, se formará con ellos una nueva entidad y se eliminarán de la antigua. La clave principal de la nueva entidad será el atributo del cual dependen. Este atributo en la entidad antigua, pasará a ser una clave ajena.</p><h3 id="Notacion-1"><a href="#Notacion-1" class="headerlink" title="Notación"></a>Notación</h3><p>Una herramienta muy útil para visualizar las dependencias funcionales es el grafo o diagrama de dependencias funcionales, mediante el cual se representa un conjunto de atributos y las dependencias funcionales existentes entre ellos.</p><p>En el grafo aparecen los nombre de los atributos unidos por flechas, las cuales indican las dependencias funcionales completas que existen entre ellos, partiendo del implicante hacia el implicado. Cuando el implicante de una dependencia no es un único atributo, es decir, se trata de un implicante compuesto, los atributos que lo componen se encierran en un recuadro y la flecha parte de éste, no de cada atributo.</p><p><img src="https://gsitic.files.wordpress.com/2018/04/dependencia_funcional.png?w=825" alt=""></p><p>En la figura se presenta un ejemplo de cómo se visualizan las dependencias. Se puede observar que COD_LIBRO determina funcionalmente el TITULO del libro y la EDITORIAL, como indica la correspondiente flecha; de forma análoga, NUM_SOCIO determina NOMBRE, DOMICILIO y TEL. del socio (suponiendo que sólo se proporciona un teléfono); mientras que ambos atributos en conjunto COD_LIBRO y NUM_SOCIO (lo que se indica mediante el recuadro que los incluye) determinan FECHA_PRESTAMO y FECHA_DEV.</p><h3 id="Ejemplo"><a href="#Ejemplo" class="headerlink" title="Ejemplo"></a>Ejemplo</h3><p>Sea una entidad TÉCNICOS de un grupo de empresas, con los siguientes atributos:</p><ul><li>cod_empresa</li><li>cod_técnico</li><li>nombre_técnico</li><li>cod_categoría</li><li>categoría</li><li>nombre_empresa</li><li>fecha_alta</li><li>fecha_baja</li><li>cod_conoc</li><li>titulo_conoc</li><li>área_conoc</li><li>grado</li><li>cod_proyecto</li><li>nombre_proyecto</li><li>f_inicio</li><li>f_fin</li><li>f_asignación</li><li>f_cese</li><li>cod_cliente</li><li>nombre_cliente</li></ul><p>La entidad TÉCNICOS tiene la clave principal compuesta por _cod_empresa_ y _cod_técnico_ , ya que, al ser varias empresas, el código de técnico no será único, sino que puede coincidir con otros de otras empresas.</p><p><em>Primera Forma Normal (1FN)</em></p><p>Evidentemente no se cumple la primera forma normal, ya que un técnico tendrá más o de un conocimiento (lenguajes, sistemas, operativos, bases de datos, etc), es decir habrá varios valores de _cod_conoc_ , por lo que este atributo y los asociados a conocimientos no dependen funcionalmente de la clave principal.</p><p>Los atributos _cod_conoc_ , _título_conoc_ , _área_conoc_ y <em>grado</em> identificados como no dependientes, formarán la nueva entidad CONOCIMIENTOS y desaparecerán de la entidad TÉCNICOS. La clave de la nueva entidad será _cod_conoc_ concatenada con _cod_empresa_ y _cod_técnico_ .</p><p>Por otro lado, en este sistema un técnico puede trabajar en más de un proyecto a tiempo parcial, por lo que _cod_proyecto_ tampoco depende funcionalmente de la clave principal de TÉCNICOS.</p><p>Se obtiene entonces la entidad PROYECTOS con los atributos de los proyectos, y su clave compuesta de _cod_proyecto_ concatenada con _cod_empresa_ y _cod_técnico_ de la antigua entidad.</p><p>Esta situación se completará con dos tipos de relaciones: <em>Poseen</em> , cuyo tipo de correspondencia es <em>1:N</em> entre TÉCNICOS y CONOCIMIENTOS y <em>Están asignados</em> , también del tipo <em>M:N</em> entre TÉCNICOS y PROYECTOS, tal y como muestra el diagrama siguiente:</p><p><img src="https://gsitic.files.wordpress.com/2018/04/diagrama_1fn.png?w=825" alt=""></p><p>Como se aprecia en la figura, se ha trasladado el atributo <em>grado</em> de la entidad CONOCIMIENTOS a la relación <em>Poseen</em> , pues es un atributo que determina la relación entre las dos entidades. También han sido trasladado los atributos que caracterizan la relación <em>Están asignados</em> , como son _f_asignación_ y _f_cese_ , ya que un técnico no siempre estará trabajando en un proyecto, sino en determinado periodo.</p><p><em>Segunda Forma Normal (2FN)</em></p><p>En la entidad TÉCNICOS se observa que el atributo _nombre_empresa_ no tiene una dependencia funcional completa con la clave, sino que la tiene sólo de una parte de la misma: _cod_empresa_ .</p><p>El atributo identificado formará parte de una nueva entidad, EMPRESAS, siendo eliminado de la antigua. La clave principal de la nueva entidad será _cod_empresa_ .</p><p>Para representar la segunda forma normal en el modelo de datos, deberá añadirse un tipo de relación, <em>Se componen</em> , y el tipo de correspondencia <em>1:N</em> .</p><p><img src="https://gsitic.files.wordpress.com/2018/04/diagrama_2fn.png?w=825" alt=""></p><p><em>Tercera Forma Normal (3FN)</em></p><p>En la entidad TÉCNICOS de la figura se puede observar que para un _cod_técnico_ hay un único _cod_categoría_ , es decir, el segundo depende funcionalmente del primero; para un _cod_categoría_ hay una única <em>categoría</em> , es decir, que este atributo depende funcionalmente del _cod_categoría_ ; y por último, para un _cod_categoría_ hay varios valores de _cod_técnico_ . Así pues, la categoría depende transitivamente del _cod_técnico_ , por lo que la entidad TÉCNICOS no está en 3FN.</p><p>Una vez identificado el atributo categoría que depende de otro atributo distinto de la clave, _cod_categoría_ , se formará con él una nueva entidad y se quitará de la antigua. La clave principal de la nueva entidad será el atributo del cual depende _cod_categoría_ y en la entidad antigua pasará a ser una clave ajena.</p><p>Del mismo modo, puede observarse que la entidad PROYECTOS tampoco está en 3FN, pues el _nombre_cliente_ depende de _cod_cliente_ , que no forma parte de la clave de la entidad.</p><p><img src="https://gsitic.files.wordpress.com/2018/04/diagramas_3fn.png?w=825" alt=""></p><p>Así pues, aparecen dos entidades nuevas en el modelo: CATEGORÍAS y CLIENTES, y sus respectivas relaciones y tipos de correspondencias: <em>Están clasificados 1:N</em> y <em>Tiene contratados 1:N</em> .</p><h2 id="Optimizacion"><a href="#Optimizacion" class="headerlink" title="Optimización"></a>Optimización</h2><p>El objetivo de esta técnica es reestructurar el modelo físico de datos con el fin de asegurar que satisface los requisitos de rendimiento establecidos y conseguir una adecuada eficiencia del sistema.</p><h3 id="Descripcion-2"><a href="#Descripcion-2" class="headerlink" title="Descripción"></a>Descripción</h3><p>La optimización consiste en una desnormalización controlada del modelo físico de datos que se aplica para reducir o simplificar el número de accesos a la base de datos.</p><p>Para ello, se seguirán alguna de las recomendaciones que a continuación se indican:</p><ul><li>Introducir elementos redundantes.</li><li>Dividir entidades.</li><li>Combinar entidades si los accesos son frecuentes dentro de la misma transacción.</li><li>Redefinir o añadir relaciones entre entidades para hacer más directo el acceso entre entidades.</li><li>Definir claves secundarias o índices para permitir caminos de acceso alternativos.</li></ul><p>Con el fin de analizar la conveniencia o no de la desnormalización, se han de considerar, entre otros, los siguientes aspectos:</p><ul><li>Los tiempos de respuesta requeridos.</li><li>La tasa de actualizaciones respecto a la de recuperaciones.</li><li>Las veces que se accede conjuntamente a los atributos.</li><li>La longitud de los mismos.</li><li>El tipo de aplicaciones (en línea / por lotes).</li><li>La frecuencia y tipo de acceso.</li><li>La prioridad de los accesos.</li><li>El tamaño de las tablas.</li><li>Los requisitos de seguridad: accesibilidad, confidencialidad, integridad y disponibilidad que se consideren relevantes.</li></ul><h2 id="Reglas-de-Obtencion-del-Modelo-Fisico-a-partir-del-Logico"><a href="#Reglas-de-Obtencion-del-Modelo-Fisico-a-partir-del-Logico" class="headerlink" title="Reglas de Obtención del Modelo Físico a partir del Lógico"></a>Reglas de Obtención del Modelo Físico a partir del Lógico</h2><p>El objetivo de esta técnica es obtener un modelo físico de datos a paritr del modelo lógico de datos normalizado. Para ello es necesario aplicar un conjunto de reglas que conserven la semántica del modelo lógico.</p><h3 id="Descripcion-3"><a href="#Descripcion-3" class="headerlink" title="Descripción"></a>Descripción</h3><p>Cada uno de los elementos del modelo lógico se tiene que transformar en un elemento del modelo físico. En algunos casos la transformación es directa porque el concepto se soporta igual en ambos modelos, pero otras veces no existe esta correspondencia, por lo que es necesario buscar una transformación que conserve lo mejor posible la semántica, teniendo en cuenta los aspectos de eficiencia que sean necesarios en cada caso.</p><p><strong>Transformación de entidades</strong></p><p>Una entidad se transforma en una tabla.</p><p><strong>Transformación de atributos de entidades</strong></p><p>Cada atributo se transforma en una columna de la tabla en la que se transformó la entidad a la que pertenece. El identificador único se convierte en clave primaria.</p><p>Si existen restricciones asociadas a los atributos, éstas pueden recogerse con algunas cláusulas del lenguaje lógico, que se convertirán en disparadores cuando éstos sean soportados por el sistema gestor de base de datos.</p><p><strong>Transformación de relaciones</strong></p><p>Según el tipo de correspondencia:</p><ul><li><strong>Relaciones 1:N</strong> : se propaga el identificador de la entidad de cardinalidad máxima _1_ a la que es _N_ , teniendo en cuenta que:<ul><li>Si la relación es de asociación, la clave propagada es clave ajena en la tabla a la que se ha propagado.</li><li>Si la relación es de dependencia, la clave primaria de la tabla correspondiente a la entidad débil está formada por la concatenación de los identificadores de ambas entidades.</li></ul></li><li><strong>Relaciones 1:1</strong> : es un caso particular de las <em>1:N</em> y por tanto se propaga la clave en las dos direcciones. Se debe analizar la situación, intentando recoger la mayor semántica posible, y evitar valores nulos.</li></ul><p>Las relaciones de agregación se transforman del mismo modo que las <em>1:N</em> .</p><p><strong>Transformación de relaciones exclusivas</strong></p><p>Después de haber realizado la transformación según las relaciones <em>1:N</em> , se debe tener en cuenta que si los identificadores propagados se han convertido en claves ajenas de la tabla originada por la entidad común a las relaciones, hay que comprobar que una y sólo una de esas claves es nula en cada ocurrencia. En otro caso, estas comprobaciones se deben hacer en las tablas resultantes de transformar las relaciones.</p><p><strong>Transformación de la jerarquía</strong></p><p>Existen varias posibilidades que deben ser evaluadas por el diseñador a fin de elegir la que mejor se ajuste a los requisitos. Las opciones para tratar la transformación de la jerarquía son:</p><ul><li><strong>Opción a</strong> : Consiste en crear una tabla para el supertipo que tenga de clave primaria el identificador y una tabla para cada uno de los subtipos que tengan el identificador del supertipo como clave ajena.<br>Esta solución es apropiada cuando los subtipos tienen muchos atributos distintos y se quieren conservar los atributos comunes en una tabla. También se deben implantar las restricciones y aserciones adecuadas. Es la solución que mejor conserva la semántica.</li><li><strong>Opción b</strong> : Se crea una tabla para cada subtipo, los atributos comunes aparecen en todos los subtipos y la clave primaria para cada tabla es el identificador del supertipo.<br>Esta opción mejora la eficiencia en los accesos a todos los atributos de un subtipo, sean los comunes al supertipo o los específicos.</li><li><strong>Opción c</strong> : Agrupar en una tabla todos los atributos de la entidad supertipo y de los subtipos. La clave primaria de esta tabla es el identificador de la entidad. Se añade un atributo que indique a qué subtipo pertenece cada ocurrencia (el atributo discriminante de la jerarquía). Esta solución puede aplicarse cuando los subtipos se diferencien en pocos atributos y las relaciones entre los subtipos y otras entidades sean las mismas. Para el caso de que la jerarquía sea total, el atributo discriminante no podrá tomar valor nulo (ya que toda ocurrencia pertenece a alguna de las entidades subtipo).</li></ul><h3 id="Notacion-2"><a href="#Notacion-2" class="headerlink" title="Notación"></a>Notación</h3><p><strong>Tabla</strong></p><p>La representación gráfica de una tabla es un rectángulo con una línea horizontal que lo divide en dos. La parte superior, de ancho menor, se etiqueta con el nombre de la tabla.</p><p><img src="https://gsitic.files.wordpress.com/2018/04/tabla.png?w=825" alt=""></p><p><strong>Relación</strong></p><p>La relación entre tablas se representa gráficamente mediante una línea que las une. En ella pueden aparecer en sus extremos diversos símbolos para indicar la cardinalidad de la relación, como se muestra a continuación:</p><p><img src="https://gsitic.files.wordpress.com/2018/04/relacion2.png?w=825" alt=""></p><p><em>Ejemplo.</em></p><p>Sea el diagrama entidad-relación del ejemplo realizado para la Normalización sobre conocimientos de técnicos informáticos y su asignación a proyectos.</p><p><img src="https://gsitic.files.wordpress.com/2018/04/diagrama_entidad_relacion.png?w=825" alt=""></p><p>El modelo físico de la figura muestra que cada una de las entidades se ha convertido en una tabla, cuyo contenido coincide con los atributos de la entidad. Pero hay dos tablas más: POSEEN, que surge de la relación del mismo nombre y ASIGNACIONES, que se origina a partir de la relación <em>Están asignados</em> .</p><p>La tabla POSEEN está formada por su atributo <em>grado</em> , más _cod_empresa_ , _cod_tecnico_ y _cod_conoc_ . La tabla ASIGNACIONES se forma con los atributos clave _cod_empres_ a, _cod_tecnico_ y _cod_proyecto_ y los propios _f_asignación_ y _f_cese_ .</p><p>La relación entre EMPRESAS y TÉCNICOS era <em>1:N</em> , y la cardinalidad de la figura así lo muestra, pues la empresa siempre estará compuesta de uno o varios técnicos. Lo mismo sucede entre CLIENTES y PROYECTOS: un cliente siempre tendrá 1 o varios proyectos contratados.</p><p>El caso de CATEGORÍAS y TÉCNICOS es <em>(0,n)</em> . Cada técnico es de una categoría y una categoría corresponde, por regla general, a varios técnicos, pero puede existir alguna en la que no encaje ningún técnico (contable, secretaria de dirección, etc.).</p><p>La situación del subconjunto TÉCNICOS-POSEEN-CONOCIMIENTOS tienen algo más de complejidad. Un técnico posee normalmente varios conocimientos, pero debe poseer al menos uno para que tenga sentido su situación. La cardinalidad es pues <em>(1,n)</em> entre TÉCNICOS y POSEEN. En el otro lado, lo natural es que un conocimiento sea poseído por varios técnicos, sin embargo puede existir algún conocimiento que no sea poseído por ningún técnico, por lo que la cardinalidad es <em>(0,n)</em> y dibujada desde la tabla CONOCIMIENTOS a POSEEN.</p><p>Por último, en el subconjunto TÉCNICOS-ASIGNACIONES-PROYECTOS, se dispone de: una cardinalidad <em>(0,n)</em> , pues a un proyecto estarán asignados uno o más técnicos, pero puede haber algún técnico que, en un momento dado, no esté asignado aún a ningún proyecto y una cardinalidad <em>(1,n)</em> , pues un proyecto siempre tendrá asignado al menos a un técnico, o varios.</p><p>(Nota.- La notación utilizada para el ejemplo es la más habitual, pero MÉTRICA Versión 3 no exige su utilización).</p><h2 id="Reglas-de-Transformacion"><a href="#Reglas-de-Transformacion" class="headerlink" title="Reglas de Transformación"></a>Reglas de Transformación</h2><p>El objetivo de esta técnica es obtener un modelo físico de datos a partir del modelo de clases. Para ello es necesario aplicar un conjunto de reglas de transformación que conserven la semántica del modelo de clases.</p><h3 id="Descripcion-4"><a href="#Descripcion-4" class="headerlink" title="Descripción"></a>Descripción</h3><p>Cada uno de los elementos del modelo de clases se tiene que transformar en un elemento del modelo físico. En algunos casos la transformación es directa porque el concepto se soporta igual en ambos modelos, pero otras veces no existe esta correspondencia, por lo que es necesario buscar una transformación que conserve lo mejor posible la semántica, teniendo en cuenta los aspectos de eficiencia que sean necesarios en cada caso.</p><p><strong>Transformación de clases</strong></p><p>Una clase se transforma en una tabla. Lo habitual es que en los modelos con herencia pueden surgir excepciones cuando se apliquen las reglas de transformación propias de la herencia. Además, es posible que dos clases se transformen en una sola tabla cuando el comportamiento de una de ellas sea irrelevante en la base de datos.</p><p><strong>Transformación de atributos de clases</strong></p><p>Cada atributo se transforma en una columna de la tabla en la que se transformó la clase a la que pertenece. El identificador único se convierte en clave primaria. Además, se deben tener en cuenta las reglas de transformación que se aplican a la herencia de clases.</p><p>Si existen restricciones asociadas a los atributos, éstas pueden recogerse con algunas cláusulas del lenguaje lógico, que se convertirán en disparadores cuando éstos sean soportados por el sistema gestor de base de datos.</p><p><strong>Transformación de relaciones</strong></p><p>Según el tipo de correspondencia:</p><ul><li><strong>Relaciones M:N</strong> : se transforman en una tabla, cuya clave primaria es la concatenación de los identificadores de las clases asociadas, siendo cada uno de ellos clave ajena de la propia tabla. Si la relación tienen atributos, éstos se transforman en columnas de la tabla.</li><li><strong>Relaciones 1:N</strong> : existen varias posibilidades:<ul><li>Propagar el identificador de la clase de cardinalidad máxima _1_ a la que es _N_ , teniendo en cuenta que:<ul><li>Si la relación es de asociación, la clave propagada es clave ajena en la tabla a la que se ha propagado.</li><li>Si la relación es de dependencia, la clave primaria de la tabla correspondiente a la clase débil está formada por la concatenación de los identificadores de ambas clases.</li></ul></li><li>La relación se transforma en una tabla de clave primaria sólo el identificador de la clase de cardinalidad máxima _N_ si:<ul><li>La relación tiene atributos propios y se desea que aparezcan como tales.</li><li>Se piensa que en un futuro la relación puede convertirse en <em>M:N</em> .</li><li>El número de ocurrencias relacionadas de la clase que propaga su clave es muy pequeño (y por tanto pueden existir muchos valores nulos).</li></ul></li><li>Al igual que en el caso de relaciones <em>M:N</em> , las claves propagadas son claves ajenas de la nueva tabla creada.</li></ul></li><li><strong>Relaciones 1:1</strong> : es un caso particular de las <em>1:N</em> y se puede tanto crear una tabla o propagar la clave, si bien, en este último caso, la clave se propaga en las dos direcciones. Para decidir qué solución adoptar, se debe analizar la situación, intentando recoger la mayor semántica posible, y evitar valores nulos.<br>Las relaciones de agregación se transforman del mismo modo que las <em>1:N</em> .</li></ul><p><strong>Transformación de relaciones exclusivas</strong></p><p>Después de haber realizado la transformación según las relaciones <em>1:N</em> , se debe tener en cuenta que si se han propagado los atributos de las clases, convirtiéndose en claves ajenas de la tabla que provenía de la clase común a las relaciones, hay que comprobar que una y sólo una de esas claves es nula en cada ocurrencia. En caso de no propagarse las claves, estas comprobaciones se deben hacer en las tablas resultantes de transformar las relaciones.</p><p><strong>Transformación de la herencia</strong></p><p>Existen varias posibilidades que deben ser evaluadas por el diseñador a fin de elegir la que mejor se ajuste a los requisitos. Las opciones para tratar la transformación de la herencia son:</p><ul><li><strong>Opción a</strong> : Consiste en crear una tabla para la superclase que tenga de clave primaria el identificador y una tabla para cada una de las subclases que tengan el identificador de la superclase como clave ajena.<br>Esta solución es apropiada cuando las subclases tienen muchos atributos distintos, y se quieren conservar los atributos comunes en una tabla. También se deben implantar las restricciones y/o aserciones adecuadas. Es la solución que mejor conserva la semántica.</li><li><strong>Opción b</strong> : Se crea una tabla para cada subclase, los atributos comunes aparecen en todas las subclases y la clave primaria para cada tabla es el identificador de la superclase.<br>Esta opción mejora la eficiencia en los accesos a todos los atributos de una subclase (los heredados y los específicos).</li><li><strong>Opción c</strong> : Agrupar en una tabla todos los atributos de la clase y sus subclases. La clave primaria de esta tabla es el identificador de la clase. Se añade un atributo que indique a qué subclase pertenece cada ocurrencia (el atributo discriminante de la jerarquía).<br>Esta solución puede aplicarse cuando las subclases se diferencien en pocos atributos y las relaciones que asocian a las subclases con otras clases, sean las mismas. Para el caso de que la jerarquía sea total, el atributo discriminante no podrá tomar valor nulo (ya que toda ocurrencia pertenece a alguna subclase).</li></ul><h2 id="Tecnicas-Matriciales"><a href="#Tecnicas-Matriciales" class="headerlink" title="Técnicas Matriciales"></a>Técnicas Matriciales</h2><p>Las técnicas matriciales tienen como objetivo representar las relaciones existentes entre distintos tipos de entidades, objetos o cualquier otro elemento del sistema.</p><p>Se utilizan, principalmente, para analizar la consistencia entre los modelos generados durante el desarrollo, comprobar la trazabilidad con los requisitos especificados por el usuario, etc.</p><h3 id="Descripcion-5"><a href="#Descripcion-5" class="headerlink" title="Descripción"></a>Descripción</h3><p>Las técnicas matriciales son útiles para representar las relaciones entre elementos comunes de los distintos modelos, tales como entidades/procesos, procesos/diálogos, datos/localización geográfica, y asegurar que los modelos son coherentes entre sí.</p><p>Las siguientes son algunas de las matrices empleadas en MÉTRICA Versión 3:</p><ul><li>Procesos/localización geográfica: permite representar la localización geográfica de los procesos de una organización.</li><li>Almacenes de datos/entidades del modelo lógico de datos normalizado: establece las relaciones existentes entre los almacenes de datos y las entidades, y permite verificar que cada almacén de datos definido en el modelo de procesos se corresponde con una o varias entidades del modelo lógico de datos normalizado.</li><li>Atributos de interfaz/atributos de entidades del modelo lógico de datos normalizado: permite verificar que los atributos que aparecen en cada diálogo de la interfaz de usuario forman parte del modelo lógico de datos normalizado.</li><li>Entidades/procesos: permite representar el tratamiento lógico de los procesos sobre los datos del sistema y verificar que cada entidad del modelo lógico de datos normalizado es accedida por algún proceso primitivo representado en el DFD.</li><li>Diálogos/procesos: permite representar los diálogos asociados a un proceso interactivo y verificar que cada proceso interactivo tiene asociado al menos un diálogo.</li><li>Objetos Diagrama de interacción / clases, atributos al modelo de clases: permite verificar que cada mensaje entre objetos se corresponde con un método de una clase.</li><li>Mensajes Diagrama de interacción / métodos, atributos del modelo de clases: permite verificar que una clase tiene capacidad para proporcionar los datos que se soliciten en los mensajes que recibe.</li><li>Evento, acción, actividad de clases / métodos de clases: permite verificar que todo evento, actividad o acción de una clase se corresponde con un método de esa clase.</li><li>Clases/elementos del modelo físico de datos: permite verificar que cada elemento del modelo físico de datos se corresponde con un elemento del modelo de clases.</li><li>Dependencias entre subsistemas/subsistemas: permite representar para cada subsistema, los subsistemas que dependen de él.</li><li>Esquemas físicos de datos / nodos: permite representar la localización física de los datos en los nodos de la arquitectura del sistema, así como verificar que cada esquema del modelo físico de datos está asociado con un nodo del particionamiento físico del sistema de información.</li></ul><h3 id="Notacion-3"><a href="#Notacion-3" class="headerlink" title="Notación"></a>Notación</h3><p>Dados dos tipos de elementos A y B, su representación será una matriz bidimensional NxM, siendo N el número de elementos de A, y M el número de elementos de B.</p><p>En el cruce de una fila y una columna (C), se tendrá el modo en que se relacionan un elemento concreto de A y uno de B.</p><p><img src="https://gsitic.files.wordpress.com/2018/04/notacion_matriz.png?w=825" alt=""></p><h2 id="Bibliografia"><a href="#Bibliografia" class="headerlink" title="Bibliografia"></a>Bibliografia</h2><ul><li><a href="https://eclap.jcyl.es/web/jcyl/ECLAP/es/Plantilla66y33/1259395037582/_/_/_" rel="external nofollow noopener noreferrer" target="_blank">Junta de Castilla y León (SOP_INF_T09_FINAL)</a></li><li><a href="https://administracionelectronica.gob.es/pae_Home/pae_Documentacion/pae_Metodolog/pae_Metrica_v3.html#.WtYfDnpuZpg" rel="external nofollow noopener noreferrer" target="_blank">PAe</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Modelizacion-conceptual-El-modelo-Entidad-Relacion-extendido-E-R-elementos-Reglas-de-modelizacion-Validacion-y-construccion-de-model
      
    
    </summary>
    
      <category term="B3" scheme="http://localhost:4000/categories/B3/"/>
    
    
  </entry>
  
  <entry>
    <title>B3-T09</title>
    <link href="http://localhost:4000/wiki/B3/b3-t09/"/>
    <id>http://localhost:4000/wiki/B3/b3-t09/</id>
    <published>2019-01-16T15:11:23.000Z</published>
    <updated>2019-01-18T10:45:16.871Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Diseno-de-programas-Diseno-estructurado-Analisis-de-transformacion-y-de-transaccion-Cohesion-y-acoplamiento"><a href="#Diseno-de-programas-Diseno-estructurado-Analisis-de-transformacion-y-de-transaccion-Cohesion-y-acoplamiento" class="headerlink" title="Diseño de programas. Diseño estructurado. Análisis de transformación y de transacción. Cohesión y acoplamiento."></a>Diseño de programas. Diseño estructurado. Análisis de transformación y de transacción. Cohesión y acoplamiento.</h1><h2 id="Introduccion-al-Diseno-Estructurado"><a href="#Introduccion-al-Diseno-Estructurado" class="headerlink" title="Introducción al Diseño Estructurado"></a>Introducción al Diseño Estructurado</h2><h3 id="Conceptos-Generales-Sobre-el-Diseno"><a href="#Conceptos-Generales-Sobre-el-Diseno" class="headerlink" title="Conceptos Generales Sobre el Diseño"></a>Conceptos Generales Sobre el Diseño</h3><p>Definición: “Diseño es el proceso de aplicar distintas técnicas y principios con el propósito de definir un dispositivo, proceso, o sistema, con los suficientes detalles como para permitir su realización física”.</p><p>El objetivo del diseñador es producir un modelo de una entidad que se construirá más adelante. El proceso por el cual se desarrolla el modelo combina:</p><ul><li>La intuición y los criterios en base a la experiencia de construir entidades similares.</li><li>Un conjunto de principios y/o heurísticas que guían la forma en la que se desarrolla el modelo.</li><li>Un conjunto de criterios que permiten discernir sobre la calidad.</li><li>Un proceso de iteración que conduce finalmente a una representación del diseño final.</li></ul><p>La actividad de Diseño se dedica a asignar porciones de la especificación estructurada (también conocida como modelo esencial) a procesadores adecuados (sean máquinas o humanos) y a labores apropiadas (o tareas, particiones, etc) dentro de cada procesador. Dentro de cada labor, la actividad de diseño se dedica a la creación de una jerarquía apropiada de módulos de programas y de interfaces entre ellos para implantar la especificación creada en la actividad de análisis. Además, la actividad de diseño se ocupa de la transformación de modelos de datos de entidad/relación en un diseño de base de datos.</p><h3 id="¿Que-es-Diseno-Estructurado"><a href="#¿Que-es-Diseno-Estructurado" class="headerlink" title="¿Qué es Diseño Estructurado?"></a>¿Qué es Diseño Estructurado?</h3><p>Definición: “Diseño estructurado es el proceso de decidir qué componentes, y la interconexión entre los mismos, para solucionar un problema bien especificado”.</p><p>El diseño es una actividad que comienza cuando el analista de sistemas ha producido un conjunto de requerimientos funcionales lógicos para un sistema, y finaliza cuando el diseñador ha especificado los componentes del sistema y las relaciones entre los mismos.</p><p>Frecuentemente analista y diseñador son la misma persona, sin embargo es necesario que se realice un cambio de enfoque mental al pasar de una etapa a la otra. <em>Al abordar la etapa de diseño, la persona debe quitarse el sombrero de analista y colocarse el sombrero de diseñador</em> .</p><p>Una vez que se han establecido los requisitos del software (en el análisis), el diseño del software es la primera de tres actividades técnicas: <em>diseño</em> , <em>codificación</em> y <em>prueba</em> . Cada actividad transforma la información de forma que finalmente se obtiene un software para computadora válido.</p><p>En la figura se muestra el flujo de información durante la fase de desarrollo. Los requisitos del sistema, establecidos mediante los <em>modelos de información</em> , <em>funcional</em> y <em>de comportamiento</em> , alimentan el proceso del diseño. Mediante alguna metodología (en nuestro caso, estructurada basada en el flujo de información) se realiza el diseño estructural, procedimiental y de datos.</p><p><img src="https://gsitic.files.wordpress.com/2018/04/flujo_informacion_fase_desarrollo.png?w=825" alt=""></p><p>El <em>diseño de datos</em> transforma el modelo del campo de información, creado durante el análisis, en las estructuras de datos que se van a requerir para implementar el software.</p><p>El <em>diseño estructural</em> define las relaciones entre los principales elementos estructurales del programa. El objetivo principal del diseño estructural es desarrollar una estructura de programa modular y representar las relaciones de control entre los módulos.</p><p>El <em>diseño procedimental</em> transforma los elementos estructurales en una descripción procedimental del software. El diseño procedimental se realiza después de que se ha establecido la estructura del programa y de los datos. Define los algoritmos de procesamiento necesarios.</p><p>Concluido el diseño se genera el código fuente y para integrar y validar el software, se llevan a cabo pruebas de testeo.</p><p>Las fases del diseño, codificación y prueba absorben el 75% o más del coste de la ingeniería del software (excluyendo el mantenimiento). Es aquí donde se toman <em>decisiones</em> que afectarán finalmente al éxito de la implementación del programa y, con igual importancia, a la facilidad de mantenimiento que tendrá el software. Estas decisiones se llevan a cabo durante el diseño del software, haciendo que sea un paso <em>fundamental</em> de la fase de desarrollo.</p><p>La importancia del diseño del software se pueden sentar con una única palabra: <em>calidad</em> . El diseño es el proceso en el que se asienta la calidad del desarrollo del software. El diseño produce las representaciones del software de las que puede evaluarse su calidad. El diseño sirve como base para todas las posteriores etapas del desarrollo y de la fase de mantenimiento. Sin diseño nos arriesgamos a construir un sistema inestable, un sistema que falle cuando se realicen pequeños cambios, un sistema que pueda ser difícil de probar, un sistema cuya calidad no pueda ser evaluada hasta más adelante en el proceso de ingeniería de software, cuando quede poco tiempo y se haya gastado ya mucho dinero.</p><p><img src="https://gsitic.files.wordpress.com/2018/04/con_disec3b1o_sin_disec3b1o.png?w=825" alt=""></p><h3 id="Objetivos-del-Diseno-Estructurado"><a href="#Objetivos-del-Diseno-Estructurado" class="headerlink" title="Objetivos del Diseño Estructurado"></a>Objetivos del Diseño Estructurado</h3><p><em>El diseño estructurado, tiende a transformar el desarrollo de software de una práctica artesanal a una disciplina de ingeniería.</em></p><ul><li>Eficiencia</li><li>Mantenibilidad</li><li>Modificabilidad</li><li>Flexibilidad</li><li>Generalidad</li><li>Utilidad</li></ul><p><em>“Diseño” significa planear la forma y método de una solución</em> . Es el proceso que determina las características principales del sistema final, establece los límites en performance y calidad que la mejor implementación puede alcanzar, y puede determinar a qué costos se alcanzará.</p><p>El diseño se caracteriza usualmente por un gran número de decisiones técnicas individuales. En orden de transformar el desarrollo de software en una disciplina de ingeniería, se debe sistematizar tales decisiones, hacerlas más explícitas y técnicas, y menos implícitas y artesanales.</p><p>Un ingeniero no busca simplemente <em>una</em> solución, busca la <em>mejor</em> solución, dentro de las <em>limitaciones</em> reconocidas, y realizando <em>compromisos</em> requeridos en el trabajo del mundo real.</p><p>En orden de convertir el diseño de sistemas de computadoras en una disciplina de ingeniería, previo a todo, debemos definir <em>objetivos técnicos claros</em> para los programas de computadora. Es esencial además comprender las <em>restricciones</em> primarias que condicionan las soluciones posibles.</p><p>Para realizar decisiones concisas y deliberadas, debemos identificar los <em>puntos de decisión</em> .</p><p>Finalmente necesitamos una <em>metodología</em> que nos asista en la <em>toma de decisiones</em> .</p><p>Dadas estas cosas: objetivos, restricciones, decisiones reconocidas, y una metodología efectiva, podemos obtener soluciones de ingeniería, y no artesanales.</p><p><strong><em>Diseño estructurado y calidad del software</em></strong></p><p>Un concepto importante a clarificar es el de <em>calidad</em> . Desafortunadamente, muchos diseñadores se conforman con un sistema que “funcione” sin reparar en un <em>buen</em> sistema.</p><p>Una corriente de pensamiento estima que un programa es bueno si sus algoritmos son astutos y no obvios a otro programador; esto refleja la “inteligencia” del programador.</p><p>Otra escuela de pensamiento asocia calidad con incremento de la velocidad de ejecución y disminución de los requerimientos de memoria central. Estos son aspectos de un concepto más amplio: <em>eficiencia</em> . En general, se busca diseños que hagan un uso inteligente de los <em>recursos</em> . Estos recursos no incluyen solamente procesador y memoria, también incluyen almacenamiento secundario, tiempo de periféricos de entrada/salida, tiempo de líneas de teleproceso, tiempo de personal y más.</p><p>Otra medida de calidad es la <em>confiabilidad</em> . Es importante notar que si bien la confiabilidad del software puede ser vista como un problema de depuración de errores en los programas, es también un problema de diseño. La confiabilidad se expresa en como MTBF (mean time between fairules: tiempo medio entre fallas).</p><p>Un concepto muy relacionado a la confiabilidad y de suma importancia es el de <em>mantenibilidad</em> . Podemos definir la mantenibilidad como:</p><p><img src="https://gsitic.files.wordpress.com/2018/04/mantenibilidad.png?w=825" alt=""></p><p>donde:</p><ul><li>MBTF: tiempo medio entre fallas.</li><li>MTTR: tiempo medio de reparación (mean time to repair).</li></ul><p>Diremos que un sistema es mantenible si permite la detección, análisis, rediseño y corrección de errores fácilmente.</p><p>En tanto la mantenibilidad afecta la viabilidad del sistema en un entorno relativamente constante, la <em>modificabilidad</em> influye en los costos de mantener un sistema viable en condiciones de cambio de requerimientos. La modificabilidad es la posibilidad de realizar modificaciones y extensiones a partes del sistema, o agregar nuevas partes con facilidad (no corrección de errores).</p><p>En estudios realizados se determinó que las organizaciones abocadas al procesamiento de datos invierten aproximadamente un 50% del presupuesto en mantenimiento de los sistemas, involucrando esto corrección de errores y modificaciones, razón por la cual la mantenibilidad y la modificabilidad son dos objetivos primarios en el diseño de software.</p><p>La <em>flexibilidad</em> representa la facilidad de que el mismo sistema pueda realizar variaciones sobre una misma temática, sin necesidad de modificaciones.</p><p>La <em>generalidad</em> expresa el alcance sobre un determinado tema.</p><p>Flexibilidad y generalidad son dos objetivos importantes en el diseño de sistemas del tipo de propósitos generales.</p><p>La <em>utilidad</em> o facilidad de uso es un factor importante que influye en el éxito del sistema y su aceptación por parte del usuario. Un sistema bien diseñado pero con interfaces muy “duras” tiende a ser resistido por los usuarios.</p><p>Finalmente diremos que eficiencia, mantenibilidad, modificabilidad, flexibilidad, generalidad y utilidad, con componentes de la <em>calidad</em> objetiva de un sistema.</p><p>En términos simples también diremos que nuestro objetivo primario es obtener sistemas de <em>costo mínimo</em> . Es decir, es nuestro interés obtener sistemas económicos para desarrollar, operar, mantener y modificar.</p><h3 id="Restricciones-compromisos-y-decisiones-del-Diseno"><a href="#Restricciones-compromisos-y-decisiones-del-Diseno" class="headerlink" title="Restricciones, compromisos y decisiones del Diseño"></a>Restricciones, compromisos y decisiones del Diseño</h3><p>Podemos ver los objetivos técnicos del diseño como constituyendo una “función objetivo” de un problema de optimización, la cual se desea maximizar, sujeta a ciertas restricciones.</p><p>Como regla, las restricciones sobre un proceso de diseño de un sistema, caen en dos categorías: <em>restricciones de desarrollo</em> y <em>restricciones operacionales</em> .</p><p>Las <strong>restricciones de desarrollo</strong> son limitaciones al consumo de recursos durante el período de desarrollo, y pueden ser expresadas en términos generales o descomponerla en sus partes como ser tiempo de máquina y horas/hombre. Dentro de las restricciones de desarrollo, entran también las <em>restricciones de planificación</em> . Estas se refieren a metas y plazos a ser cumplidos (“el módulo X debe terminarse para Febrero”).</p><p>Las <strong>restricciones operacionales</strong> pueden ser expresadas en términos técnicos, como ser máximo tamaño de memoria disponible, máximo tiempo de respuesta aceptable, etc.</p><p>El carácter de muchas decisiones de diseño no fija límites rígidos, si no un intervalo de tolerancia, dentro del cual el diseñador puede moverse a costa de variaciones en otros aspectos del sistema. Por ejemplo se puede priorizar eficiencia, en detrimento de facilidad de mantenimiento, o velocidad de ejecución contra tamaño de memoria utilizada.</p><p>La esencia del diseño en el mundo real y las decisiones inherentes al mismo es obtener una solución de <em>compromiso</em> .</p><p>El diseño total es el resultado acumulativo de un gran número de <em>decisiones técnicas</em> incrementales.</p><h3 id="Principios-utilizados-por-el-Diseno-Estructurado"><a href="#Principios-utilizados-por-el-Diseno-Estructurado" class="headerlink" title="Principios utilizados por el Diseño Estructurado"></a>Principios utilizados por el Diseño Estructurado</h3><p><strong>Abstracción</strong></p><p>La noción psicológica de abstracción permite concentrarse en un problema al mismo nivel de generalización, independientemente de los detalles irrelevantes de bajo nivel. El uso de la abstracción también permite trabajar con conceptos y términos que son familiares al entorno del problema, sin tener que transformarlos a una estructura no familiar.</p><p>Cada paso de un proceso de ingeniería de software es un refinamiento del nivel de abstracción de la solución de software.</p><p>Conforme nos movemos por diferentes niveles de abstracción, trabajamos para crear <em>abstracciones</em> de datos y de procedimientos. Una <em>abstracción procedural</em> es una determinada secuencia de instrucciones que tienen una función limitada y específica.</p><p>Una <em>abstracción de datos</em> es una determina colección de datos que describen un objeto.</p><ul><li><strong>Rumbaugh: O.O. Modeling and Design</strong><br><em>La abstracción es el exámen selectivo de ciertos aspectos de un problema</em> . El objetivo de la abstracción es aislar aquellos aspectos que son importantes para algún propósito y suprimir aquellos aspectos que no son importantes. La abstracción debe realizarse siempre con un propósito, ya que el propósito determina que es y que no es relevante. Muchas abstracciones son posibles sobre una misma cosa, dependiendo de cual sea su propósito.</li><li><strong>Alan Cameron Will (Object Expert Jan/Feb 1996)</strong><br><em>La abstracción, para mí, es cercana a palabras como “teórico”, “esotérico”, “académico”, e “impráctico”. Pero en un sentido en particular, significa la separación de los aspectos más importantes de un determinado problema, del detalle. Este el el único camino que tengo para abordar con mi mente finita cualquier tema complejo</em> .</li></ul><p><strong>Refinamiento sucesivo</strong></p><p>El <em>refinamiento sucesivo</em> es una primera estrategia de diseño descendente propuesta por Niclaus Wirth. La arquitectura de un programa se desarrolla en niveles sucesivos de refinamiento de los detalles procedimentales. Se desarrolla una jerarquía descomponiendo una declaración macroscópica de una función de una forma sucesiva, hasta que se llega a las sentencias del lenguaje de programación.</p><p><strong>Modularidad</strong></p><p>La arquitectura implica modularidad, el software se divide en componentes con nombres y ubicaciones determinados, que se denominan <em>módulos</em> , y que se integran para satisfacer los requisitos del problema.</p><p><strong>Arquitectura del software</strong></p><p>La <em>arquitectura del software</em> se refiere a dos características importantes del software de computadoras:</p><ul><li>la estructura jerárquica de los componentes procedimientales (módulos)</li><li>la estructura de datos</li></ul><p><strong>Jerarquía de control</strong></p><p>La <em>jerarquía de control</em> , también denominada <em>estructura de programa</em> , representa la organización (frecuentemente jerárquica) de los componentes del programa (módulos) e implica una jerarquía de control. No representa aspectos procedimentales del software, tales como secuencias de procesos, o la repetición de operaciones.</p><p><strong>Estructura de datos</strong></p><p>La <em>estructura de datos</em> es una representación de la relación lógica existente entre los elementos individuales de datos. Debido a que la estructura de la información afectará invariablemente al diseño procedimental final, la estructura de datos es tan importante como la estructura del programa en la representación de la arquitectura del software.</p><p><strong>Procedimientos del software</strong></p><p>La estructura del programa define la jerarquía de control, independientemente de las decisiones y secuencias de procesamiento. El procedimiento del software se centra sobre los detalles de procesamiento de cada módulo individual.</p><p>El procedimiento debe proporcionar una especificación precisa del procesamiento, incluyendo la secuencia de sucesos, los puntos concretos de decisiones, la repetición de operaciones, e incluso la organización/estructura de los datos.</p><p><strong>Ocultamiento de la información</strong></p><p>El principio de <em>ocultamiento de la información</em> sugiere que los módulos se han de caracterizar por decisiones de diseño que los oculten unos a otros. Los módulos deben especificarse y diseñarse de forma que la información (procedimientos y datos) contenida dentro de un módulo sea accesible a otros módulos únicamente a través de las <em>interfaces</em> formales establecidas para cada módulo.</p><h2 id="Conceptos-Basicos-de-Diseno-Estructurado"><a href="#Conceptos-Basicos-de-Diseno-Estructurado" class="headerlink" title="Conceptos Básicos de Diseño Estructurado"></a>Conceptos Básicos de Diseño Estructurado</h2><h3 id="Estrategia-del-Diseno-Estructurado"><a href="#Estrategia-del-Diseno-Estructurado" class="headerlink" title="Estrategia del Diseño Estructurado"></a>Estrategia del Diseño Estructurado</h3><p>Cuando se trata con un problema de diseño de reducida envergadura, por ejemplo un sistema que pueda ser desarrollado en un par de semanas,no se tienen mayores problemas, y el desarrollador puede tener todos los elementos del problema “en mente” a la vez. Sin embargo cuando se trabaja en proyectos de gran escala, es difícil que una sola persona sea capaz de llevar todas las tareas y tener en mente todos los elementos a la vez.</p><p>El diseño exitoso se basa en un viejo principio conocido desde los días de Julio César: <em>Divide y conquistarás</em> .</p><p>Específicamente, diremos que el costo de implementación de un sistema de computadora podrá minimizarse cuando pueda separarse en partes:</p><ul><li><em>manejablemente pequeñas</em></li><li><em>solucionables separadamente</em></li></ul><p>Por supuesto la interpretación de manejablemente pequeña varía de persona en persona. Por otro lado muchos intentos de particionar sistemas en pequeñas partes arribaron incrementos en los tiempos de implementación. Esto se debe fundamentalmente al segundo punto: solucionables separadamente. En muchos sistemas para implementar la parte A, debemos conocer algo sobre la B, y para implementar algo de B, debemos conocer algo de C.</p><p>De manera similar, podemos decir que el costo de <em>mantenimiento</em> puede ser minimizado cuando las partes de un sistema son:</p><ul><li><em>fácilmente relacionables con la aplicación</em></li><li><em>manejablemente pequeñas</em></li><li><em>corregibles separadamente</em></li></ul><p>Muchas veces la persona que realiza la modificación no es quien diseñó el sistema. Es importante que las partes de un sistema sean manejablemente pequeñas en orden de simplificar el mantenimiento. Un trabajo de encontrar y corregir un error en una “pieza” de código de 1000 líneas es muy superior a hacerlo con piezas de 20 líneas. No solo disminuye el tiempo de localizar la falla sino que si la modificación es muy engorrosa, puede reescribirse la pieza completamente. Este concepto de “módulos descartables” ha sido utilizado con éxito muchas veces.</p><p>Por otra parte, para minimizar los costos de mantenimiento debemos lograr que cada pieza sea independiente de otra. En otras palabras debemos ser capaces de realizar modificaciones al módulo A sin introducir efectos indeseados en el módulo B.</p><p>Finalmente, diremos que el costo de <em>modificación</em> de un sistema puede minimizarse si sus partes son:</p><ul><li><em>fácilmente relacionables con la aplicación</em></li><li><em>modificables separadamente</em></li></ul><p>En resumen, podemos afirmar lo siguiente: los costos de implementación, mantenimiento y modificación, generalmente serán minimizados cuando <em>cada pieza del sistema corresponda a exactamente una pequeña, bien definida pieza del dominio del problema, y cada relación entre las piezas del sistema corresponde a relaciones entre piezas del dominio del problema</em> .</p><p>En la siguiente figura apreciamos este concepto.</p><p><img src="https://gsitic.files.wordpress.com/2018/04/dominio_problema.png?w=825" alt=""></p><h3 id="Particionamiento-y-Organizacion"><a href="#Particionamiento-y-Organizacion" class="headerlink" title="Particionamiento y Organización"></a>Particionamiento y Organización</h3><p>Un buen diseño estructurado es un ejercicio de particionamiento y organización de los componentes de un sistema.</p><p>Entenderemos por particionamiento, la subdivisión de un problema en subproblemas más pequeños, de tal forma que cada subproblema corresponda a una pieza del sistema. La cuestión es: ¿Dónde y cómo debe dividirse el problema? ¿Qué aspectos del problema deben pertenecer a la misma pieza del sistema, y cuales a distintas piezas? El diseño estructurado responde estas preguntas con dos principios básicos:</p><ul><li><em>Partes del problema altamente interrelacionadas deberán pertenecer a la misma pieza del sistema</em> .</li><li><em>Partes sin relación entre ellas, deben pertenecer a diferentes piezas del sistema sin relación directa</em> .</li></ul><p>Otro aspecto importante del diseño estructurado es la organización del sistema. Debemos decidir como se interrelacionan las partes, y que parte está en relación con cual.</p><p>El objetivo es organizar el sistema de tal forma que no existan piezas más grandes de lo estrictamente necesario para resolver los aspectos del problema que ella abarca. Igualmente importante, es el evitar la introducción de relaciones en el sistema, que no existe en el dominio del problema.</p><h3 id="El-concepto-de-Cajas-Negras"><a href="#El-concepto-de-Cajas-Negras" class="headerlink" title="El concepto de Cajas Negras"></a>El concepto de Cajas Negras</h3><p>Una caja negra es un sistema (o un componente) con entradas conocidas, salidas conocidas, y generalmente transformaciones conocidas, pero del cual no se conoce el contenido en su interior.</p><p>En la vida diaria existe innumerable cantidad de ejemplos de uso cotidiano: una radio, un televisor, un automóvil, son cajas negras que usamos a diario sin conocer (en general) como funciona en su interior. Solo conocemos como controlarlos (entradas) y las respuestas que podemos obtener de los artefactos (salidas).</p><p>El concepto de caja negra utiliza el principio de <em>abstracción</em> .</p><p>Este concepto es de suma utilidad e importancia en la ingeniería en general, y por ende en el desarrollo de software. Lamentablemente muchas veces para poder hacer un uso efectivo de determinado módulo, el diseñador debe revisar su contenido ante posibles contingencias como ser comportamientos no deseados ante determinados valores. Por ejemplo es posible que una rutina haya sido desarrollada para aceptar un determinado rango de valores y falla si se la utiliza con valores fuera de dicho rango, o produce resultados inesperados. Una buena documentación en tales casos, es de utilidad pero no transforma al módulo en una verdadera caja negra. Podríamos hablar en todo caso de “cajas blancas”.</p><p>Los módulos de programas de computadoras pueden variar en un amplio rango de aproximación al ideal de caja negra. En la mayoría de los casos podemos hablar de “cajas grises”.</p><h2 id="La-Estructura-de-los-Programas-de-Computadora"><a href="#La-Estructura-de-los-Programas-de-Computadora" class="headerlink" title="La Estructura de los Programas de Computadora"></a>La Estructura de los Programas de Computadora</h2><h3 id="Diagramas-de-Flujo-y-Diagramas-de-Estructura"><a href="#Diagramas-de-Flujo-y-Diagramas-de-Estructura" class="headerlink" title="Diagramas de Flujo y Diagramas de Estructura"></a>Diagramas de Flujo y Diagramas de Estructura</h3><p>Normalmente los procedimientos se representan con <em>diagramas de flujo</em> (no confundir con diagramas de flujo de datos) los cuales modelan la secuencia de operaciones que realiza el programa a través del tiempo.</p><p>Un <em>diagrama de estructura</em> en cambio no modela la secuencia de ejecución sino la <em>jerarquía de control</em> existente entre los módulos que conforman el programa, independientemente del factor tiempo. Existe un módulo raíz de máximo nivel, del cual dependen los demás, en una estructura arborescente.</p><h3 id="Notacion-de-los-Diagramas-de-Flujo-de-Control"><a href="#Notacion-de-los-Diagramas-de-Flujo-de-Control" class="headerlink" title="Notación de los Diagramas de Flujo de Control"></a>Notación de los Diagramas de Flujo de Control</h3><p><img src="https://gsitic.files.wordpress.com/2018/04/notacion_diagramas_flujo_control.png?w=825" alt=""></p><p><img src="https://gsitic.files.wordpress.com/2018/04/construcciones_estructuradas.png?w=825" alt=""></p><h3 id="Notacion-de-los-Diagramas-de-Estructura"><a href="#Notacion-de-los-Diagramas-de-Estructura" class="headerlink" title="Notación de los Diagramas de Estructura"></a>Notación de los Diagramas de Estructura</h3><p><img src="https://gsitic.files.wordpress.com/2018/04/notacion_diagramas_estructura.png?w=825" alt=""></p><h3 id="Ejemplo-comparativo-entre-Diagramas-de-Procesamiento-y-de-Estructura"><a href="#Ejemplo-comparativo-entre-Diagramas-de-Procesamiento-y-de-Estructura" class="headerlink" title="Ejemplo comparativo entre Diagramas de Procesamiento y de Estructura"></a>Ejemplo comparativo entre Diagramas de Procesamiento y de Estructura</h3><p><img src="https://gsitic.files.wordpress.com/2018/04/diagrama_flujo.png?w=825" alt=""> <img src="https://gsitic.files.wordpress.com/2018/04/diagrama_estructura.png?w=825" alt=""></p><h2 id="Acoplamiento"><a href="#Acoplamiento" class="headerlink" title="Acoplamiento"></a>Acoplamiento</h2><h3 id="Introduccion"><a href="#Introduccion" class="headerlink" title="Introducción"></a>Introducción</h3><p>Muchos aspectos de la modularización pueden ser comprendidos solo si se examinan módulos en relación con otros. En principio veremos el concepto de <em>independencia</em> : diremos que dos módulos son totalmente independientes si ambos pueden funcionar completamente sin la presencia del otro. Esto implica que no existen interconexiones entre los módulos, y que se tiene un valor cero en la escala de “dependencia”.</p><p>En general veremos que a mayor número de interconexiones entre dos módulos, se tiene una menor independencia.</p><p>El concepto de independencia funcional es una derivación directa del de modularidad y de los conceptos de abstracción y ocultamiento de la información.</p><p>La cuestión aquí es: ¿cuánto debe conocerse acerca de un módulo para poder comprender otro módulos? Cuanto más debamos conocer acerca del módulo B para poder comprender el módulo A, menos independientes serán A y B.</p><p>La simple cantidad de conexiones entre módulos, no es una medida completa de la independencia funcional. La dependencia funcional se mide con dos criterios cualitativos: <em>acoplamiento</em> y <em>cohesión</em> . Estudiaremos en principio el primero de ellos.</p><p>Módulos altamente “acoplados” estarán unidos por fuertes interconexiones, módulos débilmente acoplados tendrán pocas y débiles interconexiones, en tanto que los módulos “desacoplados” no tendrán interconexiones entre ellos y serán independientes.</p><blockquote><p>El <em>acoplamiento</em> es un concepto abstracto que nos indica el grado de interdependencia entre módulos.</p></blockquote><p>En la práctica podemos materializarlo como la probabilidad de que en la codificación, depuración, o modificación de un determinado módulo, el programador necesite tomar conocimiento acerca de partes de otro módulo. Si dos módulos están fuertemente acoplados, existe una alta probabilidad de que el programador necesite conocer uno de ellos en orden de intentar realizar modificaciones al otro.</p><p>Claramente, el costo total del sistema se verá fuertemente influenciado por el grado de acoplamiento entre módulos.</p><h3 id="Factores-que-influencian-el-Acoplamiento"><a href="#Factores-que-influencian-el-Acoplamiento" class="headerlink" title="Factores que influencian el Acoplamiento"></a>Factores que influencian el Acoplamiento</h3><p>Los cuatro factores principales que influyen en el acoplamiento entre módulos son:</p><ul><li><em>Tipo de conexión entre módulos</em> : los sistemas normalmente conectados, tienen menor acoplamiento que aquellos que tienen conexiones patológicas.</li><li><em>Complejidad de la interface</em> : está determinada por la cantidad, accesibilidad y estructura de la información que define la interface.</li><li><em>Tipo de flujo de información en la conexión</em> : los sistemas con acoplamiento de datos tienen menor acoplamiento que los sistema con acoplamiento de control y estos a su vez menos que los que tienen acoplamiento híbrido.</li><li><em>Momento en que se produce el ligado de la Conexión</em> : conexiones ligadas a referentes fijos en tiempo de ejecución, resultan con menor acoplamiento que cuando el ligado tiene lugar en tiempo de carga, el cual tiene a su vez menor acoplamiento que cuando el ligado se realiza en tiempo de ligado (link-edición), el cual tiene menos acoplamiento que el que se realiza en tiempo de compilación, todos los que a su vez tiene menos acoplamiento que cuando el ligado se realiza en tiempo de codificación.</li></ul><h3 id="Acoplamiento-en-Entorno-Comun-common-environment-coupling"><a href="#Acoplamiento-en-Entorno-Comun-common-environment-coupling" class="headerlink" title="Acoplamiento en Entorno Común (common-environment coupling)"></a>Acoplamiento en Entorno Común (common-environment coupling)</h3><p>Siempre que dos o más módulos interactúan con un entorno de datos común, se dice que dichos módulos están en <em>acoplamiento por entorno común</em> .</p><p>Ejemplos de entorno común pueden ser áreas de datos globales como la DATA DIVISION de COBOL, un archivo en disco.</p><p>El acoplamiento de entorno común es una forma de acoplamiento de segundo orden, distinto de los tratados anteriormente. La severidad del acoplamiento dependerá de la cantidad de módulos que acceden simultáneamente al entorno común. En el caso extremo de solo dos módulos donde uno utiliza como entrada los datos generados por el otro hablaremos de un acoplamiento de <em>entrada/salida</em> .</p><p>El punto es que el acoplamiento por entorno común no es necesariamente malo y deba ser evitado a toda costa. Por el contrario existen ciertas circunstancias en que es una opción válida.</p><h3 id="Desacoplamiento"><a href="#Desacoplamiento" class="headerlink" title="Desacoplamiento"></a>Desacoplamiento</h3><p>El concepto de acoplamiento invita a un concepto recíproco: <em>desacoplamiento</em> .</p><p>Desacoplamiento es cualquier método sistemático o técnica para hacer más independientes a los módulos de un programa.</p><p>Cada tipo de acoplamiento generalmente sugiere un método de desacoplamiento. Por ejemplo, el acoplamiento causado por ligado, puede desacoplarse cambiando los parámetros apropiados.</p><p>El desacoplamiento desde el punto de vista funcional, rara vez puede realizarse, excepto en los comienzos de la fase del diseño.</p><p>Como regla general, una disciplina de diseño que favorezca el acoplamiento de entrada/salida y el acoplamiento de control por sobre el acoplamiento por contenido y el acoplamiento híbrido, y que busque limitar el alcance del acoplamiento por entorno común es el enfoque más efectivo.</p><p>Otras técnicas para reducir el acoplamiento son:</p><ul><li>Convertir las referencias implícitas en explícitas. Lo que puede verse con mayor facilidad es más fácil de comprender.</li><li>Estandarización de las conexiones.</li><li>Uso de “buffers” para los elementos comunicados en una conexión. Si un módulo puede ser diseñado desde el comienzo asumiendo que un buffer mediará cada corriente de comunicación, las cuestiones temporización, velocidad, frecuencia, etc, dentro de un módulo no afectarán al diseño de otros.</li><li>Localización. Utilizado para reducir el acoplamiento por entorno común. Consiste en dividir el área común en regiones para que los módulos solo tengan acceso a aquellos datos que les son de su estricta incumbencia.</li></ul><h2 id="Cohesion"><a href="#Cohesion" class="headerlink" title="Cohesión"></a>Cohesión</h2><h3 id="Introduccion-Relacion-Funcional"><a href="#Introduccion-Relacion-Funcional" class="headerlink" title="Introducción: Relación Funcional"></a>Introducción: Relación Funcional</h3><p>Hemos visto que la determinación de módulos en un sistema no es arbitraria. La manera en la cual dividimos físicamente un sistema en piezas (particularmente en relación con la estructura del problema) puede afectar significativamente la complejidad estructural del sistema resultante, así como el número total de referencias intermodulares.</p><p>Adaptar el diseño del sistema a la estructura del problema (o estructura de la aplicación, o dominio del problema) es una filosofía de diseño sumamente importante. A menudo encontramos que elementos de procesamiento del dominio del problema altamente relacionados, son trasladados en código altamente interconectado. Las estructuras que agrupan elementos del problema altamente interrelacionados, tienden a ser modularmente efectivas.</p><p>Imaginemos que tengamos una magnitud para medir el grado de relación funcional existente entre pares de módulos. En términos de tal medida, diremos que el sistema más modularmente efectivo será aquel cuya suma de relación funcional entre pares de elementos que pertenezcan a diferentes módulos sea mínima. Entre otras cosas, esto tiende a minimizar el número de conexiones intermodulares requeridas y el acoplamiento intermodular.</p><blockquote><p>Esta relación funcional intramodular se conoce como <em>cohesión</em> . La cohesión es la medida cualitativa de cuan estrechamente relacionados están los elementos internos de un módulo.</p></blockquote><p>Otros términos utilizados frecuentemente son “fuerza modular”, “ligazón” y “funcionalidad”.</p><p>En la práctica un elemento de procesamiento simple aislado, puede estar funcionalmente relacionado en diferentes grados a otros elementos. Como consecuencia, diferentes diseñadores, con diferentes “visiones” o interpretaciones de un mismo problema, pueden obtener diferentes estructuras modulares con diferentes niveles de cohesión y acoplamiento. A esto se suma el inconveniente de que muchas veces es difícil evaluar el grado de relación funcional de un elemento respecto de otro.</p><p>La cohesión modular puede verse como el cemento que amalgama junto a los elementos de procesamiento dentro de un mismo módulo. Es el factor más crucial en el diseño estructurado, y el de mayor importancia en un diseño modular efectivo.</p><p>Este concepto representa la técnica principal que posee un diseñador para mantener su diseño lo más semánticamente próximo al problema real, o dominio del problema.</p><p>Claramente los conceptos de cohesión y acoplamiento están íntimamente relacionados. Un mayor grado de cohesión implica uno menor de acoplamiento. Maximizar el nivel de cohesión intramodular en todo el sistema resulta en una minimización del acoplamiento intermodular.</p><h3 id="Niveles-de-Cohesion"><a href="#Niveles-de-Cohesion" class="headerlink" title="Niveles de Cohesión"></a>Niveles de Cohesión</h3><p>Diferentes principios asociativos fueron desenvolviéndose a través de los años por medio de la experimentación, argumentos teóricos, y la experiencia práctica de muchos diseñadores.</p><p>Existen siete niveles de cohesión distinguibles por siete principios asociativos. Estos se listan a continuación en orden creciente del grado de cohesión, de menor a mayor relación funcional:</p><ul><li>Cohesión Casual (la peor)</li><li>Cohesión Lógica (sigue a la peor)</li><li>Cohesión Temporal (de moderada a pobre)</li><li>Cohesión de Procedimiento (moderada)</li><li>Cohesión de Comunicación (moderada a buena)</li><li>Cohesión Secuencial</li><li>Cohesión Funcional (la mejor)</li></ul><p>Podemos visualizar el grado de cohesión como un espectro que va desde un máximo a un mínimo.</p><p><strong>Cohesión Casual (la peor)</strong></p><p>La <em>cohesión casual</em> ocurre cuando existe poca o ninguna relación entre los elementos de un módulo.</p><p>La cohesión casual establece un punto cero en la escala de cohesión.</p><p>Es muy difícil encontrar módulos puramente casuales. Puede aparecer como resultado de la modularización de un programa ya escrito, en el cual el programador encuentra una determinada secuencia de instruccciones que se repiten de forma aleatoria, y decide por lo tanto agruparlas en una rutina.</p><p>Otro factor que influenció muchas veces la confección de módulos casualmente cohesivos, fue la mala práctica de la programación estructurada, cuando los programadores mal entendían que modularizar consistía en cambiar las sentencias GOTO por llamadas a subrutinas.</p><p>Finalmente diremos que si bien en la práctica es difícil encontrar módulos casualmente cohesivos en su totalidad, es común que tengan elementos casualmente cohesivos. Tal es el caso de operaciones de inicialización y terminación que son puestas juntas en un módulo superior.</p><p>Debemos notar que si bien la cohesión casual no es necesariamente perjudicial (de hecho es preferible un casualmente cohesivo a uno lineal), dificulta las modificaciones y mantenimiento del código.</p><p><strong>Cohesión Lógica (sigue a la peor)</strong></p><p>Los elementos de un módulo están <em>lógicamente</em> asociados si puede pensarse en ellos como pertenecientes a la misma clase lógica de funciones, es decir, aquellas que pueden pensarse como juntas lógicamente.</p><p>Por ejemplo, se puede combinar en un módulo simple todos los elementos de procesamiento que caen en la clase de “entradas”, que abarca todas las operaciones de entrada.</p><p>Podemos tener un módulo que lea desde consola una tarjeta con parámetros de control, registros con transacciones erróneas de un archivo en cinta, registros con transacciones válidas de otro archivo en cinta, y los registros maestros anterior de un archivo en disco. Este módulo que podría llamarse “Lecturas”, y que agrupa todas las operaciones de entrada, es lógicamente cohesivo.</p><p>La cohesión lógica es más fuerte que la casual, debido a que representa un mínimo de asociación entre el problema y los elementos del módulo. Sin embargo podemos ver que un módulo lógicamente cohesivo no realiza una función específica, sino que abarca una serie de funciones.</p><p><strong>Cohesión Temporal (de moderada a pobre)</strong></p><p><em>Temporal cohesión</em> significa que todos los elementos de procesamiento de una colección ocurren en el mismo periodo de tiempo durante la ejecución del sistema. Debido a que dicho procesamiento debe o puede realizarse en el mismo periodo de tiempo, los elementos asociados temporalmente pueden combinarse en un único módulo que los ejecute a la misma vez.</p><p>Existe una relación entre cohesión lógica y la temporal, sin embargo, la primera no implica una relación de tiempo entre los elementos de procesamiento. La cohesión temporal es más fuerte que la cohesión lógica, ya que implica un nivel de relación más: el factor tiempo. Sin embargo la cohesión temporal aún es pobre en nivel de cohesión y acarrea inconvenientes en el mantenimiento y modificación del sistema.</p><p>Un ejemplo común de cohesión temporal son las rutinas de inicialización (start-up) comúnmente encontradas en la mayoría de los programas, donde se leen parámetros de control, se abren archivos, se inicializan variables contadores y acumuladores, etc.</p><p><strong>Cohesión de Procedimiento (moderada)</strong></p><p>Elementos de procesamiento relacionados <em>proceduralmente</em> son elementos de una unidad procedural común. Estos se combinan en un módulo de cohesión procedural. Una unidad procedural común puede ser un proceso de iteración (loop) y de decisión, o una secuencia lineal de pasos. En este último caso la cohesión es baja y es similar a la cohesión temporal, con la diferencia que la cohesión temporal no implica una determinada secuencia de ejecución de los pasos.</p><p>Al igual que en los casos anteriores, para decir que un módulo tiene <em>solo</em> cohesión procedural, los elementos de procesamiento deben ser elementos de alguna iteración, decisión, o secuencia, pero no deben estar vinculados con ningún principio asociativo de orden superior.</p><p>La cohesión procedural asocia elementos de procesamiento sobre la base de sus relaciones algorítmicas o procedurales.</p><p>Este nivel de cohesión comúnmente se tiene como resultado de derivar una estructura modular a partir de modelos de procedimiento como ser diagramas de flujo, o diagramas Nassi-Shneiderman.</p><p><strong>Cohesión de Comunicación (moderada a buena)</strong></p><p>Ninguno de los niveles de cohesión discutidos previamente están fuertemente vinculados a una estructura de problema en particular. <em>Cohesión de Comunicación</em> es el menor nivel en el cual encontramos una relación entre los elementos de procesamiento que es intrínsecamente <em>dependiente del problema.</em></p><p>Decir que un conjunto de elementos de procesamiento están vinculados por comunicación significa que <em>todo los elementos operan sobre el mismo conjunto de datos de entrada o de salida</em> .</p><p><img src="https://gsitic.files.wordpress.com/2018/04/cohesion_comunicacion.png?w=825" alt=""></p><p>En el diagrama de la figura podemos observar que los elementos de procesamiento 1, 2 y 3 están asociados por comunicación sobre la corriente de datos de entrada, en tanto que 2, 3 y 4 se vinculan por los datos de salida.</p><p>Los diagramas de flujo de datos (DFD) son un medio objetivo para determinar si los elementos en un módulo están asociados por comunicación.</p><p>Las relaciones por comunicación presentan un grado de cohesión aceptable.</p><p>La cohesión por comunicación es común en aplicaciones comerciales. Ejemplos típicos pueden ser:</p><ul><li>un módulo que imprima o grabe un archivo de transacciones</li><li>un módulo que reciba datos de diferentes fuentes y los transforme y ensamble en una línea de impresión</li></ul><p><strong>Cohesión Secuencial</strong></p><p>El siguiente nivel de cohesión en la escala es la asociación <em>secuencial</em> . En ella, los datos de salida (resultados) de un elemento de procesamiento sirven como datos de entrada al siguiente elemento de procesamiento.</p><p>En términos de un diagrama de flujo de datos de un problema, la cohesión secuencial combina una cadena lineal de sucesivas transformaciones de datos.</p><p>Este es claramente un principio asociativo relacionado con el dominio del problema.</p><p><strong>Cohesión Funcional (la mejor)</strong></p><p>En el límite superior del espectro de relación funcional encontramos la cohesión funcional. En un módulo completamente funcional, cada elemento de procesamiento, es parte integral de, y esencial para, la realización de una función simple.</p><p>En términos prácticos podemos decir que cohesión funcional es aquella que no es secuencial, por comunicación, por procedimiento, temporal, lógica o casual.</p><p>Los ejemplos más claros y comprensibles provienen del campo de las matemáticas. Un módulo para realizar el cálculo de raíz cuadrada ciertamente será altamente cohesivo, y probablemente, completamente funcional. Es improbable que haya elementos superfluos más allá de los absolutamente esenciales para realizar la función matemática, y es improbable que elementos de procesamiento puedan ser agregados sin alterar el cálculo de alguna forma.</p><p>En contraste, un módulo que calcule la raíz cuadrada y coseno, es improbable que sea enteramente funcional (deben realizarse dos funciones ambiguas).</p><p>En adición a estos ejemplos matemáticos obvios, usualmente podemos reconocer módulos funcionales que son elementales en naturaleza. Un módulo llamado LEER-REGISTRO-MAESTRO o TRATAR-TRANS-TIPO3, presumiblemente serán funcionalmente cohesivos, en cambio TRATAR-TODAS-TRANS presumiblemente realizará más de una función y será lógicamente cohesivo.</p><h3 id="Criterios-para-establecer-el-grado-de-cohesion"><a href="#Criterios-para-establecer-el-grado-de-cohesion" class="headerlink" title="Criterios para establecer el grado de cohesión"></a>Criterios para establecer el grado de cohesión</h3><p>Una técnica útil para determinar si un módulo está acotado funcionalmente, es escribir una frase que describa la función (propósito) del módulo y luego examinar dicha frase. Puede hacerse la siguiente prueba:</p><ol><li>Si la frase resulta ser una sentencia compuesta, contiene una coma, o contiene más de un verbo, probablemente el módulo realiza más de una función: por tanto, probablemente tienen vinculación secuencial o de comunicación.</li><li>Si la frase contiene palabras relativas al tiempo, tales como “primero”, “a continuación”, “entonces”, “después”, “cuando”, “al comienzo”, etc, entonces probablemente el módulo tiene una vinculación secuencial o temporal.</li><li>Si el predicado de la frase no contiene un objeto específico sencillo a continuación del verbo, probablemente el módulo esté acotado lógicamente. Por ejemplo <em>editar todos los datos</em> tiene una vinculación lógica; <em>editar sentencia fuerte</em> puede tener vinculación funcional.</li><li>Palabras tales como “inicializar”, “limpiar”, etc, implican vinculación temporal.</li></ol><p>Los módulos acotados funcionalmente siempre se pueden describir en función de sus elementos usando una sentencia compuesta. Pero si no se puede evitar el lenguaje anterior, siendo aún una descripción completa de la función del módulo, entonces probablemente el módulo no esté acotado funcionalmente.</p><p>Es importante notar que no es necesario determinar el nivel preciso de cohesión. En su lugar, lo importante es intentar conseguir una cohesión alta y saber reconocer la cohesión baja, de forma que se pueda modificar el diseño del software para que disponga de una mayor independencia funcional.</p><p><strong>Árbol de valuación</strong></p><p><img src="https://gsitic.files.wordpress.com/2018/04/arbol_de_evaluacion.png?w=825" alt=""></p><h2 id="Analisis-de-Transformacion"><a href="#Analisis-de-Transformacion" class="headerlink" title="Análisis de Transformación"></a>Análisis de Transformación</h2><h3 id="Introduccion-1"><a href="#Introduccion-1" class="headerlink" title="Introducción"></a>Introducción</h3><blockquote><p>El <em>Análisis de Transformación, o diseño centrado en la transformación</em> , es una estrategia para derivar diseños estructurados que son bastante buenos (con respecto a su modularidad) y que necesitan solo una modesta reestructuración para llegar al diseño final.</p></blockquote><p>Es una forma particular de la estrategia descendente (top-down), que toma ventaja de la perspectiva global. Aplicado rigurosamente, el análisis de transacción conduce a estructuras que son altamente factorizadas. Produce un número variable de módulos en los niveles intermedios de la jerarquía, los cuales representan composición de funciones básicas. Siempre se trata de evitar que los módulos intermedios realicen cualquier “trabajo” excepto el de control y coordinación de sus subordinados.</p><p>El propósito de la estrategia es el de identificar las funciones de procesamiento primarias del sistema, las entradas de alto nivel de dichas funciones, y las salidas de alto nivel. Se crean módulos de alto nivel dentro de la jerarquía que realizan cada una de estas tareas: creación de entradas de alto nivel, transformación de entradas en salidas de alto nivel, y procesamiento de dichas salidas.</p><blockquote><p>El análisis de transformación es un modelo de <em>flujo de información</em> más que un modelo procedural.</p></blockquote><p>La estrategia de análisis de transformación consiste de <strong>cuatro pasos</strong> principales:</p><ol><li>Plantear el problema como un diagrama de flujo de datos.</li><li>Identificar los elementos de datos aferentes y eferentes.<ul><li><em>Datos Aferentes</em> .<br>Son aquellos elementos de datos de alto nivel que habiendo sido removidos de sus entradas físicas, todavía pueden considerarse entradas al sistema.</li><li><em>Datos Eferentes</em> .<br>Son elementos de datos que desde sus salidas física a través de los flujos, hasta que no puedan seguir siendo considerados como datos de salida del sistema.</li></ul></li><li>Factorización del primer nivel.</li><li>Factorización de las ramas aferente, eferente y de transformación.</li></ol><h2 id="Analisis-de-Transaccion"><a href="#Analisis-de-Transaccion" class="headerlink" title="Análisis de Transacción"></a>Análisis de Transacción</h2><h3 id="Introduccion-2"><a href="#Introduccion-2" class="headerlink" title="Introducción"></a>Introducción</h3><p>En el anterior capítulo exploramos la estrategia del análisis de transformación como la estrategia principal para el diseño de programas y sistemas bien estructurados. En verdad, el análisis de transformación, servirá de guía en el diseño de la mayoría de los sistemas. Sin embargo hay numerosas situaciones en las cuales estrategias adicionales pueden utilizarse para suplementar, y aún reemplazar, el enfoque básico del análisis de transformación.</p><p>Una de estas estrategias suplementarias principales se conoce como <em>Análisis de Transacción</em> .</p><p>El análisis de transacción es sugerido por un DFD del siguiente tipo:</p><p><img src="https://gsitic.files.wordpress.com/2018/04/analisis_transaccic3b3n.png?w=825" alt=""></p><p>En este DFD existe una transformación que bifurca la corriente de datos de entrada en varias corrientes de salida discretas. En muchos sistemas tal transformación puede ocurrir dentro de la transformación <em>central</em> . En otros, podremos encontrarla tanto en las ramas aferentes como eferentes del diagrama de estructura.</p><p>La frase análisis de transacción sugiere que construiremos un sistema alrededor del concepto de “transacción”, y para muchos la palabra transacción está asociada con sistemas administrativos. Esto si bien es cierto, es común encontrar centros de transacción en los sistemas administrativos, también pueden encontrarse en otro tipo de sistemas como los de tiempo real, aplicaciones de ingeniería, etc.</p><p>Un factor importante es como definimos el término transacción. En el sentido más general podemos decir:</p><blockquote><p><em>Una transacción es cualquier elemento de datos, control, señal, evento, o cambio de estado, que causa, dispara o inicia alguna acción o secuencia de acciones.</em></p></blockquote><p>Acorde a esta definición, un gran número de situaciones encontradas en aplicaciones de procesamiento de datos comunes pueden ser consideradas transacciones. Por ejemplo cualquiera de los siguientes casos pueden considerarse transacciones:</p><ul><li>El operador presiona el botón de inicio de un dispositivo de entrada.</li><li>Algún tipo de datos de entrada que designe un ingreso en el inventario.</li><li>Un carácter de escape desde una terminal, indicando la necesidad e un procesamiento especial.</li><li>Una interrupción de hardware ante un índice fuera de los rangos definidos dentro de un programa de aplicación.</li><li>Un cuelgue o descuelgue de teléfono para un sistema de control de llamadas telefónicas.</li></ul><h2 id="Bibliografia"><a href="#Bibliografia" class="headerlink" title="Bibliografía"></a>Bibliografía</h2><ul><li><a href="http://exa.unne.edu.ar/informatica/anasistem2/public_html/apuntes/de1.pdf" rel="external nofollow noopener noreferrer" target="_blank">Universidad Tecnológica Nacional – F.R.R.</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Diseno-de-programas-Diseno-estructurado-Analisis-de-transformacion-y-de-transaccion-Cohesion-y-acoplamiento&quot;&gt;&lt;a href=&quot;#Diseno-de-pro
      
    
    </summary>
    
      <category term="B3" scheme="http://localhost:4000/categories/B3/"/>
    
    
  </entry>
  
  <entry>
    <title>B3-T01</title>
    <link href="http://localhost:4000/wiki/B3/b3-t01/"/>
    <id>http://localhost:4000/wiki/B3/b3-t01/</id>
    <published>2019-01-16T15:11:23.000Z</published>
    <updated>2019-01-18T10:45:16.607Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Concepto-del-ciclo-de-vida-de-los-sistemas-y-fases-Modelos-de-ciclo-de-vida"><a href="#Concepto-del-ciclo-de-vida-de-los-sistemas-y-fases-Modelos-de-ciclo-de-vida" class="headerlink" title="Concepto del ciclo de vida de los sistemas y fases. Modelos de ciclo de vida."></a>Concepto del ciclo de vida de los sistemas y fases. Modelos de ciclo de vida.</h1><h2 id="Introduccion"><a href="#Introduccion" class="headerlink" title="Introducción"></a>Introducción</h2><p>En este tema se va a dar una visión de lo que se llama ciclo de vida del software, así como distintos modelos de representación del mismo.</p><p>¿Para qué un ciclo de vida? En un departamento de sistemas de información de una empresa es necesario establecer lo que llamamos un marca de referencia común que pueda ser empleado por todas las personas que participan en el desarrollo de un proyecto informático: directivos, consultores externos e internos, jefes de proyecto, analistas, programadores, usuarios, etc.</p><p>En este marco de referencia deben estar claramente definidos los procesos, actividades y tareas a desarrollar.</p><p>Veamos primeramente dos definiciones publicadas por dos organismos internacionales:</p><ul><li>Norma IEEE 1074: Se entiende por ciclo de vida del software una aproximación lógica a la adquisición, el suministro, el desarrollo, la explotación y el mantenimiento software.</li><li>Norma ISO 12207-1: Se entiende por modelo de ciclo de vida un marco de referencia que contiene los procesos, las actividades y las tareas involucradas en el desarrollo, la explotación y el mantenimiento de un producto de software, abarcando la vida del sistema desde la definición de requisitos hasta la finalización de su uso.</li></ul><h3 id="La-Evolucion-del-Software"><a href="#La-Evolucion-del-Software" class="headerlink" title="La Evolución del Software"></a>La Evolución del Software</h3><p>El concepto de ciclo de vida se utilizó para modelar el proceso de ingeniería del software que, a su vez, apareció como solución a la llamada “crisis del software”.</p><p>Veamos un poco de historia. El desarrollo del software ha ido en paralelo con la evolución de los sistemas informáticos, los cuales han ido mejorando notablemente debido al aumento de la potencia del hardware, a la reducción de su tamaño y la disminución de su coste económico.</p><p>Siguiendo a Presmann podemos distinguir las siguientes etapas en la evolución del software:</p><ul><li>1ª Etapa: Primeros años de la informática (1950-1965). El hardware sufrió numerosos cambios. Se desarrollaba software sin planificación y sin metodologías sistemáticas. En casi todos los sistemas se utilizaba programación en “batch”. La mayoría del software era desarrollado y utilizado por la misma persona.</li><li>2ª Etapa: (1965-1975). Aparición de la multiprogramación y de los sistemas multiusuarios. Como consecuencia de la interactividad de los sistemas aparecen nuevos tipos de aplicaciones. Surgen, asimismo, los sistemas de tiempo real. También los primeros gestores de BD.</li><li>3ª Etapa: (1975-1985). Aparecen los sistemas distribuidos, redes de área local LAN y de área global WAN. Hay una fuerte presión sobre los desarrolladores de software. Los ordenadores personales impulsan el crecimiento de muchas compañías de software.</li><li>4ª Etapa: (1985- ). Tecnologías de cuarta generación. Tecnologías orientadas a objetos.</li></ul><h3 id="Caracteristicas-especiales-del-Software"><a href="#Caracteristicas-especiales-del-Software" class="headerlink" title="Características especiales del Software"></a>Características especiales del Software</h3><p>Existen características propias del software que lo diferencian de otros productos:</p><ul><li>El software no se fabrica en un sentido clásico, sino que se desarrolla: Si bien existen similitudes con la fabricación del hardware, se trata de actividades fundamentalmente diferentes. Tanto en una como en otra la buena calidad se adquiere mediante un buen diseño pero la fabricación del hardware es muy diferente de la del software y puede introducir problemas de calidad que no existen o son fácilmente corregibles en el software. Ambas actividades requieren la construcción de un produce pero con métodos muy diferentes. Los costes del desarrollo del software están en la ingeniería por lo que no se pueden gestionar como si fueran clásicos proyectos de fabricación.</li><li>El software no se “estropea”: El hardware se deteriora con el paso del tiempo y con el uso. Los errores no detectados del software provocarán fallos al principio de su vida. Sin embargo, una vez corregidos deberían desaparecer los fallos y no aparecer nuevos. No obstante la realidad suele ser diferente. El software sufre a lo largo de su vida modificaciones y al introducir estos cambios suelen producirse nuevos fallos que, a su vez, tienen que ser corregidos y así sucesivamente.</li><li>La mayor parte del software se construye a medida, en lugar de ensamblar componentes como hace la industria: En la fabricación del hardware, la reutilización de componentes es una parte natural del proceso de ingeniería. En el mundo del software es algo que sólo ha comenzado a lograrse recientemente.</li></ul><h3 id="La-“Crisis-del-Software”"><a href="#La-“Crisis-del-Software”" class="headerlink" title="La “Crisis del Software”"></a>La “Crisis del Software”</h3><p>Desde que se empezó a desarrollar software a gran escala empezaron a ser comunes una serie de problemas:</p><ul><li>La planificación resultaba ser muy imprecisa. Los plazos de entrega eran superados en la mayoría de los casos.</li><li>El coste final de los proyectos era frecuentemente mucho mayor que el previsto.</li><li>La productividad era muy baja.</li><li>La calidad el producto entregado era, asimismo, muy baja.</li><li>El cliente solía quedar insatisfecho del producto.</li><li>El software era difícil de mantener.</li></ul><p>Hay que añadir que el conjunto de problemas encontrados en el desarrollo del software no se limitan al software que “no funciona correctamente”. La llamada crisis abarca los problemas asociados a cómo desarrollar software, como mantener el volumen cada vez mayor de software existente y cómo poder mantenernos al corriente de la demanda creciente de software.</p><h3 id="Ingenieria-del-Software"><a href="#Ingenieria-del-Software" class="headerlink" title="Ingeniería del Software"></a>Ingeniería del Software</h3><p>La ingeniería del Software surge de la necesidad de sistematizar el desarrollo del software afectado por la llamada “crisis del software”, aplicando principios de ingeniería para poder obtener software de calidad.</p><p>¿Qué es software de calidad? Si asumimos que el software cumple con la funcionalidad requerida, para que sea de calidad deberá tener las siguientes características:</p><ul><li>El software debe ser mantenible. Deberá estar escrito y documentado de forma tal que las modificaciones se puedan realizar con el menor coste posible. Esto es fundamental ya que la mayor parte del coste asociado del software se produce después de su puesta en funcionamiento.</li><li>El software debe ser fiable. Es decir, debe comportarse como esperan los usuarios y no debe fallar más de lo permitido por la especificación.</li><li>El software debe ser eficiente.</li><li>Debe ofrecer una interfaz de usuario apropiada.</li></ul><h2 id="Concepto-del-Ciclo-de-Vida-y-Fases"><a href="#Concepto-del-Ciclo-de-Vida-y-Fases" class="headerlink" title="Concepto del Ciclo de Vida y Fases"></a>Concepto del Ciclo de Vida y Fases</h2><p>Podemos definir ciclo de vida de un sistema de información como el conjunto de etapas por las que atraviesa el sistema desde su concepción, hasta su retirada de servicio pasando por su desarrollo y explotación.</p><p>A veces también se habla de “ciclo de desarrollo”, que es un subconjunto del anterior que empieza en el análisis y finaliza con la entrega del sistema al usuario.</p><p>Existen diferentes modelos de ciclo de vida o sea distintas pautas a seguir en el desarrollo de los sistemas de información. Más adelante estudiaremos dos, el llamado modelo clásico o en cascada y el modelo en espiral.</p><p>Tres son los objetivos básicos que cualquier modelo de ciclo de vida debe cubrir:</p><ul><li>Definir las actividades a realizar y su orden.</li><li>Asegurar la consistencia con el resto de los sistemas de información de la organización.</li><li>Proporcionar puntos de control para la gestión del proyecto (presupuesto y calendario).</li></ul><h3 id="Procesos-del-Ciclo-de-Vida-Software"><a href="#Procesos-del-Ciclo-de-Vida-Software" class="headerlink" title="Procesos del Ciclo de Vida Software"></a>Procesos del Ciclo de Vida Software</h3><p>Según la Norma ISO 12207-1, las actividades a realizar durante el ciclo de vida del software se agrupan en cinco procesos principales, ocho procesos de soporte y cuatro procesos de la organización, así como un proceso especial que permite adaptar el ciclo de vida a cada proyecto en concreto.</p><p>A destacar que la norma no recomienda ningún modelo concreto de ciclo de vida, ni de gestión del software, ni detalla cómo realizar ninguna de las actividades.</p><p><img src="https://gsitic.files.wordpress.com/2018/01/proceso_ciclo_vida_software.png?w=825" alt=""></p><h3 id="Procesos-Principales"><a href="#Procesos-Principales" class="headerlink" title="Procesos Principales"></a>Procesos Principales</h3><p>Son aquellos que resultan útiles a las personas que inician o realizan el desarrollo, la explotación o el mantenimiento del software a lo largo del ciclo de vida. Estas personas son los compradores, los proveedores, el personal de desarrollo, los usuarios y el personal encargado del mantenimiento del software.</p><ul><li><strong>Proceso de adquisición</strong> : Contiene las actividades y tareas que el comprador, el cliente o el usuario realizan para adquirir un sistema o un producto software. Aquí están incluidos la preparación y publicación de una solicitud de ofertas, la selección del proveedor del software y la correspondiente gestión de los procesos desde la adquisición hasta la aceptación del producto.</li><li><strong>Proceso de suministro</strong> : Contiene las actividades y tareas que el suministrador o proveedor realiza. Comienzan con la preparación de una propuesta para responder a una petición de oferta de un comprador o con la firma de un contrato con el comprador para proporcionarle un producto software. Trata, asimismo de la identificación de los procedimientos y de los recursos necesarios para gestionar y garantizar el éxito del proyecto, incluyendo el desarrollo de los planes del proyecto y la ejecución de dichos planes hasta la entrega del producto software al comprador.</li><li><strong>Proceso de desarrollo</strong> : Contiene las actividades de análisis de requisitos, diseño, codificación, integración, pruebas e instalación y aceptación. Vamos a resumir someramente estas actividades:<ul><li><em>Análisis de requisitos del sistema</em> : Aquí son especificados todos los requisitos del Sistema de Información, funciones y capacidades que debe cumplir, requisitos de seguridad, interfaces, de mantenimiento, etc.</li><li><em>Diseño de la arquitectura del sistema</em> : Se identifican los principales componentes hardware y software.</li><li><em>Análisis de los requisitos de software</em> : Se establecen dichos requisitos, incluyendo el nivel de calidad que debe cumplir el sistema.</li><li><em>Diseño de la arquitectura del software</em> : El diseñador debe transformar el análisis anterior en una arquitectura en la que se puedan identificar sus componentes principales.</li><li><em>Diseño detallado del software</em> : Aquí se realiza un diseño detallado de cada componente software, de las BD y manuales de usuario.</li><li><em>Codificación y pruebas unitarias</em> : Se desarrollan y se documentan los componentes del punto anterior. Finalmente se realizan las pruebas unitarias de cada uno de ellos para asegurarse de que cumplen los requisitos exigidos.</li><li><em>Pruebas de integración</em> : Se integran los componentes del software realizando las correspondientes pruebas.</li><li><em>Prueba del software</em> : Las pruebas se planifican y diseñan de forma sistemática para poder detectar el máximo número y variedad de defectos con el mínimo consumo de tiempo y esfuerzo.</li><li><em>Integración del sistema</em> : Aquí se realizan las pruebas conjuntas de los elementos hardware y software.</li><li><em>Implantación del software desarrollado en el entorno de explotación final</em> . Cuando se sustituya a un software ya existente, puede ser recomendable un período de tiempo en el que convivan los dos sistemas.</li><li><em>Proceso de aceptación del software</em> .</li></ul></li><li><strong>Proceso de explotación</strong> : Comprende la propia explotación del software y el soporte operativo a los usuarios del sistema.</li><li><strong>Proceso de mantenimiento</strong> : Aparece cuando, tarde o temprano, el software requiere modificaciones, bien por errores, necesidades de mejora, etc.</li></ul><h3 id="Procesos-de-Soporte"><a href="#Procesos-de-Soporte" class="headerlink" title="Procesos de Soporte"></a>Procesos de Soporte</h3><p>Sirven de apoyo al resto de procesos y pueden aplicarse en cualquier punto del ciclo de vida.</p><ul><li><strong>Proceso de documentación</strong> : Comprende todas las actividades que permiten desarrollar, distribuir y mantener la documentación necesaria para todas las personas involucradas: consultores, jefes de proyecto, analistas, programadores, usuarios, etc.</li><li><strong>Proceso de gestión de la configuración</strong> : Controla las modificaciones y las versiones de los elementos de configuración del software del sistema.</li><li><strong>Proceso de aseguramiento de la calidad</strong> : Comprueba que los procesos y los productos software del ciclo de vida cumplen con los requisitos especificados y se ajustan a los plantes establecidos.</li><li><strong>Proceso de verificación</strong> : El objetivo es demostrar la consistencia, completitud y corrección del software entre las fases del ciclo de desarrollo de un proyecto (por ejemplo, si el código es coherente con el diseño). Este proceso puede ser responsabilidad de una empresa de servicios y, en este caso se conoce como proceso de verificación independiente.</li><li><strong>Proceso de validación</strong> : El objetivo es determinar la corrección del producto final respecto a las necesidades del usuario. Al igual que el anterior, este proceso puede ser ejecutado por una organización de servicios, denominándose proceso de validación independiente.</li><li><strong>Proceso de revisión conjunta</strong> : Para evaluar el estado del software y sus productos en una determinada actividad del ciclo de vida o una fase de un proyecto. Las revisiones conjuntas se celebran tanto a nivel de gestión como a nivel técnico del proyecto a lo largo de todo su ciclo de vida. Un mecanismo habitual de revisión son las reuniones y la responsabilidad es generalmente compartida entre un grupo de personas pertenecientes a la organización.</li><li><strong>Proceso de auditoría</strong> : Permite determinar, en los hitos preestablecidos, si se han cumplido los requisitos, los planes y, en suma, el contrato.</li><li><strong>Proceso de resolución de problemas</strong> : Permite analizar y solucionar los problemas, sean éstos diferencias con los requisitos o con el contrato. Aporta un medio oportuno y documentado para asegurar que los problemas detectados son analizados y solucionados.</li></ul><h3 id="Procesos-de-la-Organizacion"><a href="#Procesos-de-la-Organizacion" class="headerlink" title="Procesos de la Organización"></a>Procesos de la Organización</h3><p>Son los utilizados por una organización para llevar a cabo funciones como la gestión, formación del personal o procesos de mejora continua.</p><ul><li><strong>Proceso de gestión</strong> : Contiene las actividades y las tareas genéricas que puede emplear una organización que tenga que gestionar sus procesos. Incluye actividades como la planificación, el seguimiento y control, la revisión y evaluación.</li><li><strong>Proceso de infraestructura</strong> : Establece la infraestructura necesaria para cualquier otro proceso: hardware, software, herramientas, técnicas, etc para el desarrollo, explotación y mantenimiento.</li><li><strong>Proceso de mejora</strong> : Para mejorar los procesos del ciclo de vida del software.</li><li><strong>Proceso de formación</strong> : Para mantener al personal con la adecuada formación, lo que conlleva el desarrollo del material de formación, así como la implementación del plan de formación de la organización.</li></ul><h3 id="Proceso-de-Adaptacion"><a href="#Proceso-de-Adaptacion" class="headerlink" title="Proceso de Adaptación"></a>Proceso de Adaptación</h3><p>Sirve para realizar la adaptación básica de la norma ISO 12207-1 respecto a los proyectos software. Como es sabido, las variaciones en las políticas y procedimientos de la organización, los métodos y estrategias de adquisición, el tamaño y complejidad de los proyectos, los requisitos del sistema y los métodos de desarrollo, entre otros, influencian la forma de adquirir, desarrollar, explotar o mantener un sistema.</p><p>Dado que los procesos se aplican durante el ciclo de vida del software, y además se utilizan de diferentes formas por las diferentes organizaciones y con distintos puntos de vista y objetivos, es preciso comprender los procesos, las organizaciones y sus relaciones bajo diferentes puntos de vista:</p><ul><li>Contrato: El comprador y el proveedor negocian y firman el contrato, empleando los procesos de adquisición y suministro.</li><li>Gestión o dirección: El comprador, el proveedor, el desarrollador, el operador y el personal de mantenimiento gestionan sus respectivos procesos en el proyecto software.</li><li>Explotación: El operador proporciona el servicio de explotación del software a los usuarios.</li><li>Ingeniería: El desarrollador o el personal de mantenimiento llevan a cabo sus respectivas tareas de ingeniería para producir o modificar los productos de software.</li><li>Soporte: Los grupos de soporte (el de gestión de la configuración, el de aseguramiento de la calidad, el de auditoría, etc) proporcionan servicios de apoyo a otros grupos en el cumplimiento de tareas únicas y específicas.</li></ul><h2 id="Modelo-en-Cascada"><a href="#Modelo-en-Cascada" class="headerlink" title="Modelo en Cascada"></a>Modelo en Cascada</h2><p>Este modelo nació durante los años setenta y supuso un gran avance con respecto a los modelos que habían sido utilizados hasta entonces. Este modelo se compone de una serie de fases que se suceden secuencialmente, generándose en cada una de las fases resultados que constituyen la entrada de la fase siguiente. Estas fases pueden diferir, pero suelen comprender:</p><ul><li>Planificación</li><li>Especificación de Requisitos</li><li>Diseño</li><li>Codificación</li><li>Pruebas e Integración</li><li>Implantación y Aceptación</li><li>Mantenimiento</li></ul><p>La fase de especificación de requisitos es conocida también como análisis funcional, la fase de diseño se denomina análisis orgánico y la fase de codificación se llama programación.</p><p>El número de fases es irrelevante, lo que caracteriza verdaderamente a este modelo es la secuencialidad entre las fases y la necesidad de completar cada una de ellas para pasar a la siguiente. El sistema está terminado cuando se han realizado todas las fases.</p><p>El modelo en cascada ayudó a eliminar muchos de los problemas que se planteaban antes de su utilización, además ha sido la base para la normalización y la adopción de estándares. A medida que ha sido utilizado se han detectado en él debilidades e inconsistencias que se han intentado corregir con diversas modificaciones y extensiones al modelo inicial.</p><h3 id="Fases-del-Modelo-en-Cascada"><a href="#Fases-del-Modelo-en-Cascada" class="headerlink" title="Fases del Modelo en Cascada"></a>Fases del Modelo en Cascada</h3><p>Vamos a analizar cada una de las posibles fases:</p><p><strong>Planificación</strong></p><p>De esta fase depende en gran medida un desarrollo efectivo en lo referente a costos y plazos de entrega.</p><p>Hay que fijar los siguientes puntos:</p><ul><li>Ámbito del trabajo a realizar.</li><li>Recursos necesarios.</li><li>Tareas a realizar.</li><li>Referencias a considerar.</li><li>Coste aproximado del desarrollo del proyecto.</li><li>Formación del equipo de desarrollo.</li><li>Ordenación y calendario de las actividades.</li></ul><p>La planificación se llevará a cabo con un nivel de detalle adecuado a la complejidad, tamaño y grado de estructuración del proyecto. Para proyectos de gran tamaño la planificación es imprescindible y en ocasiones sirve para determinar el modelo de ciclo de vida a seguir en el proyecto.</p><p>La estimación de recursos, costes y calendario se determina a partir de la experiencia acumulada por parte del jefe de proyecto y de la información histórica de otros proyectos realizados dentro o fuera de la organización. Esta es una de las fases más difíciles de realizar, pero en la actualidad se cuenta con técnicas y herramientas automatizadas para el control y la gestión del proceso de producción de los sistemas de información.</p><p><strong>Especificación de Requisitos – Análisis Funcional</strong></p><p>Una vez terminada la planificación del proyecto, la fase de análisis de requisitos es la primera del proceso de desarrollo del sistema. En esta fase es preciso analizar, entender y documentar el problema que el usuario trata de resolver con el sistema de información o aplicación a desarrollar.</p><p>Es necesario especificar en detalle las funciones, objetivos y restricciones del sistema propuesto para que el usuario y los desarrolladores puedan tomar estas especificaciones como punto de partida para acometer el resto del sistema.</p><p>El proceso de recogida de requisitos es la tarea más delicada de esta fase en la cual el analista del sistema debe llegar a comprender el dominio de la información y adaptar las necesidades del usuario a unas especificaciones formales listas para poder ser utilizadas por los desarrolladores.</p><p>Se trata de definir “qué” debe hacer el sistema identificando la información a procesar, las funciones a realizar, el rendimiento deseado del sistema, las interfaces con otros sistemas o las restricciones de diseño entre otros aspectos. Es fundamental en esta fase la participación e implicación del usuario del sistema.</p><p>Para el análisis de las necesidades a cubrir y los requisitos a satisfacer por el sistema, su priorización, comprobar que el sistema se ajusta a las necesidades del usuario y plantear alternativas viables no solo a nivel técnico sino desde el punto de vista de costes y riesgos, hay que utilizar todas aquellas técnicas o elementos a nuestro alcance como, por ejemplo, realización de entrevistas con los usuarios, utilización de información referente al sistema actual si es que existe, utilización de técnicas de diagramación para facilitar la comprensión del sistema, técnicas de análisis coste-beneficio, técnicas de prototipado rápido o técnicas de análisis estructurado.</p><p>Las tareas asociadas a esta fase y los resultados que se obtienen serán independientes del entorno tecnológico del sistema de información.</p><p><strong>Diseño – Análisis Orgánico</strong></p><p>A partir, como siempre, de las especificaciones de la fase anterior y una vez elegida la mejor alternativa, se debe comenzar a crear la solución al problema descrito atendiendo a aspectos de interfaz de usuario, estructura del sistema y de decisiones sobre la implantación posterior.</p><p>Esta fase aborda el “cómo”, es decir, deberá diseñar las estructuras de datos, la arquitectura del sistema, los detalles que permitan la codificación posterior y las pruebas a realizar.</p><p>Para el diseño del sistema habrá que trasladar las especificación de requisitos a un conjunto de representaciones ya sean gráficas, tabulares o basadas en lenguajes que constituirán la estructura de datos lógica y física, la arquitectura y los procedimientos.</p><p>Otras cuestiones que se abordan en esta fase son los requisitos de comunicaciones, algoritmos, seguridad y control. Al igual que en las fases anteriores la de diseño conlleva una documentación en la que se recogen sus resultados. En esta fase hay que tener en cuenta el entorno del sistema referente a hardware y software de base.</p><p><strong>Codificación – Programación</strong></p><p>En esta fase se traducen las especificaciones de diseño a un lenguaje de programación capaz de ser interpretado y ejecutado por el ordenador. Existen lenguajes de distintos grados de complejidad o eficacia y la utilización de uno u otro determinará la forma de trabajo de esta fase. En todo caso, el lenguaje vendrá determinado por el entorno lógico del sistema.</p><p>El programador deberá velar por la claridad de su estilo para facilitar cualquier interpretación posterior de los programas. Asimismo se respetarán los estándares de la organización en cuanto a nomenclatura y formato. Es imprescindible que los programas incorporen comentarios escritos que ayuden a su comprensión y que se acompañen de la documentación externa necesaria que describa su objeto, los algoritmos que incluye, sus entradas y salidas y cualquier otro elemento relevante.</p><p>Muchas son las técnicas aplicables a la programación, como, por ejemplo, las técnicas estructuradas ampliamente extendidas desde hace años. Más reciente es la generación automática de código, que a partir de especificaciones formales algunas herramientas CASE (Computed Aided Software Engineering) facilitan con un mayor o menor grado de optimización, según los casos, código en los lenguajes de programación más utilizados.</p><p><strong>Pruebas e Integración</strong></p><p>Una vez que los programas han sido desarrollados, es preciso llevar a cabo las pruebas necesarias para asegurar la corrección de la lógica interna de los mismos y comprobar que cubren las funcionalidades previstas.</p><p>La integración de las distintas partes que componen la aplicación o el sistema es precisa en proyectos complejos o de grandes dimensiones que hayan sido descompuestos por razones de facilidad de gestión y control. La integración debe solucionar posibles problemas de interacción y garantizar el buen funcionamiento del conjunto.</p><p>En esta fase se debe proporcionar la documentación que ilustre los procedimientos de usuario en la utilización y funcionamiento del sistema y si fuera preciso se organiza un plan de formación para usuarios con el material didáctico necesario.</p><p>Como en las fases anteriores existen técnicas y herramientas para la realización de las tareas de esta fase.</p><p><strong>Implantación y Aceptación</strong></p><p>En esta fase se trata de conseguir la aceptación final del sistema por parte de los usuarios del mismo y llevar a cabo las actividades necesarias para su puesta en producción.</p><p>Para ello se tomarán como punto de partida los componentes del sistema probados de forma unitaria e integrada en la fase anterior y se probarán una vez más esta vez con el fin de verificar que cumplen los requisitos de usuario y que el sistema es capaz de manipular los volúmenes de información requeridos en los tiempos y velocidades deseados, que las interfaces con otros sistemas funcionan, etc.</p><p>En estas pruebas participará el usuario que si está conforme deberá aceptar formalmente el sistema.</p><p><strong>Mantenimiento</strong></p><p>Esta fase comienza una vez que el sistema es entregado al usuario y continúa mientras permanece activa su vida útil. El mantenimiento puede venir propiciado por:</p><ul><li>Errores no detectados previamente.</li><li>Modificaciones, mejoras o ampliaciones solicitadas por los usuarios.</li><li>Adaptaciones requeridas por la evolución del entorno tecnológico o cambios normativos.</li></ul><p>En el primer caso se habla de mantenimiento “correctivo” puesto que debe solventar defectos en el sistema. El segundo caso se denomina mantenimiento “perfectivo” puesto que se produce una modificación de los requisitos iniciales aumentando las funcionalidades. El último de los casos se conoce por mantenimiento “adaptativo”, con el paso del tiempo es muy posible que la situación inicial respecto de la cual se concibió el sistema cambie.</p><p>Para la realización del mantenimiento se siguen los mismos pasos que para la realización del sistema, pero en el contexto de un sistema existente. Es fundamental que las variaciones producidas en esta fase queden reflejadas en todas las fases anteriores y no simplemente en la fase de codificación. De lo contrario esta práctica conduciría a sistemas intratables al cabo de varias modificaciones sin actualización de la documentación afectada.</p><p>La fase de mantenimiento lleva asociada su propia documentación reflejando los cambios, su objeto, la fecha, el autor y cualquier dato que pueda ayudar al control de dichos cambios o a procesos de mantenimiento posteriores.</p><h3 id="La-Documentacion"><a href="#La-Documentacion" class="headerlink" title="La Documentación"></a>La Documentación</h3><p>El modelo de ciclo de vida en cascada está regido por la documentación, es decir, la decisión del paso de una fase a la siguiente se toma en función de si la documentación asociada a esa fase está completa o no.</p><p>El concepto de documentación debe entenderse en sentido amplio como todos los productos resultantes de las tareas realizadas en cada fase ya sean informes, programas, juegos de pruebas, etc, se podría definir la documentación como aquello que se construye y ha de mantenerse durante la vida del sistema.</p><p>A pesar de posibles críticas a esta orientación se recogen a continuación las características que deben incluir los documentos asociados a cada fase. No hay que olvidar que el objetivo final es construir con éxito un sistema de información y que la documentación nos ayudará a conseguirlo pero no es un fin en sí misma.</p><p>En la fase de planificación se elaborará documentación que tendrá el carácter de marco básico de referencia del proyecto y deberá incluir:</p><ul><li>Descripción y alcance de las tareas que se van a llevar a cabo.</li><li>Identificación de los principales métodos, instrumentos y procedimientos de trabajo que se utilizarán.</li><li>Procedimientos de seguimiento y control de los trabajos y mecanismos de revisión y aprobación de los mismos.</li><li>Calendario de tareas y su ordenación temporal.</li><li>Asignación de recursos.</li><li>Organización de las personas que intervienen en el proyecto.</li></ul><p>En la fase de especificación de requisitos será necesaria la existencia de documentación en el que se recojan las necesidades del usuario respecto al sistema: funcionalidades, rendimientos, limitaciones y restricciones, los interfaces de usuario. La descripción de los requisitos de los usuario debe ser descrita de forma que se pueda verificar su cumplimiento mediante inspecciones o pruebas. Este documento reflejará el punto de vista del analista del sistema respecto de las especificaciones que el usuario ha realizado, si la comprensión por parte del analista no es adecuada el usuario debe rechazar el documento. Este documento es crucial porque sobre sus presupuestos se construirá el sistema de información, por tanto se detallará la naturaleza de la información, su contenido y su estructura lógica. La representación de las operaciones y procesos, sus entradas y salidas y cualquier característica relevante a nivel funcional referente al entorno tecnológico del sistema.</p><p>En la documentación asociada a la fase de diseño se profundizará más, llegando a describir los componentes del sistema: estructuras de datos, unidades de tratamiento o módulos de procesamiento e interfaces al máximo nivel de detalle. Se concretará la descripción técnica y cuestiones relacionadas con la implantación del sistema: arquitectura general, fichero y/o BD, pantallas, informes o comunicaciones con otros sistemas.</p><p>La fase de codificación debe proporcionar como documentación, el código fuente de todos los módulos incluidas las funciones auxiliares, el código para la creación de estructuras de datos e interfaces externas y cualquier tipo de módulos o rutinas relacionadas con el sistema. Además del código de cada módulo en el soporte físico y formato de representación previamente establecido por el usuario, se acompañará el listado del código con sus comentarios internos y comentarios externos sobre la definición de las estructuras de datos, de los algoritmos, sobre el manejo de excepciones y la gestión de errores.</p><p>La fase de pruebas e integración llevará documentación que describa el plan de pruebas a nivel unitario e integrado y los resultados de dichas pruebas. La fase de implantación y aceptación vendrá documentada con el plan de pruebas del sistema a nivel global y sus resultados. Por último si se realizan modificaciones en la fase de mantenimiento deberán reflejarse en la documentación correspondiente que haya podido ser afectada.</p><p>La documentación asociada al sistema no estaría completa sin un manual de usuario que contenga la descripción funcional de todos los procedimientos para facilitar la operativa del sistema al usuario. Recogerá los procedimientos de instalación, administración y gestión de la configuración, operaciones especiales, funcionamiento, ayudas incorporadas, tratamiento de errores, comandos y sentencias de control. A veces también puede incluir una guía de referencia rápida con el resumen de todas estas instrucciones.</p><h3 id="Critica-del-Modelo"><a href="#Critica-del-Modelo" class="headerlink" title="Crítica del Modelo"></a>Crítica del Modelo</h3><p>Las principales críticas al modelo se centran en sus características básicas, es decir, secuencialidad y utilización de los resultados de una fase para acometer la siguiente de modo que el sistema sólo se puede validar cuando está terminado.</p><p>Los proyectos reales raramente siguen el flujo secuencial que propone el modelo. Siempre ocurren interacciones y en las últimas fases sobre todo se pueden realizar en paralelo algunas áreas como por ejemplo: codificación y pruebas. Una aplicación del modelo en sentido estricto obligaría a la “congelación” de los requisitos de los usuarios, supuesto este completamente alejado de la realidad. El modelo no contempla la posibilidad de realimentación entre fases.</p><p>El modelo en su formulación pura no prevé revisiones o validaciones intermedias por parte del usuario, así los resultados de los trabajos sólo se ven al final de una serie de tareas y fases de tal forma que si se ha producido un error en las primeras fases éste sólo se detectará al final y su corrección tendrá un costo muy elevado, puesto que será preciso rehacer todo el trabajo desde el principio. El modelo no dispone de resultados parciales que permitan validar si el sistema cumple con los requisitos desde las primeras fases, dándose el caso de sistemas perfectamente formalizados y documentados que no cumplen los requisitos del usuario.</p><h3 id="Extensiones-al-Modelo-en-Cascada"><a href="#Extensiones-al-Modelo-en-Cascada" class="headerlink" title="Extensiones al Modelo en Cascada"></a>Extensiones al Modelo en Cascada</h3><p>Actualmente, después de la experiencia obtenida con la aplicación del modelo en cascada y gracias a avances tecnológicos como por ejemplo lenguajes de cuarta generación o herramientas CASE existen modelos de ciclo de vida alternativos al modelo en cascada. En la práctica se llegan a realizar incluso modelos mixtos. En este punto no se tratarán estos casos, sino que se citarán algunas innovaciones aplicables al modelo en cascada que permiten mejorar algunas de las deficiencias del modelo y aumentar su eficacia:</p><ul><li>Utilización de herramientas CASE y otras facilidades. Al hablar de las fases del ciclo de vida se mencionaban las técnicas estructuradas, en principio dichas técnicas no se utilizaban en el modelo en cascada, sin embargo, hoy en día no se plantea la realización de un sistema “artesanalmente”.</li><li>Introducción de una fase intermedia entre especificación de requisitos y el diseño denominado diseño rápido que sirva para validar las especificaciones por parte del usuario, estableciéndose un proceso iterativo de modificación de la especificación hasta que el usuario esté satisfecho con la misma.</li><li>Técnicas de diseño en grupo. Es deseable que el usuario pueda participar al máximo en la definición de los requisitos puesto que se evitarán errores y confusiones ya en las primeras etapas.</li><li>Utilizar técnicas de análisis de riesgos y de coste-beneficio para pasar a la fase siguiente y abandonar planteamientos rígidos de paso a la fase siguiente cuando se ha completado la documentación.</li><li>Dotar de autonomía al jefe de proyecto para que de acuerdo con su experiencia y las características del proyecto decida comenzar una fase sin haber terminado la anterior al 100%, pero que le permite, por ejemplo, realizar una maqueta para la validación por parte del usuario.</li><li>Codificación y pruebas de los módulos de más alto nivel en primer lugar, seguida de la de los módulos más detallados o de más bajo nivel. Esta aproximación puede propiciar el diálogo entre el analista y el usuario en fases posteriores a la especificación de requisitos estableciendo así un proceso de realimentación entre las fases de Implantación y Especificación de requisitos.</li><li>Realización de fases en paralelo como codificación y pruebas. La codificación se puede así ver beneficiada por los resultados de las pruebas y detección de errores.</li><li>Reutilización de código ya probado. A veces con pequeñas modificaciones se pueden llegar a utilizar programas existentes.</li><li>Revisiones de código. Se trata de inspecciones para localizar lo más pronto posible dentro del ciclo todos los errores de diseño y codificación.</li></ul><h2 id="Modelo-en-Espiral-del-Ciclo-de-Vida"><a href="#Modelo-en-Espiral-del-Ciclo-de-Vida" class="headerlink" title="Modelo en Espiral del Ciclo de Vida"></a>Modelo en Espiral del Ciclo de Vida</h2><h3 id="Introduccion-1"><a href="#Introduccion-1" class="headerlink" title="Introducción"></a>Introducción</h3><p>A partir de la experiencia de la aplicación del modelo en cascada se desarrolló el modelo en espiral del ciclo de vida del software y se implementó en algunos grandes proyectos.</p><p>En este modelo subyace el concepto de que cada ciclo implica una progresión que aplica la misma secuencia de pasos para cada parte del producto y para cada uno de sus niveles de elaboración, desde la concepción global de la operación hasta la codificación de cada programa individual.</p><p>El modelo en espiral se ilustra en la siguiente figura. En ella podemos apreciar:</p><ul><li><em>La dimensión radial:</em> representa el coste acumulativo en el que se ha incurrido en las etapas realizadas hasta el momento actual.</li><li><em>La dimensión angular</em> : representa el progreso hecho en completar cada ciclo de la espiral.</li></ul><p><img src="https://gsitic.files.wordpress.com/2018/01/modelo_espiral.png?w=825" alt=""></p><p>Describamos a continuación como sería un típico ciclo de espiral. Considerando cada cuadrante de izquierda a derecha en el sentido de las agujas del reloj.</p><p><strong>CUADRANTE 1</strong> : Cada ciclo en espiral empieza con la indentificación de:</p><ul><li>Los objetivos de la parte del producto que va a ser elaborada (rendimiento, funcionalidad, disponibilidad para acomodarse a nuevos cambios, etc.)</li><li>Las alternativas para implementar esta parte del producto (diseño A, diseño B, compra del software ya desarrollado, reutilización de un software ya existente, etc).</li><li>Las restricciones impuestas: costes, calendario de realización, interfaces, etc.</li></ul><p><strong>CUADRANTE 2</strong> : Aquí se evalúan las opciones relativas a los objetivos y las restricciones.</p><p>Este proceso, con frecuencia, identificará áreas de incertidumbre que son fuentes significativas de riesgo. Esto llevaría implícito la formulación de una estrategia económicamente efectiva para resolver las fuentes de riesgo: prototipado, simulación, benchmark, modelos analíticos o combinaciones de éstas y otras técnicas de resolución de riesgos.</p><p>Si los riesgos de rendimiento o los riegos del interfase de usuario tienen mucha más importancia que los riesgos de desarrollo de programas o los riesgos de interfase de control interno, entonces el paso siguiente podría ser un paso de desarrollo evolutivo: un esfuerzo mínimo para especificar la naturaleza global del producto, un plan para el siguiente nivel de prototipado y el desarrollo de un prototipo más detallado para continuar la resolución de las mayores fuentes de riesgo.</p><p>Si este prototipo es operacionalmente útil y suficientemente robusto para servir como una base de bajo riesgo para el evolución del producto, entonces, los subsiguientes pasos dirigidos por el riesgo (risk-drive) podrían ser una serie de prototipos cada vez más evolucionados, moviéndonos hacia la derecha de la figura. Así, consideraciones de riesgo, pueden llevar a la realización del proyecto utilizando sólo un subconjunto de todos los pasos potenciales en el modelo.</p><p><strong>CUADRANTES 3 y 4</strong> : Si los esfuerzos previos de prototipado han resuelto ya todos los riesgos de rendimiento o los riesgos de interface de usuario y dominan los riesgos de desarrollo en programas o los riesgos de control de interface, el paso siguiente sería el desarrollo según el modelo en cascada. Cada nivel de especificación del software en la figura, entonces, seguido por un paso de validación y planificación del siguiente ciclo.</p><p>Esta implementación, dirigida por el riesgo, de un subconjunto del modelo en espiral, permite al modelo acomodarse a cualquier mezcla de estrategias de desarrollo de software: orientado por las especificaciones, orientado por la simulación, orientado por transformaciones automáticas o cualquier otro enfoque de desarrollo.</p><p>En tales casos, la estrategia mixta apropiada se escoge, considerando, la relación relativa de magnitudes de los riesgos y la efectividad relativa de las distintas alternativas en la resolución de estos riesgos. De forma similar, consideraciones de gestión de riesgo, permiten determinar la cantidad de tiempo y esfuerzo que debe dedicarse a otras actividades del proyecto tales como: planificación, gestión de la configuración, garantía de la calidad, verificación formal, y prueba.</p><p>Un aspecto importante del modelo espiral, como en otros muchos modelos, es que cada ciclo se completa por una revisión que involucra a las personas u organizaciones principales relacionadas con el proyecto. Esta revisión cubre todas las actividades desarrolladas durante el ciclo previo, incluyendo los planes para el próximo ciclo y los recursos que se requieren para llevarlos a cabo.</p><p>El principal objetivo de la revisión es asegurar que todas las partes implicadas están de acuerdo con el camino a seguir en la siguiente fase.</p><p>Los planes para las fases sucesivas pueden incluir también el desarrollo del producto por medio de incrementos sucesivos o la división en componentes que pueden ser desarrollados por distintas personas u organizaciones. En este último caso, aparecen unos ciclos espirales paralelos (uno para cada componente) añadiendo una tercera dimensión al concepto presentado en la figura.</p><p>Además, la etapa de revisión y compromiso puede extenderse, desde una simple revisión informal del diseño de un programa a una revisión de los requerimientos principales implicando, en este caso, a clientes, usuarios, desarrolladores y organizaciones de mantenimiento.</p><h3 id="Ejemplo-de-Aplicacion-del-Modelo-en-Espiral"><a href="#Ejemplo-de-Aplicacion-del-Modelo-en-Espiral" class="headerlink" title="Ejemplo de Aplicación del Modelo en Espiral"></a>Ejemplo de Aplicación del Modelo en Espiral</h3><p>El modelo en espiral se aplicó en un proyecto muy complejo: la definición y desarrollo del Sistema de Productividad de Software (TRW-SPS) un entorno integrado de ingeniería de software de la empresa TRW. El objetivo era mejorar la productividad de las tareas de desarrollo de software realizadas por la empresa.</p><p>En primer lugar se realizó un “ciclo 0” de la espiral para determinar la viabilidad de conseguir un incremento significativo de productividad en el desarrollo software.</p><p><strong>Ciclo 0: Estudio de viabilidad</strong></p><p>Participaron cinco personal, a tiempo parcial, durante un período de dos a tres meses. Durante este ciclo los objetivos y las restricciones se consideraron a un nivel muy alto, expresándoles en términos cualitativos (“mejora significativa”, “coste razonable”, etc).</p><p>Se consideraron alternativas en cuatro áreas: gestión de los proyectos, gestión del personal, tecnología e instalaciones.</p><p>Como áreas de riesgo, se consideró la posibilidad de que la compañía realizase una inversión importante para encontrarse con:</p><ul><li>Mejoras de productividad escasamente significativas.</li><li>Mejoras potenciales incompatibles con aspectos de la cultura de la empresa.</li></ul><p>El análisis de riesgos condujo a la conclusión de que se podrían obtener significativas mejoras en la productividad, a un coste razonable, por medio de un conjunto integrado de iniciativas.</p><p><strong>Ciclo 1: Concepción de la operación</strong></p><p>En este ciclo se invirtieron más recursos (12 meses hombre en lugar de los 2 meses hombre del Ciclo 0); se consideraron objetivos más específicos (conseguir el doble de productividad en la producción de software en 5 años a un coste máximo de 10.000$ por persona); surgieron nuevas restricciones como la preferencia por la utilización de productos desarrollados por la propia empresa, en especial la red local de TRW.</p><p>Para las áreas de riesgo también se fue más específico que en el Ciclo 0 (“comprobación que la red TRW LAN ofrecía una relación precio/rendimiento dentro de la restricción de 10.0000$ por persona”). Para la resolución de riesgos se realizaron tareas más extensivas, tales como la realización de benchmarks y análisis de un prototipo de la TRW LAN.</p><p>La fase de compromisos no se limitó a la aceptación del plan. Se acordó la aplicación del entorno de desarrollo de software producido a un proyecto piloto que implicaba a más de 100 personas. Se decidió la formación de un comité de seguimiento para garantizar la coordinación de las distintas actividades y para evitar que el prototipo de entorno de desarrollo no se optimizase, excesivamente, en función de las características del proyecto en el que se iba a probar. Se recomendó que no solamente se desarrollase el prototipo, sino que también se elaborase una especificación de requerimientos y un diseño siguiendo una orientación orientada al riesgo.</p><p><strong>Ciclo 2: Especificación de los requerimientos de alto nivel</strong></p><p>Se tomaron las decisiones al comienzo del ciclo al observarse que muchos de los requisitos del sistema dependían de la decisión sobre el SO a utilizar y de si el sistema a elaborar iba a ser un sistema orientado al host o totalmente portable. Se decidió escoger UNIX y un sistema orientado a un host UNIX.</p><p><strong>Otros ciclos posteriores</strong></p><p>Las etapas posteriores se realizaron según las características generales de la implantación del modelo en este caso:</p><ul><li>Desarrollo de especificaciones, postergando la elaboración de los elementos de software de bajo riesgo hasta que no se hubieran estabilizado los elementos de software de alto riesgo.</li><li>Incorpora la construcción de prototipos como técnica de reducción de riesgos en cualquiera de las etapas del proyecto.</li><li>Permite la “vuelta atrás” a etapas anteriores cuando se encuentran alternativas más atractivas o se identifican nuevas fuentes de riesgo que requieren solución.</li></ul><h3 id="Evaluacion-del-Modelo"><a href="#Evaluacion-del-Modelo" class="headerlink" title="Evaluación del Modelo"></a>Evaluación del Modelo</h3><p><strong>Ventajas</strong></p><p>La ventaja principal del modelo en espiral es que su rango de opciones acomoda las buenas características de los otros modelos de desarrollo de software, y su procedimiento dirigido por el riesgo, evita muchas de sus dificultades.</p><p>En situaciones apropiadas, el modelo en espiral es equivalente a uno de los modelos de proceso existentes.</p><p>Si un proyecto tiene un riesgo bajo en áreas tales como el establecimiento de una interfaz de usuario no adecuada o en el cumplimiento de requerimientos rigurosos de ejecución y si, por el contrario, tiene un alto riesgo en la predicción y control del presupuesto y del calendario de elaboración, entonces estas consideraciones conducen el modelo en espiral a uno equivalente al modelo en cascada.</p><p>El modelo en espiral tiene otras ventajas adicionales:</p><ul><li>Concentra su atención en opciones que consideran la reutilización de software existente. Los pasos implicados en la identificación y evaluación de alternativas potencian estas opciones.</li><li>Permite preparar la evolución del ciclo de vida, crecimiento y cambios del producto software.</li><li>Proporciona un mecanismo de incorporación de objetivos de calidad en el desarrollo de producto software. Este mecanismo se deriva del énfasis puesto en la identificación de todos los objetivos y restricciones durante cada una de las vueltas de la espiral.</li><li>Es especialmente adecuado para la temprana eliminación de errores y alternativas poco atractivas.</li><li>No implica procedimientos separados para el desarrollo y la mejora del software.</li><li>Proporciona un marco viable para integrar los desarrollos de sistemas software-hardware. El centrar la atención en la gestión del riesgo y en la eliminación de alternativas no atractivas lo antes posible y con el menor coste es, igualmente, aplicable al software y al hardware.</li><li>Se adapta al diseño y programación orientada a objetos y posiblemente con estos métodos es cuando permite obtener mejores resultados: el modelo en espiral potencia la utilización de desarrollos incrementales, y cuando sea necesario, la reelaboración de partes ya desarrolladas. La abstracción, encapsulación, modularidad y jerarquización, elementos fundamentales de los métodos orientados a objeto, facilitan los desarrollos incrementales y hacen menos traumáticas las reelaboraciones.</li></ul><p><strong>Dificultades</strong></p><p><strong>Adaptar su aplicabilidad al software contratado</strong></p><p>El modelo en espiral actualmente trabaja bien en desarrollos de software internos pero necesita un trabajo adicional para adaptarlo al mundo de los contratos de adquisición del software.</p><p>Los desarrollos internos de software tienen bastante flexibilidad y libertad para acomodarse a confirmaciones etapa por etapa; para diferir confirmaciones a determinadas opciones; para establecer miniespirales con las que resolver caminos críticos; para ajustar niveles de esfuerzo, o para acomodar prácticas tales como el prototipado, o el desarrollo evolutivo.</p><p>En el mundo de la adquisición de software es muy difícil conseguir estos grados de flexibilidad y libertad sin perder responsabilidad y control y es muy difícil definir contratos que no especifiquen por adelantado los productos a obtener.</p><p>Recientemente, se ha progresado en el establecimiento de mecanismos de contratación más flexibles pero todavía se necesitan mejoras para conseguir que los compradores se sientan completamente cómodos utilizándolos.</p><p><strong>Dependencia de la experiencia en la evaluación de riesgos</strong></p><p>El modelo en espiral da un papel relevante a la habilidad de los desarrolladores de software para identificar y gestionar las fuentes de riesgo del proyecto. Un buen ejemplo de esto es la especificación dirigida por el riesgo en el modelo en espiral. En ella se debe llegar a un alto nivel de detalle en los elementos de alto riesgo dejando, los de bajo riesgo, para una elaboración en etapas posteriores.</p><p>Otro problema es que la especificación será, en exceso, dependiente de las personas. Por ejemplo, un diseño producido por un experto puede ser implantado por no expertos; en este caso, el experto que no necesita mucha documentación, debe producir suficiente documentación adicional para que los no expertos no se extravíen.</p><p>Con una aproximación convencional, dirigida por la documentación, el requerimiento de llevar todos los aspectos de la especificación a un nivel uniforme de detalle elimina algunos problemas potenciales y permite una adecuada revisión de algunos aspectos por revisores inexpertos. No obstante, esto produce pérdidas de tiempo a los expertos que deben buscar los aspectos críticos en medio de un gran volumen de detalles no críticos.</p><h3 id="El-Plan-de-Gestion-de-Riesgo"><a href="#El-Plan-de-Gestion-de-Riesgo" class="headerlink" title="El Plan de Gestión de Riesgo"></a>El Plan de Gestión de Riesgo</h3><p>Incluso si una organización no está lista para adoptar el procedimiento completo en espiral, una característica técnica del mismo que puede ser fácilmente adaptada a cualquier modelo de ciclo de vida proporciona muchos de los beneficios de dicho procedimiento. Se trata del Plan de Gestión del Riesgo.</p><p>Este plan, básicamente, asegura que en cada proyecto se haga una identificación temprana de sus factores de riesgo más altos; desarrolla una estrategia para resolver los factores de riesgo; identifica y establece una agenda para resolver nuevos factores de riesgo a medida que afloran y, por último, muestra los progresos respecto al plan en revisiones mensuales.</p><p>El plan de gestión de riesgo y las técnicas para gestión de riesgo de Software facilitan adaptar concepto del modelo en espiral a los procedimientos de adquisición y desarrollo de software más asentados. Se pueden sacar las siguientes cuatro conclusiones:</p><ul><li>El modelo en espiral, por su naturaleza de estar dirigido por el riesgo, es más adaptable a un amplio rango de situaciones que los procedimientos dirigidos por la documentación, tales como el modelo en cascada o los procedimientos dirigidos por el código, tales como el modelo de desarrollo evolutivo. Es particularmente aplicable a sistemas de software muy grandes y complejos.</li><li>El modelo en espiral ha tenido éxito en su mayor aplicación realizada hasta ahora: el desarrollo del TRW-SPS. Proporciona la flexibilidad necesaria para acomodar un rango de alternativas técnicas y objetivos de usuario muy dinámico.</li><li>El modelo en espiral no está, todavía, tan elaborado como los modelos más establecidos. Por esta razón, el modelo en espiral puede ser aplicado por personal experto, pero necesita elaboración posterior en áreas como contratación, especificaciones, puntos de control, revisiones, calendarios e identificación de áreas de riesgo para ser completamente aplicable en todas las situaciones.</li><li>Algunas implementaciones parciales del modelo en espiral como el Plan de Gestión del Riesgo, son compatibles con la mayoría de los modelos de proceso actuales y son muy útiles para superar las mayores fuentes de riesgo de proyectos.</li></ul><p>Tabla de los 10 factores de riesgo del software más importantes:</p><p><img src="https://gsitic.files.wordpress.com/2018/01/factores_riesgo.png?w=825" alt=""></p><p>Tabla del Plan de Gestión del Riesgo del Software:</p><p><img src="https://gsitic.files.wordpress.com/2018/01/pgrs.png?w=825" alt=""></p><h2 id="Bibliografia"><a href="#Bibliografia" class="headerlink" title="Bibliografía"></a>Bibliografía</h2><ul><li><a href="https://es.scribd.com/document/100553892/TICB2-Ciclo-de-Vida" rel="external nofollow noopener noreferrer" target="_blank">Scribd (Ricardo Costanzi)</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Concepto-del-ciclo-de-vida-de-los-sistemas-y-fases-Modelos-de-ciclo-de-vida&quot;&gt;&lt;a href=&quot;#Concepto-del-ciclo-de-vida-de-los-sistemas-y-
      
    
    </summary>
    
      <category term="B3" scheme="http://localhost:4000/categories/B3/"/>
    
    
  </entry>
  
  <entry>
    <title>B3-T02</title>
    <link href="http://localhost:4000/wiki/B3/b3-t02/"/>
    <id>http://localhost:4000/wiki/B3/b3-t02/</id>
    <published>2019-01-16T15:11:23.000Z</published>
    <updated>2019-01-18T10:45:16.609Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Gestion-del-proceso-de-desarrollo-objetivos-actores-y-actividades-Tecnicas-y-practicas-de-gestion-de-proyectos"><a href="#Gestion-del-proceso-de-desarrollo-objetivos-actores-y-actividades-Tecnicas-y-practicas-de-gestion-de-proyectos" class="headerlink" title="Gestión del proceso de desarrollo: objetivos, actores y actividades. Técnicas y prácticas de gestión de proyectos."></a>Gestión del proceso de desarrollo: objetivos, actores y actividades. Técnicas y prácticas de gestión de proyectos.</h1><h2 id="Introduccion-a-la-Gestion-del-Proceso-de-Desarrollo"><a href="#Introduccion-a-la-Gestion-del-Proceso-de-Desarrollo" class="headerlink" title="Introducción a la Gestión del Proceso de Desarrollo"></a>Introducción a la Gestión del Proceso de Desarrollo</h2><p>Los fundamentos de gestión consisten en determinar el tamaño del producto (incluyendo funcionalidad, complejidad y otras características del producto), asignando los recursos apropiados a un producto de ese tamaño, creando un plan para aplicar esos recursos y luego controlando y dirigiendo los recursos para impedir que el proyecto se desvíe. En algunos casos los altos cargos delegan explícitamente estas tareas de gestión a los responsables técnicos, y en otros casos simplemente las dejan vacantes, ocupándose de ellas un responsable o desarrollado motivado.</p><h3 id="Definiciones"><a href="#Definiciones" class="headerlink" title="Definiciones"></a>Definiciones</h3><ul><li><strong>Proceso</strong> . Conjunto de actividades con un objetivo, que transforman un conjunto de entradas en un conjunto de salidas, agregando valor.</li><li><strong>Proceso de Software</strong> . Proceso que transforma Requerimientos de Procesamiento de Información en Elementos de Software (componentes computacionales y documentos) que satisfacen los requerimientos de procesamiento de información, ofreciendo servicios a una organización.</li><li><strong>Proceso de desarrollo de software</strong> . Proceso cuyo objetivo es generar un nuevo sistema informático que satisfaga un conjunto de requerimientos iniciales de procesamiento de información en una organización.</li><li><strong>Procesos de Administración de Proyectos</strong> . Procesos orientados a organizar y guiar al equipo de desarrollo para cumplir los compromisos negociados con el cliente (fechas de entrega y costes).</li><li><strong>Procesos de Ingeniería de Software</strong> . Procesos orientados a obtener componentes de software (código y documentos) entregables al cliente, sin errores y con el menor esfuerzo posible.</li></ul><h3 id="Caracteristicas-de-la-Gestion-del-Proceso-de-Desarrollo"><a href="#Caracteristicas-de-la-Gestion-del-Proceso-de-Desarrollo" class="headerlink" title="Características de la Gestión del Proceso de Desarrollo"></a>Características de la Gestión del Proceso de Desarrollo</h3><p>Las características principales de la gestión del proceso de desarrollo son las siguientes:</p><ul><li>El producto a desarrollar es intangible.</li><li>El producto tiene su propia flexibilidad.</li><li>La ingeniería de software no es reconocida como una disciplina de la Ingeniería con el mismo estatus de la mecánica, eléctrica, matemáticas, etc.</li><li>El proceso de desarrollo de software no está estandarizado.</li></ul><p>De estas características se deduce la importancia de la propia gestión, ya que la Ingeniería de software es una actividad económica importante, que está sujeta a restricciones económicas. No hay que olvidar que los proyectos bien gestionados a veces fallan. Los proyectos mal gestionados siempre fallan.</p><h3 id="Causas-de-Fallos-en-los-Proyectos"><a href="#Causas-de-Fallos-en-los-Proyectos" class="headerlink" title="Causas de Fallos en los Proyectos"></a>Causas de Fallos en los Proyectos</h3><p>Dentro de las principales causas por las que puede fallar un proyecto, se encuentra el hecho de que los componentes del proyecto no respetan o no conocen bien las herramientas y las técnicas del análisis y diseño de sistemas, además de esto puede haber una mala gestión y dirección del proyecto.</p><p>Además existen una serie de factores que pueden hacer que el sistema sea mal evaluado:</p><ul><li>Requerimientos Incompletos.</li><li>Usuarios no Involucrados.<ul><li>Carencia de Recursos.</li></ul></li><li>Expectativas Irreales.</li><li>Falta de soporte ejecutivo.</li><li>Cambios de Requerimientos.</li><li>Falta de planificación.</li><li>Obsoleto antes de ser completado.</li><li>Carencia de supervisión por parte de la gerencia de TI.</li><li>Desconocimiento de la tecnología.</li><li>No resuelve problemas de negocio.</li><li>Requerimientos planificados de manera irreal.</li><li>Carencia de entrenamiento en Administración de Programas.</li><li>Mala Estimación.</li></ul><p>Aunque estos factores pueden influir de manera muy trascendente en la mala realización de un proyecto, generalmente están acompañados de otro tipo de problemas. Pero, ¿cuáles de estos errores de gestión de proyectos ocasionan que no se cumplan los requisitos, que se sobrepase los tiempos de entrega o se aumenten repetidas veces los costes?</p><p>La respuesta a esta pregunta puede ser hallada en dos fuentes principalmente, deficiencias en las herramientas y las técnicas de análisis del diseño de sistemas o la mala gestión de los proyectos.</p><p>En el caso de las necesidades no satisfechas o no identificadas, el error puede aparecer debido a que se omiten datos durante el desarrollo del proyecto, es por esto que es muy importante no saltar ninguna etapa del ciclo de vida del desarrollo de sistemas.</p><p>Otra causa de insatisfacción de necesidades es la mala definición de las expectativas de un proyecto en sus orígenes, ya que si no están bien definidos los requerimientos máximos y mínimos que el proyecto debe satisfacer desde el comienzo, los desarrolladores verán afectados su trabajo por el <em>síndrome de las necesidades que crecen</em> el cual les dejará hacer cambios en el proyecto en cualquier momento sin detenerse a pensar si esos cambios serán buenos para el proyecto como un todo, por supuesto todas estas modificaciones acarrearan alteraciones en los costes y en los tiempos de entrega.</p><p>El coste de un proyecto puede aumentar durante el desarrollo de este debido a varias causas:</p><ul><li>Para comenzar un proyecto generalmente se exige un estudio de viabilidad en el cual no se incluyen datos completamente precisos de la cantidad de recursos que cada tarea consumirá, y es en base a este estudio que se hacen estimaciones de los recursos totales que el proyecto va a necesitar.</li><li>El uso de criterios de estimación poco eficientes por parte de los analistas.</li><li>El aumento en los tiempos de entrega debido a que los directores del proyecto en ocasiones no gestionan bien los tiempos de entrega de cada tarea del proyecto y cuando tienen un retraso no son capaces de alterar los plazos de entrega finales creyendo que podrán recuperar el tiempo perdido, pero no siempre es posible acelerar otras tareas para ahorrar tiempo en la entrega final.</li></ul><p>Para evitar todos estos problemas, se debe tener al mando del proyecto un director que conozca las herramientas de diseño y análisis de sistemas y tenga una buena formación en las funciones de dirección.</p><h2 id="Objetivos-de-la-Gestion-del-Proceso-Desarrollo"><a href="#Objetivos-de-la-Gestion-del-Proceso-Desarrollo" class="headerlink" title="Objetivos de la Gestión del Proceso Desarrollo"></a>Objetivos de la Gestión del Proceso Desarrollo</h2><p>Los objetivos de la gestión son al final objetivos de calidad, es el primer paso de cualquier metodología de mejora, estos se pueden definir respondiendo la pregunta…</p><p>¿Cuáles son los puntos que queremos mejorar en la gestión?</p><p>Seguramente habrá muchos puntos que son susceptibles de mejora, sin embargo hay que considerar solo unos pocos y sobre todo aquellos que sean los que más nos interesa modificar.</p><p>Al establecer los objetivos debemos procurar definirlos de manera clara, concreta y deben ser cuantificables.</p><p>Básicamente estos podrían ser:</p><ul><li>Reducir la diferencia entre la fecha real y la fecha acordada.</li><li>Reducir la diferencia entre el esfuerzo real y el esfuerzo acordado.</li><li>Reducir el número de errores funcionales y no funcionales de los sistemas en entornos de producción (tendencia a cero errores).</li><li>Aumentar la productividad de los equipos de desarrollo (Relación productos-esfuerzo global de proyectos).</li></ul><p>En mejora de procesos hay tres cosas que esperamos que ocurran:</p><p>En la figura se muestra como en principio se establecen objetivos de fecha y costo que no se cumplen. La mayor parte del trabajo no está dentro del objetivo (a la izquierda de la gráfica). En la parte de abajo lo que ocurre es que el objetivo que se establece se acerca más a la realidad del desempeño del equipo de trabajo que desarrolla las tareas, volviendo más certera la estimación.</p><p><img src="https://gsitic.files.wordpress.com/2018/04/modelos_de_calidad.png?w=825" alt=""></p><p>En la siguiente figura lo que esperamos que se transforme es el control. Aquí se muestra como (en la parte de arriba) una parte importante de los resultados, a pesar de estar centrados en los objetivos, se sale de los objetivos. Disminuir (abajo) esta curva significa que nuestro proceso está bajo control.</p><p><img src="https://gsitic.files.wordpress.com/2018/04/modelos_de_calidad_2.png?w=825" alt=""></p><p>En la siguiente figura, con más certeza en la información para fijar objetivos y con más control en nuestros procesos, podemos mejorar la efectividad con objetivos más agresivos y con altas posibilidades de cumplirlos.</p><p><img src="https://gsitic.files.wordpress.com/2018/04/modelos_de_calidad_efectividad.png?w=825" alt=""></p><h3 id="El-Modelo-CMM-Capacity-Maturity-Model"><a href="#El-Modelo-CMM-Capacity-Maturity-Model" class="headerlink" title="El Modelo CMM (Capacity Maturity Model)"></a>El Modelo CMM (Capacity Maturity Model)</h3><p>Existen diferentes modelos de calidad entre los cuales se encuentran: CMM, SPICE, Bootstrap y Thrillium, los cuales se concentran en evaluar la capacidad de los procesos de software y la madurez de las organizaciones de software. Estos modelos constituyen un marco de referencia que permite calificar a las organizaciones de desarrollo de software.</p><p>Está comprobado que ISO9000 no es adecuado para evaluar capacidad de procesos de software, es por eso que el mismo ISO creó el proyecto SPICE.</p><p>El modelo CMM ubica a las organizaciones en uno de cinco niveles de madurez según se muestra en la figura:</p><ul><li>En el nivel 1 la organización es reactiva, los administradores se dedican a resolver crisis inmediatas y los tiempos calendario y los costes son excedidos básicamente porque no están basados en estimaciones reales. Cuando hay metas calendario agresivas, regularmente la funcionalidad y calidad del producto son comprometidos a fin de cumplir con las fechas. No existe un proceso definido y cuando un proyecto sale bien, no hay manera de reproducir su forma de trabajo en proyectos subsecuentes.</li><li>En el nivel 2 ya hay un proceso definido, se tienen identificadas las entradas y salidas de cada etapa y se establecen controles en las entradas y salidas de cada etapa.</li><li>En el nivel 3 se define el cómo de cada etapa, habiendo probado en la VIDA REAL las técnicas y descubierto la mejor forma de aplicarlas. Se identifican los controles internos necesarios para cada etapa.</li><li>En el nivel 4 se aplican los controles internos de cada etapa y se llevan a cabo mediciones y estimaciones en base a información estadística.</li><li>Finalmente en el nivel 5 se lleva a cabo un proceso de mejora continua REAL en el que se hace reingeniería de procesos.</li></ul><p><img src="https://gsitic.files.wordpress.com/2018/04/modelo_cmm.png?w=825" alt=""></p><h2 id="Actividades-de-Gestion"><a href="#Actividades-de-Gestion" class="headerlink" title="Actividades de Gestión"></a>Actividades de Gestión</h2><p>Son las actividades que permiten asegurar que el software se lleva a cabo a tiempo y de acuerdo a la planificación. Así como de acuerdo a los requerimientos del software:</p><ul><li>Planificación de las actividades del equipo de desarrollo dentro del proyecto.</li><li>Obtener los recursos (tanto físicos como humanos) necesarios para la ejecución del proyecto.</li><li>Organizar funciones y responsabilidades de las personas dentro del equipo de desarrollo.</li><li>Revisar cumplimento de planes y compromisos.</li><li>Supervisar/auditar la ejecución de las actividades dentro del desarrollo y revisar las características necesarias de los productos que se generan dentro del proyecto.</li><li>Administrar/controlar los cambios en los productos generados dentro del proceso de desarrollo.</li><li>Medir y registrar el desempeño durante la ejecución del proyecto.</li><li>Anticipar posibles problemas durante la ejecución del proyecto y prevenirlos.</li><li>Evaluar y retroalimentar el desempeño de los miembros del equipo de desarrollo.</li></ul><p>Estas actividades se pueden agrupar como se muestra en el diagrama general de grupos de procesos:</p><p><img src="https://gsitic.files.wordpress.com/2018/04/diagrama_grupos_procesos.png?w=825" alt=""></p><p>Todos los proyectos, que se gestionan como tales, tienen una serie de fases comunes, no tanto porque se realicen tareas iguales, sino porque el objetivo de cada fase con relación al producto a obtener es común a cualquier proyecto.</p><p>Así tenemos dos grandes fases: Planificación y Ejecución. Estas fases se subdividen en otras menores. Veamos cada una de ellas por separado.</p><h3 id="Iniciacion"><a href="#Iniciacion" class="headerlink" title="Iniciación"></a>Iniciación</h3><p>El origen de un proyecto suele ser difuso. Normalmente alguien identifica un problema o una necesidad. Este problema-necesidad hace muy interesante el nacimiento de un proyecto, ya que podemos observar como ante el problema que se plantea unos gerentes lo ven como un impedimento para alcanzar sus metas, mientras otros, pensando que el mismo problema también la tienen sus competidores, lo ven como una oportunidad para dar una solución correcta y posicionarse mejor en el mercado.</p><p>Ya sea visto como problema u oportunidad, lo primero que hay que hacer es obtener una descripción clara de éste. La pregunta clave a responder es: <em>¿Cuál es el problema, o dónde está la oportunidad?</em> Evidentemente aquí hay que trabajar con los usuarios, directores de empresa y clientes, pues ellos son los que conocen su negocio y será de ellos de quien tendremos que obtener la información para responder a esta pregunta.</p><p>La definición del problema suele ocupar muy poco tiempo, por esto muchas veces no se le da la importancia central que tiene. Hay que tener en cuenta que todo el proyecto se basará en esta definición y es mejor que quede clara. La definición del problema debe ser revisada por todos los implicados en el problema: usuarios, directivos y clientes.</p><p>Normalmente al definir el problema debemos hurgar en la organización, sus objetivos y fines. También debemos, una vez clarificado el problema, identificar los beneficios que se obtendrán si lo solucionamos. Hay que evitar “las soluciones en busca de un problema”, es decir cuando alguien ha visto una aplicación en marcha, o un sistema, y quiere algo similar. Muchas veces se esconde la idea intuitiva de que aquello resolverá un problema o generará una oportunidad. Lo mejor es sacar a flote el problema o la oportunidad y entonces definirlo en términos claros.</p><p>También es peligrosa la situación en la que los únicos interesados en el problema y su solución son los implicados en el proyecto. Muchas veces los técnicos desean aplicar nuevas técnicas o herramientas y organizan un proyecto en torno a éstas.</p><p>En todo caso lo que se debe hacer es buscar en la empresa, identificando alguna aplicación que no sea compleja y que sea útil a los objetivos de la misma.</p><p>Los siguientes puntos nos dan una idea de la forma de pensar, así como las tareas a realizar durante esta fase:</p><ul><li>Estudiar el sistema actual.</li><li>Discutir y analizar lo que se desea obtener.</li><li>Clarificar las áreas de la empresa que se verán afectadas.</li><li>Definir el problema y sus componentes, aclarando: qué es fundamental, qué es deseable y qué es opcional.</li><li>Visualizar el producto o sistema a proporcionar, así como su adaptación a la organización.</li><li>Identificar al responsable del proyecto.</li><li>Crear una declaración clara de lo que se va a hacer.</li><li>Obtener el sí de los implicados: “Sí, tenemos exactamente ese problema”.</li></ul><p>En todas las fases y en esta de forma especial se debe estimar los costes previsibles del proyecto y, sobre todo, el coste de la siguiente fase, la planificación.</p><p>En muchas organizaciones, una vez definido el problema, éste se añade a la lista de los problemas pendientes de resolución. Así un comité de dirección selecciona el próximo problema a resolver, o sistema a desarrollar.</p><h3 id="Planificacion"><a href="#Planificacion" class="headerlink" title="Planificación"></a>Planificación</h3><p>El objetivo de toda planificación es la de clarificar el problema a solucionar, definir el producto a obtener, o servicio a proporcionar, estimar los costes económicos en que va a incurrir, así como los recursos humanos y de cualquier otro tipo que se requieran para alcanzar la meta.</p><p>La función principal es la de atender a las necesidades que aparecerán a lo largo del desarrollo, anticipando el curso de las tareas a realizar, la secuencia en que se llevarán a cabo, los recursos y el momento en que serán necesarios. Hay que tener en cuenta que normalmente hay más bienes o servicios que desearíamos obtener, que recursos disponibles para obtenerlos, por lo que las empresas deben seleccionar entre varias alternativas. Así una mala definición de un proyecto puede provocar que la empresa comprometa sus recursos en un bien del que hubiera podido prescindir en favor de un sustituto más económico.</p><p>La planificación del proyecto es la fase en la que se deberán identificar todas las cosas necesarias para poder alcanzar el objetivo marcado. En esta fase se han de concretar los tres cimientos sobre los que se apoyará el desarrollo de todo el proyecto, estos son:</p><ul><li>Calidad: viene dadas por las especificaciones.</li><li>Coste económico: valorado en el presupuesto.</li><li>Duración: asignada en el calendario de trabajo.</li></ul><p>Así como en la fase anterior nos centrábamos en identificar el problema, aquí tenemos que identificar diferentes soluciones y los costes asociados a cada una de ellas.</p><p>Aunque muchos autores separan el análisis de la aplicación de la propia planificación, por entenderse que la primera es una técnica, mientras que la planificación es una tarea de gestión, cronológicamente se han de realizar de forma simultánea, aunque, se debería partir de una especificación seria del problema, antes de planificar las tareas, costes y recursos necesarios para desarrollar la aplicación.</p><p>Otro asunto es que cada trabajo que se realiza se debe planificar antes de acometerlo. Así, antes de realizar el análisis se deberá hacer una planificación de los trabajos asociados a éste, pero difícilmente se podrá realizar la planificación de todo el proyecto.</p><p>Las tareas a realizar para planificar el proyecto, las podemos agrupar en:</p><ul><li>Estimar el tamaño de la aplicación a desarrollar.</li><li>Estimar el coste en recursos humanos.</li><li>Identificar las tareas a realizar.</li><li>Asignar recursos a cada tarea.</li><li>Crear un calendario de las tareas.</li><li>Realizar un estudio económico.</li><li>Reunir todo en un documento, Estudio de viabilidad.</li></ul><p>Estas tareas se realizan de forma secuencial o iterativa entre ellas. Esta sería una iteración de las tareas:</p><p>Establecer las restricciones del proyecto<br>hacer las suposiciones iniciales de los parámetros del proyecto<br><strong>while</strong> el proyecto no termina o ha sido cancelado <strong>loop</strong><br>Describe la planificación de tiempos del proyecto<br>Inicia las actividades de acuerdo a la planificación<br>Espera (a que se lleve a cabo el desarrollo)<br>Revisa el progreso del proyecto<br>Revisa los parámetros estimados del proyecto<br>Actualiza la planificación del proyecto<br>Renegocia las restricciones del proyecto y los tiempos de entrega<br><strong>if</strong> (aparecen problemas) <strong>then</strong><br>inicia una revisión técnica y sus posibles soluciones<br><strong>end if</strong><br><strong>end loop</strong></p><p>Las actividades en un proyecto deben ser organizadas para producir resultados tangibles para que la administración pueda juzgar el progreso.</p><p>Los “Milestones” son los puntos finales de alguna actividad. Los “deliverables” son los resultados del proyecto que serán entregados a los clientes. El proceso de “cascada” permite una definición precisa de los “milestones”.</p><p><img src="https://gsitic.files.wordpress.com/2018/04/milestones.png?w=825" alt=""></p><h3 id="Ejecucion"><a href="#Ejecucion" class="headerlink" title="Ejecución"></a>Ejecución</h3><p>En esta fase, se trata de llevar a cabo el plan previo. Se verá fuertemente influida por la planificación. Una mala planificación, llevará a una mala ejecución, ya que si se planifica que costará menos tiempo del real, los usuarios presionarán a los desarrolladores, con lo que éstos trabajarán en peores condiciones, del mismo modo, si se planifica un coste inferior, los administradores de la empresa presionarán al personal del proyecto, con lo que éstos trabajarán con más estrés.</p><p>Esta fase se caracteriza fundamentalmente porque en ella se ha de organizar el equipo de desarrollo, los mecanismos de comunicación, la asignación de roles y de responsabilidades a cada persona. Tareas fundamentales son:</p><ul><li>Identificar las necesidades de personal, que aunque ya venían de la fase de planificación, habrá que ajustarla a las disponibilidades actuales.</li><li>Establecimiento de la estructura organizativa.</li><li>Definir responsabilidades y autoridad.</li><li>Organizar el lugar de trabajo. En muchas ocasiones el comienzo de un proyecto tiene tareas como instalación de equipamientos, acondicionamiento de locales, …</li><li>Puesta en funcionamiento del equipo. Cuando las personas que van a trabajar en un proyecto no se conocen, es oportuno organizar reuniones más o menos informales para que se conozcan, esto evitará malentendidos y conflictos durante la ejecución del proyecto.</li><li>Divulgación de los estándares de trabajo y sistemas de informes. Al comenzar el proyecto, las personas están más receptivas que cuando se encuentran en un trabajo rutinario o cuando el objetivo se transforma en algo obsesivo. Ésta es una razón de peso para introducir los nuevos métodos de trabajo. Es posible que sea el cliente el que marque los estándares.</li></ul><h3 id="Control"><a href="#Control" class="headerlink" title="Control"></a>Control</h3><p>En este momento, ya tenemos el proyecto con su calendario, etc, las especificaciones claras, los recursos y personas en situación de trabajo. Las personas deben llevar a término cada una de las tareas que se les ha asignado en el momento que se le haya indicado. El objetivo principal en esta fase es; establecer visibilidad adecuada del progreso real del proyecto, de manera que la administración pueda tomar acciones efectivas cuando la ejecución del proyecto de software se desvía significativamente de los planes.</p><p>Por su parte el responsable del proyecto debe realizar las siguientes actividades:</p><ul><li>Revisar cumplimiento de planes y compromisos.</li><li>Tomar medidas del rendimiento.</li><li>Revisar los informes que le llegan de los empleados.</li><li>Mantener reuniones para identificar los problemas antes de que aparezcan.</li><li>Administrar / controlar los cambios en los productos generados dentro del proceso de desarrollo.</li><li>En caso de desviaciones poner en práctica las acciones correctivas necesarias.</li><li>Coordinar las tareas.</li><li>Motivar y liderar a los empleados.</li><li>Recompensar y disciplinar.</li></ul><h3 id="Cierre"><a href="#Cierre" class="headerlink" title="Cierre"></a>Cierre</h3><p>Ésta fase es la opuesta a la de puesta en marcha. En ésta se trata primero dar por finalizado el proyecto y entregar el producto, o dejar de producir el servicio encomendado.</p><p>Las actividades a realizar son las siguientes:</p><ul><li>Hacer entrega definitiva del producto al cliente.</li><li>Revisar las desviaciones del proyecto, identificar causas e indicar formas diferentes de actuación en futuros proyectos.</li><li>Reasignar el personal a los nuevos proyectos o reintegrarlos en los departamentos de partida.</li><li>Es interesante documentar las relaciones entre los empleados para futuros proyectos.</li></ul><h3 id="Gestion-de-Riesgos"><a href="#Gestion-de-Riesgos" class="headerlink" title="Gestión de Riesgos"></a>Gestión de Riesgos</h3><p>Gestión de riesgos concierne con la identificación de riesgos y la escritura de planes para minimizar el efecto de estos en el proyecto.</p><p><img src="https://gsitic.files.wordpress.com/2018/04/gestion_de_riesgos.png?w=825" alt=""></p><p>Un riesgo se relaciona con la probabilidad de que ocurra alguna circunstancia adversa al proyecto:</p><ul><li>Los riesgos de un proyecto afectan a la planificación o a los recursos.</li><li>Los riesgos del producto afectan a la calidad o al desempeño del software por desarrollarse.</li><li>Los riesgos del negocio son aquellos que afectan a la organización que desarrolla el software.</li></ul><p><strong>Identificación de los Riesgos</strong></p><p>Identifica riesgos en el proyecto, en el producto y en el negocio:</p><ul><li>Riesgos en la tecnología.</li><li>Riesgos en la gente.</li><li>Riesgos organizacionales.</li><li>Riesgos en los Requerimientos.</li><li>Riesgos de estimación.</li></ul><p><strong>Análisis de Riesgos</strong></p><p>Calculo de la posibilidad de que ocurran estos riesgos y de sus consecuencias:</p><ul><li>Determina la probabilidad y la seriedad de cada riesgo.</li><li>Las probabilidades pueden variar entre muy alta, alta, moderada, baja o muy baja.</li><li>Los efectos de los riesgos pueden ser: catastróficos, serios, tolerables o insignificantes.</li></ul><p><strong>Planificación de Riesgos</strong></p><p>Trazar planes para evitar o minimizar el efecto de los riesgos. Considera cada riesgo y desarrolla una estrategia para manejarlo:</p><ul><li>Estrategias de evasión: La probabilidad de que el riesgo que presente se minimizara.</li><li>Estrategias de minimización: El impacto del riesgo en el producto o en el proyecto se reducirá.</li><li>Planes de contingencia: Si el riesgo se presenta, el plan de contingencia se encarga de tratar este riesgo.</li></ul><p><strong>Monitorización de Riesgos</strong></p><p>Monitorizar los riesgos durante el proyecto:</p><ul><li>Determina regularmente cada riesgo identificado y decide si es probable o no que se presente.</li><li>Determina si los efectos que produciría el riesgo ha cambiado.</li><li>Cada riesgo clave debe discutirse en las reuniones de avance del proyecto.</li></ul><h2 id="Desarrollo-en-Fases"><a href="#Desarrollo-en-Fases" class="headerlink" title="Desarrollo en Fases"></a>Desarrollo en Fases</h2><p>El proceso de desarrollo de software no es solamente escribir líneas de código, compilar y ejecutar. Lo anterior es sólo una etapa (importante) de dicho proceso. En un proceso, se debe definir quién hace qué cosa cuando y cómo para alcanzar un cierto objetivo. En la ingeniería de software el objetivo principal es construir un producto de software o mejorar alguno ya construido, tomando en cuenta los requerimientos de los clientes (usuarios). Un proceso, provee de una guía para el desarrollo eficiente de un software de calidad. Tal proceso es una guía para todos los participantes en el desarrollo (usuarios, desarrolladores, responsables de proyecto, etc.) y permite construir software más ordenado y con un tiempo de vida relativamente largo.</p><p>Para realizar un proyecto, empezaremos por ver cuales son los objetivos que queremos alcanzar y luego pensaremos qué cosas tenemos que hacer para alcanzar estos fines. Esta descomposición pasará por identificar las fases de nuestro proyecto y el esfuerzo a aplicar en cada una de ellas. A su vez estas fases se descompondrán en tareas. También tendremos que marcar unos puntos (hitos) de control que nos permitan saber si el proceso va de acuerdo a lo previsto.</p><p>Normalmente todas las fases y tareas terminan en la generación de uno o varios documentos. A éstos se les llama <em>entregables</em> . Este nombre se debe a que pasan de manos del desarrollador a manos del controlador del proyecto o cliente. En los proyectos informáticos se suele asociar los hitos a la consecución de un entregable.</p><h3 id="Descomposicion-en-Actividades-del-Proyecto-WBS"><a href="#Descomposicion-en-Actividades-del-Proyecto-WBS" class="headerlink" title="Descomposición en Actividades del Proyecto (WBS)"></a>Descomposición en Actividades del Proyecto (WBS)</h3><p>Empezaremos por ver la herramienta que se utiliza a la hora de descomponer y documentar el trabajo de un proyecto, como un conjunto de tareas. Habitualmente se le conoce como WBS (Work Breakdown Structure) que literalmente significa estructura de descomposición del trabajo. Es un método de representar de forma jerárquica los componentes de un proceso o producto. Puede ser utilizado para documentar la descomposición de un proceso, la descomposición de un producto, o de forma híbrida.</p><p><img src="https://gsitic.files.wordpress.com/2018/04/wbs.png?w=825" alt=""></p><h3 id="Entregables-de-un-Proyecto-Informatico"><a href="#Entregables-de-un-Proyecto-Informatico" class="headerlink" title="Entregables de un Proyecto Informático"></a>Entregables de un Proyecto Informático</h3><p>Los entregables son: “Productos que, en un cierto estado, se intercambian entre los clientes y los desarrolladores a lo largo de la ejecución del proyecto informático”.</p><p>Los entregables se clasifican como relativos al objetivo y relativos a la gestión del proyecto. Son relativos al objetivo todos aquellos documentos que hacen referencia exclusivamente al sistema de información y al subsistema informático en desarrollo. Pertenecen a este conjunto los requisitos del sistema, la especificación del sistema, la documentación del diseño, el código fuente, los programas ejecutables, los manuales de usuario, etc.</p><p>Los entregables relativos a la gestión del proyecto hacen referencia a aquellos documentos que se refieren a la situación en que se encuentra un proyecto, previsiones de costes, gastos realizados, informe sobre entornos de trabajo, etc, siendo su objetivo el poder controlar el proyecto. Pertenecen a esta clase la planificación del proyecto, los presupuestos, los documentos de control de la planificación o de la calidad, los estudios de riesgos durante el desarrollo, etc.</p><p>Se deberá definir de forma clara el conjunto mínimo de entregables necesario para dar por terminada cada fase de desarrollo. Aunque algunos entregables se desarrollan a lo largo de varias tareas.</p><p>Los entregables nos proveen de:</p><ul><li>Un conjunto de componentes que formarán el producto una vez finalizado el desarrollo.</li><li>Los medios para medir el progreso y la calidad del producto en desarrollo.</li><li>Los documentos necesarios para la siguiente etapa.</li></ul><h3 id="Entregables-mas-Usuales"><a href="#Entregables-mas-Usuales" class="headerlink" title="Entregables más Usuales"></a>Entregables más Usuales</h3><p>Dado que como hemos visto los entregables juegan un papel central en el desarrollo de un subsistema informático, vamos a listar los más importantes:</p><ul><li>Estudio de viabilidad:<ul><li>Descripción breve del sistema propuesto y sus características.</li><li>Descripción breve de las necesidades del negocio en el sistema propuesto.</li><li>Propuesta de organización del equipo de desarrollo y definición de responsabilidades.</li><li>Estudio de los costes, que contendrán estimaciones groseras de planificación y fechas, tentativas, de entrega de los productos.</li><li>Estudio de los beneficios que producirá el sistema.</li></ul></li><li>Análisis:<ul><li>Captura de requisitos:<ul><li>Análisis del sistema actual (si existe).</li><li>Requisitos nuevos de los usuarios.</li><li>Descripción del sistema propuesto.</li></ul></li><li>Especificación del sistema:<ul><li>Descripción del sistema (DFD’s, etc.).</li><li>Requisitos de datos.</li><li>Requisitos de telecomunicaciones.</li><li>Requisitos de hardware.</li><li>Plan de pruebas de integración.</li></ul></li><li>Diseño:<ul><li>Descripción detallada del sistema, contendrá:<ul><li>Programas, módulos reutilizables y objetos.</li><li>Ficheros y bases de datos.</li><li>Transacciones.</li><li>Diccionario de datos.</li><li>Procedimientos.</li><li>Carga del sistema y tiempos de respuesta.</li><li>Interfaces, tanto humanos como de máquinas.</li></ul></li><li>Descripción de los controles del sistema propuestos.</li><li>Diseños alternativos recomendados.</li><li>Estándares de programación y diseño de programas, recomendados.</li><li>Técnicas de implementación recomendadas: codificación propia, compra de paquetes, contratación externa, etc.</li><li>Plan de pruebas de programas.</li></ul></li><li>Codificación:<ul><li>Documentación del diseño final del sistema y de cada programa.</li><li>Diagramas definitivos del sistema y de los programas.</li><li>Descripción detallada de la lógica de cada programa.</li><li>Descripción de las Entradas y Salidad (ficheros, pantallas, listados, etc.).</li><li>Listado de los programas, conteniendo comentarios.</li><li>Cadenas de ejecución si es necesario (JCL, scripts, etc).</li><li>Resultado de las pruebas de cada unidad.</li><li>Resultado de las pruebas de cada programa.</li><li>Resultado de las pruebas de la integración.</li><li>Guía para los operadores del sistema.</li><li>Programa de entrenamiento de los operadores.</li><li>Manual de usuario del sistema.</li></ul></li><li>Pruebas:<ul><li>Plan de pruebas del sistema (actualizado).</li><li>Informe de los resultados de las pruebas.</li><li>Descripción de las pruebas, el resultado esperado, resultado obtenido y acciones a tomar para corregir las desviaciones.</li></ul></li><li>Instalación:<ul><li>Planes detallados de contingencias de explotación, caídas del sistema y recuperación.</li><li>Plan de revisión post-instalación.</li><li>Informe de la instalación.</li><li>Carta de aceptación del sistema.</li></ul></li><li>Mantenimiento:<ul><li>Listado de fallos detectados en el sistema.</li><li>Listado de mejoras solicitadas por los usuarios (si no dan lugar a nuevos proyectos).</li><li>Traza detallada de los cambios realizados en el sistema.</li><li>Actas de las revisiones regulares del sistema y aceptación de los niveles de soporte.</li></ul></li></ul></li></ul><p>A todos estos documentos hay que añadir en todas las fases documentos con la estimación y planificación de la próxima fase y del resto del proyecto. También habrá que ir actualizando el índice de todo el material relacionado.</p><h3 id="Descomposicion-en-Fases-del-Desarrollo-de-una-Aplicacion"><a href="#Descomposicion-en-Fases-del-Desarrollo-de-una-Aplicacion" class="headerlink" title="Descomposición en Fases del Desarrollo de una Aplicación"></a>Descomposición en Fases del Desarrollo de una Aplicación</h3><p>La descomposición por fases (actividades) se basa en referencias históricas de la empresa que asocian una cantidad media de horas de trabajo a una actividad concreta, de modo que dado un proyecto concreto podemos estimar la cantidad de esfuerzo que se dedicará a esa actividad. En ésta se ha de tener en cuenta el tipo de proyecto, el lenguaje de desarrollo y la madurez de la organización.</p><p>Podemos plantear la descomposición desde el enfoque de entregables y asociar las tareas a la producción de un entregable concreto. Este enfoque tiene la ventaja de que la culminación de una tarea indica que ha concluido un producto y viceversa. Dado que, como veremos, no es aconsejable el tener tareas que duren más de una semana, se plantean problemas con algunos entregables que cuestan más.</p><p>El planteamiento de descomponer por procesos o actividades puede resultar más natural en algunos casos. Es más fácil conseguir tareas acotadas en el tiempo. Tiene la desventaja de que el proyecto no será tan fácil de controlar ya que en muchos casos será la palabra de los realizadores la única constancia de que la tarea está terminada o al “90%”.</p><p>En cualquier caso, los proyectos se planifican con dos horizontes, el de la próxima fase y el del proyecto completo. En el horizonte de la próxima fase se realiza con mayor nivel de detalle, mientras que según se alejan las fases se aplica un menor nivel de detalle.</p><p>La descomposición del proyecto con mayor nivel de refinamiento no puede basarse en datos recogidos de forma analítica, sino que hace falta una aportación personal de los miembros del equipo de trabajo, tanto para identificar tareas como para asignarles esfuerzos. Se suele aconsejar el trabajo en grupo donde todos puedan aportar sus conocimientos y experiencias previas.</p><p>Hay que tener en cuenta que si identificamos las tareas y se las imponemos a los desarrolladores, éstos funcionarán en una situación de sumisión lo que puede tener efectos perniciosos tanto para los plazos de entrega como para la calidad del software. Por otra parte el dejar que sean los propios desarrolladores los que identifiquen tareas y recursos, dentro de un marco razonable (puntos de función) les llevará a una situación de compromiso personal, pasando a interiorizar los objetivos y como consecuencia obtendremos mejores resultados.</p><p>La tarea fundamental de los desarrolladores es escuchar a los clientes o usuarios y traducir sus requisitos a un lenguaje comprensible por la máquina, de modo que el subsistema informático se adapte a las necesidades expresadas. Así para cualquier tarea podremos encontrar las siguientes subtareas:</p><ul><li>Documentarse, Buscar o Investigar.</li><li>Organizar, Escribir Documentos.</li><li>Verificar, Comprobar.</li><li>Revisar, Actualizar Documentos.</li><li>Entregar, Finalizar.</li></ul><p>Además de lo anterior hay que tener en cuenta que al ir desarrollando el sistema obtenemos información que nos será útil a la hora de identificar nuevas tareas. Así, el análisis estructurado nos provee de una descomposición del proyecto por productos: transacciones, archivos, entradas, salidas, etc. El Diseño de programas nos descompone el sistema por módulos, el Diseño de BD descompone por tablas, archivos, etc, y los diseños de interfaz de pantallas, listados, mensajes, etc. Así, por ejemplo, una entrada puede ser que requiera de una reunión con el usuario, un estudio de ésta y la posterior presentación y aprobación de la propuesta a desarrollar.</p><h3 id="Tareas-Usuales-de-un-Proyecto-Informatico"><a href="#Tareas-Usuales-de-un-Proyecto-Informatico" class="headerlink" title="Tareas Usuales de un Proyecto Informático"></a>Tareas Usuales de un Proyecto Informático</h3><ul><li>Estudio de viabilidad:<ul><li>Analizar el sistema propuesto y escribir una descripción.</li><li>Definir y documentar posibles tipos de sistemas.</li><li>Hacer un análisis de coste de sistemas similares.</li><li>Hacer una estimación del tamaño del sistema, la planificación y los costes (tener en cuenta los entregables más importantes).</li><li>Definir cualitativa y cuantitativamente los beneficios del sistema propuesto.</li><li>Realizar una planificación inicial del plazo de recuperación de la inversión.</li><li>Realización de una estimación detallada de costes, planificación, recursos, etc, de la siguiente fase (Análisis).</li><li>Asignar director del proyecto.</li><li>Composición del documento de estudio de viabilidad.</li><li>Presentación del documento de viabilidad a la dirección para su aprobación.</li></ul></li><li>Análisis:<ul><li>Captura de requisitos:<ul><li>Definir el ámbito del sistema propuesto.<ul><li>Funciones</li><li>Usuarios</li><li>Restricciones</li></ul></li><li>Entrevista a todos los usuarios propuestos y actuales:<ul><li>Determinar:<ul><li>Utilización del sistema actual.</li><li>Deficiencias del sistema actual.</li><li>Requisitos nuevos del sistema.</li></ul></li><li>Documentar:<ul><li>Descripción del sistema actual.</li><li>Deficiencias del sistema actual.</li></ul></li></ul></li><li>Producir el documento de requisitos del nuevo sistema:<ul><li>Incluir:<ul><li>Requisitos del usuario priorizados.</li><li>Resoluciones sobre las deficiencias del sistema actual.</li></ul></li></ul></li><li>Producir una lista de los beneficios tangibles e intangibles (un refinamiento de la lista del estudio de viabilidad).</li><li>Realización de una estimación detallada de costes, planificación, recursos, etc, de la siguiente fase (Especificación del sistema).</li><li>Producir una estimación revisada de costes, planificación, recursos, etc, para el resto del proyecto.</li><li>Producir el documento de definición de requisitos, esta tarea incluye la construcción de un prototipo.</li><li>Realizar una revisión final del documento de requisitos.</li><li>Toma la decisión de continuar o no con el proyecto.</li><li>Definir las responsabilidades en la próxima fase para el director, miembros del equipo de desarrollo y otros.</li></ul></li><li>Especificación del sistema:<ul><li>Definir el tipo de sistema propuesto: Transformar las restricciones físicas, ambientales y operacionales a características del sistema. Por ejemplo: ¿Sistema basado en transacciones? ¿Distribuido o centralizado?¿Estaciones de trabajo o terminales?</li><li>Esquematizar el sistema propuesto: Transformar los requerimientos del usuario de la fase anterior en unas especificaciones funcionales (DFD, Organigramas, etc).</li><li>Construir el diccionario de datos (DD): Describir todos los elementos del DFD incluyendo funciones y datos; asegurarse de que todas las relaciones inter-funcionales y entre datos sean documentadas. Si existe DD de la empresa, hacerlo compatible con el que estamos realizando.</li><li>Revisar y expandir el análisis de coste beneficio: Actualizarlo con la información nueva y verificar que los beneficios esperados se mantienen y que el plazo de recuperación de una inversión sigue siendo aceptable.</li><li>Realización de una estimación detallada de costes, planificación, recursos, etc, de la siguiente fase (Diseño del sistema).</li><li>Producir una estimación revisada de costes, planificación, recursos, etc, para el resto del proyecto.</li><li>Producir el documento de especificación del sistema.</li><li>Realizar una revisión final del documento de especificación del sistema.</li><li>Tomar la decisión de continuar o no con el proyecto.</li><li>Definir las responsabilidades en la próxima fase para el director, miembros del equipo de desarrollo y otros.</li></ul></li></ul></li><li>Diseño:<ul><li>Producir el diseño global del sistema, contendrá:<ul><li>Definir los programas y sus principales funciones.</li><li>Definir los principales flujos de datos entre programas y funciones.</li><li>Diseñar el esquema de datos lógico y físico.</li><li>Definir las fronteras con paquetes software, si existen.</li><li>Definir los entornos de hardware y software, proponiendo alternativas.</li></ul></li><li>Localización de paquetes software: Buscar paquetes software apropiados que puedan implementar parte, o toda la funcionalidad requerida del sistema de forma rentable y que, si se implementa, ofrezca un entorno compatible con los objetivos de la organización. (Puede realizarse antes del diseño, o de forma simultánea a la tarea anterior).</li><li>Desarrollar un diseño detallado del sistema, para cada alternativa de diseño planteada:<ul><li>Crear una descripción narrativa detallada del diseño para todo el sistema y cada una de sus partes (programas, funciones y datos).</li><li>Actualizar el diccionario de datos.</li><li>Definir los componentes hardware específicos (Capturadores de datos, sistemas de comunicación, etc) y sus funciones.</li><li>Validar el diseño con las especificaciones del sistema.</li><li>Documentar el entorno hardware y software necesarios para esta alternativa.</li></ul></li><li>Revisar y expandir el análisis de coste beneficio para cada alternativa:<ul><li>Actualizar con la información nueva.</li><li>Verificar que los beneficios esperados se mantienen y que el plazo de recuperación de la inversión sigue siendo aceptable.</li></ul></li><li>Evaluar las alternativas de diseño, para cada alternativa, documentar:<ul><li>Requerimientos de usuario que se alcanzan con esta alternativa.</li><li>Nivel de aceptación esperado de los usuarios.</li><li>Realización de una estimación detallada de costes, planificación, recursos, etc, de la siguiente fase (Codificación) con esta alternativa.</li><li>Producir una estimación revisada de costes, planificación, recursos, etc, para el resto del proyecto.</li><li>Alternativa recomendada.</li></ul></li><li>Desarrollo de un plan de test del sistema:<ul><li>Crear datos de entrada del test.</li><li>Producir el listado de los resultados esperados.</li><li>Producir el listado de los criterios de test.</li><li>Desarrollar la planificación de test del sistema.</li></ul></li><li>Desarrollar un plan de test diferenciado para cada alternativa.</li><li>Identificar las necesidades de entrenamiento y documentación de los usuarios. Definir las guías de:<ul><li>Documentación completa de usuario.</li><li>Manuales de operador.</li><li>Documentos y planificación de formación para usuarios y operadores.</li></ul></li><li>Producir el documento de diseño del sistema.</li><li>Realizar una revisión final del documento de diseño del sistema.</li><li>Tomar la decisión de continuar o no con el proyecto.</li><li>Recomendar una alternativa.</li><li>Definir las responsabilidades de la próxima fase para el director, miembros de los equipo de programación y test, así como de otros implicados.</li></ul></li><li>Codificación:<ul><li>Producir un plan de trabajo:<ul><li>Creación de la lista detallada de tareas necesarias para realizar la codificación y test de todos los componentes del sistema.</li><li>Producir una planificación para las tareas anteriores con las fechas más tempranas y más tardías, así como la asignación de responsabilidades.</li><li>Instaurar los procedimientos para recoger los progresos y estados del proyecto.</li><li>Instaurar los procedimientos para recoger tiempos, si resulta apropiado.</li><li>Obtener la aprobación del plan de trabajo por parte de la dirección.</li></ul></li><li>Realización del diseño detallado de cada programa:<ul><li>Diseñar detalladamente los diagramas:<ul><li>De estructura de los programas.</li><li>De estructura de los ficheros.</li><li>Pantallas, informes, y otras composiciones.</li><li>Esquemas de la base de datos.</li><li>Composición de las tablas y sus diseños.</li></ul></li><li>Pseudocódigo de la lógica del programa (Dependerá de los métodos de diseño utilizados).</li></ul></li><li>Codificar, documentar y pasar los test en cada programa:<ul><li>Codificar el programa.</li><li>Realizar las pruebas de unidad, hasta que los programas se adapten a las especificaciones descritas en las etapas anteriores.</li><li>Actualizar todo lo necesario en el sistema y en el DD de la organización.</li></ul></li><li>Realizar el test de integración:<ul><li>Poner todos los programas probados en la librería de pruebas de integración.</li><li>Realizar el test de integración de cada programa.</li><li>Documentar todos los resultados del test de integración.</li></ul></li><li>Terminar los manuales de operador y usuario, así como los de formación.</li><li>Realización de una estimación detallada de costes, planificación, recursos, etc, de la siguiente fase (Prueba del sistema).</li><li>Producir una estimación revisada de costes, planificación, recuros, etc, para el resto del proyecto.</li><li>Confeccionar el documento de diseño de programas y codificación.</li><li>Realizar revisiones del documento de diseño de programas y codificación.</li><li>Obtener los resultados finales de la integración completa del sistema y de las pruebas de integración.</li><li>Definir las responsabilidades en la próxima fase para el director, miembros del equipo de test, así como de otros implicados.</li></ul></li><li>Pruebas:<ul><li>Realizar el test del sistema:<ul><li>Hacer el test de sistema de acuerdo al documento de test del sistema.</li><li>Verificar la operatividad de los manuales de usuario y operador, utilizándolas en los cursos de formación de los usuarios y operadores que realicen el test del sistema.</li><li>Verificar los documentos de entrenamiento de usuarios y operadores, utilizándolos en los cursos de formación de los usuarios y operadores que realicen el test del sistema.</li><li>Documentar completamente los resultados del test del sistema.</li></ul></li><li>Revisar la planificación de instalación:<ul><li>Disponibilidad de los recursos.</li><li>Revisión de los factores de contingencia que puedan afectar a la instalación:<ul><li>Procesos especiales de final de mes y fin de año.</li><li>Vacaciones y fiestas.</li></ul></li><li>Disponibilidad de soporte por parte de otros proveedores.</li><li>Revisión final del calendario de instalación.</li></ul></li><li>Esbozar el plan de contingencia ante caídas del sistema:<ul><li>Criterios para las caídas.</li><li>Identificación de recursos para contingencias.</li><li>Horario para recuperaciones o abandonos.</li></ul></li><li>Desarrollar un acuerdo de nivel de servicio:<ul><li>Criterios de rendimiento de usuario, precisión y volumen.</li><li>Criterios de apoyo de los proveedores:<ul><li>Tiempo medio entre fallos.</li><li>Tiempo medio de reparación.</li></ul></li><li>Criterios de calidad del sistema.</li><li>Frecuencia con la que se medirán los criterios.</li></ul></li><li>Producir los documentos de test en la entrega.</li><li>Revisión y aprobación de los documentos de entrega.</li><li>Aprobación de la documentación del sistema.<ul><li>Documentación de programas.</li><li>Manuales de operador.</li><li>Manuales de usuario.</li><li>Manuales de formación.</li><li>Documentación de ayuda.</li></ul></li><li>Aprobación del plan de instalación.</li><li>Aprobación de los planes de contingencia, recuperación y caídas.</li><li>Finalización del sistema completamente probado:<ul><li>Documento de finalización del desarrollo del sistema.</li><li>Documento de finalización de los usuarios.</li><li>Documento de finalización del CPD.</li><li>Documento de finalización de garantía de calidad.</li><li>Documento de finalización de finanzas.</li></ul></li></ul></li><li>Instalación:<ul><li>Instalación de hardware y software nuevo.</li><li>Formar a los primeros usuarios y operadores.</li><li>Desarrollar los planes de contingencia, recuperación y caída.</li><li>Desarrollar los procedimientos de mantenimiento y versiones.</li><li>Establecer procedimientos para:<ul><li>Versiones regulares.</li><li>Versiones de emergencia.</li><li>Versión por configuración, si existen diferentes tipos de hardware.</li></ul></li><li>Llevar a cabo cualquier conversión de datos necesaria.</li><li>Llevar a cabo la instalación del sistema nuevo a producción:<ul><li>Instalación completa desde cero.</li><li>Instalación en paralelo.</li><li>Instalación por fases.</li></ul></li><li>Planificar y programar las revisiones post-instalación. Establecer los criterios de:<ul><li>Rendimiento del sistema.</li><li>Calidad del sistema.</li><li>Satisfacción del usuario.</li><li>Calidad y facilidad de Gestión de: manuales de usuario y operador, formación de usuarios y operadores e información y datos producidos.</li><li>Fluidez de la instalación.</li><li>Costes de desarrollo, instalación, operaciones y mantenimiento. Establecer planificación y calendario de las revisiones, asegurando la disponibilidad del personal y documentación.</li></ul></li><li>Llevar a cabo las revisiones post-instalación:<ul><li>Crear el informe de la revisión post-instalación.</li><li>Obtener la aprobación firmada de los informes de:<ul><li>Usuarios finales del sistema.</li><li>Operadores del sistema.</li><li>Auditoria y garantía de la calidad.</li><li>Desarrollo de sistemas.</li><li>Soporte de sistemas y mantenimiento.</li><li>Finanzas.</li></ul></li><li>Obtener la carta de aprobación del sistema.</li></ul></li><li>Establecer el calendario para otras revisiones post-instalación si es necesario.</li></ul></li><li>Mantenimiento:<ul><li>Implementar los cambios del sistema:<ul><li>Utilizar los procedimientos de implementación de versiones.</li><li>Implementar versiones de emergencias.</li></ul></li><li>Asegurarse de que el sistema continúa solucionando las necesidades de los usuarios:<ul><li>Utilizar los acuerdos de niveles de soporte, en estos acuerdos se establecen los requerimientos de soporte y objetivos de funcionamiento:<ul><li>Revisiones regulares de requerimientos del nivel de acuerdo.</li><li>Revisiones regulares de como el sistema está alcanzando sus objetivos.</li></ul></li><li>Llevar a cabo revisiones regulares del sistema:<ul><li>Utilizar los procedimientos y contenido de las revisiones post-instalación.</li></ul></li></ul></li></ul></li></ul><p>Estas tareas se han enumerado a modo de lista de comprobación, de forma que serán los desarrolladores los encargados de identificar las tareas apropiadas a cada proyecto así como los recursos necesarios, teniendo en cuenta la estimación previa del esfuerzo.</p><h2 id="Tareas-y-Funciones-de-los-Distintos-Agentes"><a href="#Tareas-y-Funciones-de-los-Distintos-Agentes" class="headerlink" title="Tareas y Funciones de los Distintos Agentes"></a>Tareas y Funciones de los Distintos Agentes</h2><p>Son personas y organizaciones que participan activamente en el proyecto o cuyos intereses pueden ser afectados positiva o negativamente tanto por el resultado de la ejecución del proyecto como por su terminación exitosa.</p><p>Los principales <em>agentes</em> en cada proyecto pueden ser:</p><ul><li>Jefe de proyecto. Responsable de la planificación y ejecución el proyecto.</li><li>Equipo de desarrollo. Encargado de realizar el proyecto.</li><li>Cliente. Es el que arriesga su dinero en el desarrollo, es decir, el que pagará por el sistema.</li><li>Usuarios. Personas que utilizarán el sistema a nivel operativo y que normalmente pertenecen al cliente. Nos dan pistas sobre el problema a nivel de funcionamiento. Son responsables de que el sistema funcione de manera eficiente.</li></ul><h3 id="El-Jefe-de-Proyecto"><a href="#El-Jefe-de-Proyecto" class="headerlink" title="El Jefe de Proyecto"></a>El Jefe de Proyecto</h3><p>La misión del jefe de proyecto es:</p><ul><li>Con el cliente:<ul><li>Dejarlo satisfecho.</li><li>Incrementar su competitividad y/o desempeño interno a través de la solución que se le entregue.</li></ul></li><li>Con el negocio:<ul><li>Lograr rentabilidad.</li><li>Aprovechar recursos al máximo.</li></ul></li><li>Con los recursos humanos:<ul><li>Crecimiento profesional.</li><li>Satisfacción interna y externa.</li></ul></li></ul><p>Al jefe de proyecto se le concede una amplia autoridad sobre los recursos del proyecto y puede adquirir nuevos recursos ya sea dentro o fuera de la organización. Todo el personal del proyecto está bajo su autoridad mientras dure el proyecto. Debe combinar conocimiento técnico en la materia además de habilidades de dirección para poder dirigir a todo el personal del proyecto.</p><p>Las interacciones que tiene el jefe de proyecto dentro de su organización son:</p><ul><li>Con su equipo de trabajo.</li><li>Con el ejecutivo de cuenta.</li><li>Con el departamento de calidad.</li></ul><p>Las interacciones que tiene el jefe de proyecto con el cliente son:</p><ul><li>Con el usuario operativo.</li><li>Con el departamento de sistemas.</li><li>Con el experto funcional del negocio.</li><li>Con otras áreas.</li></ul><h3 id="Responsabilidades-del-Jefe-de-Proyecto"><a href="#Responsabilidades-del-Jefe-de-Proyecto" class="headerlink" title="Responsabilidades del Jefe de Proyecto"></a>Responsabilidades del Jefe de Proyecto</h3><ul><li>Conocer los criterios de negociación acordados con el cliente.</li><li>Notificar al ejecutivo de cuenta los cambios al alcance para que los renegocie adecuadamente.</li><li>Evaluar el desempeño de cada persona en base al cumplimiento de los compromisos acordados.</li><li>Informar a la dirección de manera justificada y en tiempo sobre la planificación de la asignación y liberación de recursos.</li><li>Informar los requerimientos de formación, evaluaciones y vacaciones de los miembros del equipo de trabajo al director.</li><li>Informar de avances e incidentes del proyecto.</li><li>Asegurar que el proyecto sea rentable y productivo.</li><li>Dar seguimiento al plan de trabajo y corregir desviaciones a tiempo.</li><li>Asegurar la obtención de los recursos materiales indispensables para desarrollar el proyecto.</li></ul><h3 id="Autoridad-del-Jefe-de-Proyecto"><a href="#Autoridad-del-Jefe-de-Proyecto" class="headerlink" title="Autoridad del Jefe de Proyecto"></a>Autoridad del Jefe de Proyecto</h3><ul><li>Organizar al equipo de trabajo como sea más conveniente y productivo.</li><li>Definir las expectativas de crecimiento para los miembros del equipo de trabajo.</li><li>Implementar las medidas necesarias para que las expectativas de cada persona se cumplan.</li><li>Prescindir de los servicios de un miembro del equipo de trabajo, si hay motivos para apoyar esta decisión.</li></ul><h2 id="Bibliografia"><a href="#Bibliografia" class="headerlink" title="Bibliografia"></a>Bibliografia</h2><ul><li><a href="https://es.scribd.com/document/93243574/TICB2-Gestion-Del-Proceso-de-Desarrollo" rel="external nofollow noopener noreferrer" target="_blank">Scribd (tfandos)</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Gestion-del-proceso-de-desarrollo-objetivos-actores-y-actividades-Tecnicas-y-practicas-de-gestion-de-proyectos&quot;&gt;&lt;a href=&quot;#Gestion-de
      
    
    </summary>
    
      <category term="B3" scheme="http://localhost:4000/categories/B3/"/>
    
    
  </entry>
  
  <entry>
    <title>B3-T11</title>
    <link href="http://localhost:4000/wiki/B3/b3-t11/"/>
    <id>http://localhost:4000/wiki/B3/b3-t11/</id>
    <published>2019-01-16T15:11:23.000Z</published>
    <updated>2019-01-18T10:45:16.874Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Pruebas-Planificacion-y-documentacion-Utilizacion-de-datos-de-prueba-Pruebas-de-software-hardware-procedimientos-y-datos"><a href="#Pruebas-Planificacion-y-documentacion-Utilizacion-de-datos-de-prueba-Pruebas-de-software-hardware-procedimientos-y-datos" class="headerlink" title="Pruebas. Planificación y documentación. Utilización de datos de prueba. Pruebas de software, hardware, procedimientos y datos."></a>Pruebas. Planificación y documentación. Utilización de datos de prueba. Pruebas de software, hardware, procedimientos y datos.</h1><h2 id="Documentacion-y-Pruebas-en-el-Desarrollo-Tradicional-del-Software"><a href="#Documentacion-y-Pruebas-en-el-Desarrollo-Tradicional-del-Software" class="headerlink" title="Documentación y Pruebas en el Desarrollo Tradicional del Software"></a>Documentación y Pruebas en el Desarrollo Tradicional del Software</h2><h3 id="Documentacion-y-Desarrollo-de-Software"><a href="#Documentacion-y-Desarrollo-de-Software" class="headerlink" title="Documentación y Desarrollo de Software"></a>Documentación y Desarrollo de Software</h3><p>En general se habla mucho de la documentación, pero no se hace, no se le asigna presupuesto, no se la mantiene y casi nunca está al día en los proyectos de desarrollo de software. Lo importante es la disponibilidad de la documentación que se necesita en el momento en que se la necesita.</p><p>Muchas veces se hace porque hay que hacerla y se escribe, con pocas ganas, largos textos, a la vez que se está convencido de estar haciendo un trabajo inútil. A veces se peca por exceso y otras por defecto. Ocurre mucho en la Web y con productos RAD. En ocasiones se olvida que el mantenimiento también debe llegar a la documentación.</p><p>La documentación se suele clasificar en función de las personas o grupos a los cuales está dirigida:</p><ul><li>Documentación para los desarrolladores.</li><li>Documentación para los usuarios.</li><li>Documentación para los administradores o soporte técnico.</li></ul><p>La documentación para desarrolladores es aquélla que se utiliza para el propio desarrollo del producto y, sobre todo, para su mantenimiento futuro. Se documenta para comunicar estructura y comportamiento del sistema o de sus partes, para visualizar y controlar la arquitectura del sistema, para comprender mejor el mismo y para controlar el riesgo, entre otras cosas. Obviamente, cuanto más complejo es el sistema, más importante es la documentación.</p><p>En este sentido, todas las fases de un desarrollo deben documentarse: requerimientos, análisis, diseño, programación, pruebas, etc. Una herramienta muy útil en este sentido es una notación estándar de modelado, de modo que mediante ciertos diagramas se puedan comunicar ideas entre grupos de trabajo.</p><p>Hay decenas de notaciones, tanto estructuradas como orientadas a objetos. Un caso particular es el de UML. De todas maneras, los diagramas son muy útiles, pero siempre y cuando se mantengan actualizados, por lo que más vale calidad que cantidad.</p><p>La documentación para desarrolladores a menudo es llamada <strong>modelo</strong> , pues es una simplificación de la realidad para comprender mejor el sistema como un todo.</p><p>Otro aspecto a tener en cuenta cuando se documenta o modela, es el del nivel de detalle. Así como cuando construimos planos de un edificio podemos hacer planos generales, de arquitectura, de instalaciones y demás, también al documentar el software debemos cuidar el nivel de detalle y hacer diagramas diferentes en función del usuario de la documentación, concentrándonos en un aspecto a la vez.</p><p>De toda la documentación para los desarrolladores, nos interesa especialmente en esta obra aquella que se utiliza para documentar la programación, y en particular hemos analizado la que se usa para documentar desarrollos orientados a objetos.</p><p>La documentación para usuarios es todo aquello que necesita el usuario para la instalación, aprendizaje y uso del producto. Puede consistir en guías de instalación, guía del usuario, manuales de referencia y guía de mensajes.</p><p>En el caso de los usuarios que son programadores, esta documentación se debe acompañar con ejemplos de uso recomendados o de muestra y una reseña de efectos no evidentes de las bibliotecas.</p><p>Más allá de todo esto, debemos tener en cuenta que la estadística demuestra que los usuarios no leen los manuales a menos que nos les quede otra opción. Las razones pueden ser varias, pero un análisis de la realidad muestra que se recurre a los manuales solamente cuando se produce un error o se desconoce cómo lograr algo muy puntual, y recién cuando la ayuda en línea no satisface las necesidades del usuario. Por lo tanto, si bien es cierto que debemos realizar manuales, la existencia de un buen manual nunca nos libera de hacer un producto amigable para el usuario, que incluso contenga ayuda en línea. Es incluso deseable proveer un software tutorial que guíe al usuario en el uso del sistema, con apoyo multimedia, y que puede llegar a ser un curso on-line.</p><p>Buena parte de la documentación para los usuarios puede empezar a generarse desde que comienza el estudio de requisitos del sistema. Esto está bastante en consonancia con las ideas de <em>extreme programming</em> y con metodologías basadas en casos de uso.</p><p>La documentación para administradores o soporte técnico, a veces llamada manual de operaciones, contiene toda la información sobre el sistema terminado que no hace al uso por un usuario final. Es necesario que tenga una descripción de los errores posibles del sistema, así como los procedimientos de recuperación. Como esto no es algo estático, pues la aparición de nuevos errores, problemas de compatibilidad y demás nunca se puede descartar, en general el manual de operaciones es un documento que va engrosándose con el tiempo.</p><h3 id="Las-Pruebas-en-el-Desarrollo-de-Software"><a href="#Las-Pruebas-en-el-Desarrollo-de-Software" class="headerlink" title="Las Pruebas en el Desarrollo de Software"></a>Las Pruebas en el Desarrollo de Software</h3><p><strong>Calidad, errores y pruebas</strong></p><p>La calidad no es algo que se pueda agregar al software después de desarrollado si no se hizo todo el desarrollo con la cantidad en mente. Muchas veces parece que el software de calidad es aquel que brinda lo que se necesita con adecuada velocidad de procesamiento. En realidad, es mucho más que eso. Tiene que ver con la corrección, pero también con usabilidad, costo, consistencia, confiabilidad, compatibilidad, utilidad, eficiencia y apego a los estándares.</p><p>Todos estos aspectos de la calidad pueden ser objeto de tests o pruebas que determinen el grado de calidad. Incluso la documentación para el usuario debe ser probada.</p><p>Como en todo proyecto de cualquier índole,siempre se debe tratar que las fallas sean mínimas y poco costosas, durante todo el desarrollo. Y además, es sabido que cuanto más tarde se encuentra una falla, más caro resulta eliminarla. Es claro que si un error es descubierto en la mitad del desarrollo de un sistema, el costo de su corrección será mucho menor al que se debería enfrentar en caso de descubrirlo con el sistema instalado y en funcionamiento.</p><p>Desde el punto de vista de la programación,nos interesa la ausencia de errores (corrección), la confiabilidad y la eficiencia. Dejando de lado las dos últimas, nos concentraremos en este capítulo en las pruebas que determinan que un programa está libre de errores.</p><p>Un <strong>error</strong> es un comportamiento distinto del que espera un usuario razonable. Puede haber errores aunque se hayan seguido todos los pasos indicados en el análisis y en el diseño, y hasta en los requisitos aprobados por el usuario. Por lo tanto,no necesariamente un apego a los requisitos y un perfecto seguimiento de las etapas nos lleva a un producto sin errores, porque aún en la mente de un usuario pudo haber estado mal concebida la idea desde el comienzo. De allí la importancia del desarrollo incremental, que permite ir viendo versiones incompletas del sistema.</p><p>Por lo tanto, una primera fuente de errores ocurre antes de los requerimientos o en el propio proceso de análisis. Pero también hay errores que se introducen durante el proceso de desarrollo posterior. Así, puede haber errores de diseño y errores de implementación. Finalmente, puede haber incluso errores en la propia etapa de pruebas y depuración.</p><p><strong>Categorías de pruebas</strong></p><p>Según la naturaleza de lo que se esté controlando, las pruebas se pueden dividir en dos categorías:</p><ul><li>Pruebas centradas en la verificación.</li><li>Pruebas centradas en la validación.</li></ul><p>Las primeras sirven para determinar la consistencia entre los requerimientos y el programa terminado. Soporta metodologías formales de testeo, de mucho componente matemático. De todas maneras, hay que ser cuidadoso, porque no suele ser fácil encontrar qué es lo que hay que demostrar. La verificación consisten en determinar si estamos construyendo el sistema correctamente, a partir de los requisitos.</p><p>En general a los informáticos no les gustan las pruebas formales, en parte porque no las entienden y en parte porque requieren un proceso matemático relativamente complejo.</p><p>La validación consiste en saber si estamos construyendo el sistema correcto. Las tareas de validación son más informales. Las pruebas suelen mostrar la presencia de errores, pero nunca demuestran su ausencia.</p><p><strong>Las pruebas y el desarrollo de software</strong></p><p>La etapa de pruebas es una de las fases del ciclo de vida de los proyectos. Se la podría ubicar después del análisis, el diseño y la programación, pero dependiendo del proyecto en cuestión y del modelo de proceso elegido, su realización podría ser en forma paralela a las fases citadas o inclusive repertirse varias veces durante la duración del proyecto.</p><p>La importancia de esta fase será mayor o menor según las características del sistema desarrollado, llegando a ser vital en sistemas de tiempo real u otros en los que los errores sean irrecuperables.</p><p>Las pruebas no tienen el objeto de prevenir errores sino de detectarlos. Se efectúan sobre el trabajo realizado y se deben encarar con la intención de descubrir la mayor cantidad de errores posible.</p><p>Para realizar las pruebas se requiere gente que disfrute encontrando errores, por eso no es bueno que sea el mismo equipo de desarrollo el que lleve a cabo este trabajo. Además, es un principio fundamental de las auditorías. Por otro lado, es bastante común que a quien le guste programar no le guste probar y viceversa.</p><p>A veces se dan por terminadas las pruebas antes de tiempo. En las pruebas de caja blanca no es mala idea probar un 85% de las ramas y dar por terminado luego de esto. Otra posibilidad es la siembra de errores y seguir las pruebas hasta que se encuentren un 85% de los errores sembrados, lo que presumiblemente implica que se encontró un 86% de los no sembrados. Otros métodos se basan en la estadística y las comparaciones, ya sea por similitud con otro sistema en cantidad de errores o por el tiempo de prueba usado en otro sistema.</p><p>En un proyecto ideal, podríamos generar casos de prueba para cubrir todas las posibles entradas y todas las posibles situaciones por las que podría atravesar el sistema. Examinaríamos así exhaustivamente el sistema para asegurar que su comportamiento sea perfecto. Pero hay un problema con esto: el número de casos de prueba para un sistema complejo es tan grande que no alcanzaría una vida para terminar con las pruebas. Como consecuencia, nadie realiza una prueba exhaustiva de nada salvo en sistemas triviales.</p><p>En un sistema real, los casos de prueba se deben hacer sobre las partes del sistema en los cuales una buena prueba brinde un mayor retorno de la inversión o en las cuales un error represente un riesgo mayor.</p><p>Las pruebas cuestan mucho dinero. Pero para ello existe una máxima: “pague por la prueba ahora o pague el doble por el mantenimiento después”.</p><p>Todo esto lleva a que se deban planificar bien las pruebas, con suficiente anticipación, y determinar desde el comienzo los resultados que se deben obtener.</p><p>La idea de <em>extreme programming</em> es más radical: propone primero escribir los programas de prueba y después la aplicación, obligando a correr las pruebas siempre antes de una integración. Se basa en la idea bastante acertada de que los programas de prueba son la mejor descripción de los requerimientos.</p><p>Las pruebas son prácticas a realizar en diversos momentos de la vida del sistema de información para verificar:</p><ul><li>El correcto funcionamiento de los componentes del sistema.</li><li>El correcto ensamblaje entre los distintos componentes.</li><li>El funcionamiento correcto de las interfaces entre los distintos subsistemas que lo componen y con el resto de sistemas de información con los que se comunica.</li><li>El funcionamiento correcto del sistema integrado de hardware y software en el entorno de operación.</li><li>Que el sistema cumple con el funcionamiento esperado y permite al usuario de dicho sistema que determine su aceptación, desde el punto de vista de su funcionalidad y rendimiento.</li><li>Que los cambios sobre un componente de un sistema de información, no introducen un comportamiento no deseado o errores adicionales en otros componentes no modificados.</li></ul><p>Las diversas pruebas a que debe ser sometido un sistema deben ser realizadas tanto por el equipo de desarrolladores, como por los usuarios, equipos de operación y mantenimiento en la implantación, aceptación y mantenimiento del sistema de información.</p><p><strong>Tipos de pruebas</strong></p><p>Analizaremos 7 tipos de pruebas:</p><ul><li>Revisiones de código.</li><li>Pruebas unitarias.</li><li>Pruebas de integración.</li><li>Pruebas de sistema.</li><li>Pruebas de implantación.</li><li>Pruebas de aceptación.</li><li>Pruebas de regresión.</li></ul><p>No son tipos de pruebas intercambiables, ya que testean cosas distintas.</p><p>Otra posible clasificación de las pruebas es:</p><ul><li>De caja blanca o de código</li><li>De caja negra o de especificación</li></ul><p>En las primeras se evalúa el contenido de los módulos, mientras en las segundas se trata al módulo como una caja cerrada y se lo prueba con valores de entrada, evaluando los valores de salida. Vistas de este modo, las pruebas de caja negra sirven para verificar especificaciones.</p><p>Las pruebas unitarias suelen ser de caja blanca o de caja negra, mientras que las de integración, sistema y aceptación son de caja negra. Las tareas de depuración luego de encontrar errores son más bien técnicas de caja blanca, así como las revisiones de código. En todos los casos, uno de los mayores desafíos es encontrar los datos de prueba: hay que encontrar un subconjunto de todas las entradas que tengan alta probabilidad de detectar el mayor número de errores.</p><p><strong>Revisiones de código</strong></p><p>Las revisiones de código son las únicas que se podrían omitir de todos los tipos de pruebas, pero tal vez sea buen idea por lo menos hacer alguna de ellas:</p><ul><li>Pruebas de escritorio.</li><li>Recorridos de código.</li><li>Inspecciones de código.</li></ul><p>La <em>prueba de escritorio</em> rinde muy poco, tal vez menos de lo que cuesta, pero es una costumbre difícil de desterrar. Es bueno centrarse en buscar anomalías típicas, como variables u objetos no inicializados o que no se usan, ciclos infinitos y demás.</p><p>Los <em>recorridos</em> rinden mucho más. Son exposiciones del código escrito frente a pares. El programador, exponiendo su código, encuentra muchos errores. Además da ideas avanzadas a programadores nuevos que se lleva a recorrer.</p><p>Las llamadas <em>inspecciones de código</em> consisten en reuniones en conjunto entre los responsables de la programación y los responsables de la revisión.Tienen como objetivo revisar el código escrito por los programadores para chequear que cumpla con las normas que se hayan fijado y para verificar la eficiencia del mismo. Se realizan siguiendo el código de un pequeño porcentaje de módulos seleccionados al azar o según su grado de complejidad. Las inspecciones se pueden usar en sistemas grandes, pero con cuidado para no dar idea de estar evaluando al programador. Suelen servir porque los revisores están más acostumbrados a ver determinados tipos de errores comunes a todos los programadores. Además, después de una inspección a un programador, de la que surge un tipo de error, pueden volver a inspeccionar a otro para ver si no cayó en el mismo error.</p><p>El concepto de <em>extreme programming</em> propone programar de a dos, de modo que uno escribe y el otro observa el trabajo. Si el que está programando no puede avanzar en algún momento, sigue el que miraba. Y si ambos se traban pueden pedir ayuda a otro par. Esta no sólo es una forma más social de programación, sino que aprovecha las mismas ventajas de los recorridos e inspecciones de código, y puede prescindir de ellos.</p><p><strong>Pruebas unitarias</strong></p><p>Las pruebas unitarias se realizan para controlar el funcionamiento de pequeñas porciones de código como ser subprogramas (en la programación estructurada) o métodos (en POO). Generalmente son realizadas por los mismos programadores puesto que al conocer con mayor detalle el código, se les simplifica la tarea de elaborar conjuntos de datos de prueba para testearlo.</p><p>Si bien una prueba exhaustiva sería impensada teniendo en cuenta recursos, plazos, etc, es posible y necesario elegir cuidadosamente los casos de prueba para recorrer tantos caminos lógicos como sea posible. Inclusive procediendo de esta manera, deberemos estar preparados para manejar un gran volumen de datos de prueba.</p><p>Los métodos de cobertura de caja blanca tratan de recorrer todos los caminos posibles por lo menos una vez, lo que no garantiza que no haya errores pero pretende encontrar la mayor parte.</p><p>El tipo de prueba a la cual se someterá a cada uno de los módulos dependerá de su complejidad. Recordemos que nuestro objetivo aquí es encontrar la mayor cantidad de errores posible. Si se pretende realizar una prueba estructurada, se puede confeccionar un grafo de flujo con la lógica del código a probar. De esta manera se podrán determinar todos los caminos por los que el hilo de ejecución pueda llegar a pasar, y por consecuente elaborar los juegos de valores de pruebas para aplicar al módulo, con mayor facilidad y seguridad.</p><p>Un grafo de flujo se compone de:</p><ul><li>Nodos (círculos), que representan una o más acciones del módulo.</li><li>Aristas (flechas), que representan el flujo de control entre los distintos nodos.</li></ul><p>Los nodos predicados son aquellos que contienen una condición, por lo que de ellos emergen dos o más aristas.</p><p><img src="https://gsitic.files.wordpress.com/2018/05/nodos_predicados.png?w=825" alt=""></p><p>El paso de un diseño detallado o un pseudocódigo que representa una porción de programa a un grafo de flujo, requiere de las siguientes etapas:</p><ul><li>Señalar cada condición, tanto en sentencias _if_ y <em>case</em> como en bucles <em>while</em> y <em>repeat</em> .</li><li>Agrupar todas las secuencias siguiendo los esquemas de representación de construcciones.</li><li>Numerar cada uno de los nodos resultantes de manera que consten de un identificador único. Las ramas de cada bifurcación pueden identificarse por el mismo número seguido de distintas letras.</li><li>Dibujar en forma ordenada los nodos y sus aristas.</li></ul><p>En el siguiente ejemplo, se muestra la manera de traducir un pequeño tramo de programa escrito en pseudocódigo a forma de grafo de flujo:</p><p><img src="https://gsitic.files.wordpress.com/2018/05/pseudocodigo_grafo.png?w=825" alt=""></p><p>Las pruebas unitarias tienen como objetivo verificar la funcionalidad y estructura de cada componente individualmente una vez que ha sido codificado.</p><p>Las pruebas unitarias constituyen la prueba inicial de un sistema y las demás pruebas deben apoyarse sobre ellas.</p><p>Existen dos enfoques principales para el diseño de casos de prueba:</p><ul><li><strong>Enfoque estructural</strong> o de <strong>caja blanca</strong> . Se verifica la estructura interna del componente con independencia de la funcionalidad establecida para el mismo. Por tanto, no se comprueba la corrección de los resultados si éstos se producen. Ejemplos de este tipo de pruebas pueden ser ejecutar todas las instrucciones del programa, localizar código no usado, comprobar los caminos lógicos del programa, etc.</li><li><strong>Enfoque funcional</strong> o de <strong>caja negra</strong> . Se comprueba el correcto funcionamiento de los componentes del sistema de información, analizando las entradas y salidas y verificando que el resultado es el esperado. Se consideran exclusivamente las entradas y salidas del sistema sin preocuparse por la estructura interna del mismo.</li></ul><p>El enfoque que suele adoptarse para una prueba unitaria está claramente orientado al diseño de casos de caja blanca, aunque se complemente con caja negra. El hecho de incorporar casos de caja blanca se debe, por una parte, a que el tamaño del componente es apropiado para poder examinar toda la lógica y por otra, a que el tipo de defectos que se busca, coincide con los propios de la lógica detallada en los componentes.</p><p>Los pasos necesarios para llevar a cabo las pruebas unitarias son los siguientes:</p><ul><li>Ejecutar todos los casos de prueba asociados a cada verificación establecida en el plan de pruebas, registrando su resultado. Los casos de prueba deben contemplar tanto las condiciones válidas y esperadas como las inválidas e inesperadas.</li><li>Corregir los errores o defectos encontrados y repetir las pruebas que lo detectaron. Si se considera necesario, debido a su implicación o importancia, se repetirán otros casos de prueba ya realizados con anterioridad.</li></ul><p>La prueba unitaria se da por finalizada cuando se hayan realizado todas las verificaciones establecidas y no se encuentre ningún defecto, o bien se determine su suspensión.</p><p><strong>Pruebas de integración</strong></p><p>En el caso de las pruebas de integración y de sistema,dado que ya se han realizado las pruebas unitarias, se tomará a cada uno de los módulos unitarios como una caja negra.</p><p>Las pruebas de integración tienen como base las pruebas unitarias y consisten en una progresión ordenada de testeos para los cuales los distintos módulos van siendo ensamblados y probados hasta haber integrado el sistema completo. Si bien se realizan sobre módulos ya probados en forma individual, no es necesario que se terminen todas las pruebas unitarias para comenzar con las de integración. Dependiendo de la forma en que se organicen, se pueden realizar en paralelo a las unitarias.</p><p>El orden de integración de los módulos influye en:</p><ul><li>La forma de preparar los casos de prueba.</li><li>Las herramientas a utilizar (módulos ficticios, muñones, impulsores o “stubs”).</li><li>El orden para codificar y probar los módulos.</li><li>El costo de preparar los casos.</li><li>El costo de la depuración.</li></ul><p>Tanto es así que se le debe prestar especial atención al proceso de elección del orden de integración que se emplee.</p><p>Existen principalmente dos tipos de integración:</p><ul><li>La <em>integración incremental</em></li><li>La integración <em>no incremental</em> .</li></ul><p>La <strong>integración incremental</strong> consiste en combinar el conjunto de módulos ya probados (al principio será un conjunto vacío) con los siguientes módulos a probar. Luego se va incrementando progresivamente el número de módulos unidos hasta que se forma el sistema completo.</p><p>En la <strong>integración no incremental</strong> o <strong>Big Bang</strong> se combinan todos los módulos de una vez.</p><p>Para ambos tipos de integración se deberán preparar los datos de prueba junto con los resultados esperados. Esta tarea debe ser realizada por personas ajenas a la programación de los módulos. No es necesario que la lleven a cabo una vez codificados los módulos puesto que basta con conocer qué módulos compondrán el sistema y cuál será la interfaz entre ellos.</p><p>Si en algún momento de la prueba se detectara uno o más errores, se dejará constancia del hecho y se reenviarán los módulos afectados al responsable de la programación para que identifique la causa del problema y lo solucione. Luego se volverán a efectuar las pruebas programadas y así sucesivamente hasta que el sistema entero esté integrado y sin errores.</p><p>Por el hecho de poder ser llevada a cabo por distintos caminos, la integración incremental brinda una mayor flexibilidad en el uso de recursos. Se puede integrar la estructura de módulos desde un extremo a otro y continuar hacia el extremo opuesto según distintas prioridades. La forma de llevar a cabo esta tarea dependerá de la naturaleza del sistema en cuestión, pero sea cual fuere el camino elegido, será de suma importancia una correcta planificación.</p><p>En la <strong>integración incremental ascendente (De abajo arriba – bottom-up)</strong> se comienza integrando primero los módulos de más bajo nivel. El proceso deberá seguir los siguientes pasos:</p><ul><li>Elegir los módulos de bajo nivel que se van a probar.</li><li>Escribir un módulo impulsor para la entrada de datos de prueba a los módulos y para la visualización de los resultados.</li><li>Probar la integración de los módulos.</li><li>Eliminar los módulos impulsores y juntar los módulos ya probados con los módulos de niveles superiores, para continuar con las pruebas.</li></ul><p>Estas tareas se pueden realizar en paralelo si es que se dispone de tres equipos de trabajo, o en serie de lo contrario. Para la prueba de cada uno de los módulos mencionados, es necesaria la preparación de un módulo impulsor. El objeto de los módulos impulsores es transmitir o impulsar los casos de prueba a los módulos testeados y recibir los resultados que estos produzcan en los casos en que sea necesario. Es decir, que deben simular las operaciones de llamada de los módulos jerárquicos superiores correspondientes. Estos módulos tienen que estar bien diseñados, para que no arrojen ni más ni menos errores que los que realmente pueden producirse. Al fin y al cabo, deben simular todas las situaciones que se van a producir en el sistema real.</p><p>La <strong>integración incremental descendente (De arriba abajo – top-down)</strong> parte del módulo de control principal (de mayor nivel) para luego ir incorporando los módulos subordinados progresivamente. No hay un procedimiento considerado óptimo para seleccionar el siguiente módulo a incorporar. La única regla es que el módulo incorporado tenga todos los módulos que lo invocan previamente probados.</p><p>En general no hay una secuencia óptima de integración. Debe estudiarse el problema concreto y de acuerdo a este, buscar el orden de integración más adecuado para la organización de las pruebas. No obstante, pueden considerarse las siguientes pautas:</p><ul><li>Si hay secciones críticas como ser un módulo complicado, se debe proyectar la secuencia de integración para incorporarlas lo antes posible.</li><li>El orden de integración debe incorporar cuanto antes los módulos de entrada y salida.</li></ul><p>Existen principalmente dos métodos para la incorporación de módulos:</p><ul><li>Primero en profundidad: primero se mueve verticalmente en la estructura de módulos.</li><li>Primero en anchura: Primero se mueve horizontalmente en la estructura de módulos.</li></ul><p>Etapas de la integración descendente:</p><ul><li>El módulo de mayor nivel hace de impulsor y se escriben módulos ficticios simulando a los subordinados, que serán llamados por el módulo de control superior.</li><li>Probar cada vez que se incorpora un módulo nuevo al conjunto ya engarzado.</li><li>Al terminar cada prueba, sustituir un módulo ficticio subordinado por el real que reemplazaba, según el orden elegido.</li><li>Escribir los módulos ficticios subordinados que se necesiten para la prueba del nuevo módulo incorporado.</li></ul><p>Los módulos ficticios subordinados se crean para permitir la prueba de los demás módulos. Pueden llevar a cabo una variedad de funciones, como por ejemplo:</p><ul><li>Mostrar un mensaje que demuestre que ese módulo fue alcanzado (“Módulo XX alcanzado”).</li><li>Establecer una conversación con una terminal. De esta forma se puede permitir que la misma persona que realiza la prueba actúe de módulo subordinado.</li><li>Devolver un valor constante, tabulado o elegido al azar.</li><li>Ser una versión simplificada del módulo representado.</li><li>Mostrar los datos recibidos.</li><li>Ser un loop sin nada que hacer más que dejar pasar el tiempo.</li></ul><p>Ventajas de la integración descendente:</p><ul><li>Las fallas que pudieran existir en los módulos superiores se detectan en una etapa temprana.</li><li>Permite ver la estructura del sistema desde un principio, facilitando la elaboración de demostraciones de su funcionamiento.</li><li>Concuerda con la necesidad de definir primero las interfaces de los distintos subsistemas para después seguir con las funciones específicas de cada uno por separado.</li></ul><p>Desventajas de la integración descendente:</p><ul><li>Requiere mucho trabajo de desarrollo adicional ya que se deben escribir un gran número de módulos ficticios subordinados que no siempre son fáciles de realizar. Suelen ser más complicados de lo que aparentan.</li><li>Antes de incorporar los módulos de entrada y salida resulta difícil introducir los casos de prueba y obtener los resultados.</li><li>Los juegos de datos de prueba pueden resulta difíciles o imposibles de generar puesto que generalmente son los módulos de nivel inferior los que proporcionan los detalles.</li><li>Induce a diferir la terminación de la prueba de ciertos módulos.</li></ul><p>Ventajas de la integración incremental ascendente:</p><ul><li>Las entradas para las pruebas son más fáciles de crear ya que los módulos inferiores suelen tener funciones más específicas.</li><li>Es más fácil la observación de los resultados de las pruebas puesto que es en los módulos inferiores donde se elaboran.</li><li>Resuelve primero los errores de los módulos inferiores que son los que acostumbran tener el procesamiento más complejo, para luego nutrir de datos al resto del sistema.</li></ul><p>Desventajas de la integración incremental ascendente:</p><ul><li>Se requieren módulos impulsores, que deben escribirse especialmente y que no son necesariamente sencillos de codificar.</li><li>El sistema como entidad no existe hasta que se agrega el último módulo.</li></ul><p>El método de <strong>integración incremental sándwich (estrategia combinada)</strong> combina facetas de los métodos ascendente y descendente. Consiste en integrar una parte del sistema en forma ascendente y la restante en forma descendente, provocando la unión de ambas partes en algún punto intermedio. La principal ventaja es que nos da mayor libertad para elegir el orden de integración de los módulos según las características específicas del sistema en cuestión. De esta manera, podremos incluir y probar antes los módulos que consideremos críticos:</p><ul><li>Módulos dirigidos a múltiples propósitos.</li><li>Módulos con mayor control (en general, los módulos de mayor nivel controlan a muchos otros módulos).</li><li>Módulos con alto grado de complejidad.</li><li>Módulos con requisitos de rendimiento muy definidos.</li></ul><p>La <strong>integración no incremental</strong> puede ser beneficiosa par la prueba de sistema de pequeñísima envergadura cuya cantidad de módulos sea muy limitada y la interfaz entre los mismos clara y sencilla. Consiste en integrar todos los módulos del sistema a la vez e ingresar los valores de prueba para testear todas las interfaces.</p><p>La única ventaja es que no se necesita ningún tipo de trabajo adicional: ni planificar el orden de integración, ni crear módulos impulsores, ni crear módulos ficticios subordinados. Por otro lado, la lista de desventajas incluye:</p><ul><li>No se tiene noción de la comunicación de los módulos hasta el final.</li><li>En ningún momento se dispone de un producto -siquiera parcial- para mostrar o presentar.</li><li>El hecho de realizar todas las pruebas de una vez hace que las sesiones de prueba sean largas y tediosas.</li><li>La cantidad de errores que arroje puede ser atemorizante.</li><li>La tarea de encontrar la causa de los errores resulta mucho más compleja que con los métodos incrementales.</li><li>Se corre el riesgo de que a poco tiempo de que se cumpla el plazo de entrega, haya que volver sobre el diseño y la codificación del sistema.</li></ul><p><strong>Pruebas de sistema</strong></p><p>Son pruebas de integración del sistema de información completo, y permiten probar el sistema en su conjunto y con otros sistemas con los que se relaciona para verificar que las especificaciones funcionales y técnicas se cumplen. Dan una visión muy similar a su comportamiento en el entorno de producción.</p><p>Las pruebas de sistema se realizan una vez integrados todos los componentes. Su objetivo es ver la respuesta del sistema en su conjunto, frente a distintas situaciones. Se simulan varias alternativas que podrían darse con el sistema implantado y en base a ellas se prueba la eficacia y eficiencia de la respuesta que se obtiene.</p><p>Se pueden distinguir varios tipos de pruebas distintos, por ejemplo:</p><ul><li><strong>Pruebas negativas</strong> : se trata de que el sistema falle para ver sus debilidades.</li><li><strong>Pruebas funcionales</strong> : dirigidas a asegurar que el sistema de información realiza correctamente todas las funciones que se han detallado en las especificaciones dadas por el usuario del sistema.</li><li><strong>Pruebas de comunicaciones</strong> : determinan que las interfaces entre los componentes del sistema funcionan adecuadamente, tanto a través de dispositivos remotos, como locales. Asimismo, se han de probar las interfaces hombre/máquina.</li><li><strong>Pruebas de volumen</strong> : consisten en examinar el funcionamiento del sistema cuando está trabajando con grandes volúmenes de datos, simulando las cargas de trabajo esperadas.</li><li><strong>Pruebas de sobrecarga</strong> : consisten en comprobar el funcionamiento del sistema en el umbral límite de los recursos, sometiéndole a cargas masivas. El objetivo es establecer los puntos extremos en los cuales el sistema empieza a operar por debajo de los requisitos establecidos.</li><li><strong>Pruebas de disponibilidad de datos</strong> : consisten en demostrar que el sistema puede recuperarse ante fallos, tanto de equipo físico como lógico, sin comprometer la integridad de los datos.</li><li><strong>Pruebas de facilidad de uso</strong> : consisten en comprobar la adaptabilidad del sistema a las necesidades de los usuarios, tanto para asegurar que se acomoda a su modo habitual de trabajo, como para determinar las facilidades que aporta al introducir datos en el sistema y obtener los resultados.</li><li><strong>Pruebas de operación</strong> : consisten en comprobar la correcta implementación de los procedimientos de operación, incluyendo la planificación y control de trabajos, arranque y rearranque del sistema, etc.</li><li><strong>Pruebas de entorno</strong> : consisten en verificar las interacciones del sistema con otros sistemas dentro del mismo entorno.</li><li><strong>Pruebas de recuperación</strong> : se simulan fallas de software y/o hardware para verificar la eficacia del proceso de recuperación.</li><li><strong>Pruebas de rendimiento</strong> : tiene como objeto evaluar el rendimiento del sistema integrado en condiciones de uso habitual. Consisten en determinar que los tiempos de respuesta están dentro de los intervalos establecidos en las especificaciones del sistema.</li><li><strong>Pruebas de resistencia o de estrés</strong> : comprueban el comportamiento del sistema ante situaciones donde se demanden cantidades extremas de recursos (número de transacciones simultáneas anormal, excesivo uso de las memorias, etc).</li><li><strong>Pruebas de seguridad</strong> : se utilizan para testear el esquema de seguridad intentando vulnerar los métodos utilizados para el control de accesos no autorizados al sistema. Consisten en verificar los mecanismos de control de acceso al sistema para evitar alteraciones indebidas en los datos.</li><li><strong>Pruebas de instalación</strong> : verifican que el sistema puede ser instalado satisfactoriamente en el equipo del cliente, incluyendo todas las plataformas y configuraciones de hardware necesarias.</li><li><strong>Pruebas de compatibilidad</strong> : se prueba al sistema en las diferentes configuraciones de hardware o de red y de plataformas de software que debe soportar.</li></ul><p><strong>Pruebas de implantación</strong></p><p>El objetivo de las pruebas de implantación es comprobar el funcionamiento correcto del sistema integrado de hardware y software en el entorno de operación, y permitir al usuario que, desde el punto de vista de operación, realice la aceptación del sistema una vez instalado en su entorno real y en base al cumplimiento de los requisitos no funcionales especificados.</p><p>Una vez que hayan sido realizadas las pruebas del sistema en el entorno de desarrollo, se llevan a cabo las verificaciones necesarias para asegurar que el sistema funcionará correctamente en el entorno de operación. Debe comprobarse que responde satisfactoriamente a los requisitos de rendimiento, seguridad, operación y coexistencia con el resto de los sistemas de la instalación para conseguir la aceptación del usuario de operación.</p><p>Las pruebas de <strong>seguridad</strong> van dirigidas a verificar que los mecanismos de protección incorporados al sistema cumplen su objetivo; las de <strong>rendimiento</strong> a asegurar que el sistema responde satisfactoriamente en los márgenes establecidos en cuanto a tiempos de respuesta, de ejecución y de utilización de recursos, así como los volúmenes de espacio en disco y capacidad; por último con las pruebas de <strong>operación</strong> se comprueba que la planificación y control de trabajos del sistema se realiza de acuerdo a los procedimientos establecidos, considerando la gestión y control de las comunicaciones y asegurando la disponibilidad de los distintos recursos.</p><p>Asimismo, también son llevadas a cabo las pruebas de <strong>gestión de copias de seguridad</strong> y recuperación, con el objetivo de verificar que el sistema no ve comprometido su funcionamiento al existir un control y seguimiento de los procedimientos de salvaguarda y de recuperación de la información, en caso de caídas en los servicios o en algunos de sus componentes. Para comprobar estos últimos, se provoca el fallo del sistema, verificando si la recuperación se lleva a cabo de forma apropiada. En el caso de realizarse de forma automática, se evalúa la inicialización, los mecanismos de recuperación del estado del sistema, los datos y todos aquellos recursos que se vean implicados.</p><p>Las verificaciones de las pruebas de implantación y las pruebas del sistema tienen muchos puntos en común al compartir algunas de las fuentes para su diseño como pueden ser los casos para probar el rendimiento (pruebas de sobrecarga o <em>stress</em> ).</p><p>El responsable de implantación junto al equipo de desarrollo determina las verificaciones necesarias para realizar las pruebas así como los criterios de aceptación del sistema. Estas pruebas las realiza el equipo de operación, integrado por los técnicos de sistemas y de operación que han recibido previamente la formación necesaria para llevarlas a cabo.</p><p><strong>Pruebas de aceptación</strong></p><p>El objetivo de las pruebas de aceptación es validar que un sistema cumple con el funcionamiento esperado y permitir al usuario de dicho sistema que determine su aceptación, desde el punto de vista de su funcionalidad y rendimiento.</p><p>Las pruebas de aceptación, al igual que las de sistema, se realizan sobre el producto terminado e integrado; pero a diferencia de aquellas, están concebidas para que sea un usuario final quien detecte los posibles errores.</p><p>Se clasifican en dos tipos:</p><ul><li>Pruebas Alfa.</li><li>Pruebas Beta.</li></ul><p>Las <strong>pruebas Alfa</strong> se realizan por un cliente en un entorno controlado por el equipo de desarrollo. Para que tengan validez, se debe primero crear un ambiente con las mismas condiciones que se encontrarán en las instalaciones del cliente. Una vez logrado esto, se procede a realizar las pruebas y a documentar los resultados.</p><p>Cuando el software sea la adaptación de una versión previa, deberán probarse también los procesos de transformación de datos y actualización de archivos de todo tipo.</p><p>Las <strong>pruebas Beta</strong> se realizan en las instalaciones propias de los clientes. Para que tengan lugar, en primer término se deben distribuir copias del sistema para que cada cliente lo instale en sus oficinas, dependencias y/o sucursales, según sea el caso. Si se tratase de un número reducido de clientes el tema de la distribución de las copias no representa grandes dificultades, pero en el caso de productos de venta masiva, la elección de los <em>beta testers</em> debe realizarse con sumo cuidado. En el caso de las pruebas Beta ,cada usuario realizará sus propias pruebas y documentará los errores que encuentre, así como las sugerencias que crea conveniente realizar, para que el equipo de desarrollo tenga en cuenta al momento de analizar las posibles modificaciones.</p><p>Cuando el sistema tenga un cliente individual, las pruebas de aceptación se hacen de común acuerdo con éste, y los usuarios se determinan en forma programada, así como también se definen los aspectos a probar y la forma de informar resultados. Cuando, en cambio, se está desarrollando un producto masivo, los usuarios para pruebas de determinan de formas menos estrictas, y hay que ser muy cuidado en la evaluación del <em>feedback</em> que proveen. Por lo tanto, en este segundo caso hay que dedicar un esfuerzo considerable a la planificación de las pruebas de aceptación.</p><p><strong>Pruebas de regresión</strong></p><p>El objetivo de las pruebas de regresión es eliminar el efecto onda, es decir, comprobar que los cambios sobre un componente de un sistema de información, no introducen un comportamiento no deseado o errores adicionales en otros componentes no modificados.</p><p>Las pruebas de regresión se deben llevar a cabo cada vez que se hace un cambio en el sistema, tanto para corregir un error como para realizar una mejora. No es suficiente probar sólo los componentes modificados o añadidos, o las funciones que en ellos se realizan, sino que también es necesario controlar que las modificaciones no produzcan efectos negativos sobre el mismo u otros componentes.</p><p>Normalmente, este tipo de pruebas implica la repetición de las pruebas que ya se han realizado previamente, con el fin de asegurar que no se introducen errores que puedan comprometer el funcionamiento de otros componentes que no han sido modificados y confirmar que el sistema funciona correctamente una vez realizados los cambios.</p><p>Las pruebas de regresión pueden incluir:</p><ul><li>La repetición de los casos de pruebas que se han realizado anteriormente y están directamente relacionados con la parte del sistema modificada.</li><li>La revisión de los procedimientos manuales preparados antes del cambio, para asegurar que permanecen correctamente.</li><li>La obtención impresa del diccionario de datos de forma que se comprueba que los elementos de datos que han sufrido algún cambio son correctos.</li></ul><p>El responsable de realizar las pruebas de regresión será el equipo de desarrollo junto al técnico de mantenimiento, quien a su vez, será responsable de especificar el plan de pruebas de regresión y de evaluar los resultados de dichas pruebas.</p><h3 id="Relacion-ante-los-resultados-de-las-pruebas"><a href="#Relacion-ante-los-resultados-de-las-pruebas" class="headerlink" title="Relación ante los resultados de las pruebas"></a>Relación ante los resultados de las pruebas</h3><p>Las pruebas nos llevan a descubrir errores, que en la mayoría de los casos son de tipo funcional, es decir, del tipo: “el sistema debería hacer tal cosa y hace tal otra”.</p><p>En este apartado analizaremos nada más que los pasos a seguir cuando el error sólo es atribuible a la codificación.</p><p><strong>Depuración</strong></p><p>La depuración es la corrección de errores que sólo afectan a la programación, porque no provienen de errores previos en el análisis o en el diseño. A veces la depuración se hace luego de la entrega del sistema al cliente y es parte del mantenimiento.</p><p>En realidad, en las revisiones de código y las pruebas unitarias, encontrar un error es considerablemente más sencillo, ya que se hace con el código a mano. Aun cuando se hubiera optado por una prueba unitaria de caja negra,es sencillo recorrer el módulo que revela un comportamiento erróneo por dentro para determinar el lugar exacto del error. Existen incluso herramientas de depuración ( <em>debugging</em> ) de los propios ambientes de desarrollo que facilitan esta tarea, que incluso proveen recorrido paso a paso y examen de valores de datos. Y el lenguaje C traía una macro <em>assert</em> portable, que sencillamente abortaba un programa si una condición no se cumplía.</p><p>De todas maneras, es importante analizar correctamente si el error está donde parece estar o proviene de una falla oculta más atrás en el código. Para encontrar estos casos más complejos son útiles las herramientas de recorrida hacia atrás, que permiten partir del lugar donde se genera el error y recorrer paso a paso el programa en sentido inverso.</p><p>Las pruebas de integración, de sistema y de aceptación también pueden llevar a que sea necesaria una depuración, aunque aquí es más difícil encontrar el lugar exacto del error. Por eso a menudo se utilizan <em>bitácoras</em> ( <em>logs</em> ), que nos permiten evaluar las condiciones que se fueron dando antes de un error mediante el análisis de un historial de uso del sistema que queda registrado en medios de almacenamiento permanente.</p><p>La depuración se hace en cuatro pasos:</p><ul><li>Reproducir el error.</li><li>Diagnosticar la causa.</li><li>Corregirla.</li><li>Verificar la corrección.</li></ul><p>Si el error no se repite al intentar reproducirlo es muy difícil hacer el diagnóstico. Como en casi todas las ciencias, se buscan causas y efectos, condiciones necesarias y suficientes para que se produzca el error. Luego hay que buscar el sector del código donde se produce el error, lo que nos lleva a las consideraciones hechas recientemente. La corrección del error entraña mucho riesgo, porque a menudo se introducen nuevos errores (hay quienes hablan de tasas de 0,2 a 0,5 nuevos errores por corrección). Y nunca hay que olvidarse de realizar una nueva verificación después de la corrección.</p><p><strong>Reacción ante los errores en las pruebas de sistema y de aceptación</strong></p><p>Hemos dicho ya que los errores que aparezcan en estos tipos de prueba van a llevar a la larga a una depuración, en la medida en que sean errores de codificación.</p><p>Para llegar a ello, no obstante, se requiere determinar el módulo donde se produjo el error. Esta tarea, en apariencia dificultosa, puede facilitarse considerablemente si trabajamos con un entorno de desarrollo que nos permita recorrer el código en modo de depuración sin necesidad de entrar en todos los módulos.</p><h2 id="Revision-Formal"><a href="#Revision-Formal" class="headerlink" title="Revisión Formal"></a>Revisión Formal</h2><p>El objetivo de la revisión formal es detectar y registrar los defectos de un producto intermedio verificando que satisface sus especificaciones y que se ajusta a los estándares establecidos, señalando las posibles desviaciones.</p><p>Es un proceso de revisión riguroso en el que hay poca flexibilidad a la hora de llevarlo a cabo debido a que su objetivo es llegar a detectar lo antes posible, los posibles defectos o desviaciones en los productos que se van generando a lo largo del desarrollo. Esta característica fuerza a que se adopte esta práctica únicamente para productos que son de especial importancia, porque de otro modo podría frenar la marcha del proyecto.</p><p>En este proceso intervienen varias personas del grupo de aseguramiento de calidad, el equipo de desarrollo y según el tipo de revisión formal puede participar también el usuario.</p><p>El responsable del grupo de aseguramiento de calidad una vez que conoce los productos que se van a revisar formalmente, establece los grupos funcionales que van a llevar a cabo las revisiones, convocando a los participantes por adelantado, e informando del objetivo de la revisión, la agenda y las responsabilidades que tendrán asignadas en la revisión.</p><p>Es importante que en el transcurso de la revisión se sigan las directrices que estableció el responsable del grupo de aseguramiento de calidad, con el fin de que sea productiva y no se pierda tiempo en discusiones o ataques al responsable del producto.</p><p>Se concluye determinando las áreas de problemas y elaborando un informe de revisión formal y una lista de acciones correctivas que posee un carácter formal y vinculante.</p><h2 id="Revision-Tecnica"><a href="#Revision-Tecnica" class="headerlink" title="Revisión Técnica"></a>Revisión Técnica</h2><p>El objetivo de la revisión técnica es evaluar un producto intermedio del desarrollo para comprobar que se ajusta a sus especificaciones y que se está elaborando de acuerdo a las normas, estándares y guías aplicables al proyecto.</p><p>Con el fin de asegurar la calidad en el producto final del desarrollo, se deben llevar a cabo revisiones semiformales sobre los productos intermedios durante todo el ciclo de vida del software. Para ello, se fijan los objetivos de la revisión, la agenda que se podrá ir ajustando a lo largo del proyecto y el tipo de informe que se elaborará después de las revisiones.</p><p>Los participantes en una revisión técnica son el jefe de proyecto y el responsable del grupo de aseguramiento de calidad que, de forma conjunta, revisarán el producto que corresponda en cada momento.</p><p>Una vez fijado sobre qué productos intermedios se llevarán a cabo las revisiones, el responsable de aseguramiento de calidad recoge la información necesaria de cada producto para poder establecer los criterios de revisión y más adelante, evaluar si el producto cumple las especificaciones, es decir, si se ha elaborado de acuerdo a unas características concretas como pueden ser la aplicación de una técnica específica, la inclusión de algún tipo de información, etc. Además, se debe contar con la normativa y estándares aplicables al proyecto de forma que, no sólo se asegure que el producto cumpla sus especificaciones, sino también del modo adecuado.</p><p>Si se detecta alguna desviación en cuanto a sus especificaciones o a los estándares aplicados, y se considera que es necesario realizar alguna modificación, el responsable del grupo de aseguramiento de calidad elabora un informe con el que el jefe de proyecto tomará las medidas que estime convenientes. Con dichos informes de calidad, el jefe de proyecto irá confeccionando el dossier de aseguramiento de calidad, que formará parte de la documentación del proyecto al finalizar el desarrollo.</p><h2 id="Bibliografia"><a href="#Bibliografia" class="headerlink" title="Bibliografía"></a>Bibliografía</h2><ul><li><a href="http://materias.fi.uba.ar/7507/content/20101/lecturas/documentacion_pruebas.pdf" rel="external nofollow noopener noreferrer" target="_blank">UBA (Universidad de Buenos Aires)</a></li><li><a href="https://administracionelectronica.gob.es/pae_Home/pae_Documentacion/pae_Metodolog/pae_Metrica_v3.html" rel="external nofollow noopener noreferrer" target="_blank">PAe (Métrica 3)</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Pruebas-Planificacion-y-documentacion-Utilizacion-de-datos-de-prueba-Pruebas-de-software-hardware-procedimientos-y-datos&quot;&gt;&lt;a href=&quot;#
      
    
    </summary>
    
      <category term="B3" scheme="http://localhost:4000/categories/B3/"/>
    
    
  </entry>
  
  <entry>
    <title>B4-T03</title>
    <link href="http://localhost:4000/wiki/B4/b4-t03/"/>
    <id>http://localhost:4000/wiki/B4/b4-t03/</id>
    <published>2019-01-16T15:11:23.000Z</published>
    <updated>2019-01-18T10:45:16.881Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Practicas-de-mantenimiento-de-equipos-e-instalaciones-Tipos-de-mantenimiento-Monitorizacion-y-gestion-de-capacidad"><a href="#Practicas-de-mantenimiento-de-equipos-e-instalaciones-Tipos-de-mantenimiento-Monitorizacion-y-gestion-de-capacidad" class="headerlink" title="Prácticas de mantenimiento de equipos e instalaciones. Tipos de mantenimiento. Monitorización y gestión de capacidad."></a>Prácticas de mantenimiento de equipos e instalaciones. Tipos de mantenimiento. Monitorización y gestión de capacidad.</h1><h2 id="Introduccion"><a href="#Introduccion" class="headerlink" title="Introducción"></a>Introducción</h2><p>El mantenimiento se puede definir como aquel conjunto de técnicas que aseguran el continuo funcionamiento del ordenador personal, se puede ver como el cuidado que se le da al ordenador para prevenir posibles fallos y para prolongarle la vida, teniendo en cuenta la ubicación física del equipo ya sea en la oficina o en casa.</p><h3 id="Tipos-de-Mantenimiento"><a href="#Tipos-de-Mantenimiento" class="headerlink" title="Tipos de Mantenimiento"></a>Tipos de Mantenimiento</h3><p>Hay tres tipos de mantenimiento:</p><ul><li>Mantenimiento preventivo.</li><li>Mantenimiento correctivo.</li><li>Mantenimiento perfectivo.</li></ul><p><strong>Mantenimiento preventivo de ordenadores</strong></p><p>El mantenimiento preventivo consiste en crear un ambiente favorable para el sistema y conservar limpias todas las partes que componen un computador, por ejemplo, basta decir que la mayor parte de fallos que presentan los equipos se debe al exceso de polvo en los componentes internos, ya que éste actúa como aislante térmico. En definitiva se trata de conocer aquellos elementos que pueden disminuir la vida útil del equipo.</p><p>Otro aspecto que junto al polvo perjudica a la vida del ordenador es que el calor generado por los componentes no pueda dispersarse adecuadamente porque es atrapado en la capa de polvo.</p><p>Ni que decir tiene el hecho de junto con el polvo se mezclen las partículas de grasa y aceite que pueda contener el aire del ambiente, ya que crean una espesa capa aislante que refleja el calor hacia los demás componentes, con lo cual se reduce la vida útil del sistema en general.</p><p>Por otro lado, el polvo contiene elementos conductores que pueden generar cortocircuitos entre las trayectorias de los circuitos impresos y tarjetas de periféricos.</p><p>Si se quiere prolongar la vida útil del equipo y hacer que permanezca libre de reparaciones por muchos años se debe realizar una limpieza con frecuencia del entorno, o por lo menos evitar en la medida de los posible una serie de factores como son:</p><ul><li>El agua.</li><li>La electricidad.</li><li>Los golpes.</li><li>El frío.</li><li>El calor.</li><li>etc.</li></ul><p><strong>Mantenimiento correctivo y perfectivo para PCs</strong></p><p>El mantenimiento correctivo consiste en la reparación de alguno de los componentes del ordenador, que abarcan desde una soldadura pequeña, el cambio total de una tarjeta (sonido, video, memoria), o el cambio total de algún dispositivo periférico como el ratón, teclado, monitor, disco duro, etc.</p><p>El mantenimiento perfectivo consiste en la ampliación de algún componente del equipo para aumentar su capacidad en base a una serie de requerimientos, por ejemplo, ampliar la capacidad del disco duro con uno nuevo, aumentar un módulo de memoria, etc.</p><p>Generalmente resulta mucho más barato cambiar algún dispositivo que al tratar de repararlo pues muchas veces la complejidad del dispositivo nos limita ya no solo por la necesidad de tener aparatos especiales, sino por la complejidad técnica del componente en si mismo. Por ejemplo intentar reparar una placa base de una marca X modelo XXX puede ser completamente distinto de reparar una placa base de la misma marca X pero el modelo XXY. En estos casos es más sencillo sustituir la pieza y enviar la defectuosa al servicio técnico de la casa X.</p><p>Asimismo, para realizar el mantenimiento debe considerarse lo siguiente:</p><ul><li>Revisión de los recursos del sistema, memoria, procesador y disco duro.</li><li>Optimización de la velocidad del micro.</li><li>Revisión de la instalación eléctrica (sólo para especialistas).</li><li>Un informe de los problemas de cada equipo junto con el mantenimiento realizado a cada equipo.</li><li>Observaciones que puedan mejorar el ambiente de funcionamiento.</li></ul><h3 id="Criterios-que-se-deben-considerar-para-el-mantenimiento-del-PC"><a href="#Criterios-que-se-deben-considerar-para-el-mantenimiento-del-PC" class="headerlink" title="Criterios que se deben considerar para el mantenimiento del PC"></a>Criterios que se deben considerar para el mantenimiento del PC</h3><p>A la hora de realizar el mantenimiento basta con seguir dos criterios muy sencillos de aplicar:</p><ul><li>La periodicidad: debería de hacerse, con una periodicidad semestral, una limpieza física del ordenador para evitar tener que realizar un mantenimiento correctivo.</li><li>La ubicación del equipo: afectará o beneficiará al ordenador, deben tenerse en cuenta varios factores:<ul><li>En casa:<ul><li>Alejar el ordenador de las ventanas para evitar que los rayos del sol dañen al equipo y para evitar que el polvo se acumule con mayor rapidez.</li><li>Colocar el equipo en un mueble que se pueda limpiar con facilidad.</li><li>Comprar enchufes protectores de corriente.</li><li>Aspirar con frecuencia la alfombra o moqueta en la que se encuentra el equipo para evitar que se acumule el polvo.</li><li>No colocar objetos sobre el monitor que le tapen la ventilación y por tanto no disipen bien el calor.</li><li>No colocar el equipo muy pegado a la pared, dejando que el ventilado de la fuente de alimentación disipe bien el calor.</li></ul></li><li>Oficina, en el lugar de trabajo, el mantenimiento es más tedioso debido a que se genera más polvo que en casa, hay más vibraciones y seguramente descargas eléctricas, habrá aparatos que produzcan magnetismo y pueden provocar pérdidas de datos, hay más humo, etc.</li></ul></li></ul><p>Consideraciones finales con respecto al equipo:</p><ul><li>No exponerlo a los rayos del sol.</li><li>No colocarlo en lugares húmedos.</li><li>Mantenerlo alejado de equipos electrónicos que produzcan campos magnéticos ya que pueden dañarlo.</li><li>Limpiar con frecuencia.</li><li>No fumar.</li><li>Evitar comer y beber cuando se esté usando.</li><li>Utilizar sistemas de alimentación ininterrumpida en los servidores para que si la energía se corta tener tiempo para guardar la información.</li><li>Revisión de la instalación eléctrica de la casa u oficina, pero esto lo debe de hacer un especialista.</li></ul><h2 id="Herramientas-para-Mantener-el-PC"><a href="#Herramientas-para-Mantener-el-PC" class="headerlink" title="Herramientas para Mantener el PC"></a>Herramientas para Mantener el PC</h2><p>Antes de empezar a realizar un mantenimiento del PC, o a ensamblar uno nuevo a partir de componentes sueltos, es muy conveniente tener en cuenta una serie de recomendaciones en cuanto a las herramientas que posiblemente se vayan a precisar y alguna advertencia sobre la manipulación de los componentes y la electricidad estática.</p><p>Para mantener y ampliar un ordenador, es necesario tener algunas herramientas, las cuales en un principio deberían de ser de una calidad aceptable para que duren más y ayuden en la facilidad de mantener.</p><p>Por lo menos se tiene que quitar la carcasa de la torre e insertar o quitar tarjetas de expansión, ventiladores, fuente de alimentación, memoria, reemplazar un lector de disquetes de CDROM, un disco duro, etc.</p><p>Se debe también ser capaz de configurar los jumpers y los conmutadores que se pueden encontrar en los dispositivos IDE y en la placa base.</p><p>Hay dispositivos a los que se les conectan cables de corriente y por lo tanto hay que probar la continuidad en fusibles y cables.</p><p>Para ejecutar tales tareas es necesario un equipo de herramienta básico que contenga los elementos siguientes:</p><ul><li>Destornillador de estrella de un tamaño mediano.</li><li>Destornillador de cabeza plana de un tamaño mediano.</li><li>Destornillador Torx (especial para tornillos con una cabeza en forma de estrella de 6 puntas). Por norma general, estos tornillos son típicos de PC de marca o se encuentran en lugares a donde el fabricante del PC no desea que se acceda.</li><li>Pinza extractora: Permite recuperar un tornillo cuando se cae entre los componentes de la placa base, y también se utiliza para insertar y sacar jumpers.</li><li>Alicates terminados en punta: Útiles para, por ejemplo, extraer los separadores de la placa base.</li><li>Destornillador buscapolos: Para comprobar, por ejemplo, el interruptor de encendido del ordenador.</li><li>Bridas: Para no dejar cables sueltos.</li><li>Insertor / Extrator de chips: necesarios para llevar a cabo ampliaciones de memoria (las famosas tarjetas gráficas que se les podía expandir la memoria) y reemplazar chips defectuosos.</li><li>Cortador de cables.</li><li>Pelacables.</li><li>Pulsera antiestática: Para evitar la electricidad estática.</li><li>Un polímetro: Permite comprobar la continuidad de corriente.</li><li>Tenacillas.</li><li>Un disquete y una cinta para limpiar las unidades correspondientes.</li><li>Piezas de recambio.</li></ul><p>La siguiente lista de elementos no son imprescindibles para realizar las tareas de mantenimiento de PC’s, pero sí que son útiles para determinadas tareas:</p><ul><li>Un soldador y su soporte.</li><li>Un bote de aire comprimido: Quita el polvo que se acumula en el interior de la caja del ordenador y en el ventilador de la fuente de alimentación.</li><li>Un pequeño limpiador de vacío: para las placas y el teclado.</li><li>Materiales de limpieza. Elimina la suciedad que se “pega” en el exterior del ordenador, incluido el monitor.</li></ul><h3 id="Polimetros"><a href="#Polimetros" class="headerlink" title="Polímetros"></a>Polímetros</h3><p>Un polímetro es una pieza extremadamente útil en un equipo de comprobación y debe formar parte del equipo de herramientas para realizar mantenimiento. Para mantener un equipo no es necesario comprar el mejor polímetro del mercado, simplemente es bueno comprar aquel que incluya protección a las sobrecargas, ya que de haberlas, un polímetro de protección de sobrecarga es más resistente a estos abusos y el costo extra que pueda suponer se amortiza rápidamente.</p><p>Existen en el mercado polímetros analógicos y digitales, siendo estos últimos más caros y más precisos pero en el uso que se le da para el mantenimiento del equipo no son recomendables por su alto coste.</p><p>Con un polímetro se comprueban los fusibles y la continuidad de los conectores, utilizando los rangos de resistencias para medir continuidad y determinar si hay alguna resistencia alta. Se puede usar en los rangos de voltios DC, entre otras cosas, para comprobar las salidas de la fuente de alimentación.</p><p>Para comprobar un fusible, se utiliza el rango de resistencias. Primero se cortocircuitan las puntas de pruebas y luego se ajusta a cero la medida que da, utilizando el control que hay en el polímetro. A continuación se conectan las puntas una a cada extremo del fusible. Si no se obtiene una lectura de cero ohmios, el fusible está defectuoso.</p><p>Para comprobar una batería se pone el polímetro en el rango de voltaje DC y en la escala más alta en la que se espera que se encuentre el voltaje de la batería. Luego se conectan las puntas de prueba a los contactos de la batería, teniendo cuidado de que la polaridad sea correcta observando el voltaje en la escala.</p><h3 id="Extraccion-y-Cambio-de-chips"><a href="#Extraccion-y-Cambio-de-chips" class="headerlink" title="Extracción y Cambio de chips"></a>Extracción y Cambio de chips</h3><p>No es normal que en las labores de mantenimiento se tengan que reparar las placas base y de las tarjetas de un PC cambiando algún chip por dos motivos:</p><ul><li>Es una tarea de los técnicos de las respectivas casas.</li><li>No es habitual encontrar en el mercado un componente de esas características.</li></ul><p>Pero si que puede llegarse a dar el caso de tener que quitar y volver a instalar algún que otro chip. Por ejemplo, a las tarjetas gráficas de hace 3 años (que aún se encuentran en numerosos puntos de nuestra geografía), se les podía ampliar la memoria, y esta ampliación se realizaba insertándole un chip en un slot de la tarjeta.</p><h3 id="Piezas-de-Recambio"><a href="#Piezas-de-Recambio" class="headerlink" title="Piezas de Recambio"></a>Piezas de Recambio</h3><p>Para realizar un buen mantenimiento, aparte de las herramientas también hace falta disponer de ciertas piezas de recambio, exactamente las piezas que más hacen falta en todo sistema informático son:</p><ul><li>Fuentes de alimientación.</li><li>Discos Duros.</li><li>Disqueteras. Son estándar, de 3’5″.</li><li>Ratones. No ocupan mucho espacio y es habitual tener que cambiarlos.</li><li>Teclados.</li><li>Monitores: Tienen el problema de que son voluminosos para tenerlos almacenados.</li></ul><p>Estas piezas se pueden obtener por diversos cauces:</p><ul><li>Comprándolas: La compra de fuentes de alimentación, disqueteras, ratones y teclados son triviales y no son excesivamente caras a no ser que se deseen componentes especiales como p.ej. un ratón inalámbrico. Sin embargo los discos duros y los monitores suelen ser caros, y los monitores son voluminosos para tenerlos de recambios.</li><li>Reutilizando: Cuando se retira un equipo se pueden aprovecha los componentes como la fuente, el teclado, etc, para en un momento dado volverlo a utilizar.</li></ul><h2 id="Mantenimiento-Preventivo-Elementos-que-afectan-a-la-vida-del-equipo"><a href="#Mantenimiento-Preventivo-Elementos-que-afectan-a-la-vida-del-equipo" class="headerlink" title="Mantenimiento Preventivo: Elementos que afectan a la vida del equipo"></a>Mantenimiento Preventivo: Elementos que afectan a la vida del equipo</h2><p>Hoy en día los ordenadores (clónicos y de marca) junto con los periféricos son muy fiables. Funcionan durante mucho tiempo sin el más mínimo fallo, pero es prudente no dar ciertas cosas por supuestas. Si se acondiciona el entorno en el que se va a instalar un PC y se cuida durante el uso, se evitarán muchos problemas.</p><p>En este apartado se hace un repaso a aquellos elementos que a veces parecen insignificantes, pero que tanto pueden afectar a la vida útil de un equipo. Conocerlos ayudará a evitar que se produzcan problemas o, al menos, reducir su importancia. Se verán los factores que hay que tener en cuenta a la hora de elegir un entorno de trabajo adecuado. También se comentarán los problemas causados por los picos de tensión y cómo solucionarlos. Y una serie de consejos a seguir para prolongar la vida de los ordenadores y de los cuidados que se deben tener durante el trabajo, para conseguirlo.</p><h3 id="Ubicacion-del-Equipo"><a href="#Ubicacion-del-Equipo" class="headerlink" title="Ubicación del Equipo"></a>Ubicación del Equipo</h3><p>De todos es sabido que los mainframes requieren un entorno refrigerado con temperatura constante ya que sus complejos circuitos generan una gran cantidad de calor. El exceso de humedad y el polvo pueden reducir la fiabilidad de su gran número de interconexiones además los mainframes también necesitan fuentes de alimentación con filtros especiales y altamente fiables.</p><p>Los ordenadores actuales tienen menos componentes y generan menos calor, siendo más silenciosos que sus predecesores (sin tener en cuenta el ruido que generan los ventiladores).</p><p>No obstante, lo mejor sería cuidar el ambiente en el que está ubicado el equipo, en concreto sería correcto tener en cuenta las siguientes consideraciones:</p><ul><li>Tenerlo correctamente ventilado.</li><li>No tenerlo con un exceso de calor ni de frío.</li><li>Evitar los humos.</li><li>Evitar colocarlo cerca de materiales magnéticos.</li><li>Evitar ubicarlo cerca de fuentes de vibración (impresoras) pues pueden dañar los discos duros.</li><li>No conectarlo en líneas eléctricas a la que estén conectados aparatos con gran consumo de energía como aparatos de aire acondicionado.</li><li>Mantener el entorno limpio, libre de polvo.</li></ul><h3 id="Frio-y-Calor"><a href="#Frio-y-Calor" class="headerlink" title="Frío y Calor"></a>Frío y Calor</h3><p>Los componentes electrónicos consumen corriente y, por tanto, terminan por calentarse, pero hay que tener muy en cuenta que el exceso de calor perjudica. Para comprobar este consumo de energía basta con abrir la caja del equipo después de apagarlo y comprobar si componentes como el disco duro, los chips, etc, están calientes.</p><p>Los componentes electrónicos tienen una vida limitada, que se reduce en la medida que el calor se incrementa, por lo que es muy importante tener en cuenta la temperatura ambiente a la que el PC funciona. Dentro del ordenador, se disipa una gran cantidad de calor gracias a la corriente de aire que el ventilador hace circular a través de la caja. Además de incrementar el riesgo de fallo de los componentes, el calor excesivo puede producir otros problemas.</p><p>Si la temperatura se eleva considerablemente, habrá muchas posibilidades de que algún componente deje de funcionar bien o que funcione mal. Algunos dispositivos, como por ejemplo las fuentes de alimentación, en la actualidad disponen de diseños de circuitos protegidos contra el calor, de tal forma que si la temperatura de funcionamiento excede de ciertos niveles, se produce una parada en el funcionamiento.</p><p>Todos los componentes se calientan cuando se conectan y se enfrían cuando se desconectan, lo que produce dilataciones y contracciones, que a su vez, producen tensiones mecánicas. El problema es más grave con los chips instalados sobre zócalos que con los soldados en la placa. Con el paso del tiempo, las dilataciones y las contracciones hacen que las patillas se salgan fuera del zócalo produciéndose un fallo. Este tipo de fallos es muy común en las tarjetas gráficas, de hecho en los nuevos zócalos AGP traen incorporado una especie de “amarra tarjetas AGP”, para evitar que se muevan.</p><p>De igual forma se debe evitar un exceso de frío, porque fomenta la formación de condensación, lo que puede causar la oxidación de las superficies metálicas tanto en los conectores como en los zócalos de los chips. Con el tiempo, esto produce contactos eléctricos poco fiables.</p><p>Si se ha dejado la máquina en un medio extremadamente frío durante un tiempo, no se debe conectarla hasta que pase el tiempo suficiente como para que alcance la temperatura de la habitación. la resistencia de los componentes eléctricos disminuye con la temperatura, lo que hace que por ellos circule más corriente, de este modo, al conectar el ordenador, se podría estropear algún fusible o causar daños más serios.</p><p>Los ordenadores no habrían llegado a ser tan populares si hubiesen necesitado aire acondicionado, pero no deben estar sometidos a temperaturas extremas; por ejemplo, no se deben poner junto a una ventana que a veces reciba directamente la luz solar, sobre todo en verano, cuando la temperatura puede pasar de 40ºC. También se debe evitar poner junto a calentadores o fogones.</p><p>Un punto importante que no se debe pasar por alto es permitir la obstrucción de las ranuras de ventilación de las cajas de la unidad y del monitor. El ventilador no funcionará de forma totalmente eficiente si no hay suficiente espacio detrás de la unidad. No se debe poner la máquina contra una pared u otra barrera, ni apilar papeles, manuales o discos en lo alto del ordenador o del monitor.</p><h3 id="Humedad"><a href="#Humedad" class="headerlink" title="Humedad"></a>Humedad</h3><p>Un exceso de humedad puede dañar al ordenador. Este problema puede ser particularmente serio a altas temperaturas. La condensación puede tener muchos efectos, como pueden ser la oxidación de las superficies de las partes metálicas, o de los contactos eléctricos, o la rotura de los materiales de aislamiento de la fuente de alimentación y del monitor. Este fenómeno es frecuente en zonas costeras españoles, donde el problema se agrava aún más debido a la salinidad del agua del mar que se mezcla con la humedad en las viviendas.</p><p>La ausencia de humedad, por calor, o por tiempo seco, puede crear problemas con la electricidad estática.</p><h3 id="Polvo-y-Suciedad"><a href="#Polvo-y-Suciedad" class="headerlink" title="Polvo y Suciedad"></a>Polvo y Suciedad</h3><p>Hay poco que se pueda hacer cuando se utiliza el ordenador en un entorno sucio y polvoriento. Sin embargo, se ha de tener en cuenta que la acumulación de polvo reduce la fiabilidad del ordenador. Una limpieza periódica podría ser necesaria para evitar problemas.</p><p>El monitor es un buen indicador de la cantidad de polvo que hay en el entorno. Los monitores de ordenador, atraen el polvo, debido a la electricidad estática que hay en la pantalla. Si se acerca la mano a la pantalla se nota como los pelos del dorso son atraídos hacia el CTR. Se pueden incluso notar chasquidos de la electricidad estática. La pantalla actúa como un imán para el polvo, que se pega a ella o se mete en la unidad del sistema.</p><p>Es asombrosa la cantidad de polvo que se puede acumular dentro de la unidad. Esto se debe a la corriente de aire del ventilador que actúa como una bomba de vacío. La mayor parte de los ventiladores funcionan soplando aire por la parte trasera de la unidad. Este aire entra a través de las ranuras de ventilación, así como por otras aberturas, como las ranuras de las unidades de disco.</p><p>El polvo puede causar varios problemas en los ordenadores, ya que se amontona en las unidades de disquetes, ensuciando sus mecanismos y lo que es peor, pasándose a los discos, causando errores de lectura y otros fallos. El polvo se adhiere también a los componentes de la placa, reduciendo la capacidad que tienen de disipar calor. Se acumula, de la misma forma, en enchufes y zócalos, en los que las sustancias químicas que transporta pueden provocar que los contactos se enmohezcan, pudiendo producir conexiones poco fiables. Por último, puede introducirse dentro del motor, que en caso extremo, podría quemarse.</p><p>Si hay que trabajar con el ordenador en un medio polvoriento, lo único y más importante que se puede hacer es aumentar la frecuencia del mantenimiento preventivo, por lo que se debería limpiar más a menudo. Sin embargo, se puede reducir la cantidad de polvo que puede entrar en el ordenador si se es cuidadoso al elegir su colocación.</p><p>Las cajas tipo torre que se colocan en el suelo aumentan el nivel del polvo ya que los humanos al andar levantan gran cantidad de polvo.</p><p>Es muy recomendable utilizar un aspirador o una mopa en las salas de ordenadores, ya que las escobas lo único que hacen es levantar el polvo, sin embargo el aspirador lo absorbe.</p><p>El problema del polvo se vuelve peliagudo si se habla de los típicos servidores ubicados en una esquina y encendidos las 24 horas del día los 365 días del año, ya que suelen atraer gran cantidad de polvo, que puede repercutir en la disponibilidad.</p><p>Los teclados son también vulnerables a los efectos de la suciedad y del polvo, ya que por su naturaleza, son propensos a recoger otras cosas como migajas y ceniza de cigarrillos. Con el paso del tiempo, estas cosas se acumulan en su interior y pueden impedir, por un atasco, el funcionamiento de las teclas.</p><p>Se deben limpiar los teclados de forma periódica, como parte del mantenimiento preventivo. Sin embargo, en un medio particularmente sucio, se debe emplear un mayor nivel de protección, por lo que sería una buena idea comprar una membrana de plástico transparente y flexible que se adapta sobre las teclas y las protege de la suciedad, del polvo y de los líquidos.</p><p>Esto es irrelevante en oficinas, pues se supone que se limpia todos los días, pero es un factor muy importante en las industrias o almacenes.</p><h3 id="Golpes-y-Vibraciones"><a href="#Golpes-y-Vibraciones" class="headerlink" title="Golpes y Vibraciones"></a>Golpes y Vibraciones</h3><p>Los ordenadores son bastante resistentes, pero hay un límite al que ellos pueden resistir. Las vibraciones constantes pueden ser la causa de que los chips se salgan de sus zócalos y de que los conectores se aflojen.</p><p>Los golpes y los impactos repentinos pueden ser dañinos, sobre todo para los discos duros, que son especialmente vulnerables. Si se mueve un disco duro o se produce una vibración mientras está funcionando, se pueden producir serios daños y pérdida de datos. También hay que asegurarse que el ordenador no se instala en un lugar fácilmente desplazable.</p><p>Si hay que instalar un PC donde los choques y las vibraciones son inevitables, sería conveniente disponer de una máquina especial, resistente a dichos golpes.</p><h3 id="Electricidad-Estatica"><a href="#Electricidad-Estatica" class="headerlink" title="Electricidad Estática"></a>Electricidad Estática</h3><p>Al moverse por una habitación, se genera una carga eléctrica cuya cantidad depende de varios factores: de las ropas que se tengan puestas, del tipo de cobertura del suelo, del nivel de humedad de la atmósfera y de la conductividad de los zapatos.</p><p>Cuando se está cargado eléctricamente y se toca algo conectado a tierra seguramente se recibirá una descarga eléctrica. Estas descargas eléctricas son inofensivas para el individuo. Sin embargo, pueden ser la causa de un deterioro de la memoria del ordenador, para el micro o para la placa base (comúnmente se denomina quemar la memoria, el micro y la placa).</p><p>Los generadores de electricidad estática son:</p><ul><li>La piel humana.</li><li>El vidrio.</li><li>El nylon.</li><li>La lana.</li><li>El pelo.</li><li>El plomo.</li><li>La seda.</li><li>El aluminio.</li><li>El algodón.</li><li>El acero.</li><li>El poliéster.</li><li>El teflón.</li></ul><p>Se pueden utilizar pulverizadores antiestáticos para las alfombras y reducir la generación de electricidad estática. También, se pueden colocar felpudos antiestáticos, conectados a tierra, debajo del ordenador y de las sillas. Esto impedirá que se genere electricidad estática al moverse mientras trabaja en el ordenador. En climas secos será necesario un humidificador.</p><p>La electricidad estática puede ser un serio problema para los empleados de servicio técnico y para todos aquellos que trabajan en ordenadores abiertos ya que al tocar un componente electrónico, puede quedar inutilizado fácilmente. Se puede evitar esto trabajando con pulseras antiestáticas conectadas a tierra a través del chasis del equipo, pero, a veces, es posible que no se pueda evitar ni usándolos.</p><p>A continuación se dan una serie de indicaciones para eliminar el riesgo de dañar los componentes con descargas de electricidad estática:</p><ul><li>Tocar la caja del ordenador, o cualquier otra cosa que esté conectada a tierra, antes de tocar una placa del circuito o cualquier otra parte de la máquina. Esto dará la seguridad de que la electricidad estática se descarga inofensivamente a tierra.</li><li>Evitar tocar los componentes electrónicos o los conectores laterales cuando se proceda a instalar, quitar o configurar placas del circuito.</li><li>No tocar los pines de los módulos de memoria cuando se hagan ampliaciones.</li><li>Las placas, tarjetas y memorias se deben de colocar en un embalaje antiestático.</li><li>Utilizar calzado deportivo por ser un buen aislante.</li></ul><h3 id="Problemas-relacionados-con-la-corriente"><a href="#Problemas-relacionados-con-la-corriente" class="headerlink" title="Problemas relacionados con la corriente"></a>Problemas relacionados con la corriente</h3><p>Los ordenadores están diseñados para funcionar con salidas normales de corriente, sin embargo, la calidad del voltaje de la línea de corriente alterna puede variar en momentos puntuales e incluso en algunos lugares, el suministro puede ser tan poco fiable como para impedir al ordenador funcionar correctamente.</p><p>Los ordenadores mainframes son tan complejos que un leve fallo podría hacer caer a todo el sistema, destruyendo el trabajo de cientos de usuarios. En estos sistemas se emplean circuitos especiales de filtro para proteger el hardware de los efectos de las pequeñas fluctuaciones de la línea de voltaje.</p><p>Los ordenadores personales son mucho más tolerantes con las irregularidades de la corriente. Sin embargo, si la calidad del suministro es pobre, también se producirán problemas.</p><p>Hay dos tipos principales de perturbaciones que se pueden dar en cualquier edificio y por cualquier motivo que son: los picos de alto voltaje y las fluctuaciones de la línea de corriente.</p><p><strong>Picos de Voltaje</strong></p><p>Los picos de voltaje pueden causar el deterioro de la memoria y la caída del sistema. Ocurren con frecuencia cuando aparatos como los aires acondicionados, los calentadores y cafeteras se conectan y desconectan. Otros elementos del equipo de una oficina, que consumen mucha corriente, como los radiadores, son también culpables de estas perturbaciones.</p><p>Cuando un dispositivo se conecta y desconecta, en vez de un incremento o disminución de la corriente a través de los cables, lo que se produce es una oscilación amortiguada de alta frecuencia.</p><p>La oscilación es lo que comúnmente se llama <em>pico</em> . Algunas veces, ese pico no se elimina en los circuitos de filtro de la fuente de alimentación y aparece en las líneas de voltaje que alimentan los circuitos electrónicos de un PC, pudiendo causar deterioros en la memoria y la caída del sistema. Los picos pueden ser tan grandes como para causar el fallo de los componentes de la fuente de alimentación, e incluso llegar a afectar al micro y a la placa.</p><p>Las fluctuaciones de voltaje, producidas por la conexión y desconexión de elementos del equipo, están presentes en cualquier línea eléctrica. Las condiciones que determinan si estas fluctuaciones son suficientemente fuertes como para hacer que el equipo funcione mal, son complejas y difíciles de analizar. Sin embargo, los pisos superiores de los edificios altos son particularmente propensos a ello.</p><p><strong>Fluctuaciones de la Línea de Corriente</strong></p><p>La fuente de alimentación de un ordenador está diseñada para funcionar a un cierto voltaje nominal de entrada. Las diseñadas para usarse en Estados Unidos y Canadá tienen una entrada de 110 V de corriente alterna, mientras que para la mayor parte de Europa, la entrada estándar es de 240 V de corriente alterna. Otros países usan 220 V de corriente alterna.</p><p>Cuando se compre cualquier componente para el equipo (incluida la fuente de alimentación) hay que asegurarse de que están diseñadas para ser utilizadas en España y que han sido fabricados para adaptarse a las normas de seguridad eléctricas.</p><p>La pérdida de corriente puede causar mayores inconvenientes, de tal forma que, aunque dure menos de un segundo, puede hacer que el ordenador vuelva a arrancar, con lo que se perderían todos los cambios que hayan hecho desde la última vez que se salvó el trabajo. Los archivos que no fueron cerrados correctamente, pueden hacer estragos en el sistema de archivos de la mayor parte de los SO, produciendo la pérdida de sectores y otros problemas.</p><p>Para tratar los problemas de la línea de corriente se pueden tomar tres opciones:</p><ul><li>Se puede comprar un enchufe protector especial de onda en almacenes de componentes electrónicos o de ordenadores, que ofrecen protección limitada contra picos de corriente.</li><li>Comprar un rectificador de corriente. su tamaño es como el de una caja de zapatos y se conecta al enchufe de la pared, teniendo, a su vez, dos o tres salidas. Se componen de circuitos que filtran la corriente y eliminan tanto los picos como los ruidos.</li><li>Adquirir un sistema de alimentación continua o ininterrumpida SAI (UPS, Uninterrumpible Power Supply). Esta fuente, al igual que el rectificador, se conecta entre el enchufe de la pared y el ordenador. Durante el funcionamiento normal, la corriente alterna pasa por ella y por algún filtro que lleve incluido. La UPS tiene unas baterías que se cargan continuamente con el voltaje de la línea. También contienen componentes electrónicos llamados inversores que convierten el bajo voltaje de la salida de la batería en alto voltaje de corriente alterna. cuando la UPS detecta una rápida caída de voltaje, un relé se conecta sobre el circuito inversor que comienza a generar un voltaje de corriente alterna. Dependiendo del consumo de corriente y de la capacidad de las baterías de la UPS, un PC puede seguir funcionando desde unos minutos hasta hora y media. Esto permite al usuario salvar su trabajo y preparar ordenadamente una salida del sistema si la corriente no se restablece. Las UPS se pueden encontrar en una amplia gama de tipos y tamaños. Algunos más baratos generan una onda cuadrada de salida, en lugar de la senoidal de la corriente de la red. Esto es aceptable para alimentar las fuentes de alimentación conmutadas que usan los ordenadores, pero no en otros equipos.</li></ul><h3 id="Deterioro"><a href="#Deterioro" class="headerlink" title="Deterioro"></a>Deterioro</h3><p>Los ordenadores, como cualquier componente electrónico se deterioran con el paso del tiempo. Sin embargo, el modo en que se use, también afectará a la mayor o menor probabilidad de que ocurran fallos.</p><p>Por ejemplo aunque no parezca cierto, el hecho de encender y apagar el equipo en intervalos de tiempo cortos hará que se deteriore antes.</p><p>Si se quiere alargar la vida del PC, se debe conectar y desconectar tan espaciadamente como sea posible.</p><p>Si se deja el ordenador conectado durante mucho tiempo, sin usarlo, el CRT puede sufrir daños, ya que, al estar presentando la misma imagen de forma continuada, se puede quemar el revestimiento de fósforo de la pantalla; para solucionar este problema se puede coger el hábito de habilitar el salvador de pantallas o simplemente apagar el monitor cuando uno se ausenta durante un espacio prolongado de tiempo.</p><p>Los mayores problemas pueden venir por descuidar y abusar del equipo. Hay varias reglas básicas de buen comportamiento que se deben de conocer que son:</p><ul><li>Evitar fumar o comer mientras se está trabajando con el ordenador, ya que esto puede conducir a que la ceniza y las migajas se introduzcan en el teclado, pudiendo atascar las teclas.</li><li>Mantener los disquetes aislados del polvo y de la suciedad, almacenándolos, metidos en sus fundas, cuando no se usan.</li><li>Manejar los disquetes cuidadosamente, sin tocar la superficie de grabación. Esto ayudará a preservar los datos ya que el polvo y la grasa no se introduzcan dentro de mecanismo de la unidad.</li><li>No se debe ser brusco en el manejo del ordenador. Para introducir un disquete en la unidad, sólo es necesario presionar suavemente con la punta de los dedos. También se debe mover el cierre de la unidad con delicadeza.</li><li>No se deben machacar las teclas como si se tratara de una vieja máquina de escribir.</li><li>Evitar presionar los cables. cuando se intente desconectar una regleta, se debe tirar del enchufe y no de los cables.</li></ul><h2 id="Mantenimiento-Correctivo-y-Perfectivo"><a href="#Mantenimiento-Correctivo-y-Perfectivo" class="headerlink" title="Mantenimiento Correctivo y Perfectivo"></a>Mantenimiento Correctivo y Perfectivo</h2><p>El mantenimiento correctivo consiste en la reparación de alguno de los componentes del ordenador, que abarcan desde una soldadura pequeña, el cambo total de una tarjeta (sonido, video, memoria), o el cambio total de algún dispositivo periférico como el ratón, teclado, monitor, disco duro, etc.</p><p>El mantenimiento perfectivo consiste en la ampliación de algún componente del equipo para aumentar su capacidad en base a una serie de requerimientos, por ejemplo, ampliar la capacidad del disco duro con uno nuevo, aumentar un módulo de memoria, etc.</p><p>En ambos tipos de mantenimiento habrá que abrir el equipo y sustituir una pieza o simplemente añadir una pieza, por eso en los siguientes aparatados se va a ver cuales son las piezas más importantes de un ordenador y como realizar su sustitución o como insertar una nueva pieza en el mismo.</p><p>Los componentes físicos de un ordenador que se pueden cambiar o ampliar son los siguientes:</p><ul><li>Placas Base.</li><li>Micro.</li><li>Memoria.</li><li>Disco duro, lectores de CD, CD-RW, DVD, etc.</li><li>Disqueteras.</li></ul><h3 id="Abriendo-la-Caja-del-Equipo"><a href="#Abriendo-la-Caja-del-Equipo" class="headerlink" title="Abriendo la Caja del Equipo"></a>Abriendo la Caja del Equipo</h3><p>Se abrirá la caja del ordenador para limpiarle el polvo o sustituir o ampliar algún componente.</p><p>Para abrir la caja será necesario un destornillador plano, de estrella o de Torx.</p><p>Existen cajas que ni siquiera tienen tornillos sino que se abren pulsando alguna lengüeta y desplazando los laterales. También es posible encontrar cajas que llevan candados con lo cual antes habrá que abrir el candado con la llave respectiva.</p><p>Cuando se habla de formatos de cajas hay que tener en cuenta dos aspectos básicos. Por una parte el formato exterior, que determina su tamaño, estilo, … Y por otra parte los formatos basados en especificaciones técnicas, que determinarán la futura distribución de los componentes internos.</p><ul><li>Formatos “técnicos”: Va a determinar el formado de la placa base del PC. Los elementos que más se van a ver influenciados por el formato de la caja son la placa base y la fuente de alimentación. A continuación se detallan cuales son estos formatos:<ul><li>XT: Es el formato de los primeros PC’s. Surge en 1981 con el IBM PC. Se caracterizaban por la existencia de grandes interruptores en su parte posterior y su gran tamaño y peso.</li><li>AT: También diseñado por IBM, surge en 1984. Similar al formato anterior, pero con grandes diferencias en el interior de la caja que determinaba otra colocación de la placa. Tenía aspecto de torre y no era compatible con el anterior. En años posteriores fueron apareciendo formatos que apenas diferían de éste, como Baby AT que presentaba unas dimensiones menor y consecuentemente menos coste.</li><li>ATX: Surge en 1995 y supone un gran cambio con respecto a sus predecesores. Sobre todo en el formato de la fuente de alimentación (que permite diferentes voltajes) y en que son mucho más fáciles de ampliar.</li><li>NLX: Formato reciente que tiene por objetivo reducir el tamaño.</li></ul></li><li>Aspecto:<ul><li>Mini-Torre:<ul><li>2 bahías 5 ¼</li><li>2 bahías 3 1/5</li><li>FA: 200 W</li></ul></li><li>Midi-Torre:<ul><li>3 bahías 5 ¼</li><li>2 habías 3 1/5 (poseen itnernas)</li><li>FA: 250-300W</li></ul></li><li>Torre</li><li>Gran-Torre</li><li>Semi-Torre</li><li>Server</li><li>Mini-ITX</li></ul></li></ul><p>Pasos a dar:</p><ul><li>Desconectar el cable de alimentación del PC ya que no llega con tener apagado el equipo.</li><li>Descargarse de la electricidad estática.</li><li>Localizar los tornillos o buscar las lengüetas y quitarlos.</li><li>Desplazar los laterales de la carcasa para tener acceso al interior</li></ul><h3 id="Placas-Base"><a href="#Placas-Base" class="headerlink" title="Placas Base"></a>Placas Base</h3><p>Para colocar la placa en la caja del equipo hace falta el siguiente material:</p><ul><li>Placa</li><li>Tornillos</li><li>arpones</li><li>Herramientas:<ul><li>Destornillador</li><li>Brazalete antiestático</li><li>Cutter</li></ul></li></ul><p>Antes de insertar la placa en la caja hay que realizar el siguiente trabajo previo:</p><ul><li>Anclar los buses a la placa antes de instalarla, además del procesador y la memoria, ya que si la caja es pequeña, o incomoda de trabajar, más tarde será más difícil.</li><li>Antes de colocar la placa será necesario colocar la fuente de alimentación, si bien actualmente la mayor parte de las cajas ya traen la fuente de alimentación colocada de “fábrica”.</li><li>Configurar los Jumpers ajustando el voltaje adecuado, la frecuencia de reloj del bus principal y el multiplicador.</li></ul><p>A la hora de colocar la placa en la caja hay que seguir los siguientes consejos:</p><ul><li>Evitar que la placa contacte con cualquier parte metálica de la caja. Para ello se deben de utilizar los arpones suministrados con la placa.</li><li>Si la caja no dispusiera de bahías para poder enganchar los arpones, se cortará el enganche de éstos con un cutter.</li><li>Para evitar que la placa toque la superficie metálica de la caja también se puede recurrir a un truco muy viejo que consiste en utilizar la esponja en la que viene embalada.</li><li>Si el procesador alcanza temperaturas muy altas habrá que recortar la superficie de esponja que se aloje debajo del microprocesador ya que se podrá llegar a quemar.</li><li>Al atornillas los tornillos hay que cerciorarse de que la placa está bien anclada pero sin pasarse. La circuitería es muy delicada.</li></ul><p>El siguiente paso es colocar los conectores de la fuente de alimentación en la placa. Para realizar esto hay que tener en cuenta que existen dos tipos de placa (que coincide con los tipos de caja):</p><ul><li>Placas AT: Para este tipo de placas de las fuentes de alimentación salen dos conectores hembras del mismo tamaño y para enchufarlos en los conectores machos de la placa hay que saber que los cables negros tienen que ir en el medio. De esta forma sólo un sentido es válido.</li></ul><p><img src="https://gsitic.files.wordpress.com/2018/03/conector_placa_at.png?w=825" alt=""></p><ul><li>Placas ATX: El conector sólo encaja perfectamente en un sentido.</li></ul><p><img src="https://gsitic.files.wordpress.com/2018/03/conector_placa_atx.png?w=825" alt=""></p><p>Lo último que queda por realizar es conectar los LEDs luminosos y el altavoz, estos son los cables que vienen incluidos en la caja. Habrá que enchufar los cables de la placa etiquetados con el led correspondiente a la toma correspondiente de la placa.</p><p>Para realizar la correcta conexión hay que:</p><ul><li>Contar con el manual de la placa.</li><li>En caso de no tenerlo, mirar las inscripciones de la placa.</li><li>Si esto no funciona queda el método de “prueba-error”.</li></ul><h3 id="El-Procesador"><a href="#El-Procesador" class="headerlink" title="El Procesador"></a>El Procesador</h3><p>Técnicamente resulta imposible realizar un mantenimiento correctivo del procesador, por la imposibilidad de contar con las herramientas necesarias, como mucho se puede realizar una sustitución de un procesador por otro.</p><p>Realizar un mantenimiento perfectivo del procesador consiste en sustituir un procesador por otro más avanzado siempre y cuando la placa base lo soporte.</p><p>Hay que tener en cuenta que se distinguen distintos tipos de procesadores, aparte de por su fabricante y por su velocidad por el tipos de conexión. Según esta, se distinguen los siguientes:</p><ul><li><strong>ZIF</strong> : Zero Insertion Force. Para encajar el microprocesador en la placa no hace falta hacer fuerza, simplemente basca con levantar una palanca del zócalo en la placa base, colocar el procesador encima y bajar la palanca. Es necesario decir que estos procesadores traen los pines alrededor de la carcasa de tal forma que estos fines encajan en el zócalo. En los micros los pines no se cierran en un cuadrado perfecto, sino que dejan unas esquinas que indican por qué lado encajar el micro en el zócalo.</li></ul><p>Vista de un micro</p><p><img src="https://gsitic.files.wordpress.com/2018/03/micro_zif.png?w=825" alt=""></p><p>Ejemplos de estos micros son:</p><ul><li>Socket 7: Pentium</li><li>Socket 8: Pentium Pro de Intel</li><li>Socket 370 o PPGA: Pentium III más modernos y Pentium celerón más modernos</li><li>Socket 462/Socket A: Procesadores AMD Athlon, Duron, Thunderbird, XP y MP</li><li>Socket 423 y 478: Pentium IV de Intel</li></ul><p>Zócalo donde se inserta el micro</p><p><img src="https://gsitic.files.wordpress.com/2018/03/zocalo_zif.png?w=825" alt=""></p><p>Inserción del micro en el zócalo</p><p><img src="https://gsitic.files.wordpress.com/2018/03/insercion_zif.png?w=825" alt=""></p><ul><li><strong>SEC</strong> : En estos zócalos los micros se insertan como si fueran unos cartuchos y ya hay que hacer fuerza para que encaje el micro en su zócalo.<ul><li>Slot 1: Pentium II</li><li>Slot II: Pentium III</li><li>Slot A: Athlon</li></ul></li></ul><p>Procesador SEC</p><p><img src="https://gsitic.files.wordpress.com/2018/03/procesador_sec.png?w=825" alt=""></p><ul><li><strong>No ZIF</strong> : Antiguos zócalos donde se insertaban procesadores 486 y anteriores.</li><li><strong>Soldados</strong> : Antiguamente algunos procesadores estaban soldados a su placa base.</li></ul><p>Una vez colocado el micro es necesario colocarle el disipador para evitar que se queme.</p><p>Antes de realizar este paso a la superficie del micro hay que echarle “pasta térmica” que elimina los huecos que quedan entre el disipador y el micro, consiguiendo una correcta refrigeración.</p><p>El ventilador suele necesitar alimentación, que la suele proporcionar la placa a través de unos conectores etiquetados generalmente con “CPU FAN”, que será donde hay que colocar el enchufe del disipador.</p><h3 id="Disquetera"><a href="#Disquetera" class="headerlink" title="Disquetera"></a>Disquetera</h3><p>La disquetera se suele estropear con más frecuencia de la necesaria debido al exceso de polvo que suele acumular. Para evitar hacer un mantenimiento correctivo o perfectivo basta con realizar un mantenimiento preventivo previo.</p><p>La disquetera se conecta a la placa a través de un bus de datos que conecta la placa con la disquetera. El conector donde se enganchan los buses de datos de la disquetera a la placa se denomina FDC: Floppy Disk Controler o FDD: Floppy Disk Drive y está situado al lado de los conectores IDE’s.</p><p>A continuación se exponen los pasos a seguir para realizar un mantenimiento perfectivo (añadir una nueva disquetera) o correctivo (sustituir la disquetera).</p><ul><li>Localizar la bahía de la caja correspondiente 3 ¼.</li><li>Insertar la disquetera.</li><li>Atornillarla en la bahía.</li><li>Colocar Bus de Datos:<ul><li>Si solo hay una disquetera, insertar el extremo del cable que contiene una doblez a la disquetera y el otro extremo del bus al conector FDC o FDD de la placa.</li><li>Si hay ya una disquetera colocar el conector que no tiene la doblez y que está más próximo a ésta en la segunda disquetera y el otro extremo del bus al conector FDC o FDD de la placa.<ul><li>La disquetera que tiene la doblez actuaría como maestra.</li><li>La disquetera que no tiene la doblez actuaría como esclava.</li></ul></li></ul></li><li>Enchufar la disquetera a la fuente de alimentación utilizando el conector pequeño de la misma.</li></ul><h3 id="Conectar-un-dispositivo-IDE-Integrated-Drive-Electronic"><a href="#Conectar-un-dispositivo-IDE-Integrated-Drive-Electronic" class="headerlink" title="Conectar un dispositivo IDE (Integrated Drive Electronic)"></a>Conectar un dispositivo IDE (Integrated Drive Electronic)</h3><p>Las interfaces IDE es un estándar que define la interfaz para conectar periféricos como discos duros, cd-rom, cdrw, etc, a la placa.</p><p>EIDE (Enhanced): soporta 4 dispositivos conectados, si bien coloquialmente se le sigue llamando por el nombre IDE.</p><p>Una placa base convencional suele tener 2 canales IDE: el primario y el secundario. En la placa base se distinguen porque aparecen impresas las letras: IDE1 (primario) e IDE2 (secundario).</p><p>A cada canal se pueden conectar dos dispositivos:</p><ul><li>Primario (Maestro). El maestro es el primero de los dos y se suele situar al final del cable. Tiene preferencia sobre el esclavo a la hora de transmitir datos.</li><li>Secundario (Esclavo). El esclavo es el segundo, normalmente conectado en el centro del cable entre el maestro y la controladora.</li></ul><p>Si tenemos en cuenta el hecho de que en una placa base hay 2 canales IDE y que cada canal soporta 2 dispositivos, podemos tener en total 4 dispositivos.</p><p>Los dispositivos (discos duros, CD-ROM, DVD-ROM, etc) tienen unos “puentes” llamados jumpers, situados generalmente en la parte posterior o inferior de los mismos, que permiten seleccionar su carácter de maestro, esclavo. Las posiciones de los jumpers vienen indicadas en una calcomanía en la superficie del disco, o bien en el manual o serigrafiadas en la placa de circuito del disco rígido, con las letras _M_ para designar “maestro” y _S_ para designar “esclavo”.</p><p>La distribución “estándar” en un PC para un rendimiento óptimo es la siguiente:</p><ul><li>Canal o Puerto IDE 1:<ul><li>Maestro: Disco Duro principal (Contiene el SO).</li><li>Esclavo: lector de CD-ROM/DVD.</li></ul></li><li>Canal o Puerto IDE 2:<ul><li>Maestro: Grabadora de CD/DVD.</li><li>Esclavo: Segundo Disco Duro, unidad magneto óptica, …</li></ul></li></ul><p>Los pasos para montar un dispositivo IDE son los siguientes:</p><ul><li>Localizar la bahía de la caja correspondiente: 3¼ para discos duros y 5½ para lectores de CD, DVD, etc.</li><li>Insertar el dispositivo.</li><li>Atornillarla en la bahía.</li><li>Colocar el Bus de Datos.</li><li>Si el dispositivo está solo en el IDE, configurarlo como maestro.</li><li>Si no está, solo se siguen las recomendaciones anteriores.</li><li>En cuanto al Bus de Datos, se observará que uno de los extremos tiene un color rojo o rosa, este hilo tiene que encajarse con la pata del dispositivo donde está serigrafiado un 1 que suele ser el de la derecha del conector macho del dispositivo.</li><li>Solo queda conectarle el cable de alimentación.</li></ul><h3 id="Memoria"><a href="#Memoria" class="headerlink" title="Memoria"></a>Memoria</h3><p>Este es el componente que con más frecuencia se necesita mantener, no porque se estropee, sino porque se necesita ampliar debido a las necesidades de las aplicaciones y SO actuales.</p><p>Cuanta más memoria se pueda insertar es mejor.</p><p><strong>Formatos</strong></p><p>La memoria RAM del PC, en cualquiera de sus tipos, es físicamente un módulo o pastilla (placa de circuito impreso que agrupa varios chips de memoria) que se acaba insertando en los zócalos correspondientes de la placa. Estos módulos pueden tener diferentes formatos que a continuación se describen.</p><ul><li><strong>DIPS (Cápsula Dual en Línea, Dual Inline Package)</strong> . Totalmente desaparecido. Sólo mencionar que en los primeros PC’s se conectaba los DIPS en zócalos libres de la placa base.</li><li><strong>SIMM (Módulo de Memoria Simple, Single Inline Memory Module)</strong> . Pequeña placa de circuito impreso que almacena chips de memoria solo por un lado de la placa, y se inserta en un zócalo SIMM en la placa madre. El primer formato tenía 30 contactos. Un formato más largo en centímetros, que usa 72 contactos y puede almacenar hasta 64MB de RAM, se popularizó con los procesadores Pentium. Las memorias en este formato presentaban la restricción de tener que instalarse siempre por pares de la misma capacidad. Es decir, para conseguir 16MB, eran necesarios 2 SIMM’s de 8MB o 4 SIMM’s de 4MB. Esta restricción venía impuesta porque estos módulos permitían almacenar 32 bits por ciclo, y los procesadores Pentium utilizaban un bus externo de 64 bits.</li><li><strong>DIMM (Módulo de Memoria Dual, Dual Inline Memory Module)</strong> . Pequeña placa de circuito impreso que almacena chips de memoria por ambos lados de la placa, y que se inserta en un zócalo DIMM.<ul><li>Existen 2 tipos de módulos DIMM:<ul><li>SDR SDRAM: 168 contactos.</li><li>DDR SDRAM: 184 pines.</li></ul></li></ul></li><li><strong>RIMM (Rambus Inline Memory Module)</strong> . Pequeña placa de circuito impreso que almacena chips de memoria por ambos lados de la placa y disponen de disipadores de calor. Tienen 184 pines.</li></ul><p><strong>Colocando la Memoria SIMM</strong></p><p>Para ampliar la memoria SIMM hay que tener en cuenta que es necesario insertar pares de módulos debiendo ser los módulos iguales en velocidad y tamaño.</p><p>Para poder ampliar memoria de este tipo, es preciso tener, al menos, 2 zócalos libres en la placa.</p><p>Los pasos a dar son los siguientes:</p><ul><li>Descargarse de la electricidad estática.</li><li>Orientar y presentar el módulo de forma correcta sobre el zócalo de la placa.<ul><li>Los contactos de los módulos están numerados del 1 al 30 o 72, dependiendo del tipo de módulo.</li><li>Solo es posible una orientación del módulo en la placa ya que en la base, el conector nº 1 del zócalo tiene una pequeña rebaba que imposibilita insertar mal el módulo.</li></ul></li><li>Para poder insertar el módulo hay que inclinarlo 45º una vez que éste está sobre el zócalo.</li><li>Posteriormente se levanta el extremo superior sin sacarlo de la ranura hasta que quede perpendicular a la placa.</li></ul><p>Para extraer la memoria SIMM hay que presionar las lengüetas de los extremos de los zócalos hacia el exterior.</p><p><strong>Colocando la Memoria DIMM</strong></p><p>Estos son los módulos de 168 contactos (SDRAM) y 184 contactos (DDR, RAMBUS).</p><p>No presentan los inconvenientes de los SIMM:</p><ul><li>Se pueden insertar módulos de diferente capacidad.</li><li>No es necesario colocar los módulos por pares.</li></ul><p>Sí es conveniente tener los módulos de la misma velocidad.</p><p>Los pasos a dar son los siguientes:</p><ul><li>Localizar los zócalos en la placa sobre los que se insertarán los módulos de memoria. Tener en cuenta que algunas placas soportan los dos tipos de módulos: SDRAM y DDR.</li><li>Orientar y presentar el módulo de forma correcta sobre el zócalo de la placa. Para ello observar que en la parte de los pines, la placa de memoria tiene unos huecos (2 para el caso de SDRAM y uno para DDR) que determinan la posición exacta.<ul><li>Es conveniente comenzar a insertar módulos de memoria por el primer zócalo del primer banco, aunque no es estrictamente necesario.</li></ul></li><li>Para anclar el módulo sobre la ranura, hay que presionar suavemente sobre el módulo una vez que esté correctamente situado.<ul><li>Estará bien colocado cuando se escuche un pequeño clic.</li></ul></li></ul><h2 id="Bibliografia"><a href="#Bibliografia" class="headerlink" title="Bibliografia"></a>Bibliografia</h2><ul><li><a href="https://es.scribd.com/document/357351182/TICB3-Mantenimiento-de-Equipos" rel="external nofollow noopener noreferrer" target="_blank">Scribd (Ibiza Ales)</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Practicas-de-mantenimiento-de-equipos-e-instalaciones-Tipos-de-mantenimiento-Monitorizacion-y-gestion-de-capacidad&quot;&gt;&lt;a href=&quot;#Practi
      
    
    </summary>
    
      <category term="B4" scheme="http://localhost:4000/categories/B4/"/>
    
    
  </entry>
  
  <entry>
    <title>B2-T14</title>
    <link href="http://localhost:4000/wiki/B2/b2-t15/"/>
    <id>http://localhost:4000/wiki/B2/b2-t15/</id>
    <published>2019-01-16T15:11:23.000Z</published>
    <updated>2019-01-18T10:45:16.601Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Tecnicas-de-evaluacion-de-alternativas-y-analisis-de-viabilidad-Personal-procedimientos-datos-software-hardware-Presupuestacion-y-control-de-costes-de-un-proyecto-informatico"><a href="#Tecnicas-de-evaluacion-de-alternativas-y-analisis-de-viabilidad-Personal-procedimientos-datos-software-hardware-Presupuestacion-y-control-de-costes-de-un-proyecto-informatico" class="headerlink" title="Técnicas de evaluación de alternativas y análisis de viabilidad. Personal, procedimientos, datos, software, hardware. Presupuestación y control de costes de un proyecto informático."></a>Técnicas de evaluación de alternativas y análisis de viabilidad. Personal, procedimientos, datos, software, hardware. Presupuestación y control de costes de un proyecto informático.</h1><h2 id="Introduccion"><a href="#Introduccion" class="headerlink" title="Introducción"></a>Introducción</h2><p>Mientras que el Plan de Sistemas de Información tiene como objetivo proporcionar un marco estratégico que sirva de referencia para los Sistemas de Información de un ámbito concreto de una organización, el objetivo del Estudio de Viabilidad del Sistema es el análisis de un conjunto concreto de necesidades para proponer una solución a corto plazo, que tenga en cuenta restricciones económicas, técnicas, legales y operativas. La solución obtenida como resultado del estudio puede ser la definición de uno o varios proyectos que afecten a uno o varios sistemas de información ya existentes o nuevos. Para ello, se identifican los requisitos que se ha de satisfacer y se estudia, si procede, la situación actual.</p><p>A partir del estado inicial, la situación actual y los requisitos planteados, se estudian las alternativas de solución. Dichas alternativas pueden incluir soluciones que impliquen desarrollos a medida, soluciones basadas en la adquisición de productos software del mercado o soluciones mixtas. Se describe cada una de las alternativas, indicando los requisitos que cubre.</p><p>Una vez descritas cada una de las alternativas planteadas, se valora el impacto en la organización, la inversión a realizar en cada caso y los riesgos asociados. Esta información se analiza con el fin de evaluar las distintas alternativas y seleccionar la más adecuada, definiendo y estableciendo su planificación.</p><h2 id="Analisis-de-Viabilidad"><a href="#Analisis-de-Viabilidad" class="headerlink" title="Análisis de Viabilidad"></a>Análisis de Viabilidad</h2><p>El propósito de este proceso es analizar un conjunto concreto de necesidades, con la idea de proponer una solución a corto plazo. Los criterios con los que se hace esta propuesta no serán estratégicos sino tácticos y relacionados con aspectos económicos, técnicos, legales y operativos.</p><p>Los resultados del Estudio de Viabilidad del Sistema constituirán la base para tomar la decisión de seguir adelante o abandonar. Si se decide seguir adelante pueden surgir uno o varios proyectos que afecten a uno o varios sistemas de información. Dichos sistemas se desarrollarán según el resultado obtenido en el estudio de viabilidad y teniendo en cuenta la cartera de proyectos para la estrategia de implantación del sistema global.</p><p>Se ha considerado que este proceso es obligatorio, aunque el nivel de profundidad con el que se lleve a cabo dependerá de cada caso. La conveniencia de la realización del estudio de la situación actual depende del valor añadido previsto para la especificación de requisitos y para el planteamiento de alternativas de solución. En las alternativas se considerarán soluciones “a medida”, soluciones basadas en la adquisición de productos software del mercado o soluciones mixtas.</p><p>Para valorar las alternativas planteadas y determinar una única solución, se estudiará el impacto en la organización de cada una de ellas, la inversión y los riesgos asociados.</p><p>El resultado final de este proceso son los productos relacionados con la solución que se propone para cubrir la necesidad concreta que se planteó en el proceso, y depende de si la solución conlleva desarrollo a medida o no:</p><ul><li>Contexto del sistema (con la definición de las interfaces en función de la solución).</li><li>Impacto en la organización.</li><li>Coste / beneficio de la solución.</li><li>Valoración de riesgos de la solución.</li><li>Enfoque del plan de trabajo de la solución.</li><li>Planificación de la solución.</li></ul><p>Solución propuesta:</p><ul><li>Descripción de la solución.</li><li>Modelo de descomposición en subsistemas.</li><li>Matriz de procesos / localización geográfica.</li><li>Matriz de datos / localización geográfica. Entorno tecnológico y comunicaciones.</li><li>Estrategia de implantación global del sistema.</li><li>Descripción de los procesos manuales.</li></ul><p>Si la alternativa incluye desarrollo:</p><ul><li>Modelo abstracto de datos / modelo de procesos.</li><li>Modelo de negocio / modelo de dominio.</li></ul><p>Si la alternativa incluye un producto software estándar de mercado:</p><ul><li>Descripción del producto.</li><li>Evolución del producto.</li><li>Costes ocasionados por el producto.</li><li>Estándares del producto.</li><li>Descripción de adaptación si es necesaria.</li></ul><p>Si en la organización se ha realizado con anterioridad un Plan de Sistemas de Información que afecte al sistema objeto de este estudio, se dispondrá de un conjunto de productos que proporcionarán información a tener en cuenta en todo el proceso.</p><p>Las actividades que engloba este proceso se recogen en la siguiente figura, en la que se indican las actividades que pueden ejecutarse en paralelo y las que precisan para su realización resultados originados en actividades anteriores.</p><p><img src="https://gsitic.files.wordpress.com/2018/01/evs1.png?w=825" alt=""></p><h3 id="Actividad-EVS-1-Establecimiento-del-alcance-del-sistema"><a href="#Actividad-EVS-1-Establecimiento-del-alcance-del-sistema" class="headerlink" title="Actividad EVS 1: Establecimiento del alcance del sistema"></a>Actividad EVS 1: Establecimiento del alcance del sistema</h3><p>En esta actividad se estudia el alcance de la necesidad planteada por el cliente o usuario, o como consecuencia de la realización de un PSI, realizando una descripción general de la misma. Se determinan los objetivos, se inicia el estudio de los requisitos y se identifican las unidades organizativas afectadas estableciendo su estructura.</p><p>Se analizan las posibles restricciones, tanto generales como específicas, que puedan condicionar el estudio y la planificación de las alternativas de solución que se propongan.</p><p>Si la justificación económica es obvia, el riesgo técnico bajo, se esperan pocos problemas legales y no existe ninguna alternativa razonable, no es necesario profundizar en el estudio de viabilidad del sistema, analizando posibles alternativas y realizando una valoración y evaluación de las mismas, sino que éste se orientará a la especificación de requisitos, descripción del nuevo sistema y planificación.</p><p>Se detalla la composición del equipo de trabajo necesario para este proceso y su planificación. Finalmente, con el fin de facilitar la implicación activa de los usuarios en la definición del sistema, se identifican sus perfiles, dejando claras sus tareas y responsabilidades.</p><p><img src="https://gsitic.files.wordpress.com/2018/01/tabla_evs.png?w=825" alt=""></p><p><strong>Tarea EVS 1.1: Estudio de la solicitud</strong></p><p>Se realiza una descripción general de la necesidad planteada por el usuario, y se estudian las posibles restricciones de carácter económico, técnico, operativo y legal que puedan afectar al sistema. Antes de iniciar el estudio de los requisitos del sistema se establecen los objetivos generales del Estudio de Viabilidad, teniendo en cuenta las restricciones identificadas anteriormente.</p><p>Si el sistema objeto de estudio se encuentra en el ámbito de un Plan de Sistemas de Información vigente, se debe tomar como referencia el catálogo de requisitos y la arquitectura de información resultante del mismo, como información adicional para la descripción general del sistema y determinación de los requisitos iniciales.</p><p><strong>Productos</strong></p><ul><li>De entrada<ul><li>Catálogo de Requisitos del PSI (PSI 9.2)</li><li>Arquitectura de Información (PSI 9.2)</li><li>Solicitud (externo)</li></ul></li><li>De salida<ul><li>Descripción General del Sistema</li><li>Catálogo de Objetivos del EVS</li><li>Catálogo de Requisitos</li></ul></li></ul><p><strong>Prácticas</strong></p><ul><li>Catalogación</li><li>Sesiones de trabajo</li></ul><p><strong>Participantes</strong></p><ul><li>Comité de Dirección</li><li>Jefe de Proyecto</li><li>Analistas</li></ul><p><strong>Tarea EVS 1.2: Identificación del alcance del sistema</strong></p><p>Se analiza el alcance de la necesidad planteada y se identifican las restricciones relativas a la sincronización con otros proyectos, que puedan interferir en la planificación y futura puesta a punto del sistema objeto del estudio. Esta información se recoge en el catálogo de requisitos.</p><p>Si el sistema pertenece al ámbito de un Plan de Sistemas de Información, se debe tener en cuenta la arquitectura de información propuesta para analizar el alcance del sistema e identificar los sistemas de información que quedan fuera del ámbito del estudio. Además, se estudia el plan de proyectos, para determinar las posibles dependencias con otros proyectos.</p><p>Una vez establecido el alcance, se identifican las unidades organizativas afectadas por el sistema, así como su estructura y responsables de las mismas. Para determinar los responsables se tiene en cuenta a quiénes afecta directamente y quiénes pueden influir en el éxito o fracaso del mismo.</p><p><strong>Productos</strong></p><ul><li>De entrada<ul><li>Plan de Proyectos (PSI 9.2)</li><li>Arquitectura de Información (PSI 9.2)</li><li>Descripción General del Sistema (EVS 1.1)</li><li>Catálogo de Objetivos del EVS (EVS 1.1)</li><li>Catálogo de Requisitos (EVS 1.1)</li></ul></li><li>De salida<ul><li>Descripción General del Sistema:<ul><li>Contexto del Sistema</li><li>Estructura Organizativa</li></ul></li><li>Catálogo de Requisitos:<ul><li>Requisitos Relativos a Restricciones o Dependencias con Otros Proyectos</li></ul></li><li>Catálogo de Usuarios</li></ul></li></ul><p><strong>Técnicas</strong></p><ul><li>Diagrama de Flujo de Datos</li><li>Diagrama de Descomposición Funcional</li></ul><p><strong>Prácticas</strong></p><ul><li>Catalogación</li><li>Sesiones de trabajo</li></ul><p><strong>Participantes</strong></p><ul><li>Comité de Dirección</li><li>Jefe de Proyecto</li><li>Analistas</li></ul><p><strong>Tarea EVS 1.3: Especificación del alcance del EVS</strong></p><p>En función del alcance del sistema y los objetivos del Estudio de Viabilidad del Sistema, se determinan las actividades y tareas a realizar. En particular, hay que decidir si se realiza o no el estudio de la situación actual y, en el caso de considerarlo necesario, con qué objetivo. Si el sistema pertenece al ámbito de un Plan de Sistemas de Información, los criterios que pueden orientar sobre la necesidad de llevar a cabo el estudio de la situación actual dependen de la arquitectura de información propuesta, en cuanto a la identificación de los sistemas de información actuales, implicados en el ámbito de este estudio, que se haya decidido conservar.</p><p>Se identifican los usuarios participantes de las distintas unidades organizativas afectadas para la realización del Estudio de Viabilidad del Sistema, determinando previamente sus perfiles y responsabilidades.</p><p>Debe comunicarse el plan de trabajo a los usuarios identificados como implicados en el Estudio de Viabilidad, solicitando su aceptación y esperando su confirmación.</p><p><strong>Productos</strong></p><ul><li>De entrada<ul><li>Arquitectura de Información (PSI 9.2)</li><li>Catálogo de Objetivos del EVS (EVS 1.1)</li><li>Descripción General del Sistema (EVS 1.2)</li><li>Catálogo de Usuarios (EVS 1.2)</li></ul></li><li>De salida<ul><li>Catálogo de Objetivos del EVS:<ul><li>Objetivos del Estudio de la Situación Actual</li></ul></li><li>Catálogo de Usuarios</li><li>Plan de Trabajo</li></ul></li></ul><p><strong>Prácticas</strong></p><ul><li>Catalogación</li><li>Sesiones de trabajo</li></ul><p><strong>Participantes</strong></p><ul><li>Comité de Dirección</li><li>Jefe de Proyecto</li><li>Analistas</li></ul><h3 id="Actividad-EVS-2-Estudio-de-la-situacion-actual"><a href="#Actividad-EVS-2-Estudio-de-la-situacion-actual" class="headerlink" title="Actividad EVS 2: Estudio de la situación actual"></a>Actividad EVS 2: Estudio de la situación actual</h3><p>La situación actual es el estado en el que se encuentran los sistemas de información existentes en el momento en el que se inicia su estudio. Teniendo en cuenta el objetivo del estudio de la situación actual, se realiza una valoración de la información existente acerca de los sistemas de información afectados. En función de dicha valoración, se especifica el nivel de detalle con que se debe llevar a cabo el estudio. Si es necesario, se constituye un equipo de trabajo específico para su realización y se identifican los usuarios participantes en el mismo.</p><p>Si se decide documentar la situación actual, normalmente es conveniente dividir el sistema actual en subsistemas. Si es posible se describirá cada uno de los subsistemas, valorando qué información puede ser relevante para la descripción.</p><p>Como resultado de esta actividad se genera un diagnóstico, estimando la eficiencia de los sistemas de información existentes e identificando los posibles problemas y las mejoras.</p><p><img src="https://gsitic.files.wordpress.com/2018/01/evs21.png?w=825" alt=""></p><p><strong>Tarea EVS 2.1: Valoración del estudio de la situación actual</strong></p><p>En función de los objetivos establecidos para el estudio de la situación actual, y considerando el contexto del sistema especializado en la descripción general del mismo, se identifican los sistemas de información existentes que es necesario analizar con el fin de determinar el alcance del sistema actual. Asimismo, se decide el nivel de detalle con el que se va a llevar a cabo el estudio de cada uno de los sistemas de información implicados. En el caso de haber realizado un Plan de Sistemas de Información que afecte a dicho sistema, se toma como punto de partida para este análisis la arquitectura de información propuesta.</p><p>Para poder abordar el estudio, se realiza previamente una valoración de la información existente acerca de los sistemas de información afectados por el EVS. Se debe decidir si se realizan o no los modelos lógicos del sistema actual o si se describe el modelo físico, en función de los siguientes criterios:</p><ul><li>Si existen los modelos lógicos, y son fiables, se utilizan en la tarea Descripción de los Sistemas de Información Existentes (EVS 2.3).</li><li>Si no existen dichos modelos, o no son fiables, se considera el tiempo de vida estimado para el sistema de información en función de la antigüedad, la obsolescencia de la tecnología o la falta de adecuación funcional para determinar si se obtienen los modelos lógicos y físicos del sistema actual o por el contrario no se elabora ningún modelo.</li></ul><p>La información relativa a los sistemas de información que se decida analizar, se obtiene mediante sesiones de trabajo con los Directores de Usuarios y el apoyo de los profesionales de Sistemas y Tecnologías de la Información y Comunicaciones (STIC) que se considere necesario.</p><p><strong>Productos</strong></p><ul><li>De entrada<ul><li>Información Existente del Sistema Actual (externo)</li><li>Arquitectura de Información (PSI 9.2)</li><li>Catálogo de Objetivos del EVS (EVS 1.3)</li><li>Descripción General del Sistema (EVS 1.2)</li></ul></li><li>De salida<ul><li>Descripción de la Situación Actual:<ul><li>Contexto del Sistema Actual</li><li>Descripción de los Sistemas de Información Actuales</li></ul></li></ul></li></ul><p><strong>Técnicas</strong></p><ul><li>Diagrama de Flujo de Datos</li></ul><p><strong>Prácticas</strong></p><ul><li>Diagrama de Representación</li><li>Sesiones de Trabajo</li></ul><p><strong>Participantes</strong></p><ul><li>Jefe de Proyecto</li><li>Analistas</li><li>Directores de Usuarios</li></ul><p><strong>Tarea EVS 2.2: Identificación de usuarios participantes en el estudio de la situación actual</strong></p><p>En función del nivel de detalle establecido para el estudio de la situación actual, se identifican los usuarios participantes de cada una de las unidades organizativas afectadas por dicho estudio. Se informa a los usuarios implicados en el Estudio de la Situación Actual, se solicita su aceptación y se espera su confirmación.</p><p><strong>Productos</strong></p><ul><li>De entrada<ul><li>Descripción General del Sistema (EVS 1.2)</li><li>Catálogo de Usuarios (EVS 1.3)</li><li>Descripción de la Situación Actual (EVS 2.1)</li></ul></li><li>De salida<ul><li>Catálogo de Usuarios</li></ul></li></ul><p><strong>Prácticas</strong></p><ul><li>Catalogación</li><li>Sesiones de Trabajo</li></ul><p><strong>Participantes</strong></p><ul><li>Jefe de Proyecto</li><li>Directores de Usuarios</li></ul><p><strong>Tarea EVS 2.3: Descripción de los sistemas de información existentes</strong></p><p>En esta tarea se describen los sistemas de información existentes afectados, según el alcance y nivel de detalle establecido en la tarea Valoración del Estudio de la Situación Actual (EVS 2.1), mediante sesiones de trabajo con los usuarios designados para este estudio.</p><p>Si se ha decidido describir los sistemas a nivel lógico, y si existe un conocimiento suficiente de los sistemas de información a especificar, puede hacerse directamente, aplicando las técnicas de modelización y siguiendo un método descendente. Si no se dispone del conocimiento suficiente, se construyen los modelos a partir de la descripción del modelo físico, es decir, de forma ascendente.</p><p>Si se tiene que describir el modelo físico, se puede hacer mediante un Diagrama de Representación en el que se recojan todos los componentes físicos y sus referencias cruzadas. Otra opción es describir el modelo físico de forma más detallada, para lo que es necesaria la utilización de herramientas de tipo scanner.</p><p>Es conveniente indicar la localización geográfica y física actual de los módulos y datos de los sistemas de información afectados, evaluando al mismo tiempo la redundancia en las distintas unidades organizativas.</p><p><strong>Productos</strong></p><ul><li>De entrada<ul><li>Descripción de la Situación Actual (EVS 2.1)</li><li>Catálogo de Usuarios (EVS 2.2)</li></ul></li><li>De salida<ul><li>Descripción de la Situación Actual:<ul><li>Descripción Lógica del Sistema Actual</li><li>Modelo Físico del Sistema Actual (opcional)</li><li>Matriz de Localización Geográfica y Física de Módulos y Datos, incluidas las redundancias</li></ul></li></ul></li></ul><p><strong>Técnicas</strong></p><ul><li>Diagrama de Flujo de Datos</li><li>Modelo Entidad / Relación extendido</li><li>Diagrama de Clases</li><li>Diagrama de Interacción de Objetos</li><li>Matricial</li></ul><p><strong>Prácticas</strong></p><ul><li>Diagrama de Representación</li><li>Sesiones de Trabajo</li></ul><p><strong>Participantes</strong></p><ul><li>Analistas</li><li>Usuarios Expertos</li><li>Equipo de Soporte Técnico</li></ul><p><strong>Tarea EVS 2.4: Realización del diagnóstico de la situación actual</strong></p><p>Con el fin de elaborar el diagnóstico de la situación actual se analiza la información de los sistemas de información existentes, obtenida en la tarea anterior y se identifican problemas, deficiencias y mejoras. Estas últimas deben tenerse en cuenta en la definición de los requisitos.</p><p>En el caso de haber realizado un Plan de Sistemas de Información, se considera la valoración realizada sobre los sistemas de información actuales que pertenecen al ámbito de este estudio.</p><p>Si se ha tomado la decisión de no describir la situación actual, se realiza un diagnóstico global justificando esta decisión</p><p><strong>Productos</strong></p><ul><li>De entrada<ul><li>Descripción de la Situación Actual (EVS 2.3)</li><li>Catálogo de Objetivos del EVS (EVS 1.3)</li><li>Valoración de la Situación actual (EVS 5.3)</li></ul></li><li>De salida<ul><li>Descripción de la Situación Actual:<ul><li>Diagnóstico de Situación Actual</li></ul></li></ul></li></ul><p><strong>Participantes</strong></p><ul><li>Analistas</li><li>Responsable de Mantenimiento</li></ul><h3 id="Actividad-EVS-3-Definicion-de-requisitos-del-sistema"><a href="#Actividad-EVS-3-Definicion-de-requisitos-del-sistema" class="headerlink" title="Actividad EVS 3: Definición de requisitos del sistema"></a>Actividad EVS 3: Definición de requisitos del sistema</h3><p>Esta actividad incluye la determinación de los requisitos generales, mediante una serie de sesiones de trabajo con los usuarios participantes, que hay que planificar y realizar. Una vez finalizadas, se analiza la información obtenida definiendo los requisitos y sus prioridades, que se añaden al catálogo de requisitos que servirá para el estudio y valoración de las distintas alternativas de solución que se propongan.</p><p><img src="https://gsitic.files.wordpress.com/2018/01/evs3.png?w=825" alt=""></p><p><strong>Tarea EVS 3.1: Identificación de las directrices técnicas y de gestión</strong></p><p>La realización de esta tarea permite considerar los términos de referencia para el sistema en estudio desde el punto de vista de directrices tanto técnicas como de gestión. Si el sistema en estudio pertenece al ámbito de un Plan de Sistemas de Información vigente, éste proporciona un marco de referencia a considerar en esta tarea.</p><p>Con este fin, se recoge información sobre los estándares y procedimientos que deben considerarse al proponer una solución, relativos a:</p><ul><li>Políticas técnicas:<ul><li>Gestión de Proyectos (seguimiento, revisión y aprobación final).</li><li>Desarrollo de Sistemas (existencia de normativas, metodologías y técnicas de programación).</li><li>Arquitectura de Sistemas (centralizada, distribuida).</li></ul></li><li>Política de Seguridad (control de accesos, integridad de datos, disponibilidad de aplicaciones).</li><li>Directrices de Planificación.</li><li>Directrices de Gestión de Cambios.</li><li>Directrices de Gestión de Calidad.</li></ul><p><strong>Productos</strong></p><ul><li>De entrada<ul><li>Catálogo de Normas del PSI (PSI 3.2)</li><li>Recopilación de Directrices Técnicas y de Gestión (externo)</li></ul></li><li>De salida<ul><li>Catálogo de Normas</li></ul></li></ul><p><strong>Prácticas</strong></p><ul><li>Catalogación</li></ul><p><strong>Participantes</strong></p><ul><li>Jefe de Proyecto</li><li>Analistas</li><li>Usuarios Expertos</li></ul><p><strong>Tarea EVS 3.2: Identificación de Requisitos</strong></p><p>Para la obtención de las necesidades que ha de cubrir el sistema en estudio, se debe decidir qué tipo de sesiones de trabajo se realizarán y con qué frecuencia tendrán lugar, en función de la disponibilidad de los usuarios participantes.</p><p>Si se ha realizado el Estudio de la Situación Actual (EVS 2), puede ser conveniente seleccionar la información de los sistemas de información existentes que resulte de interés para el desarrollo de dichas sesiones de trabajo.</p><p>Una vez establecidos los puntos anteriores, se planifican las sesiones de trabajo con los usuarios participantes identificados al estudiar el alcance del Estudio de Viabilidad del Sistema (EVS 1.3), y se realizan de acuerdo al plan previsto. La información obtenida depende del tipo de sesión de trabajo seleccionado.</p><p><strong>Productos</strong></p><ul><li>De entrada<ul><li>Descripción General del Sistema (EVS 1.2)</li><li>Catálogo de Requisitos (EVS 1.2)</li><li>Equipo de Trabajo del EVS (EVS 1.3)</li><li>Catálogo de Usuarios (EVS 2.2/1.3)</li><li>Descripción de la Situación Actual (EVS 2.4)</li></ul></li><li>De salida<ul><li>Identificación de Requisitos</li></ul></li></ul><p><strong>Prácticas</strong></p><ul><li>Sesiones de Trabajo</li></ul><p><strong>Participantes</strong></p><ul><li>Jefe de Proyecto</li><li>Analistas</li><li>Usuarios Expertos</li></ul><p><strong>Tarea EVS 3.3: Catalogación de Requisitos</strong></p><p>Se analiza la información obtenida en las sesiones de trabajo para la Identificación de Requisitos, definiendo y catalogando los requisitos (funcionales y no funcionales) que debe satisfacer el sistema, indicando sus prioridades.</p><p>Se incluirán también requisitos relativos a distribución geográfica y entorno tecnológico.</p><p><strong>Productos</strong></p><ul><li>De entrada<ul><li>Identificación de Requisitos (EVS 3.2)</li><li>Catálogo de Requisitos (EVS 1.2)</li></ul></li><li>De salida<ul><li>Catálogo de Requisitos</li></ul></li></ul><p><strong>Prácticas</strong></p><ul><li>Catalogación</li></ul><p><strong>Participantes</strong></p><ul><li>Jefe de Proyecto</li><li>Analistas</li><li>Usuarios Expertos</li></ul><h3 id="Actividad-EVS-4-Estudio-de-alternativas-de-solucion"><a href="#Actividad-EVS-4-Estudio-de-alternativas-de-solucion" class="headerlink" title="Actividad EVS 4: Estudio de alternativas de solución"></a>Actividad EVS 4: Estudio de alternativas de solución</h3><p>Este estudio se centra en proponer diversas alternativas que respondan satisfactoriamente a los requisitos planteados, considerando también los resultados obtenidos en el Estudio de la Situación Actual (EVS 2), en el caso de que se haya realizado.</p><p>Teniendo en cuenta el ámbito y funcionalidad que debe cubrir el sistema, puede ser conveniente realizar, previamente a la definición de cada alternativa, una descomposición del sistema en subsistemas.</p><p>En la descripción de las distintas alternativas de solución propuestas, se debe especificar si alguna de ellas está basada, total o parcialmente, en un producto existente en el mercado. Si la alternativa incluye un desarrollo a medida, se debe incorporar en la descripción de la misma un modelo abstracto de datos y un modelo de procesos, y en orientación a objetos, un modelo de negocio y un modelo de dominio.</p><p><img src="https://gsitic.files.wordpress.com/2018/01/evs4.png?w=825" alt=""></p><p><strong>Tarea EVS 4.1: Preselección de Alternativas de Solución</strong></p><p>Una vez definidos los requisitos a cubrir por el sistema, se estudian las diferentes opciones que hay para configurar la solución. Entre ellas, hay que considerar la adquisición de productos software estándar del mercado, desarrollos a medida o soluciones mixtas.</p><p>Dependiendo del alcance del sistema y las posibles opciones, puede ser conveniente realizar inicialmente una descomposición del sistema en subsistemas. Se establecen las posibles alternativas sobre las que se va a centrar el estudio de la solución, combinando las opciones que se consideren más adecuadas.</p><p><strong>Productos</strong></p><ul><li>De entrada<ul><li>Información de Productos Software del Mercado (externo)</li><li>Descripción General del Sistema (EVS 1.2)</li><li>Descripción de la Situación Actual (EVS 2.4)</li><li>Catálogo de Requisitos (EVS 3.3)</li></ul></li><li>De salida<ul><li>Descomposición Inicial del Sistema en Subsistemas (opcional)</li><li>Alternativas de Solución a Estudiar</li></ul></li></ul><p><strong>Prácticas</strong></p><ul><li>Diagrama de Representación</li></ul><p><strong>Participantes</strong></p><ul><li>Jefe de Proyecto</li><li>Analistas</li><li>Técnicos de Sistemas</li></ul><p><strong>Tarea EVS 4.2: Descripción de las Alternativas de Solución</strong></p><p>Para cada alternativa propuesta, se identifican los subsistemas que cubre y los requisitos a los que se da respuesta. Se deben considerar también aspectos relativos a la cobertura geográfica (ámbito y limitaciones) de procesos y datos, teniendo en cuenta a su vez la gestión de comunicaciones y control de red.</p><p>En la definición de cada alternativa, se propone una estrategia de implantación teniendo en cuenta tanto la cobertura global del sistema como la cobertura geográfica. Si la alternativa incluye desarrollo se describe el modelo abstracto de datos y el modelo de procesos, y en el caso de Orientación a Objetos, el modelo de negocio y, opcionalmente, el modelo de dominio. Se propone el entorno tecnológico que se considera más apropiado para la parte del sistema basada en desarrollo y se describen los procesos manuales.</p><p>Si la alternativa incluye una solución basada en producto se analiza su evolución prevista, adaptabilidad y portabilidad, así como los costes ocasionados por licencias, y los estándares del producto. Igualmente se valora y determina su entorno tecnológico.</p><p><strong>Productos</strong></p><ul><li>De entrada<ul><li>Descripción General del Sistema (EVS 1.2)</li><li>Descripción de la Situación Actual (EVS 2.4)</li><li>Catálogo de Requisitos (EVS 3.3)</li><li>Descomposición Inicial del Sistema en Subsistemas (EVS 4.1) (opcional)</li><li>Alternativas de Solución a Estudiar (EVS 4.1)</li></ul></li><li>De salida<ul><li>Catálogo de Requisitos (actualizado)</li><li>Alternativas de Solución a Estudiar:<ul><li>Catálogo de Requisitos (cobertura)</li><li>Modelo de Descomposición en Subsistemas</li><li>Matriz Procesos / Localización Geográfica</li><li>Matriz Datos / Localización Geográfica</li><li>Entorno Tecnológico y Comunicaciones</li><li>Estrategia de Implantación Global del Sistema</li><li>Descripción de Procesos Manuales</li></ul></li><li>Si la alternativa incluye desarrollo:<ul><li>Modelo Abstracto de Datos / Modelo de Procesos</li><li>Modelo de Negocio / Modelo de Dominio (en caso de Orientación a Objetos)</li></ul></li><li>Si la alternativa incluye un producto software estándar de mercado:<ul><li>Descripción del Producto</li><li>Evolución del Producto</li><li>Costes Ocasionados por Producto</li><li>Estándares del Producto</li><li>Descripción de Adaptación (si es necesaria)</li></ul></li></ul></li></ul><p><strong>Técnicas</strong></p><ul><li>Matricial</li><li>Diagrama de Flujo de Datos</li><li>Modelo Entidad / Relación extendido</li><li>Diagrama de Clases</li><li>Casos de Uso</li></ul><p><strong>Prácticas</strong></p><ul><li>Catalogación</li><li>Diagrama de Representación</li></ul><p><strong>Participantes</strong></p><ul><li>Jefe de Proyecto</li><li>Analistas</li><li>Usuarios Expertos</li><li>Técnicos de Sistemas</li><li>Responsable de Seguridad</li><li>Especialistas en Comunicaciones</li></ul><h3 id="Actividad-EVS-5-Valoracion-de-la-alternativas"><a href="#Actividad-EVS-5-Valoracion-de-la-alternativas" class="headerlink" title="Actividad EVS 5: Valoración de la alternativas"></a>Actividad EVS 5: Valoración de la alternativas</h3><p>Una vez descritas las alternativas se realiza una valoración de las mismas, considerando el impacto en la organización, tanto desde el punto de vista tecnológico y organizativo como de operación, y los posibles beneficios que se esperan contrastados con los costes asociados. Se realiza también un análisis de los riesgos, decidiendo cómo enfocar el plan de acción para minimizar los mismos y cuantificando los recursos y plazos precisos para planificar cada alternativa.</p><p><img src="https://gsitic.files.wordpress.com/2018/01/evs5.png?w=825" alt=""></p><p><strong>Tarea EVS 5.1: Estudio de la Inversión</strong></p><p>Para cada alternativa de solución propuesta, se valora el impacto y se establece su viabilidad económica. Para ello, se realiza un análisis coste/beneficio que determina los costes del sistema y los pondera con los beneficios tangibles, cuantificables directamente, y con los beneficios intangibles, buscando el modo de cuantificarlos.</p><p><strong>Productos</strong></p><ul><li>De entrada<ul><li>Alternativas de Solución a Estudiar (EVS 4.2)</li></ul></li><li>De salida<ul><li>Valoración de Alternativas:<ul><li>Impacto en la Organización de Alternativas</li><li>Coste / beneficio de Alternativas</li></ul></li></ul></li></ul><p><strong>Técnicas</strong></p><ul><li>Análisis Coste / Beneficio</li></ul><p><strong>Participantes</strong></p><ul><li>Jefe de Proyecto</li><li>Analistas</li></ul><p><strong>Tarea EVS 5.2: Estudio de los Riesgos</strong></p><p>Para cada alternativa se seleccionan los factores de situación que habrá que considerar, relativos tanto a la incertidumbre como a la complejidad del sistema. Se identifican y valoran los riesgos asociados y se determinan las medidas a tomar para minimizarlos.</p><p><strong>Productos</strong></p><ul><li>De entrada<ul><li>Alternativas de Solución a Estudiar (EVS 4.2)</li><li>Valoración de Alternativas (EVS 5.1)</li></ul></li><li>De salida<ul><li>Valoración de Alternativas:<ul><li>Valoración de Riesgos</li></ul></li></ul></li></ul><p><strong>Prácticas</strong></p><ul><li>Impacto en la Organización</li></ul><p><strong>Participantes</strong></p><ul><li>Jefe de Proyecto</li><li>Analistas</li></ul><p><strong>Tarea EVS 5.3: Planificación de Alternativas</strong></p><p>En función del análisis de riesgos realizado en la tarea anterior, y para cada una de las alternativas existentes:</p><ul><li>Se determina el enfoque más adecuado para llevar a buen fin la solución propuesta en cada alternativa.</li><li>Se realiza una planificación, teniendo en cuenta los puntos de sincronismo con otros proyectos en desarrollo o que esté previsto desarrollar, según se ha recogido en el catálogo de requisitos.</li></ul><p>De esta manera se garantiza el cumplimiento del plan de trabajo en los restantes procesos del ciclo de vida.</p><p><strong>Productos</strong></p><ul><li>De entrada<ul><li>Catálogo de Requisitos (EVS 4.2)</li><li>Alternativas de Solución a Estudiar (EVS 4.2)</li><li>Valoración de Alternativas (EVS 5.2)</li></ul></li><li>De salida<ul><li>Plan de Trabajo de Cada Alternativa:<ul><li>Enfoque del Plan de Trabajo de Cada Alternativa</li><li>Planificación de Cada Alternativa</li></ul></li></ul></li></ul><p><strong>Técnicas</strong></p><ul><li>Planificación</li></ul><p><strong>Participantes</strong></p><ul><li>Jefe de Proyecto</li><li>Analistas</li></ul><h3 id="Actividad-EVS-6-Seleccion-de-la-solucion"><a href="#Actividad-EVS-6-Seleccion-de-la-solucion" class="headerlink" title="Actividad EVS 6: Selección de la solución"></a>Actividad EVS 6: Selección de la solución</h3><p>Antes de finalizar el Estudio de Viabilidad del Sistema, se convoca al Comité de Dirección para la presentación de las distintas alternativas de solución, resultantes de la actividad anterior. En dicha presentación, se debaten las ventajas de cada una de ellas, incorporando las modificaciones que se consideren oportunas, con el fin de seleccionar la más adecuada. Finalmente, se aprueba la solución o se determina su inviabilidad.</p><p><img src="https://gsitic.files.wordpress.com/2018/01/evs6.png?w=825" alt=""></p><p><strong>Tarea EVS 6.1: Convocatoria de la Presentación</strong></p><p>Se efectúa la convocatoria de la presentación de las distintas alternativas propuestas, adjuntando los productos de la actividad anterior con el fin de que el Comité de Dirección pueda estudiar previamente su contenido. Se espera confirmación por parte del Comité de Dirección de las alternativas a presentar.</p><p><strong>Productos</strong></p><ul><li>De entrada<ul><li>Catálogo de Usuarios (EVS 2.2/1.3)</li><li>Alternativas de Solución a Estudiar (EVS 4.2)</li><li>Valoración de Alternativas (EVS 5.2)</li><li>Plan de Trabajo de Cada Alternativa (EVS 5.3)</li></ul></li><li>De salida<ul><li>Plan de Presentación de Alternativas</li></ul></li></ul><p><strong>Prácticas</strong></p><ul><li>Presentación</li></ul><p><strong>Participantes</strong></p><ul><li>Jefe de Proyecto</li></ul><p><strong>Tarea EVS 6.2: Evaluación de las Alternativas y Selección</strong></p><p>Una vez recibida la confirmación de qué alternativas van a ser presentadas para su valoración, se efectúa su presentación al Comité de Dirección, debatiendo sobre las ventajas e inconvenientes de cada una de ellas y realizando las modificaciones que sugiera dicho Comité, hasta la selección de la solución final.</p><p><strong>Productos</strong></p><ul><li>De entrada<ul><li>Descripción General del Sistema (Contexto del Sistema) (EVS 1.2)</li><li>Catálogo de Requisitos (EVS 4.2)</li><li>Alternativas de Solución a Estudiar (EVS 4.2)</li><li>Valoración de Alternativas (EVS 5.2)</li><li>Plan de Trabajo de Cada Alternativa (EVS 5.3)</li><li>Plan de Presentación de Alternativas (EVS 6.1)</li></ul></li><li>De salida<ul><li>Plan de Presentación de Alternativas</li><li>Catálogo de Requisitos (Actualizado en Función de la Cobertura de la Solución)</li><li>Solución Propuesta:<ul><li>Descripción de la Solución:<ul><li>Modelo de Descomposición en Subsistemas</li><li>Matriz Procesos / Localización Geográfica</li><li>Matriz Datos / Localización Geográfica</li><li>Entorno Tecnológico y Comunicaciones</li><li>Estrategia de Implantación Global del Sistema</li><li>Descripción de Procesos Manuales</li></ul></li></ul></li><li>Si la alternativa incluye desarrollo:<ul><li>Modelo Abstracto de Datos / Modelo de Procesos</li><li>Modelo de Negocio / Modelo de Dominio</li></ul></li><li>Si la alternativa incluye un producto software estándar del mercado:<ul><li>Descripción del Producto</li><li>Evolución del Producto</li><li>Costes Ocasionados por Producto</li><li>Estándares del Producto</li><li>Descripción de Adaptación (si es necesaria)</li><li>Contexto del Sistema (con la Definición de las Interfaces en Función de la Solución)</li><li>Impacto en la Organización de la Solución</li><li>Coste / Beneficio de la Solución</li><li>Valoración de Riesgos de la Solución</li><li>Enfoque del Plan de Trabajo de la Solución</li><li>Planificación de la Solución</li></ul></li></ul></li></ul><p><strong>Prácticas</strong></p><ul><li>Presentación</li><li>Sesiones de Trabajo</li></ul><p><strong>Participantes</strong></p><ul><li>Comité de Dirección</li><li>Jefe de Proyecto</li><li>Analistas</li></ul><p><strong>Tarea EVS 6.3: Aprobación de la Solución</strong></p><p>El Comité de Dirección da su aprobación formal o determina la inviabilidad del sistema, por motivos económicos, de funcionalidad como resultado del incumplimiento de los requisitos identificados en plazos razonables o de cobertura de los mismos, etc.</p><p><strong>Productos</strong></p><ul><li>De entrada<ul><li>Catálogo de Requisitos (EVS 6.2)</li><li>Solución Propuesta (EVS 6.2)</li></ul></li><li>De salida<ul><li>Aprobación de la Solución</li></ul></li></ul><p><strong>Participantes</strong></p><ul><li>Comité de Dirección</li><li>Jefe de Proyecto</li></ul><h2 id="Tecnicas-de-Evaluacion-de-Alternativas"><a href="#Tecnicas-de-Evaluacion-de-Alternativas" class="headerlink" title="Técnicas de Evaluación de Alternativas"></a>Técnicas de Evaluación de Alternativas</h2><h3 id="Tecnicas-de-Analisis-Coste-Beneficio"><a href="#Tecnicas-de-Analisis-Coste-Beneficio" class="headerlink" title="Técnicas de Análisis Coste / Beneficio"></a>Técnicas de Análisis Coste / Beneficio</h3><p><strong>Objetivos</strong></p><p>La técnica de análisis coste/beneficio tiene como objetivo fundamental proporcionar una medida de los costes en que se incurre en la realización de un proyecto y comparar dichos costes previstos con los beneficios esperados de la realización de dicho proyecto.</p><p>Esta medida o estimación servirá para:</p><ul><li>Valorar la necesidad y oportunidad de acometer la realización del proyecto.</li><li>Seleccionar la alternativa más beneficiosa para la realización del proyecto.</li><li>Estimar adecuadamente los recursos económicos necesarios en el plazo de realización del proyecto.</li></ul><p>Es de destacar la necesidad cada vez mayor de guiarse por criterios económicos y no sólo técnicos para la planificación de trabajos y proyectos. Por ello se hace una primera introducción sobre las técnicas y métodos de evaluación de conceptos económicos, con el fin de proporcionar a los profesionales criterios que les ayuden en la planificación de proyectos y evaluación de alternativas.</p><p><strong>Conceptos</strong></p><p><strong>Punto de amortización (Break-Even Point)</strong></p><p>Es el momento en el tiempo en que el conjunto de beneficios obtenidos por la explotación del nuevo sistema iguala al conjunto de costes de todo tipo que ha ocasionado. A partir del punto de amortización (Break-Even Point), el sistema entra en fase de aportar beneficios netos a la organización.</p><p><strong>Periodo de amortización (PayBack)</strong></p><p>Es el periodo de tiempo que transcurre desde que los costes con máximos hasta que se alcanza el punto de amortización (Break-Even Point), es decir, en cuanto el sistema empieza a aportar beneficios. Cuanto menor sea el periodo de amortización (Payback) de un Sistema, más atractivo será para la organización acometer su implantación.</p><p><strong>Retorno de Inversión – ROI (Return of Investment)</strong></p><p>Es el rendimiento de la inversión expresada en términos de procentaje. Se calcula mediante la fórmula siguiente:</p><p>ROI = 100 x (Beneficio Neto Anual - Coste Desarrollo Anualizado) / Inversión Promedio</p><p>Siendo:</p><ul><li><strong>Beneficio Neto Anual</strong> : Beneficio neto que aporta el sistema como consecuencia de su uso, es decir los beneficios obtenidos más los gastos no incurridos. Deben restársele los gastos operacionales anuales y los de mantenimiento del sistema.</li><li><strong>Coste Desarrollo Anualizado</strong> : Total del coste inicial de desarrollo del sistema, dividido por los años que se supone que va a ser operativo.</li><li><strong>Inversión Promedio</strong> : Total de la inversión realizada (costes de desarrollo, hardware, software, etc.) dividido por dos.</li></ul><p><strong>Descripción</strong></p><p>Para la realización del análisis coste/beneficio se seguirán los siguientes pasos:</p><p><strong>Producir estimaciones de costes/beneficios</strong></p><p>Se realizará una lista de todo lo que es necesario para implementar el sistema y una lista de los beneficios esperados del nuevo sistema. En un análisis de costes y beneficios se deberán considerar aquellos aspectos tangibles, es decir, medibles en valores como dinero, tiempo, etc, y no tangibles, es decir, no ponderables de una forma objetiva. En general, los costes suelen ser medibles y estimables en unidades económicas, no así en cuanto a los beneficios, los cuales pueden ser tangibles o no tangibles.</p><p>Entre los beneficios no tangibles pueden estar:</p><ul><li>El aumento de cuentas debido a un mejor servicio a los clientes.</li><li>La mejora en la toma de decisiones debido a una mejora en el soporte informático.</li></ul><p>La valoración de dichos beneficios se deberá estimar de una forma subjetiva y será realizada por las áreas correspondientes.</p><p>A menudo es conveniente dividir los costes estimados a lo largo del proyecto, para ofrecer una información más detallada de la distribución de los recursos de cara a la dirección.</p><p>En la estimación de costes se considerarán, los siguientes aspectos:</p><ul><li><strong>Adquisición de hardware y software</strong> : El que sea preciso para el desarrollo, implantación y normal funcionamiento del sistema. Se debe considerar la saturación de máquinas o sistemas actuales como consecuencia de la entrada en vigor del nuevo sistema.</li><li><strong>Gastos de mantenimiento de hardware y software</strong> anteriores.</li><li><strong>Gastos de comunicaciones</strong> : Líneas, teléfonos, correo, etc.</li><li><strong>Gastos de instalación</strong> : Cableado, acondicionamiento de sala, recursos humanos y materiales, gastos de viaje, etc.</li><li><strong>Coste de desarrollo</strong> del sistema.</li><li><strong>Gastos del mantenimiento del sistema</strong> : Coste anual.</li><li><strong>Gastos de consultoría</strong> : En caso de requerirse algún consultor externo en cualquier etapa del proyecto.</li><li><strong>Gastos de formación</strong> : De todo tipo (Desarrolladores, Operadores, Implantadores, Usuario Final, etc).</li><li><strong>Gastos de material</strong> : Papel, tóner, etc</li><li><strong>Costes derivados de la curva de aprendizaje</strong> : De todo el personal involucrado: Desarrolladores, Técnicos de Sistemas, Operadores, y desde luego, Usuarios.</li><li><strong>Costes financieros</strong> , de publicidad, etc</li></ul><p>En la estimación de beneficios se pueden considerar cuestiones como las siguientes:</p><ul><li><strong>Incremento de la productividad</strong> : Ahorro o mejor utilización de recursos humanos.</li><li><strong>Ahorro de gastos de mantenimiento</strong> del sistema actual.</li><li><strong>Ahorros de adquisición y mantenimiento de hardware y software</strong> , o reutilización de plataformas sustituidas.</li><li><strong>Incremento de ventas o resultados, disminución de costes</strong> : Producidos por una mejora de la gestión (rotación de stock “ <em>just in time</em> “, analítica de clientes, etc).</li><li><strong>Ahorro de material de todo tipo</strong> : Sustituido por datos electrónicos que proporciona el sistema, como por ejemplo: papel correo, etc.</li><li><strong>Beneficios financieros</strong> .</li><li><strong>Otros beneficios tangibles</strong> : Ahorro de recursos externos, consultoría, formación, etc.</li><li><strong>Beneficios intangibles</strong> : Incremento de la calidad del producto o servicio, mejora de la imagen de la compañía, mejora en la atención al cliente, mejora en la explotación, etc.</li></ul><p><strong>Determinar la viabilidad del proyecto y su aceptación</strong></p><p>Se basará en uno de los métodos siguientes:</p><p><em>Retorno de la inversión</em></p><p>Este método consisten en calcular el coste y el beneficio anual, conociendo el coste total al inicio del proyecto “C0”, para determinar en qué año se recupera el coste total inicialmente estimado.</p><p><img src="https://gsitic.files.wordpress.com/2018/01/retorno_inversion.png?w=825" alt=""></p><p>El año de recuperación de la inversión se produce cuando <strong>∑ Beneficio Neto = C0</strong> .</p><p><em>Valor Actual</em></p><p>Este método permite tener en cuenta que un gasto invertido durante un cierto tiempo produce un beneficio.</p><p>El método consiste en determinar el dinero que es viable invertir inicialmente para que se recupere la inversión en un periodo de tiempo definido previamente.</p><p>El resultado depende del tipo de interés (r) utilizado en la evaluación.</p><p>Se debe calcular, en primer lugar, el beneficio neto que se obtendrá cada año. Dicho beneficio no es real, ya que se debe estimar el valor real de dicha cantidad en el año n.</p><p>Para ello se aplica la fórmula:</p><p>Valor Actual = Beneficio neto / (1 + r/100)n       n = año    1,…,i</p><p>Se debe estudiar en cuántos años se recupera la inversión realizada inicialmente, o bien, si en un periodo de años fijado previamente se retorna la inversión y, por tanto, es viable el proyecto.</p><p>Si la inversión es el C0, se determinará la viabilidad del proyecto consultando la siguiente tabla:</p><p><img src="https://gsitic.files.wordpress.com/2018/01/valor_actual.png?w=825" alt=""></p><p>El proyecto será viable si <strong>∑ VAi &gt; C0</strong> a lo largo del periodo fijado.</p><h3 id="Tecnicas-basadas-en-la-teoria-de-la-decision-multicriterio-discreta"><a href="#Tecnicas-basadas-en-la-teoria-de-la-decision-multicriterio-discreta" class="headerlink" title="Técnicas basadas en la teoría de la decisión multicriterio discreta"></a>Técnicas basadas en la teoría de la decisión multicriterio discreta</h3><p>La Selección de un sistema informático, entre varias alternativas posibles, a fin de cubrir unas necesidades previas es un factor crítico de éxito de un sistema informático.</p><p>Esta tarea puede y suele ser bastante compleja en la realidad debido a múltiples razones. En primer lugar por las sutilezas técnicas de la materia, que impiden una fácil y nítida visión global del conjunto. En segundo lugar, por la dispersión y variedad de fuentes de los datos que han de constituir la información de base del problema. Por último por la dificultad de estructurar todo ello, junto con las frecuentemente diversas opiniones de expertos y directivos, de forma que pueda tomarse una decisión final.</p><p>Existen diferentes metodologías de análisis para afrontar el problema de manera más o menos cuantitativa, en un intento de hacerlo más racional y objetivo. Tradicionalmente se ha propuesto el análisis Coste-Beneficio, pero sus limitaciones son ya bien conocidas (necesidad de traducción a unidades monetarias, criterio único de evaluación), como para seguir utilizándolo.</p><p>Otra metodología muy utilizada últimamente es la denominada metodología multicriterio, que recogen la multiplicidad de aspectos y de puntos de vista que inciden en la evaluación de los sistemas que compiten por ser seleccionados. Este es el marco natural de la denominada Decisión Multicriterio Discreta (DMD).</p><p><strong>Definición de criterios</strong></p><p>El objetivo final de cualquier proceso de evaluación de bienes y/o servicios informáticos es la selección de la mejor alternativa posible escogida entre las existentes. Debe partirse de una enumeración y enunciado de las alternativas (a efectos operativos estas serán las ofertas presentadas por las empresas,los proyectos candidatos o las soluciones posibles). Las alternativas son completamente disjuntas y exhaustivas, es decir no caben en principio soluciones mixtas mezcla de otras alternativas (no obstante podemos considerar variantes dentro de la alternativa presentada por una empresa, que se introducirán en el proceso evaluativo como una oferta más). Llamaremos A, a una alternativa genérica, con una variación entre 1 y m, (i =I,M).</p><p>Por otra parte tenemos los criterios (también denominados atributos o características) que son los elementos en los que se basará el proceso de decisión, con su selección y posterior ponderación el decisor esta definiendo qué características de las alternativas le resultan importantes y en qué medida. Constituyen un conjunto discreto (C, 0=1, n). Los criterios deben ser ilustrativos de la característica que se quiera medir, cuando su número es muy grande hay que establecer un árbol de jerarquías entre ellos.</p><p>Por último tenemos las evaluaciones o puntuaciones Xi, de cada alternativa i respecto a cada criterio i, constituyendo en su conjunto la denominada matriz de decisión y que sirve para definir las alternativas en función de sus criterios. Por otro lado tenemos los pesos W, agrupados en el llamado vector de pesos (W …. W) que representa la importancia que el decisor otorga a cada criterio.</p><p><strong>Asignación de pesos</strong></p><p>Desde el punto de vista de la DMD, estimar unos pesos W, que reflejen la importancia relativa de cada criterio j para el decisor, es una cuestión bastante delicada. La naturaleza de los pesos Wi como una cuantificación de la estructura de preferencias del decisor hace necesario “extraerlos” del mismo por algún procedimiento. Esto plantea, más en unos métodos que en otros, importantes problemas ya que, como es bien conocido, las inercias psicológicas del ser humano producen peligrosos sesgos e inconsistencias.</p><p>Los principales métodos son:</p><ul><li>Método de las utilidades relativas: Partiendo de unas estimaciones provisionales, ir afinando dichas estimaciones mediante comparaciones binarias de subgrupos de criterios.</li><li>Método AHP (Analitic Hierarchy Process – Proceso Jerárquico Analítico): Comparaciones binarias de todos los criterios detallados.</li><li>Método Delphi: Es el método del consenso. Consiste en consensuar entre todos los participantes decidores.</li><li>Método de la entropía: Se utiliza cuando se quiere disminuir la subjetividad de los métodos anteriores. Determinar cual es la importancia relativa que tiene un determinado criterio. La importancia relativa se determina al estar directamente relacionada con la información intrínseca promedio generada por el conjunto de alternativas y por la asignación subjetiva que le otorgue el decisor. Información intrínseca promedio del criterio Cj es:</li></ul><p><img src="https://gsitic.files.wordpress.com/2018/01/metodo_entropia.png?w=825" alt=""></p><p><strong>Puntuación de las ofertas</strong></p><p>Una vez puntuadas los criterios de las diferentes alternativas, se hace preciso en muchos métodos (como el de ponderación lineal) el trasladar las puntuaciones brutas otorgadas a una escala normalizada por dos motivos fundamentales:</p><ul><li>Como estamos manejando un espacio multivariable hay que homogeneizar las puntuaciones para su comparación: esto es, considerarlas todas sobre la misma escala.</li><li>Es razonable trabajar con escalas de dimensión suficientemente pequeña para simplificación de cálculos.</li></ul><p>Con la normalización buscamos que las evaluaciones m de cada alternativa i correspondientes a un cierto criterio j sean comparables con las correspondientes a otros criterios. Llamaremos (Xj… Xi… Xm) al vector de puntuaciones de todas las alternativas sobre un criterio, el cual queremos transformar a uno normalizado (Yj, Yi, Ym).</p><p>Los métodos de normalización más utilizados son los siguientes:</p><ul><li>Se otorga un cero a la mínima puntuación y un 1 a la máxima y el resto de las puntuaciones proporcionales a su valor en ese rango que es muy amplio. <img src="https://gsitic.files.wordpress.com/2018/01/puntuacion_oferta1.png?w=825" alt=""></li><li>La alternativa con valor máximo alcanza el 1 en esta escala, pero la mínima no alcanza el cero si ella misma no es cero. Este método es el más utilizado. <img src="https://gsitic.files.wordpress.com/2018/01/puntuacion_oferta2.png?w=825" alt=""></li><li>Este método mantiene la proporcionalidad pre y postnormalización: <img src="https://gsitic.files.wordpress.com/2018/01/puntuacion_oferta3.png?w=825" alt=""></li></ul><p><strong>Selección de las alternativas</strong></p><ul><li>Lexicográfico: Considerar el criterio de mayor peso y elegir aquella alternativa que para ese criterio tenga mayor puntuación. Si hay igualdad se toma el siguiente criterio en peso y así sucesivamente. Es un método sencillo, teniendo además la ventaja de no requerir comparabilidad intercriterios, un inconveniente es que no utiliza toda la información disponible.</li><li>Prometheè (pertenece al conjunto de métodos “relaciones de superación”): Ignora la cuantía de la diferencia sólo señala si existe o no, y al trabajar con los pesos de los criterios, considera si esa diferencia se ha hallado en un Criterio más o menos importante para el decisor.</li><li>Concordancia: comparaciones binarias de las alternativas, como información del decisor exigen tan sólo un preorden en las evaluaciones por cada criterio, y unos pesos en escala cardinal o incluso ordinal en algunas variantes. El procedimiento esencial de todos ellos gira alrededor de construir un coeficiente de concordancia cik para cada par de alternativas i,k. Dicho cik suele definirse como la suma de pesos de los criterios en que la alternativa i es superior a la k más la mitad de los pesos en los que ambas sean consideradas iguales.</li><li>Permutación: La idea básica es la de comparar cada permutación posible de las alternativas, considerada como una ordenación de las mismas, con la información (ordinal) que aporta para cada criterio la matriz de decisión. Para cada permutación se calcula un llamado índice de evaluación, atendiendo a lo bien que concuerda con la información que proporcionan los datos, y aquella permutación que lo tenga máximo es la elegida. Entre sus ventajas figuran su flexibilidad cara al decisor (método cualitativo), y entre sus inconvenientes el que su dificultad de cálculo crece con m.</li><li>Ponderación lineal (pertenece al conjunto de métodos “utilidad multiatributo”): consiste en calcular cual es el valor de cada alternativa y se elige la que tenga mayor valor. Para calcular el valor se emplea la fórmula: V(Ai) = ∑ XijWj. El problema fundamental es una buena estimación de los pesos. Necesita normalización previa de las puntuaciones. Entre sus ventajas podemos citar las siguientes: Procesa bien los fenómenos económicos, ya que suelen ser lineales, es un método muy intuitivo (el decisor lo comprende bien, ha demostrado su utilidad en otros contextos de decisión financieros, comerciales) y es el primer método para implantar en organizaciones poco tecnificadas. En cuanto a sus inconvenientes deben citarse: El ser de relativa facilidad en su manipulación vía pesos o vía evaluaciones, tener un enfoque absolutamente compensatorio lo que tiende a favorecer a las alternativas que son medianías y los resultados no son significativos sin una cuidadosa elección de escalas de medida de las evaluaciones.</li></ul><h2 id="Bibliografia"><a href="#Bibliografia" class="headerlink" title="Bibliografía"></a>Bibliografía</h2><ul><li><a href="https://es.scribd.com/document/357349218/TICB2-Tecnicas-de-Evaluacion-de-Alternativas" rel="external nofollow noopener noreferrer" target="_blank">Scribd (Ibiza Ales)</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Tecnicas-de-evaluacion-de-alternativas-y-analisis-de-viabilidad-Personal-procedimientos-datos-software-hardware-Presupuestacion-y-co
      
    
    </summary>
    
      <category term="B2" scheme="http://localhost:4000/categories/B2/"/>
    
    
  </entry>
  
</feed>
